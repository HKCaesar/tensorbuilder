<!doctype html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />

    <title>tensorbuilder.api.applicative API documentation</title>
    <meta name="description" content="" />

  <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300' rel='stylesheet' type='text/css'>
  
  <style type="text/css">
  
* {
  box-sizing: border-box;
}
/*! normalize.css v1.1.1 | MIT License | git.io/normalize */

/* ==========================================================================
   HTML5 display definitions
   ========================================================================== */

/**
 * Correct `block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
nav,
section,
summary {
    display: block;
}

/**
 * Correct `inline-block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

audio,
canvas,
video {
    display: inline-block;
    *display: inline;
    *zoom: 1;
}

/**
 * Prevent modern browsers from displaying `audio` without controls.
 * Remove excess height in iOS 5 devices.
 */

audio:not([controls]) {
    display: none;
    height: 0;
}

/**
 * Address styling not present in IE 7/8/9, Firefox 3, and Safari 4.
 * Known issue: no IE 6 support.
 */

[hidden] {
    display: none;
}

/* ==========================================================================
   Base
   ========================================================================== */

/**
 * 1. Prevent system color scheme's background color being used in Firefox, IE,
 *    and Opera.
 * 2. Prevent system color scheme's text color being used in Firefox, IE, and
 *    Opera.
 * 3. Correct text resizing oddly in IE 6/7 when body `font-size` is set using
 *    `em` units.
 * 4. Prevent iOS text size adjust after orientation change, without disabling
 *    user zoom.
 */

html {
    background: #fff; /* 1 */
    color: #000; /* 2 */
    font-size: 100%; /* 3 */
    -webkit-text-size-adjust: 100%; /* 4 */
    -ms-text-size-adjust: 100%; /* 4 */
}

/**
 * Address `font-family` inconsistency between `textarea` and other form
 * elements.
 */

html,
button,
input,
select,
textarea {
    font-family: sans-serif;
}

/**
 * Address margins handled incorrectly in IE 6/7.
 */

body {
    margin: 0;
}

/* ==========================================================================
   Links
   ========================================================================== */

/**
 * Address `outline` inconsistency between Chrome and other browsers.
 */

a:focus {
    outline: thin dotted;
}

/**
 * Improve readability when focused and also mouse hovered in all browsers.
 */

a:active,
a:hover {
    outline: 0;
}

/* ==========================================================================
   Typography
   ========================================================================== */

/**
 * Address font sizes and margins set differently in IE 6/7.
 * Address font sizes within `section` and `article` in Firefox 4+, Safari 5,
 * and Chrome.
 */

h1 {
    font-size: 2em;
    margin: 0.67em 0;
}

h2 {
    font-size: 1.5em;
    margin: 0.83em 0;
}

h3 {
    font-size: 1.17em;
    margin: 1em 0;
}

h4 {
    font-size: 1em;
    margin: 1.33em 0;
}

h5 {
    font-size: 0.83em;
    margin: 1.67em 0;
}

h6 {
    font-size: 0.67em;
    margin: 2.33em 0;
}

/**
 * Address styling not present in IE 7/8/9, Safari 5, and Chrome.
 */

abbr[title] {
    border-bottom: 1px dotted;
}

/**
 * Address style set to `bolder` in Firefox 3+, Safari 4/5, and Chrome.
 */

b,
strong {
    font-weight: bold;
}

blockquote {
    margin: 1em 40px;
}

/**
 * Address styling not present in Safari 5 and Chrome.
 */

dfn {
    font-style: italic;
}

/**
 * Address differences between Firefox and other browsers.
 * Known issue: no IE 6/7 normalization.
 */

hr {
    -moz-box-sizing: content-box;
    box-sizing: content-box;
    height: 0;
}

/**
 * Address styling not present in IE 6/7/8/9.
 */

mark {
    background: #ff0;
    color: #000;
}

/**
 * Address margins set differently in IE 6/7.
 */

p,
pre {
    margin: 1em 0;
}

/**
 * Correct font family set oddly in IE 6, Safari 4/5, and Chrome.
 */

code,
kbd,
pre,
samp {
    font-family: monospace, serif;
    _font-family: 'courier new', monospace;
    font-size: 1em;
}

/**
 * Improve readability of pre-formatted text in all browsers.
 */

pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
}

/**
 * Address CSS quotes not supported in IE 6/7.
 */

q {
    quotes: none;
}

/**
 * Address `quotes` property not supported in Safari 4.
 */

q:before,
q:after {
    content: '';
    content: none;
}

/**
 * Address inconsistent and variable font size in all browsers.
 */

small {
    font-size: 80%;
}

/**
 * Prevent `sub` and `sup` affecting `line-height` in all browsers.
 */

sub,
sup {
    font-size: 75%;
    line-height: 0;
    position: relative;
    vertical-align: baseline;
}

sup {
    top: -0.5em;
}

sub {
    bottom: -0.25em;
}

/* ==========================================================================
   Lists
   ========================================================================== */

/**
 * Address margins set differently in IE 6/7.
 */

dl,
menu,
ol,
ul {
    margin: 1em 0;
}

dd {
    margin: 0 0 0 40px;
}

/**
 * Address paddings set differently in IE 6/7.
 */

menu,
ol,
ul {
    padding: 0 0 0 40px;
}

/**
 * Correct list images handled incorrectly in IE 7.
 */

nav ul,
nav ol {
    list-style: none;
    list-style-image: none;
}

/* ==========================================================================
   Embedded content
   ========================================================================== */

/**
 * 1. Remove border when inside `a` element in IE 6/7/8/9 and Firefox 3.
 * 2. Improve image quality when scaled in IE 7.
 */

img {
    border: 0; /* 1 */
    -ms-interpolation-mode: bicubic; /* 2 */
}

/**
 * Correct overflow displayed oddly in IE 9.
 */

svg:not(:root) {
    overflow: hidden;
}

/* ==========================================================================
   Figures
   ========================================================================== */

/**
 * Address margin not present in IE 6/7/8/9, Safari 5, and Opera 11.
 */

figure {
    margin: 0;
}

/* ==========================================================================
   Forms
   ========================================================================== */

/**
 * Correct margin displayed oddly in IE 6/7.
 */

form {
    margin: 0;
}

/**
 * Define consistent border, margin, and padding.
 */

fieldset {
    border: 1px solid #c0c0c0;
    margin: 0 2px;
    padding: 0.35em 0.625em 0.75em;
}

/**
 * 1. Correct color not being inherited in IE 6/7/8/9.
 * 2. Correct text not wrapping in Firefox 3.
 * 3. Correct alignment displayed oddly in IE 6/7.
 */

legend {
    border: 0; /* 1 */
    padding: 0;
    white-space: normal; /* 2 */
    *margin-left: -7px; /* 3 */
}

/**
 * 1. Correct font size not being inherited in all browsers.
 * 2. Address margins set differently in IE 6/7, Firefox 3+, Safari 5,
 *    and Chrome.
 * 3. Improve appearance and consistency in all browsers.
 */

button,
input,
select,
textarea {
    font-size: 100%; /* 1 */
    margin: 0; /* 2 */
    vertical-align: baseline; /* 3 */
    *vertical-align: middle; /* 3 */
}

/**
 * Address Firefox 3+ setting `line-height` on `input` using `!important` in
 * the UA stylesheet.
 */

button,
input {
    line-height: normal;
}

/**
 * Address inconsistent `text-transform` inheritance for `button` and `select`.
 * All other form control elements do not inherit `text-transform` values.
 * Correct `button` style inheritance in Chrome, Safari 5+, and IE 6+.
 * Correct `select` style inheritance in Firefox 4+ and Opera.
 */

button,
select {
    text-transform: none;
}

/**
 * 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
 *    and `video` controls.
 * 2. Correct inability to style clickable `input` types in iOS.
 * 3. Improve usability and consistency of cursor style between image-type
 *    `input` and others.
 * 4. Remove inner spacing in IE 7 without affecting normal text inputs.
 *    Known issue: inner spacing remains in IE 6.
 */

button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
    -webkit-appearance: button; /* 2 */
    cursor: pointer; /* 3 */
    *overflow: visible;  /* 4 */
}

/**
 * Re-set default cursor for disabled elements.
 */

button[disabled],
html input[disabled] {
    cursor: default;
}

/**
 * 1. Address box sizing set to content-box in IE 8/9.
 * 2. Remove excess padding in IE 8/9.
 * 3. Remove excess padding in IE 7.
 *    Known issue: excess padding remains in IE 6.
 */

input[type="checkbox"],
input[type="radio"] {
    box-sizing: border-box; /* 1 */
    padding: 0; /* 2 */
    *height: 13px; /* 3 */
    *width: 13px; /* 3 */
}

/**
 * 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome.
 * 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome
 *    (include `-moz` to future-proof).
 */

input[type="search"] {
    -webkit-appearance: textfield; /* 1 */
    -moz-box-sizing: content-box;
    -webkit-box-sizing: content-box; /* 2 */
    box-sizing: content-box;
}

/**
 * Remove inner padding and search cancel button in Safari 5 and Chrome
 * on OS X.
 */

input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
    -webkit-appearance: none;
}

/**
 * Remove inner padding and border in Firefox 3+.
 */

button::-moz-focus-inner,
input::-moz-focus-inner {
    border: 0;
    padding: 0;
}

/**
 * 1. Remove default vertical scrollbar in IE 6/7/8/9.
 * 2. Improve readability and alignment in all browsers.
 */

textarea {
    overflow: auto; /* 1 */
    vertical-align: top; /* 2 */
}

/* ==========================================================================
   Tables
   ========================================================================== */

/**
 * Remove most spacing between table cells.
 */

table {
    border-collapse: collapse;
    border-spacing: 0;
}

  </style>

  <style type="text/css">
  
  html, body {
    margin: 0;
    padding: 0;
    min-height: 100%;
  }
  body {
    background: #fff;
    font-family: "Source Sans Pro", "Helvetica Neueue", Helvetica, sans;
    font-weight: 300;
    font-size: 16px;
    line-height: 1.6em;
  }
  #content {
    width: 70%;
    max-width: 850px;
    float: left;
    padding: 30px 60px;
    border-left: 1px solid #ddd;
  }
  #sidebar {
    width: 25%;
    float: left;
    padding: 30px;
    overflow: hidden;
  }
  #nav {
    font-size: 130%;
    margin: 0 0 15px 0;
  }

  #top {
    display: block;
    position: fixed;
    bottom: 5px;
    left: 5px;
    font-size: .85em;
    text-transform: uppercase;
  }

  #footer {
    font-size: .75em;
    padding: 5px 30px;
    border-top: 1px solid #ddd;
    text-align: right;
  }
    #footer p {
      margin: 0 0 0 30px;
      display: inline-block;
    }

  h1, h2, h3, h4, h5 {
    font-weight: 300;
  }
  h1 {
    font-size: 2.5em;
    line-height: 1.1em;
    margin: 0 0 .50em 0;
  }

  h2 {
    font-size: 1.75em;
    margin: 1em 0 .50em 0;
  }

  h3 {
    margin: 25px 0 10px 0;
  }

  h4 {
    margin: 0;
    font-size: 105%;
  }

  a {
    color: #058;
    text-decoration: none;
    transition: color .3s ease-in-out;
  }

  a:hover {
    color: #e08524;
    transition: color .3s ease-in-out;
  }

  pre, code, .mono, .name {
    font-family: "Ubuntu Mono", "Cousine", "DejaVu Sans Mono", monospace;
  }

  .title .name {
    font-weight: bold;
  }
  .section-title {
    margin-top: 2em;
  }
  .ident {
    color: #900;
  }

  code {
    background: #f9f9f9;
  } 

  pre {
    background: #fefefe;
    border: 1px solid #ddd;
    box-shadow: 2px 2px 0 #f3f3f3;
    margin: 0 30px;
    padding: 15px 30px;
  }

  .codehilite {
    margin: 0 30px 10px 30px;
  }

    .codehilite pre {
      margin: 0;
    }
    .codehilite .err { background: #ff3300; color: #fff !important; } 

  table#module-list {
    font-size: 110%;
  }

    table#module-list tr td:first-child {
      padding-right: 10px;
      white-space: nowrap;
    }

    table#module-list td {
      vertical-align: top;
      padding-bottom: 8px;
    }

      table#module-list td p {
        margin: 0 0 7px 0;
      }

  .def {
    display: table;
  }

    .def p {
      display: table-cell;
      vertical-align: top;
      text-align: left;
    }

    .def p:first-child {
      white-space: nowrap;
    }

    .def p:last-child {
      width: 100%;
    }


  #index {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }
    ul#index .class_name {
      /* font-size: 110%; */
      font-weight: bold;
    }
    #index ul {
      margin: 0;
    }

  .item {
    margin: 0 0 15px 0;
  }

    .item .class {
      margin: 0 0 25px 30px;
    }

      .item .class ul.class_list {
        margin: 0 0 20px 0;
      }

    .item .name {
      background: #fafafa;
      margin: 0;
      font-weight: bold;
      padding: 5px 10px;
      border-radius: 3px;
      display: inline-block;
      min-width: 40%;
    }
      .item .name:hover {
        background: #f6f6f6;
      }

    .item .empty_desc {
      margin: 0 0 5px 0;
      padding: 0;
    }

    .item .inheritance {
      margin: 3px 0 0 30px;
    }

    .item .inherited {
      color: #666;
    }

    .item .desc {
      padding: 0 8px;
      margin: 0;
    }

      .item .desc p {
        margin: 0 0 10px 0;
      }

    .source_cont {
      margin: 0;
      padding: 0;
    }

    .source_link a {
      background: #ffc300;
      font-weight: 400;
      font-size: .75em;
      text-transform: uppercase;
      color: #fff;
      text-shadow: 1px 1px 0 #f4b700;
      
      padding: 3px 8px;
      border-radius: 2px;
      transition: background .3s ease-in-out;
    }
      .source_link a:hover {
        background: #FF7200;
        text-shadow: none;
        transition: background .3s ease-in-out;
      }

    .source {
      display: none;
      max-height: 600px;
      overflow-y: scroll;
      margin-bottom: 15px;
    }

      .source .codehilite {
        margin: 0;
      }

  .desc h1, .desc h2, .desc h3 {
    font-size: 100% !important;
  }
  .clear {
    clear: both;
  }

  @media all and (max-width: 950px) {
    #sidebar {
      width: 35%;
    }
    #content {
      width: 65%;
    }
  }
  @media all and (max-width: 650px) {
    #top {
      display: none;
    }
    #sidebar {
      float: none;
      width: auto;
    }
    #content {
      float: none;
      width: auto;
      padding: 30px;
    }

    #index ul {
      padding: 0;
      margin-bottom: 15px;
    }
    #index ul li {
      display: inline-block;
      margin-right: 30px;
    }
    #footer {
      text-align: left;
    }
    #footer p {
      display: block;
      margin: inherit;
    }
  }

  /*****************************/

  </style>

  <style type="text/css">
  .codehilite .hll { background-color: #ffffcc }
.codehilite  { background: #f8f8f8; }
.codehilite .c { color: #408080; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #FF0000 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666666 } /* Operator */
.codehilite .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.codehilite .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #BC7A00 } /* Comment.Preproc */
.codehilite .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.codehilite .c1 { color: #408080; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #408080; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .gr { color: #FF0000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #00A000 } /* Generic.Inserted */
.codehilite .go { color: #888888 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #0044DD } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #7D9029 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.codehilite .no { color: #880000 } /* Name.Constant */
.codehilite .nd { color: #AA22FF } /* Name.Decorator */
.codehilite .ni { color: #999999; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #0000FF } /* Name.Function */
.codehilite .nl { color: #A0A000 } /* Name.Label */
.codehilite .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #bbbbbb } /* Text.Whitespace */
.codehilite .mb { color: #666666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666666 } /* Literal.Number.Float */
.codehilite .mh { color: #666666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666666 } /* Literal.Number.Oct */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #BB6688 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .il { color: #666666 } /* Literal.Number.Integer.Long */
  </style>

  <style type="text/css">
  
/* ==========================================================================
   EXAMPLE Media Queries for Responsive Design.
   These examples override the primary ('mobile first') styles.
   Modify as content requires.
   ========================================================================== */

@media only screen and (min-width: 35em) {
    /* Style adjustments for viewports that meet the condition */
}

@media print,
       (-o-min-device-pixel-ratio: 5/4),
       (-webkit-min-device-pixel-ratio: 1.25),
       (min-resolution: 120dpi) {
    /* Style adjustments for high resolution devices */
}

/* ==========================================================================
   Print styles.
   Inlined to avoid required HTTP connection: h5bp.com/r
   ========================================================================== */

@media print {
    * {
        background: transparent !important;
        color: #000 !important; /* Black prints faster: h5bp.com/s */
        box-shadow: none !important;
        text-shadow: none !important;
    }

    a,
    a:visited {
        text-decoration: underline;
    }

    a[href]:after {
        content: " (" attr(href) ")";
    }

    abbr[title]:after {
        content: " (" attr(title) ")";
    }

    /*
     * Don't show links for images, or javascript/internal links
     */

    .ir a:after,
    a[href^="javascript:"]:after,
    a[href^="#"]:after {
        content: "";
    }

    pre,
    blockquote {
        border: 1px solid #999;
        page-break-inside: avoid;
    }

    thead {
        display: table-header-group; /* h5bp.com/t */
    }

    tr,
    img {
        page-break-inside: avoid;
    }

    img {
        max-width: 100% !important;
    }

    @page {
        margin: 0.5cm;
    }

    p,
    h2,
    h3 {
        orphans: 3;
        widows: 3;
    }

    h2,
    h3 {
        page-break-after: avoid;
    }
}

  </style>

  <script type="text/javascript">
  function toggle(id, $link) {
    $node = document.getElementById(id);
    if (!$node)
    return;
    if (!$node.style.display || $node.style.display == 'none') {
    $node.style.display = 'block';
    $link.innerHTML = 'Hide source &nequiv;';
    } else {
    $node.style.display = 'none';
    $link.innerHTML = 'Show source &equiv;';
    }
  }
  </script>
</head>
<body>
<a href="#" id="top">Top</a>

<div id="container">
    
  
  <div id="sidebar">
    <h1>Index</h1>
    <ul id="index">


    <li class="set"><h3><a href="#header-classes">Classes</a></h3>
      <ul>
        <li class="mono">
        <span class="class_name"><a href="#tensorbuilder.api.applicative.Applicative">Applicative</a></span>
        
          
  <ul>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.__init__">__init__</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.Assert">Assert</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.Assert_layer">Assert_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.Builder">Builder</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.BuilderTree">BuilderTree</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.NoGradient">NoGradient</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.NoGradient_layer">NoGradient_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.Print">Print</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.Print_layer">Print_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.abs">abs</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.abs_layer">abs_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.accumulate_n">accumulate_n</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.accumulate_n_layer">accumulate_n_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.acos">acos</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.acos_layer">acos_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.add">add</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.add_check_numerics_ops">add_check_numerics_ops</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.add_check_numerics_ops_layer">add_check_numerics_ops_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.add_layer">add_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.add_n">add_n</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.add_n_layer">add_n_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.add_to_collection">add_to_collection</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.add_to_collection_layer">add_to_collection_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.all_candidate_sampler">all_candidate_sampler</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.all_candidate_sampler_layer">all_candidate_sampler_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.all_variables">all_variables</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.all_variables_layer">all_variables_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.arg_max">arg_max</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.arg_max_layer">arg_max_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.arg_min">arg_min</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.arg_min_layer">arg_min_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.argmax_layer">argmax_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.argmin_layer">argmin_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.as_dtype">as_dtype</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.as_dtype_layer">as_dtype_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.asin">asin</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.asin_layer">asin_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_equal">assert_equal</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_equal_layer">assert_equal_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_integer">assert_integer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_integer_layer">assert_integer_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_less">assert_less</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_less_equal">assert_less_equal</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_less_equal_layer">assert_less_equal_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_less_layer">assert_less_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_negative">assert_negative</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_negative_layer">assert_negative_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_non_negative">assert_non_negative</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_non_negative_layer">assert_non_negative_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_non_positive">assert_non_positive</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_non_positive_layer">assert_non_positive_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_positive">assert_positive</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_positive_layer">assert_positive_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_proper_iterable">assert_proper_iterable</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_proper_iterable_layer">assert_proper_iterable_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_rank">assert_rank</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_rank_at_least">assert_rank_at_least</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_rank_at_least_layer">assert_rank_at_least_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_rank_layer">assert_rank_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_type">assert_type</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_type_layer">assert_type_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_variables_initialized">assert_variables_initialized</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assert_variables_initialized_layer">assert_variables_initialized_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assign">assign</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assign_add">assign_add</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assign_add_layer">assign_add_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assign_layer">assign_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assign_sub">assign_sub</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.assign_sub_layer">assign_sub_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.atan">atan</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.atan_layer">atan_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.atrous_conv2d">atrous_conv2d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.atrous_conv2d_layer">atrous_conv2d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.audio_summary">audio_summary</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.audio_summary_layer">audio_summary_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.avg_pool">avg_pool</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.avg_pool3d">avg_pool3d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.avg_pool3d_grad">avg_pool3d_grad</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.avg_pool3d_grad_layer">avg_pool3d_grad_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.avg_pool3d_layer">avg_pool3d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.avg_pool_layer">avg_pool_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_cholesky">batch_cholesky</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_cholesky_layer">batch_cholesky_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_cholesky_solve">batch_cholesky_solve</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_cholesky_solve_layer">batch_cholesky_solve_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_fft">batch_fft</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_fft2d">batch_fft2d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_fft2d_layer">batch_fft2d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_fft3d">batch_fft3d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_fft3d_layer">batch_fft3d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_fft_layer">batch_fft_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_ifft">batch_ifft</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_ifft2d">batch_ifft2d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_ifft2d_layer">batch_ifft2d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_ifft3d">batch_ifft3d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_ifft3d_layer">batch_ifft3d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_ifft_layer">batch_ifft_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matmul_layer">batch_matmul_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_band_part">batch_matrix_band_part</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_band_part_layer">batch_matrix_band_part_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_determinant">batch_matrix_determinant</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_determinant_layer">batch_matrix_determinant_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_diag">batch_matrix_diag</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_diag_layer">batch_matrix_diag_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_diag_part">batch_matrix_diag_part</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_diag_part_layer">batch_matrix_diag_part_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_inverse">batch_matrix_inverse</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_inverse_layer">batch_matrix_inverse_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_solve">batch_matrix_solve</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_solve_layer">batch_matrix_solve_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_solve_ls">batch_matrix_solve_ls</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_solve_ls_layer">batch_matrix_solve_ls_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_triangular_solve">batch_matrix_triangular_solve</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_matrix_triangular_solve_layer">batch_matrix_triangular_solve_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_norm_with_global_normalization">batch_norm_with_global_normalization</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_norm_with_global_normalization_layer">batch_norm_with_global_normalization_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_normalization">batch_normalization</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_normalization_layer">batch_normalization_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_self_adjoint_eig">batch_self_adjoint_eig</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_self_adjoint_eig_layer">batch_self_adjoint_eig_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_to_space">batch_to_space</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.batch_to_space_layer">batch_to_space_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.bias_add">bias_add</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.bias_add_grad">bias_add_grad</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.bias_add_grad_layer">bias_add_grad_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.bias_add_layer">bias_add_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.bias_add_v1">bias_add_v1</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.bias_add_v1_layer">bias_add_v1_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.bidirectional_rnn">bidirectional_rnn</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.bidirectional_rnn_layer">bidirectional_rnn_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.bitcast">bitcast</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.bitcast_layer">bitcast_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.boolean_mask">boolean_mask</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.boolean_mask_layer">boolean_mask_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.branch">branch</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.builders">builders</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.case">case</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.case_layer">case_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.cast">cast</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.cast_layer">cast_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ceil">ceil</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ceil_layer">ceil_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.check_numerics">check_numerics</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.check_numerics_layer">check_numerics_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.cholesky">cholesky</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.cholesky_layer">cholesky_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.cholesky_solve">cholesky_solve</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.cholesky_solve_layer">cholesky_solve_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.clip_by_average_norm">clip_by_average_norm</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.clip_by_average_norm_layer">clip_by_average_norm_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.clip_by_global_norm">clip_by_global_norm</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.clip_by_global_norm_layer">clip_by_global_norm_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.clip_by_norm">clip_by_norm</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.clip_by_norm_layer">clip_by_norm_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.clip_by_value">clip_by_value</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.clip_by_value_layer">clip_by_value_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.compile">compile</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.complex">complex</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.complex_abs">complex_abs</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.complex_abs_layer">complex_abs_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.complex_layer">complex_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.compose">compose</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.compute_accidental_hits">compute_accidental_hits</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.compute_accidental_hits_layer">compute_accidental_hits_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.concat">concat</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.concat_layer">concat_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.cond">cond</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.cond_layer">cond_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conj">conj</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conj_layer">conj_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.constant">constant</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.constant_initializer">constant_initializer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.constant_initializer_layer">constant_initializer_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.constant_layer">constant_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.control_dependencies">control_dependencies</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.control_dependencies_layer">control_dependencies_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv1d">conv1d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv1d_layer">conv1d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv2d">conv2d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv2d_backprop_filter">conv2d_backprop_filter</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv2d_backprop_filter_layer">conv2d_backprop_filter_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv2d_backprop_input">conv2d_backprop_input</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv2d_backprop_input_layer">conv2d_backprop_input_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv2d_layer">conv2d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv2d_transpose">conv2d_transpose</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv2d_transpose_layer">conv2d_transpose_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv3d">conv3d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv3d_backprop_filter">conv3d_backprop_filter</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv3d_backprop_filter_layer">conv3d_backprop_filter_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv3d_backprop_input">conv3d_backprop_input</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv3d_backprop_input_layer">conv3d_backprop_input_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.conv3d_layer">conv3d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.convert_to_tensor">convert_to_tensor</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.convert_to_tensor_layer">convert_to_tensor_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.convert_to_tensor_or_indexed_slices">convert_to_tensor_or_indexed_slices</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.convert_to_tensor_or_indexed_slices_layer">convert_to_tensor_or_indexed_slices_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.convolution2d">convolution2d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.copy">copy</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.cos">cos</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.cos_layer">cos_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.count_up_to">count_up_to</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.count_up_to_layer">count_up_to_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.create_partitioned_variables">create_partitioned_variables</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.create_partitioned_variables_layer">create_partitioned_variables_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.cross">cross</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.cross_layer">cross_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.decode_csv">decode_csv</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.decode_csv_layer">decode_csv_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.decode_json_example">decode_json_example</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.decode_json_example_layer">decode_json_example_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.decode_raw">decode_raw</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.decode_raw_layer">decode_raw_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.delete_session_tensor">delete_session_tensor</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.delete_session_tensor_layer">delete_session_tensor_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.depth_to_space">depth_to_space</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.depth_to_space_layer">depth_to_space_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.depthwise_conv2d">depthwise_conv2d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.depthwise_conv2d_layer">depthwise_conv2d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native">depthwise_conv2d_native</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_filter">depthwise_conv2d_native_backprop_filter</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_filter_layer">depthwise_conv2d_native_backprop_filter_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_input">depthwise_conv2d_native_backprop_input</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_input_layer">depthwise_conv2d_native_backprop_input_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_layer">depthwise_conv2d_native_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.deserialize_many_sparse">deserialize_many_sparse</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.deserialize_many_sparse_layer">deserialize_many_sparse_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.diag">diag</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.diag_layer">diag_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.diag_part">diag_part</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.diag_part_layer">diag_part_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.digamma">digamma</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.digamma_layer">digamma_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dilation2d">dilation2d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dilation2d_backprop_filter">dilation2d_backprop_filter</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dilation2d_backprop_filter_layer">dilation2d_backprop_filter_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dilation2d_backprop_input">dilation2d_backprop_input</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dilation2d_backprop_input_layer">dilation2d_backprop_input_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dilation2d_layer">dilation2d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.div">div</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.div_layer">div_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dropout">dropout</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dropout_layer">dropout_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dynamic_partition">dynamic_partition</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dynamic_partition_layer">dynamic_partition_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dynamic_rnn">dynamic_rnn</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dynamic_rnn_layer">dynamic_rnn_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dynamic_stitch">dynamic_stitch</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.dynamic_stitch_layer">dynamic_stitch_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.edit_distance">edit_distance</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.edit_distance_layer">edit_distance_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.elu">elu</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.elu_layer">elu_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.embedding_lookup">embedding_lookup</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.embedding_lookup_layer">embedding_lookup_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.embedding_lookup_sparse">embedding_lookup_sparse</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.embedding_lookup_sparse_layer">embedding_lookup_sparse_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.equal">equal</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.equal_layer">equal_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.erf">erf</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.erf_layer">erf_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.erfc">erfc</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.erfc_layer">erfc_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.erosion2d">erosion2d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.erosion2d_layer">erosion2d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.exp">exp</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.exp_layer">exp_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.expand_dims">expand_dims</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.expand_dims_layer">expand_dims_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.extract">extract</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.extract_image_patches">extract_image_patches</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.extract_image_patches_layer">extract_image_patches_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.fft">fft</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.fft2d">fft2d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.fft2d_layer">fft2d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.fft3d">fft3d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.fft3d_layer">fft3d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.fft_layer">fft_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.fill">fill</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.fill_layer">fill_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.fixed_unigram_candidate_sampler">fixed_unigram_candidate_sampler</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.fixed_unigram_candidate_sampler_layer">fixed_unigram_candidate_sampler_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.flatten">flatten</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.floor">floor</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.floor_layer">floor_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.floordiv">floordiv</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.floordiv_layer">floordiv_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.foldl">foldl</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.foldl_layer">foldl_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.foldr">foldr</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.foldr_layer">foldr_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.fully_connected">fully_connected</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.gather">gather</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.gather_layer">gather_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.gather_nd">gather_nd</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.gather_nd_layer">gather_nd_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_collection">get_collection</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_collection_layer">get_collection_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_collection_ref">get_collection_ref</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_collection_ref_layer">get_collection_ref_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_default_graph">get_default_graph</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_default_graph_layer">get_default_graph_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_default_session">get_default_session</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_default_session_layer">get_default_session_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_seed">get_seed</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_seed_layer">get_seed_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_session_handle">get_session_handle</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_session_handle_layer">get_session_handle_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_session_tensor">get_session_tensor</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_session_tensor_layer">get_session_tensor_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_variable">get_variable</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_variable_layer">get_variable_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_variable_scope">get_variable_scope</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.get_variable_scope_layer">get_variable_scope_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.global_norm">global_norm</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.global_norm_layer">global_norm_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.gradients">gradients</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.gradients_layer">gradients_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.greater">greater</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.greater_equal">greater_equal</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.greater_equal_layer">greater_equal_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.greater_layer">greater_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.group">group</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.group_layer">group_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.histogram_fixed_width">histogram_fixed_width</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.histogram_fixed_width_layer">histogram_fixed_width_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.histogram_summary">histogram_summary</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.histogram_summary_layer">histogram_summary_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.identity">identity</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.identity_layer">identity_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ifft">ifft</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ifft2d">ifft2d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ifft2d_layer">ifft2d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ifft3d">ifft3d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ifft3d_layer">ifft3d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ifft_layer">ifft_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.igamma">igamma</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.igamma_layer">igamma_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.igammac">igammac</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.igammac_layer">igammac_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.imag">imag</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.imag_layer">imag_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.image_summary">image_summary</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.image_summary_layer">image_summary_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.import_graph_def">import_graph_def</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.import_graph_def_layer">import_graph_def_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.in_top_k">in_top_k</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.in_top_k_layer">in_top_k_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.initialize_all_tables">initialize_all_tables</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.initialize_all_tables_layer">initialize_all_tables_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.initialize_all_variables">initialize_all_variables</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.initialize_all_variables_layer">initialize_all_variables_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.initialize_local_variables">initialize_local_variables</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.initialize_local_variables_layer">initialize_local_variables_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.initialize_variables">initialize_variables</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.initialize_variables_layer">initialize_variables_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.inv">inv</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.inv_layer">inv_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.invert_permutation">invert_permutation</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.invert_permutation_layer">invert_permutation_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_finite">is_finite</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_finite_layer">is_finite_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_inf">is_inf</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_inf_layer">is_inf_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_nan">is_nan</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_nan_layer">is_nan_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_non_decreasing">is_non_decreasing</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_non_decreasing_layer">is_non_decreasing_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_numeric_tensor">is_numeric_tensor</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_numeric_tensor_layer">is_numeric_tensor_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_strictly_increasing">is_strictly_increasing</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_strictly_increasing_layer">is_strictly_increasing_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_variable_initialized">is_variable_initialized</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.is_variable_initialized_layer">is_variable_initialized_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.l2_loss">l2_loss</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.l2_loss_layer">l2_loss_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.l2_normalize">l2_normalize</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.l2_normalize_layer">l2_normalize_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.lbeta">lbeta</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.lbeta_layer">lbeta_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.learned_unigram_candidate_sampler">learned_unigram_candidate_sampler</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.learned_unigram_candidate_sampler_layer">learned_unigram_candidate_sampler_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.less">less</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.less_equal">less_equal</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.less_equal_layer">less_equal_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.less_layer">less_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.lgamma">lgamma</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.lgamma_layer">lgamma_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.lin_space">lin_space</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.lin_space_layer">lin_space_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.linear_layer">linear_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.linspace_layer">linspace_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.list_diff">list_diff</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.list_diff_layer">list_diff_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.listdiff_layer">listdiff_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.load_file_system_library">load_file_system_library</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.load_file_system_library_layer">load_file_system_library_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.load_op_library">load_op_library</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.load_op_library_layer">load_op_library_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.local_response_normalization_layer">local_response_normalization_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.local_variables">local_variables</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.local_variables_layer">local_variables_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.log">log</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.log_layer">log_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.log_softmax">log_softmax</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.log_softmax_layer">log_softmax_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.log_uniform_candidate_sampler">log_uniform_candidate_sampler</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.log_uniform_candidate_sampler_layer">log_uniform_candidate_sampler_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.logical_and">logical_and</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.logical_and_layer">logical_and_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.logical_not">logical_not</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.logical_not_layer">logical_not_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.logical_or">logical_or</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.logical_or_layer">logical_or_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.logical_xor">logical_xor</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.logical_xor_layer">logical_xor_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.lrn">lrn</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.lrn_layer">lrn_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.make_all">make_all</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.make_all_layer">make_all_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.make_template">make_template</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.make_template_layer">make_template_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.map">map</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.map_each">map_each</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.map_fn">map_fn</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.map_fn_layer">map_fn_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matching_files">matching_files</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matching_files_layer">matching_files_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matmul">matmul</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matmul_layer">matmul_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matrix_determinant">matrix_determinant</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matrix_determinant_layer">matrix_determinant_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matrix_inverse">matrix_inverse</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matrix_inverse_layer">matrix_inverse_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matrix_solve">matrix_solve</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matrix_solve_layer">matrix_solve_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matrix_solve_ls">matrix_solve_ls</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matrix_solve_ls_layer">matrix_solve_ls_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matrix_triangular_solve">matrix_triangular_solve</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.matrix_triangular_solve_layer">matrix_triangular_solve_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.max_pool">max_pool</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.max_pool3d">max_pool3d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.max_pool3d_grad">max_pool3d_grad</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.max_pool3d_grad_layer">max_pool3d_grad_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.max_pool3d_layer">max_pool3d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.max_pool_2d">max_pool_2d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.max_pool_layer">max_pool_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.max_pool_with_argmax">max_pool_with_argmax</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.max_pool_with_argmax_layer">max_pool_with_argmax_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.maximum">maximum</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.maximum_layer">maximum_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.merge_all_summaries">merge_all_summaries</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.merge_all_summaries_layer">merge_all_summaries_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.merge_summary">merge_summary</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.merge_summary_layer">merge_summary_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.minimum">minimum</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.minimum_layer">minimum_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.mod">mod</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.mod_layer">mod_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.moments">moments</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.moments_layer">moments_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.moving_average_variables">moving_average_variables</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.moving_average_variables_layer">moving_average_variables_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.mul">mul</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.mul_layer">mul_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.multinomial">multinomial</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.multinomial_layer">multinomial_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.name_scope">name_scope</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.name_scope_layer">name_scope_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.nce_loss">nce_loss</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.nce_loss_layer">nce_loss_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.neg">neg</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.neg_layer">neg_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.no_op">no_op</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.no_op_layer">no_op_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.no_regularizer">no_regularizer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.no_regularizer_layer">no_regularizer_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.normalize_moments">normalize_moments</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.normalize_moments_layer">normalize_moments_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.not_equal">not_equal</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.not_equal_layer">not_equal_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.one_hot">one_hot</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.one_hot_layer">one_hot_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ones">ones</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ones_initializer">ones_initializer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ones_initializer_layer">ones_initializer_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ones_layer">ones_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ones_like">ones_like</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.ones_like_layer">ones_like_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.op_scope">op_scope</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.op_scope_layer">op_scope_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.pack">pack</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.pack_layer">pack_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.pad">pad</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.pad_layer">pad_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.parse_example">parse_example</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.parse_example_layer">parse_example_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.parse_single_example">parse_single_example</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.parse_single_example_layer">parse_single_example_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.parse_single_sequence_example">parse_single_sequence_example</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.parse_single_sequence_example_layer">parse_single_sequence_example_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.pipe">pipe</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.placeholder">placeholder</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.placeholder_layer">placeholder_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.placeholder_with_default">placeholder_with_default</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.placeholder_with_default_layer">placeholder_with_default_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.polygamma">polygamma</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.polygamma_layer">polygamma_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.pow">pow</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.pow_layer">pow_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.py_func">py_func</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.py_func_layer">py_func_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.random_crop">random_crop</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.random_crop_layer">random_crop_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.random_normal">random_normal</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.random_normal_initializer">random_normal_initializer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.random_normal_initializer_layer">random_normal_initializer_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.random_normal_layer">random_normal_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.random_shuffle">random_shuffle</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.random_shuffle_layer">random_shuffle_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.random_uniform">random_uniform</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.random_uniform_initializer">random_uniform_initializer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.random_uniform_initializer_layer">random_uniform_initializer_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.random_uniform_layer">random_uniform_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.range">range</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.range_layer">range_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.rank">rank</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.rank_layer">rank_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.read_file">read_file</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.read_file_layer">read_file_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.real">real</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.real_layer">real_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce">reduce</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_all">reduce_all</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_all_layer">reduce_all_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_any">reduce_any</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_any_layer">reduce_any_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_join">reduce_join</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_join_layer">reduce_join_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_max">reduce_max</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_max_layer">reduce_max_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_mean">reduce_mean</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_mean_layer">reduce_mean_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_min">reduce_min</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_min_layer">reduce_min_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_prod">reduce_prod</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_prod_layer">reduce_prod_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_sum">reduce_sum</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reduce_sum_layer">reduce_sum_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.register_map_method">register_map_method</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.register_method">register_method</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.register_reduce_method">register_reduce_method</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.register_tensor_conversion_function">register_tensor_conversion_function</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.register_tensor_conversion_function_layer">register_tensor_conversion_function_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.relu">relu</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.relu6">relu6</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.relu6_layer">relu6_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.relu_layer">relu_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.report_uninitialized_variables">report_uninitialized_variables</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.report_uninitialized_variables_layer">report_uninitialized_variables_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reset_default_graph">reset_default_graph</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reset_default_graph_layer">reset_default_graph_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reshape">reshape</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reshape_layer">reshape_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reverse">reverse</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reverse_layer">reverse_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reverse_sequence">reverse_sequence</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.reverse_sequence_layer">reverse_sequence_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.rnn">rnn</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.rnn_layer">rnn_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.round">round</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.round_layer">round_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.rsqrt">rsqrt</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.rsqrt_layer">rsqrt_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sampled_softmax_loss">sampled_softmax_loss</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sampled_softmax_loss_layer">sampled_softmax_loss_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.saturate_cast">saturate_cast</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.saturate_cast_layer">saturate_cast_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.scalar_mul">scalar_mul</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.scalar_mul_layer">scalar_mul_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.scalar_summary">scalar_summary</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.scalar_summary_layer">scalar_summary_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.scan">scan</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.scan_layer">scan_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.scatter_add">scatter_add</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.scatter_add_layer">scatter_add_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.scatter_sub">scatter_sub</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.scatter_sub_layer">scatter_sub_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.scatter_update">scatter_update</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.scatter_update_layer">scatter_update_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.segment_max">segment_max</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.segment_max_layer">segment_max_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.segment_mean">segment_mean</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.segment_mean_layer">segment_mean_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.segment_min">segment_min</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.segment_min_layer">segment_min_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.segment_prod">segment_prod</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.segment_prod_layer">segment_prod_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.segment_sum">segment_sum</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.segment_sum_layer">segment_sum_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.select">select</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.select_layer">select_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.self_adjoint_eig">self_adjoint_eig</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.self_adjoint_eig_layer">self_adjoint_eig_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.separable_conv2d">separable_conv2d</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.separable_conv2d_layer">separable_conv2d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.serialize_many_sparse">serialize_many_sparse</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.serialize_many_sparse_layer">serialize_many_sparse_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.serialize_sparse">serialize_sparse</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.serialize_sparse_layer">serialize_sparse_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.set_random_seed">set_random_seed</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.set_random_seed_layer">set_random_seed_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.shape">shape</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.shape_layer">shape_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.shape_n">shape_n</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.shape_n_layer">shape_n_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sigmoid">sigmoid</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sigmoid_cross_entropy_with_logits">sigmoid_cross_entropy_with_logits</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sigmoid_cross_entropy_with_logits_layer">sigmoid_cross_entropy_with_logits_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sigmoid_layer">sigmoid_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sign">sign</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sign_layer">sign_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sin">sin</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sin_layer">sin_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.size">size</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.size_layer">size_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.slice">slice</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.slice_layer">slice_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.softmax">softmax</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.softmax_cross_entropy_with_logits">softmax_cross_entropy_with_logits</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.softmax_cross_entropy_with_logits_layer">softmax_cross_entropy_with_logits_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.softmax_layer">softmax_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.softplus">softplus</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.softplus_layer">softplus_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.softsign">softsign</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.softsign_layer">softsign_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.space_to_batch">space_to_batch</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.space_to_batch_layer">space_to_batch_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.space_to_depth">space_to_depth</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.space_to_depth_layer">space_to_depth_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_add">sparse_add</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_add_layer">sparse_add_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_concat">sparse_concat</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_concat_layer">sparse_concat_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_fill_empty_rows">sparse_fill_empty_rows</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_fill_empty_rows_layer">sparse_fill_empty_rows_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_mask">sparse_mask</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_mask_layer">sparse_mask_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_matmul_layer">sparse_matmul_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_merge">sparse_merge</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_merge_layer">sparse_merge_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_placeholder">sparse_placeholder</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_placeholder_layer">sparse_placeholder_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_reduce_sum">sparse_reduce_sum</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_reduce_sum_layer">sparse_reduce_sum_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_reorder">sparse_reorder</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_reorder_layer">sparse_reorder_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_reset_shape">sparse_reset_shape</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_reset_shape_layer">sparse_reset_shape_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_retain">sparse_retain</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_retain_layer">sparse_retain_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_segment_mean">sparse_segment_mean</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_segment_mean_grad">sparse_segment_mean_grad</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_segment_mean_grad_layer">sparse_segment_mean_grad_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_segment_mean_layer">sparse_segment_mean_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n">sparse_segment_sqrt_n</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n_grad">sparse_segment_sqrt_n_grad</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n_grad_layer">sparse_segment_sqrt_n_grad_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n_layer">sparse_segment_sqrt_n_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_segment_sum">sparse_segment_sum</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_segment_sum_layer">sparse_segment_sum_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_softmax">sparse_softmax</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_softmax_cross_entropy_with_logits">sparse_softmax_cross_entropy_with_logits</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_softmax_cross_entropy_with_logits_layer">sparse_softmax_cross_entropy_with_logits_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_softmax_layer">sparse_softmax_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_split">sparse_split</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_split_layer">sparse_split_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_tensor_dense_matmul">sparse_tensor_dense_matmul</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_tensor_dense_matmul_layer">sparse_tensor_dense_matmul_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_tensor_to_dense">sparse_tensor_to_dense</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_tensor_to_dense_layer">sparse_tensor_to_dense_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_to_dense">sparse_to_dense</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_to_dense_layer">sparse_to_dense_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_to_indicator">sparse_to_indicator</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sparse_to_indicator_layer">sparse_to_indicator_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.split">split</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.split_layer">split_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sqrt">sqrt</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sqrt_layer">sqrt_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.square">square</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.square_layer">square_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.squared_difference">squared_difference</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.squared_difference_layer">squared_difference_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.squeeze">squeeze</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.squeeze_layer">squeeze_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.state_saving_rnn">state_saving_rnn</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.state_saving_rnn_layer">state_saving_rnn_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.stop_gradient">stop_gradient</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.stop_gradient_layer">stop_gradient_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.string_to_hash_bucket">string_to_hash_bucket</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_fast">string_to_hash_bucket_fast</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_fast_layer">string_to_hash_bucket_fast_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_layer">string_to_hash_bucket_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_strong">string_to_hash_bucket_strong</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_strong_layer">string_to_hash_bucket_strong_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.string_to_number">string_to_number</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.string_to_number_layer">string_to_number_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sub">sub</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sub_layer">sub_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sufficient_statistics">sufficient_statistics</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.sufficient_statistics_layer">sufficient_statistics_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.tan">tan</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.tan_layer">tan_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.tanh">tanh</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.tanh_layer">tanh_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.tensor">tensor</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.tensors">tensors</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.then">then</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.then_with">then_with</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.tile">tile</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.tile_layer">tile_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.to_bfloat16">to_bfloat16</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.to_bfloat16_layer">to_bfloat16_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.to_double">to_double</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.to_double_layer">to_double_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.to_float">to_float</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.to_float_layer">to_float_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.to_int32">to_int32</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.to_int32_layer">to_int32_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.to_int64">to_int64</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.to_int64_layer">to_int64_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.top_k">top_k</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.top_k_layer">top_k_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.trace">trace</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.trace_layer">trace_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.trainable_variables">trainable_variables</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.trainable_variables_layer">trainable_variables_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.transpose">transpose</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.transpose_layer">transpose_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.truediv">truediv</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.truediv_layer">truediv_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.truncated_normal">truncated_normal</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.truncated_normal_initializer">truncated_normal_initializer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.truncated_normal_initializer_layer">truncated_normal_initializer_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.truncated_normal_layer">truncated_normal_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.tuple">tuple</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.tuple_layer">tuple_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.uniform_candidate_sampler">uniform_candidate_sampler</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.uniform_candidate_sampler_layer">uniform_candidate_sampler_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.uniform_unit_scaling_initializer">uniform_unit_scaling_initializer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.uniform_unit_scaling_initializer_layer">uniform_unit_scaling_initializer_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.unique">unique</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.unique_layer">unique_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.unique_with_counts">unique_with_counts</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.unique_with_counts_layer">unique_with_counts_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.unpack">unpack</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.unpack_layer">unpack_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.unsorted_segment_sum">unsorted_segment_sum</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.unsorted_segment_sum_layer">unsorted_segment_sum_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.variable_axis_size_partitioner">variable_axis_size_partitioner</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.variable_axis_size_partitioner_layer">variable_axis_size_partitioner_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.variable_op_scope">variable_op_scope</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.variable_op_scope_layer">variable_op_scope_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.verify_tensor_all_finite">verify_tensor_all_finite</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.verify_tensor_all_finite_layer">verify_tensor_all_finite_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.weighted_cross_entropy_with_logits">weighted_cross_entropy_with_logits</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.weighted_cross_entropy_with_logits_layer">weighted_cross_entropy_with_logits_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.where">where</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.where_layer">where_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.while_loop">while_loop</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.while_loop_layer">while_loop_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.xw_plus_b">xw_plus_b</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.xw_plus_b_layer">xw_plus_b_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.xw_plus_b_v1">xw_plus_b_v1</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.xw_plus_b_v1_layer">xw_plus_b_v1_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.zero_fraction">zero_fraction</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.zero_fraction_layer">zero_fraction_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.zeros">zeros</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.zeros_initializer">zeros_initializer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.zeros_initializer_layer">zeros_initializer_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.zeros_layer">zeros_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.zeros_like">zeros_like</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.zeros_like_layer">zeros_like_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.zeta">zeta</a></li>
    <li class="mono"><a href="#tensorbuilder.api.applicative.Applicative.zeta_layer">zeta_layer</a></li>
  </ul>

        </li>
      </ul>
    </li>

    </ul>
  </div>

    <article id="content">
      
  

  


  <header id="section-intro">
  <h1 class="title"><span class="name">tensorbuilder.api.applicative</span> module</h1>
  
  
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative" class="source">
    <div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">classes</span> <span class="kn">import</span> <span class="n">Applicative</span>

<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Applicative&quot;</span><span class="p">]</span>
</pre></div>

  </div>

  </header>

  <section id="section-items">


    <h2 class="section-title" id="header-classes">Classes</h2>
      
      <div class="item">
      <p id="tensorbuilder.api.applicative.Applicative" class="name">class <span class="ident">Applicative</span></p>
      
  
    <div class="desc"><p>docstring for Applicative</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">Applicative</span><span class="p">(</span><span class="n">ApplicativeBase</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;docstring for Applicative&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Applicative</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">Builder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">Builder</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#tensorbuilder.api.applicative.Applicative">Applicative</a></li>
          <li>tensorbuilder.core.applicative.ApplicativeBase</li>
          <li>__builtin__.object</li>
          </ul>
          <h3>Methods</h3>
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, f)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.__init__', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Applicative</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.Assert">
    <p>def <span class="ident">Assert</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.Assert, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.Assert</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.Assert</strong></p>
<div class="codehilite"><pre><span></span>def Assert(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.Assert</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.Assert</code></strong></p>
<div class="codehilite"><pre><span></span>def Assert(condition, data, summarize=None, name=None)
</pre></div>


<p>Asserts that the given condition is true.</p>
<p>If <code>condition</code> evaluates to false, print the list of tensors in <code>data</code>.
<code>summarize</code> determines how many entries of the tensors to print.</p>
<p>NOTE: To ensure that Assert executes, one usually attaches a dependency:</p>
<p><code>python
 # Ensure maximum element of x is smaller or equal to 1
assert_op = tf.Assert(tf.less_equal(tf.reduce_max(x), 1.), [x])
x = tf.with_dependencies([assert_op], x)</code></p>
<p>Args:
  condition: The condition to evaluate.
  data: The tensors to print out when condition is false.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).</p>
<p>Returns:
  assert_op: An <code>Operation</code> that, when executed, raises a
  <code>tf.errors.InvalidArgumentError</code> if <code>condition</code> is not true.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.Assert', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.Assert" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.Assert_layer">
    <p>def <span class="ident">Assert_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.Assert_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.Assert_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.Assert_layer</strong></p>
<div class="codehilite"><pre><span></span>def Assert_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.Assert, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.Assert</strong></p>
<div class="codehilite"><pre><span></span>def Assert(condition, data, summarize=None, name=None):
</pre></div>


<p>Asserts that the given condition is true.</p>
<p>If <code>condition</code> evaluates to false, print the list of tensors in <code>data</code>.
<code>summarize</code> determines how many entries of the tensors to print.</p>
<p>NOTE: To ensure that Assert executes, one usually attaches a dependency:</p>
<p><code>python
 # Ensure maximum element of x is smaller or equal to 1
assert_op = tf.Assert(tf.less_equal(tf.reduce_max(x), 1.), [x])
x = tf.with_dependencies([assert_op], x)</code></p>
<p>Args:
  condition: The condition to evaluate.
  data: The tensors to print out when condition is false.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).</p>
<p>Returns:
  assert_op: An <code>Operation</code> that, when executed, raises a
  <code>tf.errors.InvalidArgumentError</code> if <code>condition</code> is not true.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.Assert_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.Assert_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.Builder">
    <p>def <span class="ident">Builder</span>(</p><p>self, tensor)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.Builder', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.Builder" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">Builder</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tensor</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">Builder</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.BuilderTree">
    <p>def <span class="ident">BuilderTree</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.BuilderTree, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.BuilderTree</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.BuilderTree</strong></p>
<div class="codehilite"><pre><span></span>def BuilderTree(self, builder_iterable):
</pre></div>


<p>None</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.BuilderTree', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.BuilderTree" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.NoGradient">
    <p>def <span class="ident">NoGradient</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.NoGradient, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.NoGradient</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.NoGradient</strong></p>
<div class="codehilite"><pre><span></span>def NoGradient(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.NoGradient</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.NoGradient</code></strong></p>
<div class="codehilite"><pre><span></span>def NoGradient(op_type)
</pre></div>


<p>Specifies that ops of type <code>op_type</code> do not have a defined gradient.</p>
<p>This function is only used when defining a new op type. It may be
used for ops such as <code>tf.size()</code> that are not differentiable.  For
example:</p>
<p><code>python
tf.NoGradient("Size")</code></p>
<p>Args:
  op_type: The string type of an operation. This corresponds to the
    <code>OpDef.name</code> field for the proto that defines the operation.</p>
<p>Raises:
  TypeError: If <code>op_type</code> is not a string.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.NoGradient', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.NoGradient" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.NoGradient_layer">
    <p>def <span class="ident">NoGradient_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.NoGradient_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.NoGradient_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.NoGradient_layer</strong></p>
<div class="codehilite"><pre><span></span>def NoGradient_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.NoGradient, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.NoGradient</strong></p>
<div class="codehilite"><pre><span></span>def NoGradient(op_type):
</pre></div>


<p>Specifies that ops of type <code>op_type</code> do not have a defined gradient.</p>
<p>This function is only used when defining a new op type. It may be
used for ops such as <code>tf.size()</code> that are not differentiable.  For
example:</p>
<p><code>python
tf.NoGradient("Size")</code></p>
<p>Args:
  op_type: The string type of an operation. This corresponds to the
    <code>OpDef.name</code> field for the proto that defines the operation.</p>
<p>Raises:
  TypeError: If <code>op_type</code> is not a string.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.NoGradient_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.NoGradient_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.Print">
    <p>def <span class="ident">Print</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.Print, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.Print</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.Print</strong></p>
<div class="codehilite"><pre><span></span>def Print(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.Print</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.Print</code></strong></p>
<div class="codehilite"><pre><span></span>def Print(input_, data, message=None, first_n=None, summarize=None, name=None)
</pre></div>


<p>Prints a list of tensors.</p>
<p>This is an identity op with the side effect of printing <code>data</code> when
evaluating.</p>
<p>Args:
  input_: A tensor passed through this op.
  data: A list of tensors to print out when op is evaluated.
  message: A string, prefix of the error message.
  first_n: Only log <code>first_n</code> number of times. Negative numbers log always;
           this is the default.
  summarize: Only print this many entries of each tensor. If None, then a
             maximum of 3 elements are printed per input tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same tensor as <code>input_</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.Print', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.Print" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.Print_layer">
    <p>def <span class="ident">Print_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.Print_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.Print_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.Print_layer</strong></p>
<div class="codehilite"><pre><span></span>def Print_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.Print, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.Print</strong></p>
<div class="codehilite"><pre><span></span>def Print(input_, data, message=None, first_n=None, summarize=None, name=None):
</pre></div>


<p>Prints a list of tensors.</p>
<p>This is an identity op with the side effect of printing <code>data</code> when
evaluating.</p>
<p>Args:
  input_: A tensor passed through this op.
  data: A list of tensors to print out when op is evaluated.
  message: A string, prefix of the error message.
  first_n: Only log <code>first_n</code> number of times. Negative numbers log always;
           this is the default.
  summarize: Only print this many entries of each tensor. If None, then a
             maximum of 3 elements are printed per input tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same tensor as <code>input_</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.Print_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.Print_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.abs">
    <p>def <span class="ident">abs</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.abs, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.abs</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.abs</strong></p>
<div class="codehilite"><pre><span></span>def abs(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.abs</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.abs</code></strong></p>
<div class="codehilite"><pre><span></span>def abs(x, name=None)
</pre></div>


<p>Computes the absolute value of a tensor.</p>
<p>Given a tensor of real numbers <code>x</code>, this operation returns a tensor
containing the absolute value of each element in <code>x</code>. For example, if x is
an input element and y is an output element, this operation computes
\(y = |x|\).</p>
<p>See <a href="#tf_complex_abs"><code>tf.complex_abs()</code></a> to compute the absolute value of a complex
number.</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>float</code>, <code>double</code>, <code>int32</code>, or <code>int64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
   A <code>Tensor</code> the same size and type as <code>x</code> with absolute values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.abs', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.abs" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.abs_layer">
    <p>def <span class="ident">abs_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.abs_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.abs_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.abs_layer</strong></p>
<div class="codehilite"><pre><span></span>def abs_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.abs, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.abs</strong></p>
<div class="codehilite"><pre><span></span>def abs(x, name=None):
</pre></div>


<p>Computes the absolute value of a tensor.</p>
<p>Given a tensor of real numbers <code>x</code>, this operation returns a tensor
containing the absolute value of each element in <code>x</code>. For example, if x is
an input element and y is an output element, this operation computes
\(y = |x|\).</p>
<p>See <a href="#tf_complex_abs"><code>tf.complex_abs()</code></a> to compute the absolute value of a complex
number.</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>float</code>, <code>double</code>, <code>int32</code>, or <code>int64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
   A <code>Tensor</code> the same size and type as <code>x</code> with absolute values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.abs_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.abs_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.accumulate_n">
    <p>def <span class="ident">accumulate_n</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.accumulate_n, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.accumulate_n</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.accumulate_n</strong></p>
<div class="codehilite"><pre><span></span>def accumulate_n(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.accumulate_n</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.accumulate_n</code></strong></p>
<div class="codehilite"><pre><span></span>def accumulate_n(inputs, shape=None, tensor_dtype=None, name=None)
</pre></div>


<p>Returns the element-wise sum of a list of tensors.</p>
<p>Optionally, pass <code>shape</code> and <code>tensor_dtype</code> for shape and type checking,
otherwise, these are inferred.</p>
<p>For example:</p>
<p>```python</p>
<h1>tensor 'a' is [[1, 2], [3, 4]]</h1>
<h1>tensor <code>b</code> is [[5, 0], [0, 6]]</h1>
<p>tf.accumulate_n([a, b, a]) ==&gt; [[7, 4], [6, 14]]</p>
<h1>Explicitly pass shape and type</h1>
<p>tf.accumulate_n([a, b, a], shape=[2, 2], tensor_dtype=tf.int32)
  ==&gt; [[7, 4], [6, 14]]
```</p>
<p>Args:
  inputs: A list of <code>Tensor</code> objects, each with same shape and type.
  shape: Shape of elements of <code>inputs</code>.
  tensor_dtype: The type of <code>inputs</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of same shape and type as the elements of <code>inputs</code>.</p>
<p>Raises:
  ValueError: If <code>inputs</code> don't all have same shape and dtype or the shape
  cannot be inferred.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.accumulate_n', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.accumulate_n" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.accumulate_n_layer">
    <p>def <span class="ident">accumulate_n_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.accumulate_n_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.accumulate_n_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.accumulate_n_layer</strong></p>
<div class="codehilite"><pre><span></span>def accumulate_n_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.accumulate_n, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.accumulate_n</strong></p>
<div class="codehilite"><pre><span></span>def accumulate_n(inputs, shape=None, tensor_dtype=None, name=None):
</pre></div>


<p>Returns the element-wise sum of a list of tensors.</p>
<p>Optionally, pass <code>shape</code> and <code>tensor_dtype</code> for shape and type checking,
otherwise, these are inferred.</p>
<p>For example:</p>
<p>```python</p>
<h1>tensor 'a' is [[1, 2], [3, 4]]</h1>
<h1>tensor <code>b</code> is [[5, 0], [0, 6]]</h1>
<p>tf.accumulate_n([a, b, a]) ==&gt; [[7, 4], [6, 14]]</p>
<h1>Explicitly pass shape and type</h1>
<p>tf.accumulate_n([a, b, a], shape=[2, 2], tensor_dtype=tf.int32)
  ==&gt; [[7, 4], [6, 14]]
```</p>
<p>Args:
  inputs: A list of <code>Tensor</code> objects, each with same shape and type.
  shape: Shape of elements of <code>inputs</code>.
  tensor_dtype: The type of <code>inputs</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of same shape and type as the elements of <code>inputs</code>.</p>
<p>Raises:
  ValueError: If <code>inputs</code> don't all have same shape and dtype or the shape
  cannot be inferred.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.accumulate_n_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.accumulate_n_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.acos">
    <p>def <span class="ident">acos</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.acos, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.acos</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.acos</strong></p>
<div class="codehilite"><pre><span></span>def acos(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.acos</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.acos</code></strong></p>
<div class="codehilite"><pre><span></span>def acos(x, name=None)
</pre></div>


<p>Computes acos of x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.acos', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.acos" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.acos_layer">
    <p>def <span class="ident">acos_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.acos_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.acos_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.acos_layer</strong></p>
<div class="codehilite"><pre><span></span>def acos_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.acos, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.acos</strong></p>
<div class="codehilite"><pre><span></span>def acos(x, name=None):
</pre></div>


<p>Computes acos of x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.acos_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.acos_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.add">
    <p>def <span class="ident">add</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.add, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.add</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.add</strong></p>
<div class="codehilite"><pre><span></span>def add(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.add</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.add</code></strong></p>
<div class="codehilite"><pre><span></span>def add(x, y, name=None)
</pre></div>


<p>Returns x + y element-wise.</p>
<p><em>NOTE</em>: Add supports broadcasting. AddN does not.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>, <code>string</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.add', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.add" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.add_check_numerics_ops">
    <p>def <span class="ident">add_check_numerics_ops</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.add_check_numerics_ops, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.add_check_numerics_ops</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.add_check_numerics_ops</strong></p>
<div class="codehilite"><pre><span></span>def add_check_numerics_ops(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.add_check_numerics_ops</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.add_check_numerics_ops</code></strong></p>
<div class="codehilite"><pre><span></span>def add_check_numerics_ops()
</pre></div>


<p>Connect a <code>check_numerics</code> to every floating point tensor.</p>
<p><code>check_numerics</code> operations themselves are added for each <code>float</code> or <code>double</code>
tensor in the graph. For all ops in the graph, the <code>check_numerics</code> op for
all of its (<code>float</code> or <code>double</code>) inputs is guaranteed to run before the
<code>check_numerics</code> op on any of its outputs.</p>
<p>Returns:
  A <code>group</code> op depending on all <code>check_numerics</code> ops added.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.add_check_numerics_ops', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.add_check_numerics_ops" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.add_check_numerics_ops_layer">
    <p>def <span class="ident">add_check_numerics_ops_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.add_check_numerics_ops_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.add_check_numerics_ops_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.add_check_numerics_ops_layer</strong></p>
<div class="codehilite"><pre><span></span>def add_check_numerics_ops_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.add_check_numerics_ops, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.add_check_numerics_ops</strong></p>
<div class="codehilite"><pre><span></span>def add_check_numerics_ops():
</pre></div>


<p>Connect a <code>check_numerics</code> to every floating point tensor.</p>
<p><code>check_numerics</code> operations themselves are added for each <code>float</code> or <code>double</code>
tensor in the graph. For all ops in the graph, the <code>check_numerics</code> op for
all of its (<code>float</code> or <code>double</code>) inputs is guaranteed to run before the
<code>check_numerics</code> op on any of its outputs.</p>
<p>Returns:
  A <code>group</code> op depending on all <code>check_numerics</code> ops added.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.add_check_numerics_ops_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.add_check_numerics_ops_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.add_layer">
    <p>def <span class="ident">add_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.add_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.add_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.add_layer</strong></p>
<div class="codehilite"><pre><span></span>def add_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.add, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.add</strong></p>
<div class="codehilite"><pre><span></span>def add(x, y, name=None):
</pre></div>


<p>Returns x + y element-wise.</p>
<p><em>NOTE</em>: Add supports broadcasting. AddN does not.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>, <code>string</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.add_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.add_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.add_n">
    <p>def <span class="ident">add_n</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.add_n, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.add_n</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.add_n</strong></p>
<div class="codehilite"><pre><span></span>def add_n(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.add_n</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.add_n</code></strong></p>
<div class="codehilite"><pre><span></span>def add_n(inputs, name=None)
</pre></div>


<p>Add all input tensors element wise.</p>
<p>Args:
  inputs: A list of at least 1 <code>Tensor</code> objects of the same type in: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Must all be the same size and shape.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>inputs</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.add_n', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.add_n" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.add_n_layer">
    <p>def <span class="ident">add_n_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.add_n_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.add_n_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.add_n_layer</strong></p>
<div class="codehilite"><pre><span></span>def add_n_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.add_n, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.add_n</strong></p>
<div class="codehilite"><pre><span></span>def add_n(inputs, name=None):
</pre></div>


<p>Add all input tensors element wise.</p>
<p>Args:
  inputs: A list of at least 1 <code>Tensor</code> objects of the same type in: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Must all be the same size and shape.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>inputs</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.add_n_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.add_n_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.add_to_collection">
    <p>def <span class="ident">add_to_collection</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.add_to_collection, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.add_to_collection</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.add_to_collection</strong></p>
<div class="codehilite"><pre><span></span>def add_to_collection(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.add_to_collection</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.add_to_collection</code></strong></p>
<div class="codehilite"><pre><span></span>def add_to_collection(name, value)
</pre></div>


<p>Wrapper for <code>Graph.add_to_collection()</code> using the default graph.</p>
<p>See <a href="../../api_docs/python/framework.md#Graph.add_to_collection"><code>Graph.add_to_collection()</code></a>
for more details.</p>
<p>Args:
  name: The key for the collection. For example, the <code>GraphKeys</code> class
    contains many standard names for collections.
  value: The value to add to the collection.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.add_to_collection', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.add_to_collection" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.add_to_collection_layer">
    <p>def <span class="ident">add_to_collection_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.add_to_collection_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.add_to_collection_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.add_to_collection_layer</strong></p>
<div class="codehilite"><pre><span></span>def add_to_collection_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.add_to_collection, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.add_to_collection</strong></p>
<div class="codehilite"><pre><span></span>def add_to_collection(name, value):
</pre></div>


<p>Wrapper for <code>Graph.add_to_collection()</code> using the default graph.</p>
<p>See <a href="../../api_docs/python/framework.md#Graph.add_to_collection"><code>Graph.add_to_collection()</code></a>
for more details.</p>
<p>Args:
  name: The key for the collection. For example, the <code>GraphKeys</code> class
    contains many standard names for collections.
  value: The value to add to the collection.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.add_to_collection_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.add_to_collection_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.all_candidate_sampler">
    <p>def <span class="ident">all_candidate_sampler</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.all_candidate_sampler, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.all_candidate_sampler</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.all_candidate_sampler</strong></p>
<div class="codehilite"><pre><span></span>def all_candidate_sampler(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.all_candidate_sampler</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.all_candidate_sampler</code></strong></p>
<div class="codehilite"><pre><span></span>def all_candidate_sampler(true_classes, num_true, num_sampled, unique, seed=None, name=None)
</pre></div>


<p>Generate the set of all classes.</p>
<p>Deterministically generates and returns the set of all possible classes.
For testing purposes.  There is no need to use this, since you might as
well use full softmax or full logistic regression.</p>
<p>Args:
  true_classes: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
    num_true]</code>. The target classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  num_sampled: An <code>int</code>.  The number of possible classes.
  unique: A <code>bool</code>. Ignored.
    unique.
  seed: An <code>int</code>. An operation-specific seed. Default is 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  sampled_candidates: A tensor of type <code>int64</code> and shape <code>[num_sampled]</code>.
    This operation deterministically returns the entire range
    <code>[0, num_sampled]</code>.
  true_expected_count: A tensor of type <code>float</code>.  Same shape as
    <code>true_classes</code>. The expected counts under the sampling distribution
    of each of <code>true_classes</code>. All returned values are 1.0.
  sampled_expected_count: A tensor of type <code>float</code>. Same shape as
    <code>sampled_candidates</code>. The expected counts under the sampling distribution
    of each of <code>sampled_candidates</code>. All returned values are 1.0.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.all_candidate_sampler', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.all_candidate_sampler" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.all_candidate_sampler_layer">
    <p>def <span class="ident">all_candidate_sampler_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.all_candidate_sampler_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.all_candidate_sampler_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.all_candidate_sampler_layer</strong></p>
<div class="codehilite"><pre><span></span>def all_candidate_sampler_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.all_candidate_sampler, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.all_candidate_sampler</strong></p>
<div class="codehilite"><pre><span></span>def all_candidate_sampler(true_classes, num_true, num_sampled, unique, seed=None, name=None):
</pre></div>


<p>Generate the set of all classes.</p>
<p>Deterministically generates and returns the set of all possible classes.
For testing purposes.  There is no need to use this, since you might as
well use full softmax or full logistic regression.</p>
<p>Args:
  true_classes: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
    num_true]</code>. The target classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  num_sampled: An <code>int</code>.  The number of possible classes.
  unique: A <code>bool</code>. Ignored.
    unique.
  seed: An <code>int</code>. An operation-specific seed. Default is 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  sampled_candidates: A tensor of type <code>int64</code> and shape <code>[num_sampled]</code>.
    This operation deterministically returns the entire range
    <code>[0, num_sampled]</code>.
  true_expected_count: A tensor of type <code>float</code>.  Same shape as
    <code>true_classes</code>. The expected counts under the sampling distribution
    of each of <code>true_classes</code>. All returned values are 1.0.
  sampled_expected_count: A tensor of type <code>float</code>. Same shape as
    <code>sampled_candidates</code>. The expected counts under the sampling distribution
    of each of <code>sampled_candidates</code>. All returned values are 1.0.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.all_candidate_sampler_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.all_candidate_sampler_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.all_variables">
    <p>def <span class="ident">all_variables</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.all_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.all_variables</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.all_variables</strong></p>
<div class="codehilite"><pre><span></span>def all_variables(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.all_variables</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.all_variables</code></strong></p>
<div class="codehilite"><pre><span></span>def all_variables()
</pre></div>


<p>Returns all variables that must be saved/restored.</p>
<p>The <code>Variable()</code> constructor automatically adds new variables to the graph
collection <code>GraphKeys.VARIABLES</code>. This convenience function returns the
contents of that collection.</p>
<p>Returns:
  A list of <code>Variable</code> objects.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.all_variables', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.all_variables" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.all_variables_layer">
    <p>def <span class="ident">all_variables_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.all_variables_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.all_variables_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.all_variables_layer</strong></p>
<div class="codehilite"><pre><span></span>def all_variables_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.all_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.all_variables</strong></p>
<div class="codehilite"><pre><span></span>def all_variables():
</pre></div>


<p>Returns all variables that must be saved/restored.</p>
<p>The <code>Variable()</code> constructor automatically adds new variables to the graph
collection <code>GraphKeys.VARIABLES</code>. This convenience function returns the
contents of that collection.</p>
<p>Returns:
  A list of <code>Variable</code> objects.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.all_variables_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.all_variables_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.arg_max">
    <p>def <span class="ident">arg_max</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.arg_max, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.arg_max</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.arg_max</strong></p>
<div class="codehilite"><pre><span></span>def arg_max(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.arg_max</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.arg_max</code></strong></p>
<div class="codehilite"><pre><span></span>def arg_max(input, dimension, name=None)
</pre></div>


<p>Returns the index with the largest value across dimensions of a tensor.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  dimension: A <code>Tensor</code> of type <code>int32</code>.
    int32, 0 &lt;= dimension &lt; rank(input).  Describes which dimension
    of the input Tensor to reduce across. For vectors, use dimension = 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.arg_max', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.arg_max" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.arg_max_layer">
    <p>def <span class="ident">arg_max_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.arg_max_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.arg_max_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.arg_max_layer</strong></p>
<div class="codehilite"><pre><span></span>def arg_max_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.arg_max, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.arg_max</strong></p>
<div class="codehilite"><pre><span></span>def arg_max(input, dimension, name=None):
</pre></div>


<p>Returns the index with the largest value across dimensions of a tensor.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  dimension: A <code>Tensor</code> of type <code>int32</code>.
    int32, 0 &lt;= dimension &lt; rank(input).  Describes which dimension
    of the input Tensor to reduce across. For vectors, use dimension = 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.arg_max_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.arg_max_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.arg_min">
    <p>def <span class="ident">arg_min</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.arg_min, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.arg_min</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.arg_min</strong></p>
<div class="codehilite"><pre><span></span>def arg_min(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.arg_min</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.arg_min</code></strong></p>
<div class="codehilite"><pre><span></span>def arg_min(input, dimension, name=None)
</pre></div>


<p>Returns the index with the smallest value across dimensions of a tensor.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  dimension: A <code>Tensor</code> of type <code>int32</code>.
    int32, 0 &lt;= dimension &lt; rank(input).  Describes which dimension
    of the input Tensor to reduce across. For vectors, use dimension = 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.arg_min', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.arg_min" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.arg_min_layer">
    <p>def <span class="ident">arg_min_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.arg_min_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.arg_min_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.arg_min_layer</strong></p>
<div class="codehilite"><pre><span></span>def arg_min_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.arg_min, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.arg_min</strong></p>
<div class="codehilite"><pre><span></span>def arg_min(input, dimension, name=None):
</pre></div>


<p>Returns the index with the smallest value across dimensions of a tensor.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  dimension: A <code>Tensor</code> of type <code>int32</code>.
    int32, 0 &lt;= dimension &lt; rank(input).  Describes which dimension
    of the input Tensor to reduce across. For vectors, use dimension = 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.arg_min_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.arg_min_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.argmax_layer">
    <p>def <span class="ident">argmax_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.argmax_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.argmax_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.argmax_layer</strong></p>
<div class="codehilite"><pre><span></span>def argmax_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.argmax, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.argmax</strong></p>
<div class="codehilite"><pre><span></span>def arg_max(input, dimension, name=None):
</pre></div>


<p>Returns the index with the largest value across dimensions of a tensor.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  dimension: A <code>Tensor</code> of type <code>int32</code>.
    int32, 0 &lt;= dimension &lt; rank(input).  Describes which dimension
    of the input Tensor to reduce across. For vectors, use dimension = 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.argmax_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.argmax_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.argmin_layer">
    <p>def <span class="ident">argmin_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.argmin_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.argmin_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.argmin_layer</strong></p>
<div class="codehilite"><pre><span></span>def argmin_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.argmin, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.argmin</strong></p>
<div class="codehilite"><pre><span></span>def arg_min(input, dimension, name=None):
</pre></div>


<p>Returns the index with the smallest value across dimensions of a tensor.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  dimension: A <code>Tensor</code> of type <code>int32</code>.
    int32, 0 &lt;= dimension &lt; rank(input).  Describes which dimension
    of the input Tensor to reduce across. For vectors, use dimension = 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.argmin_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.argmin_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.as_dtype">
    <p>def <span class="ident">as_dtype</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.as_dtype, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.as_dtype</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.as_dtype</strong></p>
<div class="codehilite"><pre><span></span>def as_dtype(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.as_dtype</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.as_dtype</code></strong></p>
<div class="codehilite"><pre><span></span>def as_dtype(type_value)
</pre></div>


<p>Converts the given <code>type_value</code> to a <code>DType</code>.</p>
<p>Args:
  type_value: A value that can be converted to a <code>tf.DType</code>
    object. This may currently be a <code>tf.DType</code> object, a
    <a href="https://www.tensorflow.org/code/tensorflow/core/framework/types.proto"><code>DataType</code> enum</a>,
    a string type name, or a <code>numpy.dtype</code>.</p>
<p>Returns:
  A <code>DType</code> corresponding to <code>type_value</code>.</p>
<p>Raises:
  TypeError: If <code>type_value</code> cannot be converted to a <code>DType</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.as_dtype', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.as_dtype" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.as_dtype_layer">
    <p>def <span class="ident">as_dtype_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.as_dtype_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.as_dtype_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.as_dtype_layer</strong></p>
<div class="codehilite"><pre><span></span>def as_dtype_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.as_dtype, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.as_dtype</strong></p>
<div class="codehilite"><pre><span></span>def as_dtype(type_value):
</pre></div>


<p>Converts the given <code>type_value</code> to a <code>DType</code>.</p>
<p>Args:
  type_value: A value that can be converted to a <code>tf.DType</code>
    object. This may currently be a <code>tf.DType</code> object, a
    <a href="https://www.tensorflow.org/code/tensorflow/core/framework/types.proto"><code>DataType</code> enum</a>,
    a string type name, or a <code>numpy.dtype</code>.</p>
<p>Returns:
  A <code>DType</code> corresponding to <code>type_value</code>.</p>
<p>Raises:
  TypeError: If <code>type_value</code> cannot be converted to a <code>DType</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.as_dtype_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.as_dtype_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.asin">
    <p>def <span class="ident">asin</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.asin, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.asin</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.asin</strong></p>
<div class="codehilite"><pre><span></span>def asin(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.asin</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.asin</code></strong></p>
<div class="codehilite"><pre><span></span>def asin(x, name=None)
</pre></div>


<p>Computes asin of x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.asin', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.asin" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.asin_layer">
    <p>def <span class="ident">asin_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.asin_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.asin_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.asin_layer</strong></p>
<div class="codehilite"><pre><span></span>def asin_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.asin, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.asin</strong></p>
<div class="codehilite"><pre><span></span>def asin(x, name=None):
</pre></div>


<p>Computes asin of x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.asin_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.asin_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_equal">
    <p>def <span class="ident">assert_equal</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_equal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_equal</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_equal</strong></p>
<div class="codehilite"><pre><span></span>def assert_equal(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assert_equal</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assert_equal</code></strong></p>
<div class="codehilite"><pre><span></span>def assert_equal(x, y, data=None, summarize=None, name=None)
</pre></div>


<p>Assert the condition <code>x == y</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_equal(x, y)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_equal(x, y)], x)</code></p>
<p>This condition holds if for every pair of (possibly broadcast) elements
<code>x[i]</code>, <code>y[i]</code>, we have <code>x[i] == y[i]</code>.
If both <code>x</code> and <code>y</code> are empty, this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  y:  Numeric <code>Tensor</code>, same dtype as and broadcastable to <code>x</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>, <code>y</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_equal".</p>
<p>Returns:
  Op that raises <code>InvalidArgumentError</code> if <code>x == y</code> is False.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_equal', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_equal" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_equal_layer">
    <p>def <span class="ident">assert_equal_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_equal_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_equal_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_equal_layer</strong></p>
<div class="codehilite"><pre><span></span>def assert_equal_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assert_equal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assert_equal</strong></p>
<div class="codehilite"><pre><span></span>def assert_equal(x, y, data=None, summarize=None, name=None):
</pre></div>


<p>Assert the condition <code>x == y</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_equal(x, y)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_equal(x, y)], x)</code></p>
<p>This condition holds if for every pair of (possibly broadcast) elements
<code>x[i]</code>, <code>y[i]</code>, we have <code>x[i] == y[i]</code>.
If both <code>x</code> and <code>y</code> are empty, this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  y:  Numeric <code>Tensor</code>, same dtype as and broadcastable to <code>x</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>, <code>y</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_equal".</p>
<p>Returns:
  Op that raises <code>InvalidArgumentError</code> if <code>x == y</code> is False.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_equal_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_equal_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_integer">
    <p>def <span class="ident">assert_integer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_integer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_integer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_integer</strong></p>
<div class="codehilite"><pre><span></span>def assert_integer(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assert_integer</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assert_integer</code></strong></p>
<div class="codehilite"><pre><span></span>def assert_integer(x, data=None, summarize=None, name=None)
</pre></div>


<p>Assert that <code>x</code> is of integer dtype.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_integer(x)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_integer(x)], x)</code></p>
<p>Args:
  x: <code>Tensor</code> whose basetype is integer and is not quantized.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_integer".</p>
<p>Returns:
  Op that raises <code>InvalidArgumentError</code> if <code>x == y</code> is False.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_integer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_integer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_integer_layer">
    <p>def <span class="ident">assert_integer_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_integer_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_integer_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_integer_layer</strong></p>
<div class="codehilite"><pre><span></span>def assert_integer_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assert_integer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assert_integer</strong></p>
<div class="codehilite"><pre><span></span>def assert_integer(x, data=None, summarize=None, name=None):
</pre></div>


<p>Assert that <code>x</code> is of integer dtype.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_integer(x)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_integer(x)], x)</code></p>
<p>Args:
  x: <code>Tensor</code> whose basetype is integer and is not quantized.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_integer".</p>
<p>Returns:
  Op that raises <code>InvalidArgumentError</code> if <code>x == y</code> is False.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_integer_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_integer_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_less">
    <p>def <span class="ident">assert_less</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_less, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_less</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_less</strong></p>
<div class="codehilite"><pre><span></span>def assert_less(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assert_less</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assert_less</code></strong></p>
<div class="codehilite"><pre><span></span>def assert_less(x, y, data=None, summarize=None, name=None)
</pre></div>


<p>Assert the condition <code>x &lt; y</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_less(x, y)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_less(x, y)], x)</code></p>
<p>This condition holds if for every pair of (possibly broadcast) elements
<code>x[i]</code>, <code>y[i]</code>, we have <code>x[i] &lt; y[i]</code>.
If both <code>x</code> and <code>y</code> are empty, this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  y:  Numeric <code>Tensor</code>, same dtype as and broadcastable to <code>x</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>, <code>y</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_less".</p>
<p>Returns:
  Op that raises <code>InvalidArgumentError</code> if <code>x &lt; y</code> is False.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_less', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_less" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_less_equal">
    <p>def <span class="ident">assert_less_equal</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_less_equal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_less_equal</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_less_equal</strong></p>
<div class="codehilite"><pre><span></span>def assert_less_equal(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assert_less_equal</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assert_less_equal</code></strong></p>
<div class="codehilite"><pre><span></span>def assert_less_equal(x, y, data=None, summarize=None, name=None)
</pre></div>


<p>Assert the condition <code>x &lt;= y</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_less_equal(x, y)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_less_equal(x, y)], x)</code></p>
<p>This condition holds if for every pair of (possibly broadcast) elements
<code>x[i]</code>, <code>y[i]</code>, we have <code>x[i] &lt;= y[i]</code>.
If both <code>x</code> and <code>y</code> are empty, this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  y:  Numeric <code>Tensor</code>, same dtype as and broadcastable to <code>x</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>, <code>y</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_less_equal"</p>
<p>Returns:
  Op that raises <code>InvalidArgumentError</code> if <code>x &lt;= y</code> is False.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_less_equal', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_less_equal" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_less_equal_layer">
    <p>def <span class="ident">assert_less_equal_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_less_equal_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_less_equal_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_less_equal_layer</strong></p>
<div class="codehilite"><pre><span></span>def assert_less_equal_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assert_less_equal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assert_less_equal</strong></p>
<div class="codehilite"><pre><span></span>def assert_less_equal(x, y, data=None, summarize=None, name=None):
</pre></div>


<p>Assert the condition <code>x &lt;= y</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_less_equal(x, y)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_less_equal(x, y)], x)</code></p>
<p>This condition holds if for every pair of (possibly broadcast) elements
<code>x[i]</code>, <code>y[i]</code>, we have <code>x[i] &lt;= y[i]</code>.
If both <code>x</code> and <code>y</code> are empty, this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  y:  Numeric <code>Tensor</code>, same dtype as and broadcastable to <code>x</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>, <code>y</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_less_equal"</p>
<p>Returns:
  Op that raises <code>InvalidArgumentError</code> if <code>x &lt;= y</code> is False.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_less_equal_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_less_equal_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_less_layer">
    <p>def <span class="ident">assert_less_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_less_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_less_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_less_layer</strong></p>
<div class="codehilite"><pre><span></span>def assert_less_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assert_less, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assert_less</strong></p>
<div class="codehilite"><pre><span></span>def assert_less(x, y, data=None, summarize=None, name=None):
</pre></div>


<p>Assert the condition <code>x &lt; y</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_less(x, y)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_less(x, y)], x)</code></p>
<p>This condition holds if for every pair of (possibly broadcast) elements
<code>x[i]</code>, <code>y[i]</code>, we have <code>x[i] &lt; y[i]</code>.
If both <code>x</code> and <code>y</code> are empty, this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  y:  Numeric <code>Tensor</code>, same dtype as and broadcastable to <code>x</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>, <code>y</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_less".</p>
<p>Returns:
  Op that raises <code>InvalidArgumentError</code> if <code>x &lt; y</code> is False.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_less_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_less_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_negative">
    <p>def <span class="ident">assert_negative</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_negative, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_negative</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_negative</strong></p>
<div class="codehilite"><pre><span></span>def assert_negative(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assert_negative</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assert_negative</code></strong></p>
<div class="codehilite"><pre><span></span>def assert_negative(x, data=None, summarize=None, name=None)
</pre></div>


<p>Assert the condition <code>x &lt; 0</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_negative(x)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_negative(x)], x)</code></p>
<p>Negative means, for every element <code>x[i]</code> of <code>x</code>, we have <code>x[i] &lt; 0</code>.
If <code>x</code> is empty this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_negative".</p>
<p>Returns:
  Op raising <code>InvalidArgumentError</code> unless <code>x</code> is all negative.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_negative', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_negative" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_negative_layer">
    <p>def <span class="ident">assert_negative_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_negative_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_negative_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_negative_layer</strong></p>
<div class="codehilite"><pre><span></span>def assert_negative_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assert_negative, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assert_negative</strong></p>
<div class="codehilite"><pre><span></span>def assert_negative(x, data=None, summarize=None, name=None):
</pre></div>


<p>Assert the condition <code>x &lt; 0</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_negative(x)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_negative(x)], x)</code></p>
<p>Negative means, for every element <code>x[i]</code> of <code>x</code>, we have <code>x[i] &lt; 0</code>.
If <code>x</code> is empty this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_negative".</p>
<p>Returns:
  Op raising <code>InvalidArgumentError</code> unless <code>x</code> is all negative.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_negative_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_negative_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_non_negative">
    <p>def <span class="ident">assert_non_negative</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_non_negative, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_non_negative</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_non_negative</strong></p>
<div class="codehilite"><pre><span></span>def assert_non_negative(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assert_non_negative</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assert_non_negative</code></strong></p>
<div class="codehilite"><pre><span></span>def assert_non_negative(x, data=None, summarize=None, name=None)
</pre></div>


<p>Assert the condition <code>x &gt;= 0</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_non_negative(x)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_non_negative(x)], x)</code></p>
<p>Non-negative means, for every element <code>x[i]</code> of <code>x</code>, we have <code>x[i] &gt;= 0</code>.
If <code>x</code> is empty this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).
    Defaults to "assert_non_negative".</p>
<p>Returns:
  Op raising <code>InvalidArgumentError</code> unless <code>x</code> is all non-negative.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_non_negative', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_non_negative" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_non_negative_layer">
    <p>def <span class="ident">assert_non_negative_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_non_negative_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_non_negative_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_non_negative_layer</strong></p>
<div class="codehilite"><pre><span></span>def assert_non_negative_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assert_non_negative, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assert_non_negative</strong></p>
<div class="codehilite"><pre><span></span>def assert_non_negative(x, data=None, summarize=None, name=None):
</pre></div>


<p>Assert the condition <code>x &gt;= 0</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_non_negative(x)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_non_negative(x)], x)</code></p>
<p>Non-negative means, for every element <code>x[i]</code> of <code>x</code>, we have <code>x[i] &gt;= 0</code>.
If <code>x</code> is empty this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).
    Defaults to "assert_non_negative".</p>
<p>Returns:
  Op raising <code>InvalidArgumentError</code> unless <code>x</code> is all non-negative.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_non_negative_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_non_negative_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_non_positive">
    <p>def <span class="ident">assert_non_positive</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_non_positive, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_non_positive</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_non_positive</strong></p>
<div class="codehilite"><pre><span></span>def assert_non_positive(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assert_non_positive</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assert_non_positive</code></strong></p>
<div class="codehilite"><pre><span></span>def assert_non_positive(x, data=None, summarize=None, name=None)
</pre></div>


<p>Assert the condition <code>x &lt;= 0</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_non_positive(x)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_non_positive(x)], x)</code></p>
<p>Non-positive means, for every element <code>x[i]</code> of <code>x</code>, we have <code>x[i] &lt;= 0</code>.
If <code>x</code> is empty this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).
    Defaults to "assert_non_positive".</p>
<p>Returns:
  Op raising <code>InvalidArgumentError</code> unless <code>x</code> is all non-positive.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_non_positive', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_non_positive" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_non_positive_layer">
    <p>def <span class="ident">assert_non_positive_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_non_positive_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_non_positive_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_non_positive_layer</strong></p>
<div class="codehilite"><pre><span></span>def assert_non_positive_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assert_non_positive, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assert_non_positive</strong></p>
<div class="codehilite"><pre><span></span>def assert_non_positive(x, data=None, summarize=None, name=None):
</pre></div>


<p>Assert the condition <code>x &lt;= 0</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_non_positive(x)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_non_positive(x)], x)</code></p>
<p>Non-positive means, for every element <code>x[i]</code> of <code>x</code>, we have <code>x[i] &lt;= 0</code>.
If <code>x</code> is empty this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).
    Defaults to "assert_non_positive".</p>
<p>Returns:
  Op raising <code>InvalidArgumentError</code> unless <code>x</code> is all non-positive.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_non_positive_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_non_positive_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_positive">
    <p>def <span class="ident">assert_positive</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_positive, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_positive</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_positive</strong></p>
<div class="codehilite"><pre><span></span>def assert_positive(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assert_positive</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assert_positive</code></strong></p>
<div class="codehilite"><pre><span></span>def assert_positive(x, data=None, summarize=None, name=None)
</pre></div>


<p>Assert the condition <code>x &gt; 0</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_positive(x)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_positive(x)], x)</code></p>
<p>Positive means, for every element <code>x[i]</code> of <code>x</code>, we have <code>x[i] &gt; 0</code>.
If <code>x</code> is empty this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_positive".</p>
<p>Returns:
  Op raising <code>InvalidArgumentError</code> unless <code>x</code> is all positive.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_positive', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_positive" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_positive_layer">
    <p>def <span class="ident">assert_positive_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_positive_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_positive_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_positive_layer</strong></p>
<div class="codehilite"><pre><span></span>def assert_positive_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assert_positive, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assert_positive</strong></p>
<div class="codehilite"><pre><span></span>def assert_positive(x, data=None, summarize=None, name=None):
</pre></div>


<p>Assert the condition <code>x &gt; 0</code> holds element-wise.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_positive(x)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_positive(x)], x)</code></p>
<p>Positive means, for every element <code>x[i]</code> of <code>x</code>, we have <code>x[i] &gt; 0</code>.
If <code>x</code> is empty this is trivially satisfied.</p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_positive".</p>
<p>Returns:
  Op raising <code>InvalidArgumentError</code> unless <code>x</code> is all positive.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_positive_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_positive_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_proper_iterable">
    <p>def <span class="ident">assert_proper_iterable</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_proper_iterable, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_proper_iterable</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_proper_iterable</strong></p>
<div class="codehilite"><pre><span></span>def assert_proper_iterable(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assert_proper_iterable</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assert_proper_iterable</code></strong></p>
<div class="codehilite"><pre><span></span>def assert_proper_iterable(values)
</pre></div>


<p>Static assert that values is a "proper" iterable.</p>
<p><code>Ops</code> that expect iterables of <code>Tensor</code> can call this to validate input.
Useful since <code>Tensor</code>, <code>ndarray</code>, byte/text type are all iterables themselves.</p>
<p>Args:
  values:  Object to be checked.</p>
<p>Raises:
  TypeError:  If <code>values</code> is not iterable or is one of
    <code>Tensor</code>, <code>SparseTensor</code>, <code>np.array</code>, <code>tf.compat.bytes_or_text_types</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_proper_iterable', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_proper_iterable" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_proper_iterable_layer">
    <p>def <span class="ident">assert_proper_iterable_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_proper_iterable_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_proper_iterable_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_proper_iterable_layer</strong></p>
<div class="codehilite"><pre><span></span>def assert_proper_iterable_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assert_proper_iterable, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assert_proper_iterable</strong></p>
<div class="codehilite"><pre><span></span>def assert_proper_iterable(values):
</pre></div>


<p>Static assert that values is a "proper" iterable.</p>
<p><code>Ops</code> that expect iterables of <code>Tensor</code> can call this to validate input.
Useful since <code>Tensor</code>, <code>ndarray</code>, byte/text type are all iterables themselves.</p>
<p>Args:
  values:  Object to be checked.</p>
<p>Raises:
  TypeError:  If <code>values</code> is not iterable or is one of
    <code>Tensor</code>, <code>SparseTensor</code>, <code>np.array</code>, <code>tf.compat.bytes_or_text_types</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_proper_iterable_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_proper_iterable_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_rank">
    <p>def <span class="ident">assert_rank</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_rank, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_rank</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_rank</strong></p>
<div class="codehilite"><pre><span></span>def assert_rank(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assert_rank</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assert_rank</code></strong></p>
<div class="codehilite"><pre><span></span>def assert_rank(x, rank, data=None, summarize=None, name=None)
</pre></div>


<p>Assert <code>x</code> has rank equal to <code>rank</code>.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_rank(x, 2)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_rank(x, 2)], x)</code></p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  rank:  Scalar integer <code>Tensor</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_rank".</p>
<p>Returns:
  Op raising <code>InvalidArgumentError</code> unless <code>x</code> has specified rank.</p>
<p>Raises:
  ValueError:  If static checks determine <code>x</code> has wrong rank.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_rank', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_rank" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_rank_at_least">
    <p>def <span class="ident">assert_rank_at_least</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_rank_at_least, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_rank_at_least</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_rank_at_least</strong></p>
<div class="codehilite"><pre><span></span>def assert_rank_at_least(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assert_rank_at_least</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assert_rank_at_least</code></strong></p>
<div class="codehilite"><pre><span></span>def assert_rank_at_least(x, rank, data=None, summarize=None, name=None)
</pre></div>


<p>Assert <code>x</code> has rank equal to <code>rank</code> or higher.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_rank_at_least(x, 2)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_rank_at_least(x, 2)], x)</code></p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  rank:  Scalar <code>Tensor</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).
    Defaults to "assert_rank_at_least".</p>
<p>Returns:
  Op raising <code>InvalidArgumentError</code> unless <code>x</code> has specified rank or higher.</p>
<p>Raises:
  ValueError:  If static checks determine <code>x</code> has wrong rank.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_rank_at_least', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_rank_at_least" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_rank_at_least_layer">
    <p>def <span class="ident">assert_rank_at_least_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_rank_at_least_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_rank_at_least_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_rank_at_least_layer</strong></p>
<div class="codehilite"><pre><span></span>def assert_rank_at_least_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assert_rank_at_least, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assert_rank_at_least</strong></p>
<div class="codehilite"><pre><span></span>def assert_rank_at_least(x, rank, data=None, summarize=None, name=None):
</pre></div>


<p>Assert <code>x</code> has rank equal to <code>rank</code> or higher.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_rank_at_least(x, 2)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_rank_at_least(x, 2)], x)</code></p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  rank:  Scalar <code>Tensor</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).
    Defaults to "assert_rank_at_least".</p>
<p>Returns:
  Op raising <code>InvalidArgumentError</code> unless <code>x</code> has specified rank or higher.</p>
<p>Raises:
  ValueError:  If static checks determine <code>x</code> has wrong rank.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_rank_at_least_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_rank_at_least_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_rank_layer">
    <p>def <span class="ident">assert_rank_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_rank_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_rank_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_rank_layer</strong></p>
<div class="codehilite"><pre><span></span>def assert_rank_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assert_rank, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assert_rank</strong></p>
<div class="codehilite"><pre><span></span>def assert_rank(x, rank, data=None, summarize=None, name=None):
</pre></div>


<p>Assert <code>x</code> has rank equal to <code>rank</code>.</p>
<p>Example of adding a dependency to an operation:</p>
<p><code>python
with tf.control_dependencies([tf.assert_rank(x, 2)]):
  output = tf.reduce_sum(x)</code></p>
<p>Example of adding dependency to the tensor being checked:</p>
<p><code>python
x = tf.with_dependencies([tf.assert_rank(x, 2)], x)</code></p>
<p>Args:
  x:  Numeric <code>Tensor</code>.
  rank:  Scalar integer <code>Tensor</code>.
  data:  The tensors to print out if the condition is False.  Defaults to
    error message and first few entries of <code>x</code>.
  summarize: Print this many entries of each tensor.
  name: A name for this operation (optional).  Defaults to "assert_rank".</p>
<p>Returns:
  Op raising <code>InvalidArgumentError</code> unless <code>x</code> has specified rank.</p>
<p>Raises:
  ValueError:  If static checks determine <code>x</code> has wrong rank.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_rank_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_rank_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_type">
    <p>def <span class="ident">assert_type</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_type, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_type</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_type</strong></p>
<div class="codehilite"><pre><span></span>def assert_type(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assert_type</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assert_type</code></strong></p>
<div class="codehilite"><pre><span></span>def assert_type(tensor, tf_type)
</pre></div>


<p>Asserts that the given <code>Tensor</code> is of the specified type.</p>
<p>Args:
  tensor: A tensorflow <code>Tensor</code>.
  tf_type: A tensorflow type (dtypes.float32, tf.int64, dtypes.bool, etc).</p>
<p>Raises:
  ValueError: If the tensors data type doesn't match tf_type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_type', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_type" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_type_layer">
    <p>def <span class="ident">assert_type_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_type_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_type_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_type_layer</strong></p>
<div class="codehilite"><pre><span></span>def assert_type_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assert_type, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assert_type</strong></p>
<div class="codehilite"><pre><span></span>def assert_type(tensor, tf_type):
</pre></div>


<p>Asserts that the given <code>Tensor</code> is of the specified type.</p>
<p>Args:
  tensor: A tensorflow <code>Tensor</code>.
  tf_type: A tensorflow type (dtypes.float32, tf.int64, dtypes.bool, etc).</p>
<p>Raises:
  ValueError: If the tensors data type doesn't match tf_type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_type_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_type_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_variables_initialized">
    <p>def <span class="ident">assert_variables_initialized</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_variables_initialized, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_variables_initialized</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_variables_initialized</strong></p>
<div class="codehilite"><pre><span></span>def assert_variables_initialized(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assert_variables_initialized</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assert_variables_initialized</code></strong></p>
<div class="codehilite"><pre><span></span>def assert_variables_initialized(var_list=None)
</pre></div>


<p>Returns an Op to check if variables are initialized.</p>
<p>NOTE: This function is obsolete and will be removed in 6 months.  Please
change your implementation to use <code>report_uninitialized_variables()</code>.</p>
<p>When run, the returned Op will raise the exception <code>FailedPreconditionError</code>
if any of the variables has not yet been initialized.</p>
<p>Note: This function is implemented by trying to fetch the values of the
variables. If one of the variables is not initialized a message may be
logged by the C++ runtime. This is expected.</p>
<p>Args:
  var_list: List of <code>Variable</code> objects to check. Defaults to the
    value of <code>all_variables().</code></p>
<p>Returns:
  An Op, or None if there are no variables.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_variables_initialized', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_variables_initialized" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assert_variables_initialized_layer">
    <p>def <span class="ident">assert_variables_initialized_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assert_variables_initialized_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assert_variables_initialized_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assert_variables_initialized_layer</strong></p>
<div class="codehilite"><pre><span></span>def assert_variables_initialized_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assert_variables_initialized, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assert_variables_initialized</strong></p>
<div class="codehilite"><pre><span></span>def assert_variables_initialized(var_list=None):
</pre></div>


<p>Returns an Op to check if variables are initialized.</p>
<p>NOTE: This function is obsolete and will be removed in 6 months.  Please
change your implementation to use <code>report_uninitialized_variables()</code>.</p>
<p>When run, the returned Op will raise the exception <code>FailedPreconditionError</code>
if any of the variables has not yet been initialized.</p>
<p>Note: This function is implemented by trying to fetch the values of the
variables. If one of the variables is not initialized a message may be
logged by the C++ runtime. This is expected.</p>
<p>Args:
  var_list: List of <code>Variable</code> objects to check. Defaults to the
    value of <code>all_variables().</code></p>
<p>Returns:
  An Op, or None if there are no variables.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assert_variables_initialized_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assert_variables_initialized_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assign">
    <p>def <span class="ident">assign</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assign, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assign</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assign</strong></p>
<div class="codehilite"><pre><span></span>def assign(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assign</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assign</code></strong></p>
<div class="codehilite"><pre><span></span>def assign(ref, value, validate_shape=None, use_locking=None, name=None)
</pre></div>


<p>Update 'ref' by assigning 'value' to it.</p>
<p>This operation outputs "ref" after the assignment is done.
This makes it easier to chain operations that need to use the reset value.</p>
<p>Args:
  ref: A mutable <code>Tensor</code>.
    Should be from a <code>Variable</code> node. May be uninitialized.
  value: A <code>Tensor</code>. Must have the same type as <code>ref</code>.
    The value to be assigned to the variable.
  validate_shape: An optional <code>bool</code>. Defaults to <code>True</code>.
    If true, the operation will validate that the shape
    of 'value' matches the shape of the Tensor being assigned to.  If false,
    'ref' will take on the shape of 'value'.
  use_locking: An optional <code>bool</code>. Defaults to <code>True</code>.
    If True, the assignment will be protected by a lock;
    otherwise the behavior is undefined, but may exhibit less contention.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same as "ref".  Returned as a convenience for operations that want
  to use the new value after the variable has been reset.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assign', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assign" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assign_add">
    <p>def <span class="ident">assign_add</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assign_add, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assign_add</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assign_add</strong></p>
<div class="codehilite"><pre><span></span>def assign_add(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assign_add</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assign_add</code></strong></p>
<div class="codehilite"><pre><span></span>def assign_add(ref, value, use_locking=None, name=None)
</pre></div>


<p>Update 'ref' by adding 'value' to it.</p>
<p>This operation outputs "ref" after the update is done.
This makes it easier to chain operations that need to use the reset value.</p>
<p>Args:
  ref: A mutable <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Should be from a <code>Variable</code> node.
  value: A <code>Tensor</code>. Must have the same type as <code>ref</code>.
    The value to be added to the variable.
  use_locking: An optional <code>bool</code>. Defaults to <code>False</code>.
    If True, the addition will be protected by a lock;
    otherwise the behavior is undefined, but may exhibit less contention.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same as "ref".  Returned as a convenience for operations that want
  to use the new value after the variable has been updated.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assign_add', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assign_add" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assign_add_layer">
    <p>def <span class="ident">assign_add_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assign_add_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assign_add_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assign_add_layer</strong></p>
<div class="codehilite"><pre><span></span>def assign_add_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assign_add, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assign_add</strong></p>
<div class="codehilite"><pre><span></span>def assign_add(ref, value, use_locking=None, name=None):
</pre></div>


<p>Update 'ref' by adding 'value' to it.</p>
<p>This operation outputs "ref" after the update is done.
This makes it easier to chain operations that need to use the reset value.</p>
<p>Args:
  ref: A mutable <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Should be from a <code>Variable</code> node.
  value: A <code>Tensor</code>. Must have the same type as <code>ref</code>.
    The value to be added to the variable.
  use_locking: An optional <code>bool</code>. Defaults to <code>False</code>.
    If True, the addition will be protected by a lock;
    otherwise the behavior is undefined, but may exhibit less contention.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same as "ref".  Returned as a convenience for operations that want
  to use the new value after the variable has been updated.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assign_add_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assign_add_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assign_layer">
    <p>def <span class="ident">assign_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assign_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assign_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assign_layer</strong></p>
<div class="codehilite"><pre><span></span>def assign_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assign, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assign</strong></p>
<div class="codehilite"><pre><span></span>def assign(ref, value, validate_shape=None, use_locking=None, name=None):
</pre></div>


<p>Update 'ref' by assigning 'value' to it.</p>
<p>This operation outputs "ref" after the assignment is done.
This makes it easier to chain operations that need to use the reset value.</p>
<p>Args:
  ref: A mutable <code>Tensor</code>.
    Should be from a <code>Variable</code> node. May be uninitialized.
  value: A <code>Tensor</code>. Must have the same type as <code>ref</code>.
    The value to be assigned to the variable.
  validate_shape: An optional <code>bool</code>. Defaults to <code>True</code>.
    If true, the operation will validate that the shape
    of 'value' matches the shape of the Tensor being assigned to.  If false,
    'ref' will take on the shape of 'value'.
  use_locking: An optional <code>bool</code>. Defaults to <code>True</code>.
    If True, the assignment will be protected by a lock;
    otherwise the behavior is undefined, but may exhibit less contention.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same as "ref".  Returned as a convenience for operations that want
  to use the new value after the variable has been reset.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assign_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assign_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assign_sub">
    <p>def <span class="ident">assign_sub</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assign_sub, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assign_sub</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assign_sub</strong></p>
<div class="codehilite"><pre><span></span>def assign_sub(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.assign_sub</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.assign_sub</code></strong></p>
<div class="codehilite"><pre><span></span>def assign_sub(ref, value, use_locking=None, name=None)
</pre></div>


<p>Update 'ref' by subtracting 'value' from it.</p>
<p>This operation outputs "ref" after the update is done.
This makes it easier to chain operations that need to use the reset value.</p>
<p>Args:
  ref: A mutable <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Should be from a <code>Variable</code> node.
  value: A <code>Tensor</code>. Must have the same type as <code>ref</code>.
    The value to be subtracted to the variable.
  use_locking: An optional <code>bool</code>. Defaults to <code>False</code>.
    If True, the subtraction will be protected by a lock;
    otherwise the behavior is undefined, but may exhibit less contention.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same as "ref".  Returned as a convenience for operations that want
  to use the new value after the variable has been updated.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assign_sub', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assign_sub" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.assign_sub_layer">
    <p>def <span class="ident">assign_sub_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.assign_sub_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.assign_sub_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.assign_sub_layer</strong></p>
<div class="codehilite"><pre><span></span>def assign_sub_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.assign_sub, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.assign_sub</strong></p>
<div class="codehilite"><pre><span></span>def assign_sub(ref, value, use_locking=None, name=None):
</pre></div>


<p>Update 'ref' by subtracting 'value' from it.</p>
<p>This operation outputs "ref" after the update is done.
This makes it easier to chain operations that need to use the reset value.</p>
<p>Args:
  ref: A mutable <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Should be from a <code>Variable</code> node.
  value: A <code>Tensor</code>. Must have the same type as <code>ref</code>.
    The value to be subtracted to the variable.
  use_locking: An optional <code>bool</code>. Defaults to <code>False</code>.
    If True, the subtraction will be protected by a lock;
    otherwise the behavior is undefined, but may exhibit less contention.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same as "ref".  Returned as a convenience for operations that want
  to use the new value after the variable has been updated.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.assign_sub_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.assign_sub_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.atan">
    <p>def <span class="ident">atan</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.atan, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.atan</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.atan</strong></p>
<div class="codehilite"><pre><span></span>def atan(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.atan</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.atan</code></strong></p>
<div class="codehilite"><pre><span></span>def atan(x, name=None)
</pre></div>


<p>Computes atan of x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.atan', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.atan" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.atan_layer">
    <p>def <span class="ident">atan_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.atan_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.atan_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.atan_layer</strong></p>
<div class="codehilite"><pre><span></span>def atan_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.atan, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.atan</strong></p>
<div class="codehilite"><pre><span></span>def atan(x, name=None):
</pre></div>


<p>Computes atan of x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.atan_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.atan_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.atrous_conv2d">
    <p>def <span class="ident">atrous_conv2d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.atrous_conv2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.atrous_conv2d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.atrous_conv2d</strong></p>
<div class="codehilite"><pre><span></span>def atrous_conv2d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.atrous_conv2d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.atrous_conv2d</code></strong></p>
<div class="codehilite"><pre><span></span>def atrous_conv2d(value, filters, rate, padding, name=None)
</pre></div>


<p>Atrous convolution (a.k.a. convolution with holes or dilated convolution).</p>
<p>Computes a 2-D atrous convolution, also known as convolution with holes or
dilated convolution, given 4-D <code>value</code> and <code>filters</code> tensors. If the <code>rate</code>
parameter is equal to one, it performs regular 2-D convolution. If the <code>rate</code>
parameter is greater than one, it performs convolution with holes, sampling
the input values every <code>rate</code> pixels in the <code>height</code> and <code>width</code> dimensions.
This is equivalent to convolving the input with a set of upsampled filters,
produced by inserting <code>rate - 1</code> zeros between two consecutive values of the
filters along the <code>height</code> and <code>width</code> dimensions, hence the name atrous
convolution or convolution with holes (the French word trous means holes in
English).</p>
<p>More specifically:</p>
<div class="codehilite"><pre><span></span>output[b, i, j, k] = sum_{di, dj, q} filters[di, dj, q, k] *
      value[b, i + rate * di, j + rate * dj, q]
</pre></div>


<p>Atrous convolution allows us to explicitly control how densely to compute
feature responses in fully convolutional networks. Used in conjunction with
bilinear interpolation, it offers an alternative to <code>conv2d_transpose</code> in
dense prediction tasks such as semantic image segmentation, optical flow
computation, or depth estimation. It also allows us to effectively enlarge
the field of view of filters without increasing the number of parameters or
the amount of computation.</p>
<p>For a description of atrous convolution and how it can be used for dense
feature extraction, please see: <a href="http://arxiv.org/abs/1412.7062">Semantic Image Segmentation with Deep
Convolutional Nets and Fully Connected CRFs</a>.
The same operation is investigated further in <a href="http://arxiv.org/abs/1511.07122">Multi-Scale Context Aggregation
by Dilated Convolutions</a>. Previous works
that effectively use atrous convolution in different ways are, among others,
<a href="http://arxiv.org/abs/1312.6229">OverFeat: Integrated Recognition, Localization and Detection using
Convolutional Networks</a> and [Fast Image
Scanning with Deep Max-Pooling Convolutional Neural Networks]
(http://arxiv.org/abs/1302.1700). Atrous convolution is also closely related
to the so-called noble identities in multi-rate signal processing.</p>
<p>There are many different ways to implement atrous convolution (see the refs
above). The implementation here reduces</p>
<div class="codehilite"><pre><span></span>atrous_conv2d(value, filters, rate, padding=padding)
</pre></div>


<p>to the following three operations:</p>
<div class="codehilite"><pre><span></span>paddings = ...
net = space_to_batch(value, paddings, block_size=rate)
net = conv2d(net, filters, strides=[1, 1, 1, 1], padding=&quot;VALID&quot;)
crops = ...
net = batch_to_space(net, crops, block_size=rate)
</pre></div>


<p>Advanced usage. Note the following optimization: A sequence of <code>atrous_conv2d</code>
operations with identical <code>rate</code> parameters, 'SAME' <code>padding</code>, and filters
with odd heights/ widths:</p>
<div class="codehilite"><pre><span></span>net = atrous_conv2d(net, filters1, rate, padding=&quot;SAME&quot;)
net = atrous_conv2d(net, filters2, rate, padding=&quot;SAME&quot;)
...
net = atrous_conv2d(net, filtersK, rate, padding=&quot;SAME&quot;)
</pre></div>


<p>can be equivalently performed cheaper in terms of computation and memory as:</p>
<div class="codehilite"><pre><span></span>pad = ...  # padding so that the input dims are multiples of rate
net = space_to_batch(net, paddings=pad, block_size=rate)
net = conv2d(net, filters1, strides=[1, 1, 1, 1], padding=&quot;SAME&quot;)
net = conv2d(net, filters2, strides=[1, 1, 1, 1], padding=&quot;SAME&quot;)
...
net = conv2d(net, filtersK, strides=[1, 1, 1, 1], padding=&quot;SAME&quot;)
net = batch_to_space(net, crops=pad, block_size=rate)
</pre></div>


<p>because a pair of consecutive <code>space_to_batch</code> and <code>batch_to_space</code> ops with
the same <code>block_size</code> cancel out when their respective <code>paddings</code> and <code>crops</code>
inputs are identical.</p>
<p>Args:
  value: A 4-D <code>Tensor</code> of type <code>float</code>. It needs to be in the default "NHWC"
    format. Its shape is <code>[batch, in_height, in_width, in_channels]</code>.
  filters: A 4-D <code>Tensor</code> with the same type as <code>value</code> and shape
    <code>[filter_height, filter_width, in_channels, out_channels]</code>. <code>filters</code>'
    <code>in_channels</code> dimension must match that of <code>value</code>. Atrous convolution is
    equivalent to standard convolution with upsampled filters with effective
    height <code>filter_height + (filter_height - 1) * (rate - 1)</code> and effective
    width <code>filter_width + (filter_width - 1) * (rate - 1)</code>, produced by
    inserting <code>rate - 1</code> zeros along consecutive elements across the
    <code>filters</code>' spatial dimensions.
  rate: A positive int32. The stride with which we sample input values across
    the <code>height</code> and <code>width</code> dimensions. Equivalently, the rate by which we
    upsample the filter values by inserting zeros across the <code>height</code> and
    <code>width</code> dimensions. In the literature, the same parameter is sometimes
    called <code>input stride</code> or <code>dilation</code>.
  padding: A string, either <code>'VALID'</code> or <code>'SAME'</code>. The padding algorithm.
  name: Optional name for the returned tensor.</p>
<p>Returns:
  A <code>Tensor</code> with the same type as <code>value</code>.</p>
<p>Raises:
  ValueError: If input/output depth does not match <code>filters</code>' shape, or if
    padding is other than <code>'VALID'</code> or <code>'SAME'</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.atrous_conv2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.atrous_conv2d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.atrous_conv2d_layer">
    <p>def <span class="ident">atrous_conv2d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.atrous_conv2d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.atrous_conv2d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.atrous_conv2d_layer</strong></p>
<div class="codehilite"><pre><span></span>def atrous_conv2d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.atrous_conv2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.atrous_conv2d</strong></p>
<div class="codehilite"><pre><span></span>def atrous_conv2d(value, filters, rate, padding, name=None):
</pre></div>


<p>Atrous convolution (a.k.a. convolution with holes or dilated convolution).</p>
<p>Computes a 2-D atrous convolution, also known as convolution with holes or
dilated convolution, given 4-D <code>value</code> and <code>filters</code> tensors. If the <code>rate</code>
parameter is equal to one, it performs regular 2-D convolution. If the <code>rate</code>
parameter is greater than one, it performs convolution with holes, sampling
the input values every <code>rate</code> pixels in the <code>height</code> and <code>width</code> dimensions.
This is equivalent to convolving the input with a set of upsampled filters,
produced by inserting <code>rate - 1</code> zeros between two consecutive values of the
filters along the <code>height</code> and <code>width</code> dimensions, hence the name atrous
convolution or convolution with holes (the French word trous means holes in
English).</p>
<p>More specifically:</p>
<div class="codehilite"><pre><span></span>output[b, i, j, k] = sum_{di, dj, q} filters[di, dj, q, k] *
      value[b, i + rate * di, j + rate * dj, q]
</pre></div>


<p>Atrous convolution allows us to explicitly control how densely to compute
feature responses in fully convolutional networks. Used in conjunction with
bilinear interpolation, it offers an alternative to <code>conv2d_transpose</code> in
dense prediction tasks such as semantic image segmentation, optical flow
computation, or depth estimation. It also allows us to effectively enlarge
the field of view of filters without increasing the number of parameters or
the amount of computation.</p>
<p>For a description of atrous convolution and how it can be used for dense
feature extraction, please see: <a href="http://arxiv.org/abs/1412.7062">Semantic Image Segmentation with Deep
Convolutional Nets and Fully Connected CRFs</a>.
The same operation is investigated further in <a href="http://arxiv.org/abs/1511.07122">Multi-Scale Context Aggregation
by Dilated Convolutions</a>. Previous works
that effectively use atrous convolution in different ways are, among others,
<a href="http://arxiv.org/abs/1312.6229">OverFeat: Integrated Recognition, Localization and Detection using
Convolutional Networks</a> and [Fast Image
Scanning with Deep Max-Pooling Convolutional Neural Networks]
(http://arxiv.org/abs/1302.1700). Atrous convolution is also closely related
to the so-called noble identities in multi-rate signal processing.</p>
<p>There are many different ways to implement atrous convolution (see the refs
above). The implementation here reduces</p>
<div class="codehilite"><pre><span></span>atrous_conv2d(value, filters, rate, padding=padding)
</pre></div>


<p>to the following three operations:</p>
<div class="codehilite"><pre><span></span>paddings = ...
net = space_to_batch(value, paddings, block_size=rate)
net = conv2d(net, filters, strides=[1, 1, 1, 1], padding=&quot;VALID&quot;)
crops = ...
net = batch_to_space(net, crops, block_size=rate)
</pre></div>


<p>Advanced usage. Note the following optimization: A sequence of <code>atrous_conv2d</code>
operations with identical <code>rate</code> parameters, 'SAME' <code>padding</code>, and filters
with odd heights/ widths:</p>
<div class="codehilite"><pre><span></span>net = atrous_conv2d(net, filters1, rate, padding=&quot;SAME&quot;)
net = atrous_conv2d(net, filters2, rate, padding=&quot;SAME&quot;)
...
net = atrous_conv2d(net, filtersK, rate, padding=&quot;SAME&quot;)
</pre></div>


<p>can be equivalently performed cheaper in terms of computation and memory as:</p>
<div class="codehilite"><pre><span></span>pad = ...  # padding so that the input dims are multiples of rate
net = space_to_batch(net, paddings=pad, block_size=rate)
net = conv2d(net, filters1, strides=[1, 1, 1, 1], padding=&quot;SAME&quot;)
net = conv2d(net, filters2, strides=[1, 1, 1, 1], padding=&quot;SAME&quot;)
...
net = conv2d(net, filtersK, strides=[1, 1, 1, 1], padding=&quot;SAME&quot;)
net = batch_to_space(net, crops=pad, block_size=rate)
</pre></div>


<p>because a pair of consecutive <code>space_to_batch</code> and <code>batch_to_space</code> ops with
the same <code>block_size</code> cancel out when their respective <code>paddings</code> and <code>crops</code>
inputs are identical.</p>
<p>Args:
  value: A 4-D <code>Tensor</code> of type <code>float</code>. It needs to be in the default "NHWC"
    format. Its shape is <code>[batch, in_height, in_width, in_channels]</code>.
  filters: A 4-D <code>Tensor</code> with the same type as <code>value</code> and shape
    <code>[filter_height, filter_width, in_channels, out_channels]</code>. <code>filters</code>'
    <code>in_channels</code> dimension must match that of <code>value</code>. Atrous convolution is
    equivalent to standard convolution with upsampled filters with effective
    height <code>filter_height + (filter_height - 1) * (rate - 1)</code> and effective
    width <code>filter_width + (filter_width - 1) * (rate - 1)</code>, produced by
    inserting <code>rate - 1</code> zeros along consecutive elements across the
    <code>filters</code>' spatial dimensions.
  rate: A positive int32. The stride with which we sample input values across
    the <code>height</code> and <code>width</code> dimensions. Equivalently, the rate by which we
    upsample the filter values by inserting zeros across the <code>height</code> and
    <code>width</code> dimensions. In the literature, the same parameter is sometimes
    called <code>input stride</code> or <code>dilation</code>.
  padding: A string, either <code>'VALID'</code> or <code>'SAME'</code>. The padding algorithm.
  name: Optional name for the returned tensor.</p>
<p>Returns:
  A <code>Tensor</code> with the same type as <code>value</code>.</p>
<p>Raises:
  ValueError: If input/output depth does not match <code>filters</code>' shape, or if
    padding is other than <code>'VALID'</code> or <code>'SAME'</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.atrous_conv2d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.atrous_conv2d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.audio_summary">
    <p>def <span class="ident">audio_summary</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.audio_summary, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.audio_summary</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.audio_summary</strong></p>
<div class="codehilite"><pre><span></span>def audio_summary(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.audio_summary</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.audio_summary</code></strong></p>
<div class="codehilite"><pre><span></span>def audio_summary(tag, tensor, sample_rate, max_outputs=3, collections=None, name=None)
</pre></div>


<p>Outputs a <code>Summary</code> protocol buffer with audio.</p>
<p>The summary has up to <code>max_outputs</code> summary values containing audio. The
audio is built from <code>tensor</code> which must be 3-D with shape <code>[batch_size,
frames, channels]</code> or 2-D with shape <code>[batch_size, frames]</code>. The values are
assumed to be in the range of <code>[-1.0, 1.0]</code> with a sample rate of
<code>sample_rate</code>.</p>
<p>The <code>tag</code> argument is a scalar <code>Tensor</code> of type <code>string</code>.  It is used to
build the <code>tag</code> of the summary values:</p>
<ul>
<li>If <code>max_outputs</code> is 1, the summary value tag is '<em>tag</em>/audio'.</li>
<li>If <code>max_outputs</code> is greater than 1, the summary value tags are
   generated sequentially as '<em>tag</em>/audio/0', '<em>tag</em>/audio/1', etc.</li>
</ul>
<p>Args:
  tag: A scalar <code>Tensor</code> of type <code>string</code>. Used to build the <code>tag</code>
    of the summary values.
  tensor: A 3-D <code>float32</code> <code>Tensor</code> of shape <code>[batch_size, frames, channels]</code>
    or a 2-D <code>float32</code> <code>Tensor</code> of shape <code>[batch_size, frames]</code>.
  sample_rate: The sample rate of the signal in hertz.
  max_outputs: Max number of batch elements to generate audio for.
  collections: Optional list of ops.GraphKeys.  The collections to add the
    summary to.  Defaults to [ops.GraphKeys.SUMMARIES]
  name: A name for the operation (optional).</p>
<p>Returns:
  A scalar <code>Tensor</code> of type <code>string</code>. The serialized <code>Summary</code> protocol
  buffer.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.audio_summary', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.audio_summary" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.audio_summary_layer">
    <p>def <span class="ident">audio_summary_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.audio_summary_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.audio_summary_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.audio_summary_layer</strong></p>
<div class="codehilite"><pre><span></span>def audio_summary_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.audio_summary, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.audio_summary</strong></p>
<div class="codehilite"><pre><span></span>def audio_summary(tag, tensor, sample_rate, max_outputs=3, collections=None, name=None):
</pre></div>


<p>Outputs a <code>Summary</code> protocol buffer with audio.</p>
<p>The summary has up to <code>max_outputs</code> summary values containing audio. The
audio is built from <code>tensor</code> which must be 3-D with shape <code>[batch_size,
frames, channels]</code> or 2-D with shape <code>[batch_size, frames]</code>. The values are
assumed to be in the range of <code>[-1.0, 1.0]</code> with a sample rate of
<code>sample_rate</code>.</p>
<p>The <code>tag</code> argument is a scalar <code>Tensor</code> of type <code>string</code>.  It is used to
build the <code>tag</code> of the summary values:</p>
<ul>
<li>If <code>max_outputs</code> is 1, the summary value tag is '<em>tag</em>/audio'.</li>
<li>If <code>max_outputs</code> is greater than 1, the summary value tags are
   generated sequentially as '<em>tag</em>/audio/0', '<em>tag</em>/audio/1', etc.</li>
</ul>
<p>Args:
  tag: A scalar <code>Tensor</code> of type <code>string</code>. Used to build the <code>tag</code>
    of the summary values.
  tensor: A 3-D <code>float32</code> <code>Tensor</code> of shape <code>[batch_size, frames, channels]</code>
    or a 2-D <code>float32</code> <code>Tensor</code> of shape <code>[batch_size, frames]</code>.
  sample_rate: The sample rate of the signal in hertz.
  max_outputs: Max number of batch elements to generate audio for.
  collections: Optional list of ops.GraphKeys.  The collections to add the
    summary to.  Defaults to [ops.GraphKeys.SUMMARIES]
  name: A name for the operation (optional).</p>
<p>Returns:
  A scalar <code>Tensor</code> of type <code>string</code>. The serialized <code>Summary</code> protocol
  buffer.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.audio_summary_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.audio_summary_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.avg_pool">
    <p>def <span class="ident">avg_pool</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.avg_pool, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.avg_pool</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.avg_pool</strong></p>
<div class="codehilite"><pre><span></span>def avg_pool(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.avg_pool</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.avg_pool</code></strong></p>
<div class="codehilite"><pre><span></span>def avg_pool(value, ksize, strides, padding, data_format=&quot;NHWC&quot;, name=None)
</pre></div>


<p>Performs the average pooling on the input.</p>
<p>Each entry in <code>output</code> is the mean of the corresponding size <code>ksize</code>
window in <code>value</code>.</p>
<p>Args:
  value: A 4-D <code>Tensor</code> of shape <code>[batch, height, width, channels]</code> and type
    <code>float32</code>, <code>float64</code>, <code>qint8</code>, <code>quint8</code>, or <code>qint32</code>.
  ksize: A list of ints that has length &gt;= 4.
    The size of the window for each dimension of the input tensor.
  strides: A list of ints that has length &gt;= 4.
    The stride of the sliding window for each dimension of the
    input tensor.
  padding: A string, either <code>'VALID'</code> or <code>'SAME'</code>. The padding algorithm.
    See the <a href="https://www.tensorflow.org/api_docs/python/nn.html#convolution">comment here</a>
  data_format: A string. 'NHWC' and 'NCHW' are supported.
  name: Optional name for the operation.</p>
<p>Returns:
  A <code>Tensor</code> with the same type as <code>value</code>.  The average pooled output tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.avg_pool', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.avg_pool" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.avg_pool3d">
    <p>def <span class="ident">avg_pool3d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.avg_pool3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.avg_pool3d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.avg_pool3d</strong></p>
<div class="codehilite"><pre><span></span>def avg_pool3d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.avg_pool3d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.avg_pool3d</code></strong></p>
<div class="codehilite"><pre><span></span>def avg_pool3d(input, ksize, strides, padding, name=None)
</pre></div>


<p>Performs 3D average pooling on the input.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Shape <code>[batch, depth, rows, cols, channels]</code> tensor to pool over.
  ksize: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The size of the window for each dimension of
    the input tensor. Must have <code>ksize[0] = ksize[1] = 1</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  The average pooled output tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.avg_pool3d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.avg_pool3d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.avg_pool3d_grad">
    <p>def <span class="ident">avg_pool3d_grad</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.avg_pool3d_grad, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.avg_pool3d_grad</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.avg_pool3d_grad</strong></p>
<div class="codehilite"><pre><span></span>def avg_pool3d_grad(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.avg_pool3d_grad</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.avg_pool3d_grad</code></strong></p>
<div class="codehilite"><pre><span></span>def avg_pool3d_grad(orig_input_shape, grad, ksize, strides, padding, name=None)
</pre></div>


<p>Computes gradients of average pooling function.</p>
<p>Args:
  orig_input_shape: A <code>Tensor</code> of type <code>int32</code>.
    The original input dimensions.
  grad: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Output backprop of shape <code>[batch, depth, rows, cols, channels]</code>.
  ksize: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The size of the window for each dimension of
    the input tensor. Must have <code>ksize[0] = ksize[1] = 1</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>grad</code>. The backprop for input.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.avg_pool3d_grad', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.avg_pool3d_grad" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.avg_pool3d_grad_layer">
    <p>def <span class="ident">avg_pool3d_grad_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.avg_pool3d_grad_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.avg_pool3d_grad_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.avg_pool3d_grad_layer</strong></p>
<div class="codehilite"><pre><span></span>def avg_pool3d_grad_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.avg_pool3d_grad, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.avg_pool3d_grad</strong></p>
<div class="codehilite"><pre><span></span>def avg_pool3d_grad(orig_input_shape, grad, ksize, strides, padding, name=None):
</pre></div>


<p>Computes gradients of average pooling function.</p>
<p>Args:
  orig_input_shape: A <code>Tensor</code> of type <code>int32</code>.
    The original input dimensions.
  grad: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Output backprop of shape <code>[batch, depth, rows, cols, channels]</code>.
  ksize: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The size of the window for each dimension of
    the input tensor. Must have <code>ksize[0] = ksize[1] = 1</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>grad</code>. The backprop for input.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.avg_pool3d_grad_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.avg_pool3d_grad_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.avg_pool3d_layer">
    <p>def <span class="ident">avg_pool3d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.avg_pool3d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.avg_pool3d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.avg_pool3d_layer</strong></p>
<div class="codehilite"><pre><span></span>def avg_pool3d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.avg_pool3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.avg_pool3d</strong></p>
<div class="codehilite"><pre><span></span>def avg_pool3d(input, ksize, strides, padding, name=None):
</pre></div>


<p>Performs 3D average pooling on the input.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Shape <code>[batch, depth, rows, cols, channels]</code> tensor to pool over.
  ksize: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The size of the window for each dimension of
    the input tensor. Must have <code>ksize[0] = ksize[1] = 1</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  The average pooled output tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.avg_pool3d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.avg_pool3d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.avg_pool_layer">
    <p>def <span class="ident">avg_pool_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.avg_pool_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.avg_pool_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.avg_pool_layer</strong></p>
<div class="codehilite"><pre><span></span>def avg_pool_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.avg_pool, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.avg_pool</strong></p>
<div class="codehilite"><pre><span></span>def avg_pool(value, ksize, strides, padding, data_format=&quot;NHWC&quot;, name=None):
</pre></div>


<p>Performs the average pooling on the input.</p>
<p>Each entry in <code>output</code> is the mean of the corresponding size <code>ksize</code>
window in <code>value</code>.</p>
<p>Args:
  value: A 4-D <code>Tensor</code> of shape <code>[batch, height, width, channels]</code> and type
    <code>float32</code>, <code>float64</code>, <code>qint8</code>, <code>quint8</code>, or <code>qint32</code>.
  ksize: A list of ints that has length &gt;= 4.
    The size of the window for each dimension of the input tensor.
  strides: A list of ints that has length &gt;= 4.
    The stride of the sliding window for each dimension of the
    input tensor.
  padding: A string, either <code>'VALID'</code> or <code>'SAME'</code>. The padding algorithm.
    See the <a href="https://www.tensorflow.org/api_docs/python/nn.html#convolution">comment here</a>
  data_format: A string. 'NHWC' and 'NCHW' are supported.
  name: Optional name for the operation.</p>
<p>Returns:
  A <code>Tensor</code> with the same type as <code>value</code>.  The average pooled output tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.avg_pool_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.avg_pool_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_cholesky">
    <p>def <span class="ident">batch_cholesky</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_cholesky, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_cholesky</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_cholesky</strong></p>
<div class="codehilite"><pre><span></span>def batch_cholesky(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_cholesky</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_cholesky</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_cholesky(input, name=None)
</pre></div>


<p>Calculates the Cholesky decomposition of a batch of square matrices.</p>
<p>The input is a tensor of shape <code>[..., M, M]</code> whose inner-most 2 dimensions
form square matrices, with the same constraints as the single matrix Cholesky
decomposition above. The output is a tensor of the same shape as the input
containing the Cholesky decompositions for all input submatrices <code>[..., :, :]</code>.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[..., M, M]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. Shape is <code>[..., M, M]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_cholesky', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_cholesky" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_cholesky_layer">
    <p>def <span class="ident">batch_cholesky_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_cholesky_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_cholesky_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_cholesky_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_cholesky_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_cholesky, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_cholesky</strong></p>
<div class="codehilite"><pre><span></span>def batch_cholesky(input, name=None):
</pre></div>


<p>Calculates the Cholesky decomposition of a batch of square matrices.</p>
<p>The input is a tensor of shape <code>[..., M, M]</code> whose inner-most 2 dimensions
form square matrices, with the same constraints as the single matrix Cholesky
decomposition above. The output is a tensor of the same shape as the input
containing the Cholesky decompositions for all input submatrices <code>[..., :, :]</code>.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[..., M, M]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. Shape is <code>[..., M, M]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_cholesky_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_cholesky_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_cholesky_solve">
    <p>def <span class="ident">batch_cholesky_solve</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_cholesky_solve, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_cholesky_solve</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_cholesky_solve</strong></p>
<div class="codehilite"><pre><span></span>def batch_cholesky_solve(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_cholesky_solve</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_cholesky_solve</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_cholesky_solve(chol, rhs, name=None)
</pre></div>


<p>Solve batches of linear eqns <code>A X = RHS</code>, given Cholesky factorizations.</p>
<p>```python</p>
<h1>Solve one linear system (K = 1) for every member of the length 10 batch.</h1>
<p>A = ... # shape 10 x 2 x 2
RHS = ... # shape 10 x 2 x 1
chol = tf.batch_cholesky(A)  # shape 10 x 2 x 2
X = tf.batch_cholesky_solve(chol, RHS)  # shape 10 x 2 x 1</p>
<h1>tf.matmul(A, X) ~ RHS</h1>
<p>X[3, :, 0]  # Solution to the linear system A[3, :, :] x = RHS[3, :, 0]</p>
<h1>Solve five linear systems (K = 5) for every member of the length 10 batch.</h1>
<p>A = ... # shape 10 x 2 x 2
RHS = ... # shape 10 x 2 x 5
...
X[3, :, 2]  # Solution to the linear system A[3, :, :] x = RHS[3, :, 2]
```</p>
<p>Args:
  chol:  A <code>Tensor</code>.  Must be <code>float32</code> or <code>float64</code>, shape is <code>[..., M, M]</code>.
    Cholesky factorization of <code>A</code>, e.g. <code>chol = tf.batch_cholesky(A)</code>.
    For that reason, only the lower triangular parts (including the diagonal)
    of the last two dimensions of <code>chol</code> are used.  The strictly upper part is
    assumed to be zero and not accessed.
  rhs:  A <code>Tensor</code>, same type as <code>chol</code>, shape is <code>[..., M, K]</code>.
  name:  A name to give this <code>Op</code>.  Defaults to <code>batch_cholesky_solve</code>.</p>
<p>Returns:
  Solution to <code>A x = rhs</code>, shape <code>[..., M, K]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_cholesky_solve', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_cholesky_solve" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_cholesky_solve_layer">
    <p>def <span class="ident">batch_cholesky_solve_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_cholesky_solve_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_cholesky_solve_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_cholesky_solve_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_cholesky_solve_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_cholesky_solve, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_cholesky_solve</strong></p>
<div class="codehilite"><pre><span></span>def batch_cholesky_solve(chol, rhs, name=None):
</pre></div>


<p>Solve batches of linear eqns <code>A X = RHS</code>, given Cholesky factorizations.</p>
<p>```python</p>
<h1>Solve one linear system (K = 1) for every member of the length 10 batch.</h1>
<p>A = ... # shape 10 x 2 x 2
RHS = ... # shape 10 x 2 x 1
chol = tf.batch_cholesky(A)  # shape 10 x 2 x 2
X = tf.batch_cholesky_solve(chol, RHS)  # shape 10 x 2 x 1</p>
<h1>tf.matmul(A, X) ~ RHS</h1>
<p>X[3, :, 0]  # Solution to the linear system A[3, :, :] x = RHS[3, :, 0]</p>
<h1>Solve five linear systems (K = 5) for every member of the length 10 batch.</h1>
<p>A = ... # shape 10 x 2 x 2
RHS = ... # shape 10 x 2 x 5
...
X[3, :, 2]  # Solution to the linear system A[3, :, :] x = RHS[3, :, 2]
```</p>
<p>Args:
  chol:  A <code>Tensor</code>.  Must be <code>float32</code> or <code>float64</code>, shape is <code>[..., M, M]</code>.
    Cholesky factorization of <code>A</code>, e.g. <code>chol = tf.batch_cholesky(A)</code>.
    For that reason, only the lower triangular parts (including the diagonal)
    of the last two dimensions of <code>chol</code> are used.  The strictly upper part is
    assumed to be zero and not accessed.
  rhs:  A <code>Tensor</code>, same type as <code>chol</code>, shape is <code>[..., M, K]</code>.
  name:  A name to give this <code>Op</code>.  Defaults to <code>batch_cholesky_solve</code>.</p>
<p>Returns:
  Solution to <code>A x = rhs</code>, shape <code>[..., M, K]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_cholesky_solve_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_cholesky_solve_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_fft">
    <p>def <span class="ident">batch_fft</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_fft, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_fft</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_fft</strong></p>
<div class="codehilite"><pre><span></span>def batch_fft(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_fft</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_fft</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_fft(input, name=None)
</pre></div>


<p>Compute the 1-dimensional discrete Fourier Transform over the inner-most</p>
<p>dimension of <code>input</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  A complex64 tensor of the same shape as <code>input</code>. The inner-most
  dimension of <code>input</code> is replaced with its 1D Fourier Transform.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_fft', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_fft" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_fft2d">
    <p>def <span class="ident">batch_fft2d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_fft2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_fft2d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_fft2d</strong></p>
<div class="codehilite"><pre><span></span>def batch_fft2d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_fft2d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_fft2d</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_fft2d(input, name=None)
</pre></div>


<p>Compute the 2-dimensional discrete Fourier Transform over the inner-most</p>
<p>2 dimensions of <code>input</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  A complex64 tensor of the same shape as <code>input</code>. The inner-most 2
  dimensions of <code>input</code> are replaced with their 2D Fourier Transform.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_fft2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_fft2d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_fft2d_layer">
    <p>def <span class="ident">batch_fft2d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_fft2d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_fft2d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_fft2d_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_fft2d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_fft2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_fft2d</strong></p>
<div class="codehilite"><pre><span></span>def batch_fft2d(input, name=None):
</pre></div>


<p>Compute the 2-dimensional discrete Fourier Transform over the inner-most</p>
<p>2 dimensions of <code>input</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  A complex64 tensor of the same shape as <code>input</code>. The inner-most 2
  dimensions of <code>input</code> are replaced with their 2D Fourier Transform.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_fft2d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_fft2d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_fft3d">
    <p>def <span class="ident">batch_fft3d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_fft3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_fft3d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_fft3d</strong></p>
<div class="codehilite"><pre><span></span>def batch_fft3d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_fft3d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_fft3d</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_fft3d(input, name=None)
</pre></div>


<p>Compute the 3-dimensional discrete Fourier Transform over the inner-most 3</p>
<p>dimensions of <code>input</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  A complex64 tensor of the same shape as <code>input</code>. The inner-most 3
  dimensions of <code>input</code> are replaced with their 3D Fourier Transform.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_fft3d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_fft3d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_fft3d_layer">
    <p>def <span class="ident">batch_fft3d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_fft3d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_fft3d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_fft3d_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_fft3d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_fft3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_fft3d</strong></p>
<div class="codehilite"><pre><span></span>def batch_fft3d(input, name=None):
</pre></div>


<p>Compute the 3-dimensional discrete Fourier Transform over the inner-most 3</p>
<p>dimensions of <code>input</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  A complex64 tensor of the same shape as <code>input</code>. The inner-most 3
  dimensions of <code>input</code> are replaced with their 3D Fourier Transform.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_fft3d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_fft3d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_fft_layer">
    <p>def <span class="ident">batch_fft_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_fft_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_fft_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_fft_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_fft_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_fft, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_fft</strong></p>
<div class="codehilite"><pre><span></span>def batch_fft(input, name=None):
</pre></div>


<p>Compute the 1-dimensional discrete Fourier Transform over the inner-most</p>
<p>dimension of <code>input</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  A complex64 tensor of the same shape as <code>input</code>. The inner-most
  dimension of <code>input</code> is replaced with its 1D Fourier Transform.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_fft_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_fft_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_ifft">
    <p>def <span class="ident">batch_ifft</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_ifft, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_ifft</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_ifft</strong></p>
<div class="codehilite"><pre><span></span>def batch_ifft(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_ifft</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_ifft</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_ifft(input, name=None)
</pre></div>


<p>Compute the inverse 1-dimensional discrete Fourier Transform over the inner-most</p>
<p>dimension of <code>input</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  A complex64 tensor of the same shape as <code>input</code>. The inner-most
  dimension of <code>input</code> is replaced with its inverse 1D Fourier Transform.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_ifft', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_ifft" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_ifft2d">
    <p>def <span class="ident">batch_ifft2d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_ifft2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_ifft2d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_ifft2d</strong></p>
<div class="codehilite"><pre><span></span>def batch_ifft2d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_ifft2d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_ifft2d</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_ifft2d(input, name=None)
</pre></div>


<p>Compute the inverse 2-dimensional discrete Fourier Transform over the inner-most</p>
<p>2 dimensions of <code>input</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  A complex64 tensor of the same shape as <code>input</code>. The inner-most 2
  dimensions of <code>input</code> are replaced with their inverse 2D Fourier Transform.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_ifft2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_ifft2d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_ifft2d_layer">
    <p>def <span class="ident">batch_ifft2d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_ifft2d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_ifft2d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_ifft2d_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_ifft2d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_ifft2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_ifft2d</strong></p>
<div class="codehilite"><pre><span></span>def batch_ifft2d(input, name=None):
</pre></div>


<p>Compute the inverse 2-dimensional discrete Fourier Transform over the inner-most</p>
<p>2 dimensions of <code>input</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  A complex64 tensor of the same shape as <code>input</code>. The inner-most 2
  dimensions of <code>input</code> are replaced with their inverse 2D Fourier Transform.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_ifft2d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_ifft2d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_ifft3d">
    <p>def <span class="ident">batch_ifft3d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_ifft3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_ifft3d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_ifft3d</strong></p>
<div class="codehilite"><pre><span></span>def batch_ifft3d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_ifft3d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_ifft3d</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_ifft3d(input, name=None)
</pre></div>


<p>Compute the inverse 3-dimensional discrete Fourier Transform over the inner-most</p>
<p>3 dimensions of <code>input</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  A complex64 tensor of the same shape as <code>input</code>. The inner-most 3
  dimensions of <code>input</code> are replaced with their inverse 3D Fourier Transform.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_ifft3d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_ifft3d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_ifft3d_layer">
    <p>def <span class="ident">batch_ifft3d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_ifft3d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_ifft3d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_ifft3d_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_ifft3d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_ifft3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_ifft3d</strong></p>
<div class="codehilite"><pre><span></span>def batch_ifft3d(input, name=None):
</pre></div>


<p>Compute the inverse 3-dimensional discrete Fourier Transform over the inner-most</p>
<p>3 dimensions of <code>input</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  A complex64 tensor of the same shape as <code>input</code>. The inner-most 3
  dimensions of <code>input</code> are replaced with their inverse 3D Fourier Transform.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_ifft3d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_ifft3d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_ifft_layer">
    <p>def <span class="ident">batch_ifft_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_ifft_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_ifft_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_ifft_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_ifft_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_ifft, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_ifft</strong></p>
<div class="codehilite"><pre><span></span>def batch_ifft(input, name=None):
</pre></div>


<p>Compute the inverse 1-dimensional discrete Fourier Transform over the inner-most</p>
<p>dimension of <code>input</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  A complex64 tensor of the same shape as <code>input</code>. The inner-most
  dimension of <code>input</code> is replaced with its inverse 1D Fourier Transform.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_ifft_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_ifft_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matmul_layer">
    <p>def <span class="ident">batch_matmul_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matmul_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matmul_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matmul_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_matmul_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_matmul, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_matmul</strong></p>
<div class="codehilite"><pre><span></span>def _batch_mat_mul(x, y, adj_x=None, adj_y=None, name=None):
</pre></div>


<p>Multiplies slices of two tensors in batches.</p>
<p>Multiplies all slices of <code>Tensor</code> <code>x</code> and <code>y</code> (each slice can be
viewed as an element of a batch), and arranges the individual results
in a single output tensor of the same batch size. Each of the
individual slices can optionally be adjointed (to adjoint a matrix
means to transpose and conjugate it) before multiplication by setting
the <code>adj_x</code> or <code>adj_y</code> flag to <code>True</code>, which are by default <code>False</code>.</p>
<p>The input tensors <code>x</code> and <code>y</code> are 3-D or higher with shape <code>[..., r_x, c_x]</code>
and <code>[..., r_y, c_y]</code>.</p>
<p>The output tensor is 3-D or higher with shape <code>[..., r_o, c_o]</code>, where:</p>
<div class="codehilite"><pre><span></span>r_o = c_x if adj_x else r_x
c_o = r_y if adj_y else c_y
</pre></div>


<p>It is computed as:</p>
<div class="codehilite"><pre><span></span>output[..., :, :] = matrix(x[..., :, :]) * matrix(y[..., :, :])
</pre></div>


<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>complex64</code>, <code>complex128</code>.
    3-D or higher with shape <code>[..., r_x, c_x]</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
    3-D or higher with shape <code>[..., r_y, c_y]</code>.
  adj_x: An optional <code>bool</code>. Defaults to <code>False</code>.
    If <code>True</code>, adjoint the slices of <code>x</code>. Defaults to <code>False</code>.
  adj_y: An optional <code>bool</code>. Defaults to <code>False</code>.
    If <code>True</code>, adjoint the slices of <code>y</code>. Defaults to <code>False</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.
  3-D or higher with shape <code>[..., r_o, c_o]</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matmul_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matmul_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_band_part">
    <p>def <span class="ident">batch_matrix_band_part</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_band_part, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_band_part</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_band_part</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_band_part(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_matrix_band_part</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_matrix_band_part</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_band_part(input, num_lower, num_upper, name=None)
</pre></div>


<p>Copy a tensor setting everything outside a central band in each innermost matrix</p>
<p>to zero.</p>
<p>The <code>band</code> part is computed as follows:
Assume <code>input</code> has <code>k</code> dimensions <code>[I, J, K, ..., M, N]</code>, then the output is a
tensor with the same shape where</p>
<p><code>band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]</code>.</p>
<p>The indicator function 'in_band(m, n)<code>is one if</code>(num_lower &lt; 0 || (m-n) &lt;= num_lower)) &amp;&amp;
(num_upper &lt; 0 || (n-m) &lt;= num_upper)`, and zero otherwise.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>if 'input' is [[ 0,  1,  2, 3]</h1>
<div class="codehilite"><pre><span></span>             [-1,  0,  1, 2]
             [-2, -1,  0, 1]
             [-3, -2, -1, 0]],
</pre></div>


<p>tf.batch_matrix_band_part(input, 1, -1) ==&gt; [[ 0,  1,  2, 3]
                                             [-1,  0,  1, 2]
                                             [ 0, -1,  0, 1]
                                             [ 0,  0, -1, 0]],</p>
<p>tf.batch_matrix_band_part(input, 2, 1) ==&gt; [[ 0,  1,  0, 0]
                                            [-1,  0,  1, 0]
                                            [-2, -1,  0, 1]
                                            [ 0, -2, -1, 0]]
```</p>
<p>Useful special cases:</p>
<p><code>prettyprint
 tf.batch_matrix_band_part(input, 0, -1) ==&gt; Upper triangular part.
 tf.batch_matrix_band_part(input, -1, 0) ==&gt; Lower triangular part.
 tf.batch_matrix_band_part(input, 0, 0) ==&gt; Diagonal.</code></p>
<p>Args:
  input: A <code>Tensor</code>. Rank <code>k</code> tensor.
  num_lower: A <code>Tensor</code> of type <code>int64</code>.
    0-D tensor. Number of subdiagonals to keep. If negative, keep entire
    lower triangle.
  num_upper: A <code>Tensor</code> of type <code>int64</code>.
    0-D tensor. Number of superdiagonals to keep. If negative, keep
    entire upper triangle.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  Rank <code>k</code> tensor of the same shape as input. The extracted banded tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_band_part', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_band_part" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_band_part_layer">
    <p>def <span class="ident">batch_matrix_band_part_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_band_part_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_band_part_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_band_part_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_band_part_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_matrix_band_part, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_matrix_band_part</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_band_part(input, num_lower, num_upper, name=None):
</pre></div>


<p>Copy a tensor setting everything outside a central band in each innermost matrix</p>
<p>to zero.</p>
<p>The <code>band</code> part is computed as follows:
Assume <code>input</code> has <code>k</code> dimensions <code>[I, J, K, ..., M, N]</code>, then the output is a
tensor with the same shape where</p>
<p><code>band[i, j, k, ..., m, n] = in_band(m, n) * input[i, j, k, ..., m, n]</code>.</p>
<p>The indicator function 'in_band(m, n)<code>is one if</code>(num_lower &lt; 0 || (m-n) &lt;= num_lower)) &amp;&amp;
(num_upper &lt; 0 || (n-m) &lt;= num_upper)`, and zero otherwise.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>if 'input' is [[ 0,  1,  2, 3]</h1>
<div class="codehilite"><pre><span></span>             [-1,  0,  1, 2]
             [-2, -1,  0, 1]
             [-3, -2, -1, 0]],
</pre></div>


<p>tf.batch_matrix_band_part(input, 1, -1) ==&gt; [[ 0,  1,  2, 3]
                                             [-1,  0,  1, 2]
                                             [ 0, -1,  0, 1]
                                             [ 0,  0, -1, 0]],</p>
<p>tf.batch_matrix_band_part(input, 2, 1) ==&gt; [[ 0,  1,  0, 0]
                                            [-1,  0,  1, 0]
                                            [-2, -1,  0, 1]
                                            [ 0, -2, -1, 0]]
```</p>
<p>Useful special cases:</p>
<p><code>prettyprint
 tf.batch_matrix_band_part(input, 0, -1) ==&gt; Upper triangular part.
 tf.batch_matrix_band_part(input, -1, 0) ==&gt; Lower triangular part.
 tf.batch_matrix_band_part(input, 0, 0) ==&gt; Diagonal.</code></p>
<p>Args:
  input: A <code>Tensor</code>. Rank <code>k</code> tensor.
  num_lower: A <code>Tensor</code> of type <code>int64</code>.
    0-D tensor. Number of subdiagonals to keep. If negative, keep entire
    lower triangle.
  num_upper: A <code>Tensor</code> of type <code>int64</code>.
    0-D tensor. Number of superdiagonals to keep. If negative, keep
    entire upper triangle.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  Rank <code>k</code> tensor of the same shape as input. The extracted banded tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_band_part_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_band_part_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_determinant">
    <p>def <span class="ident">batch_matrix_determinant</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_determinant, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_determinant</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_determinant</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_determinant(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_matrix_determinant</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_matrix_determinant</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_determinant(input, name=None)
</pre></div>


<p>Calculates the determinants for a batch of square matrices.</p>
<p>The input is a tensor of shape <code>[..., M, M]</code> whose inner-most 2 dimensions
form square matrices. The output is a 1-D tensor containing the determinants
for all input submatrices <code>[..., :, :]</code>.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    Shape is <code>[..., M, M]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. Shape is <code>[...]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_determinant', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_determinant" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_determinant_layer">
    <p>def <span class="ident">batch_matrix_determinant_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_determinant_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_determinant_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_determinant_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_determinant_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_matrix_determinant, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_matrix_determinant</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_determinant(input, name=None):
</pre></div>


<p>Calculates the determinants for a batch of square matrices.</p>
<p>The input is a tensor of shape <code>[..., M, M]</code> whose inner-most 2 dimensions
form square matrices. The output is a 1-D tensor containing the determinants
for all input submatrices <code>[..., :, :]</code>.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    Shape is <code>[..., M, M]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. Shape is <code>[...]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_determinant_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_determinant_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_diag">
    <p>def <span class="ident">batch_matrix_diag</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_diag, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_diag</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_diag</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_diag(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_matrix_diag</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_matrix_diag</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_diag(diagonal, name=None)
</pre></div>


<p>Returns a batched diagonal tensor with a given batched diagonal values.</p>
<p>Given a <code>diagonal</code>, this operation returns a tensor with the <code>diagonal</code> and
everything else padded with zeros. The diagonal is computed as follows:</p>
<p>Assume <code>diagonal</code> has <code>k</code> dimensions <code>[I, J, K, ..., N]</code>, then the output is a
tensor of rank <code>k+1</code> with dimensions [I, J, K, ..., N, N]` where:</p>
<p><code>output[i, j, k, ..., m, n] = 1{m=n} * diagonal[i, j, k, ..., n]</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'diagonal' is [[1, 2, 3, 4], [5, 6, 7, 8]]</h1>
<p>and diagonal.shape = (2, 4)</p>
<p>tf.batch_matrix_diag(diagonal) ==&gt; [[[1, 0, 0, 0]
                                     [0, 2, 0, 0]
                                     [0, 0, 3, 0]
                                     [0, 0, 0, 4]],
                                    [[5, 0, 0, 0]
                                     [0, 6, 0, 0]
                                     [0, 0, 7, 0]
                                     [0, 0, 0, 8]]]</p>
<p>which has shape (2, 4, 4)
```</p>
<p>Args:
  diagonal: A <code>Tensor</code>. Rank <code>k</code>, where <code>k &gt;= 1</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>diagonal</code>.
  Rank <code>k+1</code>, with <code>output.shape = diagonal.shape + [diagonal.shape[-1]]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_diag', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_diag" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_diag_layer">
    <p>def <span class="ident">batch_matrix_diag_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_diag_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_diag_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_diag_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_diag_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_matrix_diag, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_matrix_diag</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_diag(diagonal, name=None):
</pre></div>


<p>Returns a batched diagonal tensor with a given batched diagonal values.</p>
<p>Given a <code>diagonal</code>, this operation returns a tensor with the <code>diagonal</code> and
everything else padded with zeros. The diagonal is computed as follows:</p>
<p>Assume <code>diagonal</code> has <code>k</code> dimensions <code>[I, J, K, ..., N]</code>, then the output is a
tensor of rank <code>k+1</code> with dimensions [I, J, K, ..., N, N]` where:</p>
<p><code>output[i, j, k, ..., m, n] = 1{m=n} * diagonal[i, j, k, ..., n]</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'diagonal' is [[1, 2, 3, 4], [5, 6, 7, 8]]</h1>
<p>and diagonal.shape = (2, 4)</p>
<p>tf.batch_matrix_diag(diagonal) ==&gt; [[[1, 0, 0, 0]
                                     [0, 2, 0, 0]
                                     [0, 0, 3, 0]
                                     [0, 0, 0, 4]],
                                    [[5, 0, 0, 0]
                                     [0, 6, 0, 0]
                                     [0, 0, 7, 0]
                                     [0, 0, 0, 8]]]</p>
<p>which has shape (2, 4, 4)
```</p>
<p>Args:
  diagonal: A <code>Tensor</code>. Rank <code>k</code>, where <code>k &gt;= 1</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>diagonal</code>.
  Rank <code>k+1</code>, with <code>output.shape = diagonal.shape + [diagonal.shape[-1]]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_diag_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_diag_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_diag_part">
    <p>def <span class="ident">batch_matrix_diag_part</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_diag_part, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_diag_part</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_diag_part</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_diag_part(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_matrix_diag_part</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_matrix_diag_part</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_diag_part(input, name=None)
</pre></div>


<p>Returns the batched diagonal part of a batched tensor.</p>
<p>This operation returns a tensor with the <code>diagonal</code> part
of the batched <code>input</code>. The <code>diagonal</code> part is computed as follows:</p>
<p>Assume <code>input</code> has <code>k</code> dimensions <code>[I, J, K, ..., N, N]</code>, then the output is a
tensor of rank <code>k - 1</code> with dimensions <code>[I, J, K, ..., N]</code> where:</p>
<p><code>diagonal[i, j, k, ..., n] = input[i, j, k, ..., n, n]</code>.</p>
<p>The input must be at least a matrix.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'input' is [[[1, 0, 0, 0]</h1>
<div class="codehilite"><pre><span></span>           [0, 2, 0, 0]
           [0, 0, 3, 0]
           [0, 0, 0, 4]],
          [[5, 0, 0, 0]
           [0, 6, 0, 0]
           [0, 0, 7, 0]
           [0, 0, 0, 8]]]
</pre></div>


<p>and input.shape = (2, 4, 4)</p>
<p>tf.batch_matrix_diag_part(input) ==&gt; [[1, 2, 3, 4], [5, 6, 7, 8]]</p>
<p>which has shape (2, 4)
```</p>
<p>Args:
  input: A <code>Tensor</code>.
    Rank <code>k</code> tensor where <code>k &gt;= 2</code> and the last two dimensions are equal.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  The extracted diagonal(s) having shape
  <code>diagonal.shape = input.shape[:-1]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_diag_part', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_diag_part" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_diag_part_layer">
    <p>def <span class="ident">batch_matrix_diag_part_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_diag_part_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_diag_part_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_diag_part_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_diag_part_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_matrix_diag_part, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_matrix_diag_part</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_diag_part(input, name=None):
</pre></div>


<p>Returns the batched diagonal part of a batched tensor.</p>
<p>This operation returns a tensor with the <code>diagonal</code> part
of the batched <code>input</code>. The <code>diagonal</code> part is computed as follows:</p>
<p>Assume <code>input</code> has <code>k</code> dimensions <code>[I, J, K, ..., N, N]</code>, then the output is a
tensor of rank <code>k - 1</code> with dimensions <code>[I, J, K, ..., N]</code> where:</p>
<p><code>diagonal[i, j, k, ..., n] = input[i, j, k, ..., n, n]</code>.</p>
<p>The input must be at least a matrix.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'input' is [[[1, 0, 0, 0]</h1>
<div class="codehilite"><pre><span></span>           [0, 2, 0, 0]
           [0, 0, 3, 0]
           [0, 0, 0, 4]],
          [[5, 0, 0, 0]
           [0, 6, 0, 0]
           [0, 0, 7, 0]
           [0, 0, 0, 8]]]
</pre></div>


<p>and input.shape = (2, 4, 4)</p>
<p>tf.batch_matrix_diag_part(input) ==&gt; [[1, 2, 3, 4], [5, 6, 7, 8]]</p>
<p>which has shape (2, 4)
```</p>
<p>Args:
  input: A <code>Tensor</code>.
    Rank <code>k</code> tensor where <code>k &gt;= 2</code> and the last two dimensions are equal.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  The extracted diagonal(s) having shape
  <code>diagonal.shape = input.shape[:-1]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_diag_part_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_diag_part_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_inverse">
    <p>def <span class="ident">batch_matrix_inverse</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_inverse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_inverse</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_inverse</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_inverse(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_matrix_inverse</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_matrix_inverse</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_inverse(input, adjoint=None, name=None)
</pre></div>


<p>Calculates the inverse of square invertible matrices or their adjoints</p>
<p>(conjugate transposes).</p>
<p>The input is a tensor of shape <code>[..., M, M]</code> whose inner-most 2 dimensions
form square matrices. The output is a tensor of the same shape as the input
containing the inverse for all input submatrices <code>[..., :, :]</code>.</p>
<p>The op uses LU decomposition with partial pivoting to compute the inverses.</p>
<p>If a matrix is not invertible there is no guarantee what the op does. It
may detect the condition and raise an exception or it may simply return a
garbage result.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[..., M, M]</code>.
  adjoint: An optional <code>bool</code>. Defaults to <code>False</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. Shape is <code>[..., M, M]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_inverse', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_inverse" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_inverse_layer">
    <p>def <span class="ident">batch_matrix_inverse_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_inverse_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_inverse_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_inverse_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_inverse_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_matrix_inverse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_matrix_inverse</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_inverse(input, adjoint=None, name=None):
</pre></div>


<p>Calculates the inverse of square invertible matrices or their adjoints</p>
<p>(conjugate transposes).</p>
<p>The input is a tensor of shape <code>[..., M, M]</code> whose inner-most 2 dimensions
form square matrices. The output is a tensor of the same shape as the input
containing the inverse for all input submatrices <code>[..., :, :]</code>.</p>
<p>The op uses LU decomposition with partial pivoting to compute the inverses.</p>
<p>If a matrix is not invertible there is no guarantee what the op does. It
may detect the condition and raise an exception or it may simply return a
garbage result.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[..., M, M]</code>.
  adjoint: An optional <code>bool</code>. Defaults to <code>False</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. Shape is <code>[..., M, M]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_inverse_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_inverse_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_solve">
    <p>def <span class="ident">batch_matrix_solve</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_solve, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_solve</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_solve</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_solve(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_matrix_solve</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_matrix_solve</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_solve(matrix, rhs, adjoint=None, name=None)
</pre></div>


<p>Solves systems of linear equations. Checks for invertibility.</p>
<p>Matrix is a tensor of shape <code>[..., M, M]</code> whose inner-most 2 dimensions
form square matrices. Rhs is a tensor of shape
<code>[..., M, K]</code>. The output is a tensor shape <code>[..., M, K]</code>.  If <code>adjoint</code> is <code>False</code> then each output
matrix satisfies <code>matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]</code>.
If <code>adjoint</code> is <code>True</code> then each output
matrix satisfies <code>adjoint(matrix[..., :, :]) * output[..., :, :] = rhs[..., :, :]</code>.</p>
<p>Args:
  matrix: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[..., M, M]</code>.
  rhs: A <code>Tensor</code>. Must have the same type as <code>matrix</code>.
    Shape is <code>[..., M, K]</code>.
  adjoint: An optional <code>bool</code>. Defaults to <code>False</code>.
    Boolean indicating whether to solve with <code>matrix</code> or its (block-wise)
    adjoint.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>matrix</code>. Shape is <code>[..., M, K]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_solve', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_solve" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_solve_layer">
    <p>def <span class="ident">batch_matrix_solve_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_solve_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_solve_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_solve_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_solve_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_matrix_solve, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_matrix_solve</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_solve(matrix, rhs, adjoint=None, name=None):
</pre></div>


<p>Solves systems of linear equations. Checks for invertibility.</p>
<p>Matrix is a tensor of shape <code>[..., M, M]</code> whose inner-most 2 dimensions
form square matrices. Rhs is a tensor of shape
<code>[..., M, K]</code>. The output is a tensor shape <code>[..., M, K]</code>.  If <code>adjoint</code> is <code>False</code> then each output
matrix satisfies <code>matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]</code>.
If <code>adjoint</code> is <code>True</code> then each output
matrix satisfies <code>adjoint(matrix[..., :, :]) * output[..., :, :] = rhs[..., :, :]</code>.</p>
<p>Args:
  matrix: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[..., M, M]</code>.
  rhs: A <code>Tensor</code>. Must have the same type as <code>matrix</code>.
    Shape is <code>[..., M, K]</code>.
  adjoint: An optional <code>bool</code>. Defaults to <code>False</code>.
    Boolean indicating whether to solve with <code>matrix</code> or its (block-wise)
    adjoint.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>matrix</code>. Shape is <code>[..., M, K]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_solve_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_solve_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_solve_ls">
    <p>def <span class="ident">batch_matrix_solve_ls</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_solve_ls, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_solve_ls</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_solve_ls</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_solve_ls(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_matrix_solve_ls</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_matrix_solve_ls</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_solve_ls(matrix, rhs, l2_regularizer=0.0, fast=True, name=None)
</pre></div>


<p>Solves multiple linear least-squares problems.</p>
<p><code>matrix</code> is a tensor of shape <code>[..., M, N]</code> whose inner-most 2 dimensions
form <code>M</code>-by-<code>N</code> matrices. Rhs is a tensor of shape <code>[..., M, K]</code> whose
inner-most 2 dimensions form <code>M</code>-by-<code>K</code> matrices.   The computed output is a
<code>Tensor</code> of shape <code>[..., N, K]</code> whose inner-most 2 dimensions form <code>M</code>-by-<code>K</code>
matrices that solve the equations
<code>matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]</code> in the least squares
sense.</p>
<p>Below we will use the following notation for each pair of
matrix and right-hand sides in the batch:</p>
<p><code>matrix</code>=\(A \in \Re^{m \times n}\),
<code>rhs</code>=\(B  \in \Re^{m \times k}\),
<code>output</code>=\(X  \in \Re^{n \times k}\),
<code>l2_regularizer</code>=\(\lambda\).</p>
<p>If <code>fast</code> is <code>True</code>, then the solution is computed by solving the normal
equations using Cholesky decomposition. Specifically, if \(m \ge n\) then
\(X = (A^T A + \lambda I)^{-1} A^T B\), which solves the least-squares
problem \(X = \mathrm{argmin}<em>{Z \in \Re^{n \times k}} ||A Z - B||_F^2 +
\lambda ||Z||_F^2\). If \(m \lt n\) then <code>output</code> is computed as
\(X = A^T (A A^T + \lambda I)^{-1} B\), which (for \(\lambda = 0\)) is
the minimum-norm solution to the under-determined linear system, i.e.
\(X = \mathrm{argmin}</em>{Z \in \Re^{n \times k}} ||Z||<em>F^2 \), subject to
\(A Z = B\). Notice that the fast path is only numerically stable when
\(A\) is numerically full rank and has a condition number
\(\mathrm{cond}(A) \lt \frac{1}{\sqrt{\epsilon</em>{mach}}}\) or\(\lambda\)
is sufficiently large.</p>
<p>If <code>fast</code> is <code>False</code> an algorithm based on the numerically robust complete
orthogonal decomposition is used. This computes the minimum-norm
least-squares solution, even when \(A\) is rank deficient. This path is
typically 6-7 times slower than the fast path. If <code>fast</code> is <code>False</code> then
<code>l2_regularizer</code> is ignored.</p>
<p>Args:
  matrix: <code>Tensor</code> of shape <code>[..., M, N]</code>.
  rhs: <code>Tensor</code> of shape <code>[..., M, K]</code>.
  l2_regularizer: 0-D <code>double</code> <code>Tensor</code>. Ignored if <code>fast=False</code>.
  fast: bool. Defaults to <code>True</code>.
  name: string, optional name of the operation.</p>
<p>Returns:
  output: <code>Tensor</code> of shape <code>[..., N, K]</code> whose inner-most 2 dimensions form
    <code>M</code>-by-<code>K</code> matrices that solve the equations
    <code>matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]</code> in the least
    squares sense.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_solve_ls', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_solve_ls" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_solve_ls_layer">
    <p>def <span class="ident">batch_matrix_solve_ls_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_solve_ls_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_solve_ls_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_solve_ls_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_solve_ls_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_matrix_solve_ls, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_matrix_solve_ls</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_solve_ls(matrix, rhs, l2_regularizer=0.0, fast=True, name=None):
</pre></div>


<p>Solves multiple linear least-squares problems.</p>
<p><code>matrix</code> is a tensor of shape <code>[..., M, N]</code> whose inner-most 2 dimensions
form <code>M</code>-by-<code>N</code> matrices. Rhs is a tensor of shape <code>[..., M, K]</code> whose
inner-most 2 dimensions form <code>M</code>-by-<code>K</code> matrices.   The computed output is a
<code>Tensor</code> of shape <code>[..., N, K]</code> whose inner-most 2 dimensions form <code>M</code>-by-<code>K</code>
matrices that solve the equations
<code>matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]</code> in the least squares
sense.</p>
<p>Below we will use the following notation for each pair of
matrix and right-hand sides in the batch:</p>
<p><code>matrix</code>=\(A \in \Re^{m \times n}\),
<code>rhs</code>=\(B  \in \Re^{m \times k}\),
<code>output</code>=\(X  \in \Re^{n \times k}\),
<code>l2_regularizer</code>=\(\lambda\).</p>
<p>If <code>fast</code> is <code>True</code>, then the solution is computed by solving the normal
equations using Cholesky decomposition. Specifically, if \(m \ge n\) then
\(X = (A^T A + \lambda I)^{-1} A^T B\), which solves the least-squares
problem \(X = \mathrm{argmin}<em>{Z \in \Re^{n \times k}} ||A Z - B||_F^2 +
\lambda ||Z||_F^2\). If \(m \lt n\) then <code>output</code> is computed as
\(X = A^T (A A^T + \lambda I)^{-1} B\), which (for \(\lambda = 0\)) is
the minimum-norm solution to the under-determined linear system, i.e.
\(X = \mathrm{argmin}</em>{Z \in \Re^{n \times k}} ||Z||<em>F^2 \), subject to
\(A Z = B\). Notice that the fast path is only numerically stable when
\(A\) is numerically full rank and has a condition number
\(\mathrm{cond}(A) \lt \frac{1}{\sqrt{\epsilon</em>{mach}}}\) or\(\lambda\)
is sufficiently large.</p>
<p>If <code>fast</code> is <code>False</code> an algorithm based on the numerically robust complete
orthogonal decomposition is used. This computes the minimum-norm
least-squares solution, even when \(A\) is rank deficient. This path is
typically 6-7 times slower than the fast path. If <code>fast</code> is <code>False</code> then
<code>l2_regularizer</code> is ignored.</p>
<p>Args:
  matrix: <code>Tensor</code> of shape <code>[..., M, N]</code>.
  rhs: <code>Tensor</code> of shape <code>[..., M, K]</code>.
  l2_regularizer: 0-D <code>double</code> <code>Tensor</code>. Ignored if <code>fast=False</code>.
  fast: bool. Defaults to <code>True</code>.
  name: string, optional name of the operation.</p>
<p>Returns:
  output: <code>Tensor</code> of shape <code>[..., N, K]</code> whose inner-most 2 dimensions form
    <code>M</code>-by-<code>K</code> matrices that solve the equations
    <code>matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]</code> in the least
    squares sense.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_solve_ls_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_solve_ls_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_triangular_solve">
    <p>def <span class="ident">batch_matrix_triangular_solve</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_triangular_solve, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_triangular_solve</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_triangular_solve</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_triangular_solve(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_matrix_triangular_solve</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_matrix_triangular_solve</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_triangular_solve(matrix, rhs, lower=None, adjoint=None, name=None)
</pre></div>


<p>Solves systems of linear equations with upper or lower triangular matrices by</p>
<p>backsubstitution.</p>
<p><code>matrix</code> is a tensor of shape <code>[..., M, M]</code> whose inner-most 2 dimensions form
square matrices. If <code>lower</code> is <code>True</code> then the strictly upper triangular part
of each inner-most matrix is assumed to be zero and not accessed.
If <code>lower</code> is False then the strictly lower triangular part of each inner-most
matrix is assumed to be zero and not accessed.
<code>rhs</code> is a tensor of shape [..., M, K]`.</p>
<p>The output is a tensor of shape <code>[..., M, K]</code>. If <code>adjoint</code> is <code>True</code> then the
innermost matrices in output<code>satisfy matrix equations</code>matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]<code>.
If</code>adjoint<code>is</code>False<code>then the strictly then the  innermost matrices in</code>output<code>satisfy matrix equations</code>adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]`.</p>
<p>Args:
  matrix: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[..., M, M]</code>.
  rhs: A <code>Tensor</code>. Must have the same type as <code>matrix</code>.
    Shape is <code>[..., M, K]</code>.
  lower: An optional <code>bool</code>. Defaults to <code>True</code>.
    Boolean indicating whether the innermost matrices in <code>matrix</code> are
    lower or upper triangular.
  adjoint: An optional <code>bool</code>. Defaults to <code>False</code>.
    Boolean indicating whether to solve with <code>matrix</code> or its (block-wise)
    adjoint.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>matrix</code>. Shape is <code>[..., M, K]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_triangular_solve', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_triangular_solve" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_matrix_triangular_solve_layer">
    <p>def <span class="ident">batch_matrix_triangular_solve_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_matrix_triangular_solve_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_matrix_triangular_solve_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_matrix_triangular_solve_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_triangular_solve_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_matrix_triangular_solve, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_matrix_triangular_solve</strong></p>
<div class="codehilite"><pre><span></span>def batch_matrix_triangular_solve(matrix, rhs, lower=None, adjoint=None, name=None):
</pre></div>


<p>Solves systems of linear equations with upper or lower triangular matrices by</p>
<p>backsubstitution.</p>
<p><code>matrix</code> is a tensor of shape <code>[..., M, M]</code> whose inner-most 2 dimensions form
square matrices. If <code>lower</code> is <code>True</code> then the strictly upper triangular part
of each inner-most matrix is assumed to be zero and not accessed.
If <code>lower</code> is False then the strictly lower triangular part of each inner-most
matrix is assumed to be zero and not accessed.
<code>rhs</code> is a tensor of shape [..., M, K]`.</p>
<p>The output is a tensor of shape <code>[..., M, K]</code>. If <code>adjoint</code> is <code>True</code> then the
innermost matrices in output<code>satisfy matrix equations</code>matrix[..., :, :] * output[..., :, :] = rhs[..., :, :]<code>.
If</code>adjoint<code>is</code>False<code>then the strictly then the  innermost matrices in</code>output<code>satisfy matrix equations</code>adjoint(matrix[..., i, k]) * output[..., k, j] = rhs[..., i, j]`.</p>
<p>Args:
  matrix: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[..., M, M]</code>.
  rhs: A <code>Tensor</code>. Must have the same type as <code>matrix</code>.
    Shape is <code>[..., M, K]</code>.
  lower: An optional <code>bool</code>. Defaults to <code>True</code>.
    Boolean indicating whether the innermost matrices in <code>matrix</code> are
    lower or upper triangular.
  adjoint: An optional <code>bool</code>. Defaults to <code>False</code>.
    Boolean indicating whether to solve with <code>matrix</code> or its (block-wise)
    adjoint.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>matrix</code>. Shape is <code>[..., M, K]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_matrix_triangular_solve_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_matrix_triangular_solve_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_norm_with_global_normalization">
    <p>def <span class="ident">batch_norm_with_global_normalization</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_norm_with_global_normalization, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_norm_with_global_normalization</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_norm_with_global_normalization</strong></p>
<div class="codehilite"><pre><span></span>def batch_norm_with_global_normalization(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.batch_norm_with_global_normalization</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.batch_norm_with_global_normalization</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_norm_with_global_normalization(t, m, v, beta, gamma, variance_epsilon, scale_after_normalization, name=None)
</pre></div>


<p>Batch normalization.</p>
<p>This op is deprecated. See <code>tf.nn.batch_normalization</code>.</p>
<p>Args:
  t: A 4D input Tensor.
  m: A 1D mean Tensor with size matching the last dimension of t.
    This is the first output from tf.nn.moments,
    or a saved moving average thereof.
  v: A 1D variance Tensor with size matching the last dimension of t.
    This is the second output from tf.nn.moments,
    or a saved moving average thereof.
  beta: A 1D beta Tensor with size matching the last dimension of t.
    An offset to be added to the normalized tensor.
  gamma: A 1D gamma Tensor with size matching the last dimension of t.
    If "scale_after_normalization" is true, this tensor will be multiplied
    with the normalized tensor.
  variance_epsilon: A small float number to avoid dividing by 0.
  scale_after_normalization: A bool indicating whether the resulted tensor
    needs to be multiplied with gamma.
  name: A name for this operation (optional).</p>
<p>Returns:
   A batch-normalized <code>t</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_norm_with_global_normalization', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_norm_with_global_normalization" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_norm_with_global_normalization_layer">
    <p>def <span class="ident">batch_norm_with_global_normalization_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_norm_with_global_normalization_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_norm_with_global_normalization_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_norm_with_global_normalization_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_norm_with_global_normalization_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.batch_norm_with_global_normalization, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.batch_norm_with_global_normalization</strong></p>
<div class="codehilite"><pre><span></span>def batch_norm_with_global_normalization(t, m, v, beta, gamma, variance_epsilon, scale_after_normalization, name=None):
</pre></div>


<p>Batch normalization.</p>
<p>This op is deprecated. See <code>tf.nn.batch_normalization</code>.</p>
<p>Args:
  t: A 4D input Tensor.
  m: A 1D mean Tensor with size matching the last dimension of t.
    This is the first output from tf.nn.moments,
    or a saved moving average thereof.
  v: A 1D variance Tensor with size matching the last dimension of t.
    This is the second output from tf.nn.moments,
    or a saved moving average thereof.
  beta: A 1D beta Tensor with size matching the last dimension of t.
    An offset to be added to the normalized tensor.
  gamma: A 1D gamma Tensor with size matching the last dimension of t.
    If "scale_after_normalization" is true, this tensor will be multiplied
    with the normalized tensor.
  variance_epsilon: A small float number to avoid dividing by 0.
  scale_after_normalization: A bool indicating whether the resulted tensor
    needs to be multiplied with gamma.
  name: A name for this operation (optional).</p>
<p>Returns:
   A batch-normalized <code>t</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_norm_with_global_normalization_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_norm_with_global_normalization_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_normalization">
    <p>def <span class="ident">batch_normalization</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_normalization, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_normalization</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_normalization</strong></p>
<div class="codehilite"><pre><span></span>def batch_normalization(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.batch_normalization</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.batch_normalization</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_normalization(x, mean, variance, offset, scale, variance_epsilon, name=None)
</pre></div>


<p>Batch normalization.</p>
<p>As described in http://arxiv.org/abs/1502.03167.
Normalizes a tensor by <code>mean</code> and <code>variance</code>, and applies (optionally) a
<code>scale</code> \(\gamma\) to it, as well as an <code>offset</code> \(\beta\):</p>
<p>\(\frac{\gamma(x-\mu)}{\sigma}+\beta\)</p>
<p><code>mean</code>, <code>variance</code>, <code>offset</code> and <code>scale</code> are all expected to be of one of two
shapes:
  * In all generality, they can have the same number of dimensions as the
    input <code>x</code>, with identical sizes as <code>x</code> for the dimensions that are not
    normalized over (the 'depth' dimension(s)), and dimension 1 for the
    others which are being normalized over.
    <code>mean</code> and <code>variance</code> in this case would typically be the outputs of
    <code>tf.nn.moments(..., keep_dims=True)</code> during training, or running averages
    thereof during inference.
  * In the common case where the 'depth' dimension is the last dimension in
    the input tensor <code>x</code>, they may be one dimensional tensors of the same
    size as the 'depth' dimension.
    This is the case for example for the common <code>[batch, depth]</code> layout of
    fully-connected layers, and <code>[batch, height, width, depth]</code> for
    convolutions.
    <code>mean</code> and <code>variance</code> in this case would typically be the outputs of
    <code>tf.nn.moments(..., keep_dims=False)</code> during training, or running averages
    thereof during inference.</p>
<p>Args:
  x: Input <code>Tensor</code> of arbitrary dimensionality.
  mean: A mean <code>Tensor</code>.
  variance: A variance <code>Tensor</code>.
  offset: An offset <code>Tensor</code>, often denoted \(\beta\) in equations, or
    None. If present, will be added to the normalized tensor.
  scale: A scale <code>Tensor</code>, often denoted \(\gamma\) in equations, or
    <code>None</code>. If present, the scale is applied to the normalized tensor.
  variance_epsilon: A small float number to avoid dividing by 0.
  name: A name for this operation (optional).</p>
<p>Returns:
  the normalized, scaled, offset tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_normalization', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_normalization" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_normalization_layer">
    <p>def <span class="ident">batch_normalization_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_normalization_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_normalization_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_normalization_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_normalization_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.batch_normalization, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.batch_normalization</strong></p>
<div class="codehilite"><pre><span></span>def batch_normalization(x, mean, variance, offset, scale, variance_epsilon, name=None):
</pre></div>


<p>Batch normalization.</p>
<p>As described in http://arxiv.org/abs/1502.03167.
Normalizes a tensor by <code>mean</code> and <code>variance</code>, and applies (optionally) a
<code>scale</code> \(\gamma\) to it, as well as an <code>offset</code> \(\beta\):</p>
<p>\(\frac{\gamma(x-\mu)}{\sigma}+\beta\)</p>
<p><code>mean</code>, <code>variance</code>, <code>offset</code> and <code>scale</code> are all expected to be of one of two
shapes:
  * In all generality, they can have the same number of dimensions as the
    input <code>x</code>, with identical sizes as <code>x</code> for the dimensions that are not
    normalized over (the 'depth' dimension(s)), and dimension 1 for the
    others which are being normalized over.
    <code>mean</code> and <code>variance</code> in this case would typically be the outputs of
    <code>tf.nn.moments(..., keep_dims=True)</code> during training, or running averages
    thereof during inference.
  * In the common case where the 'depth' dimension is the last dimension in
    the input tensor <code>x</code>, they may be one dimensional tensors of the same
    size as the 'depth' dimension.
    This is the case for example for the common <code>[batch, depth]</code> layout of
    fully-connected layers, and <code>[batch, height, width, depth]</code> for
    convolutions.
    <code>mean</code> and <code>variance</code> in this case would typically be the outputs of
    <code>tf.nn.moments(..., keep_dims=False)</code> during training, or running averages
    thereof during inference.</p>
<p>Args:
  x: Input <code>Tensor</code> of arbitrary dimensionality.
  mean: A mean <code>Tensor</code>.
  variance: A variance <code>Tensor</code>.
  offset: An offset <code>Tensor</code>, often denoted \(\beta\) in equations, or
    None. If present, will be added to the normalized tensor.
  scale: A scale <code>Tensor</code>, often denoted \(\gamma\) in equations, or
    <code>None</code>. If present, the scale is applied to the normalized tensor.
  variance_epsilon: A small float number to avoid dividing by 0.
  name: A name for this operation (optional).</p>
<p>Returns:
  the normalized, scaled, offset tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_normalization_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_normalization_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_self_adjoint_eig">
    <p>def <span class="ident">batch_self_adjoint_eig</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_self_adjoint_eig, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_self_adjoint_eig</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_self_adjoint_eig</strong></p>
<div class="codehilite"><pre><span></span>def batch_self_adjoint_eig(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_self_adjoint_eig</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_self_adjoint_eig</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_self_adjoint_eig(input, name=None)
</pre></div>


<p>Calculates the Eigen Decomposition of a batch of square self-adjoint matrices.</p>
<p>The input is a tensor of shape <code>[..., M, M]</code> whose inner-most 2 dimensions
form square matrices, with the same constraints as the single matrix
SelfAdjointEig.</p>
<p>The result is a '[..., M+1, M] matrix with [..., 0,:] containing the
eigenvalues, and subsequent [...,1:, :] containing the eigenvectors.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[..., M, M]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. Shape is <code>[..., M+1, M]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_self_adjoint_eig', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_self_adjoint_eig" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_self_adjoint_eig_layer">
    <p>def <span class="ident">batch_self_adjoint_eig_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_self_adjoint_eig_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_self_adjoint_eig_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_self_adjoint_eig_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_self_adjoint_eig_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_self_adjoint_eig, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_self_adjoint_eig</strong></p>
<div class="codehilite"><pre><span></span>def batch_self_adjoint_eig(input, name=None):
</pre></div>


<p>Calculates the Eigen Decomposition of a batch of square self-adjoint matrices.</p>
<p>The input is a tensor of shape <code>[..., M, M]</code> whose inner-most 2 dimensions
form square matrices, with the same constraints as the single matrix
SelfAdjointEig.</p>
<p>The result is a '[..., M+1, M] matrix with [..., 0,:] containing the
eigenvalues, and subsequent [...,1:, :] containing the eigenvectors.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[..., M, M]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. Shape is <code>[..., M+1, M]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_self_adjoint_eig_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_self_adjoint_eig_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_to_space">
    <p>def <span class="ident">batch_to_space</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_to_space, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_to_space</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_to_space</strong></p>
<div class="codehilite"><pre><span></span>def batch_to_space(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.batch_to_space</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.batch_to_space</code></strong></p>
<div class="codehilite"><pre><span></span>def batch_to_space(input, crops, block_size, name=None)
</pre></div>


<p>BatchToSpace for 4-D tensors of type T.</p>
<p>Rearranges (permutes) data from batch into blocks of spatial data, followed by
cropping. This is the reverse transformation of SpaceToBatch. More specifically,
this op outputs a copy of the input tensor where values from the <code>batch</code>
dimension are moved in spatial blocks to the <code>height</code> and <code>width</code> dimensions,
followed by cropping along the <code>height</code> and <code>width</code> dimensions.</p>
<p>Args:
  input: A <code>Tensor</code>. 4-D tensor with shape
    <code>[batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
      depth]</code>. Note that the batch size of the input tensor must be divisible by
    <code>block_size * block_size</code>.
  crops: A <code>Tensor</code> of type <code>int32</code>.
    2-D tensor of non-negative integers with shape <code>[2, 2]</code>. It specifies
    how many elements to crop from the intermediate result across the spatial
    dimensions as follows:</p>
<div class="codehilite"><pre><span></span>    crops = [[crop_top, crop_bottom], [crop_left, crop_right]]
</pre></div>


<p>block_size: An <code>int</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  4-D with shape <code>[batch, height, width, depth]</code>, where:</p>
<div class="codehilite"><pre><span></span>    height = height_pad - crop_top - crop_bottom
    width = width_pad - crop_left - crop_right
</pre></div>


<p>The attr <code>block_size</code> must be greater than one. It indicates the block size.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_to_space', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_to_space" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.batch_to_space_layer">
    <p>def <span class="ident">batch_to_space_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.batch_to_space_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.batch_to_space_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.batch_to_space_layer</strong></p>
<div class="codehilite"><pre><span></span>def batch_to_space_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.batch_to_space, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.batch_to_space</strong></p>
<div class="codehilite"><pre><span></span>def batch_to_space(input, crops, block_size, name=None):
</pre></div>


<p>BatchToSpace for 4-D tensors of type T.</p>
<p>Rearranges (permutes) data from batch into blocks of spatial data, followed by
cropping. This is the reverse transformation of SpaceToBatch. More specifically,
this op outputs a copy of the input tensor where values from the <code>batch</code>
dimension are moved in spatial blocks to the <code>height</code> and <code>width</code> dimensions,
followed by cropping along the <code>height</code> and <code>width</code> dimensions.</p>
<p>Args:
  input: A <code>Tensor</code>. 4-D tensor with shape
    <code>[batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
      depth]</code>. Note that the batch size of the input tensor must be divisible by
    <code>block_size * block_size</code>.
  crops: A <code>Tensor</code> of type <code>int32</code>.
    2-D tensor of non-negative integers with shape <code>[2, 2]</code>. It specifies
    how many elements to crop from the intermediate result across the spatial
    dimensions as follows:</p>
<div class="codehilite"><pre><span></span>    crops = [[crop_top, crop_bottom], [crop_left, crop_right]]
</pre></div>


<p>block_size: An <code>int</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  4-D with shape <code>[batch, height, width, depth]</code>, where:</p>
<div class="codehilite"><pre><span></span>    height = height_pad - crop_top - crop_bottom
    width = width_pad - crop_left - crop_right
</pre></div>


<p>The attr <code>block_size</code> must be greater than one. It indicates the block size.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.batch_to_space_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.batch_to_space_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.bias_add">
    <p>def <span class="ident">bias_add</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.bias_add, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.bias_add</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.bias_add</strong></p>
<div class="codehilite"><pre><span></span>def bias_add(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.bias_add</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.bias_add</code></strong></p>
<div class="codehilite"><pre><span></span>def bias_add(value, bias, data_format=None, name=None)
</pre></div>


<p>Adds <code>bias</code> to <code>value</code>.</p>
<p>This is (mostly) a special case of <code>tf.add</code> where <code>bias</code> is restricted to 1-D.
Broadcasting is supported, so <code>value</code> may have any number of dimensions.
Unlike <code>tf.add</code>, the type of <code>bias</code> is allowed to differ from <code>value</code> in the
case where both types are quantized.</p>
<p>Args:
  value: A <code>Tensor</code> with type <code>float</code>, <code>double</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>,
    <code>int16</code>, <code>int8</code>, <code>complex64</code>, or <code>complex128</code>.
  bias: A 1-D <code>Tensor</code> with size matching the last dimension of <code>value</code>.
    Must be the same type as <code>value</code> unless <code>value</code> is a quantized type,
    in which case a different quantized type may be used.
  data_format: A string. 'NHWC' and 'NCHW' are supported.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with the same type as <code>value</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.bias_add', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.bias_add" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.bias_add_grad">
    <p>def <span class="ident">bias_add_grad</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.bias_add_grad, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.bias_add_grad</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.bias_add_grad</strong></p>
<div class="codehilite"><pre><span></span>def bias_add_grad(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.bias_add_grad</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.bias_add_grad</code></strong></p>
<div class="codehilite"><pre><span></span>def bias_add_grad(out_backprop, data_format=None, name=None)
</pre></div>


<p>The backward operation for "BiasAdd" on the "bias" tensor.</p>
<p>It accumulates all the values from out_backprop into the feature dimension.
For NHWC data format, the feature dimension is the last. For NCHW data format,
the feature dimension is the third-to-last.</p>
<p>Args:
  out_backprop: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Any number of dimensions.
  data_format: An optional <code>string</code> from: <code>"NHWC", "NCHW"</code>. Defaults to <code>"NHWC"</code>.
    Specify the data format of the input and output data. With the
    default format "NHWC", the bias tensor will be added to the last dimension
    of the value tensor.
    Alternatively, the format could be "NCHW", the data storage order of:
        [batch, in_channels, in_height, in_width].
    The tensor will be added to "in_channels", the third-to-the-last
        dimension.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>out_backprop</code>.
  1-D with size the feature dimension of <code>out_backprop</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.bias_add_grad', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.bias_add_grad" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.bias_add_grad_layer">
    <p>def <span class="ident">bias_add_grad_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.bias_add_grad_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.bias_add_grad_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.bias_add_grad_layer</strong></p>
<div class="codehilite"><pre><span></span>def bias_add_grad_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.bias_add_grad, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.bias_add_grad</strong></p>
<div class="codehilite"><pre><span></span>def bias_add_grad(out_backprop, data_format=None, name=None):
</pre></div>


<p>The backward operation for "BiasAdd" on the "bias" tensor.</p>
<p>It accumulates all the values from out_backprop into the feature dimension.
For NHWC data format, the feature dimension is the last. For NCHW data format,
the feature dimension is the third-to-last.</p>
<p>Args:
  out_backprop: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Any number of dimensions.
  data_format: An optional <code>string</code> from: <code>"NHWC", "NCHW"</code>. Defaults to <code>"NHWC"</code>.
    Specify the data format of the input and output data. With the
    default format "NHWC", the bias tensor will be added to the last dimension
    of the value tensor.
    Alternatively, the format could be "NCHW", the data storage order of:
        [batch, in_channels, in_height, in_width].
    The tensor will be added to "in_channels", the third-to-the-last
        dimension.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>out_backprop</code>.
  1-D with size the feature dimension of <code>out_backprop</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.bias_add_grad_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.bias_add_grad_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.bias_add_layer">
    <p>def <span class="ident">bias_add_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.bias_add_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.bias_add_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.bias_add_layer</strong></p>
<div class="codehilite"><pre><span></span>def bias_add_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.bias_add, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.bias_add</strong></p>
<div class="codehilite"><pre><span></span>def bias_add(value, bias, data_format=None, name=None):
</pre></div>


<p>Adds <code>bias</code> to <code>value</code>.</p>
<p>This is (mostly) a special case of <code>tf.add</code> where <code>bias</code> is restricted to 1-D.
Broadcasting is supported, so <code>value</code> may have any number of dimensions.
Unlike <code>tf.add</code>, the type of <code>bias</code> is allowed to differ from <code>value</code> in the
case where both types are quantized.</p>
<p>Args:
  value: A <code>Tensor</code> with type <code>float</code>, <code>double</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>,
    <code>int16</code>, <code>int8</code>, <code>complex64</code>, or <code>complex128</code>.
  bias: A 1-D <code>Tensor</code> with size matching the last dimension of <code>value</code>.
    Must be the same type as <code>value</code> unless <code>value</code> is a quantized type,
    in which case a different quantized type may be used.
  data_format: A string. 'NHWC' and 'NCHW' are supported.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with the same type as <code>value</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.bias_add_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.bias_add_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.bias_add_v1">
    <p>def <span class="ident">bias_add_v1</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.bias_add_v1, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.bias_add_v1</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.bias_add_v1</strong></p>
<div class="codehilite"><pre><span></span>def bias_add_v1(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.bias_add_v1</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.bias_add_v1</code></strong></p>
<div class="codehilite"><pre><span></span>def bias_add_v1(value, bias, name=None)
</pre></div>


<p>Adds <code>bias</code> to <code>value</code>.</p>
<p>This is a deprecated version of bias_add and will soon to be removed.</p>
<p>This is (mostly) a special case of <code>tf.add</code> where <code>bias</code> is restricted to 1-D.
Broadcasting is supported, so <code>value</code> may have any number of dimensions.
Unlike <code>tf.add</code>, the type of <code>bias</code> is allowed to differ from <code>value</code> in the
case where both types are quantized.</p>
<p>Args:
  value: A <code>Tensor</code> with type <code>float</code>, <code>double</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>,
    <code>int16</code>, <code>int8</code>, <code>complex64</code>, or <code>complex128</code>.
  bias: A 1-D <code>Tensor</code> with size matching the last dimension of <code>value</code>.
    Must be the same type as <code>value</code> unless <code>value</code> is a quantized type,
    in which case a different quantized type may be used.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with the same type as <code>value</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.bias_add_v1', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.bias_add_v1" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.bias_add_v1_layer">
    <p>def <span class="ident">bias_add_v1_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.bias_add_v1_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.bias_add_v1_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.bias_add_v1_layer</strong></p>
<div class="codehilite"><pre><span></span>def bias_add_v1_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.bias_add_v1, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.bias_add_v1</strong></p>
<div class="codehilite"><pre><span></span>def bias_add_v1(value, bias, name=None):
</pre></div>


<p>Adds <code>bias</code> to <code>value</code>.</p>
<p>This is a deprecated version of bias_add and will soon to be removed.</p>
<p>This is (mostly) a special case of <code>tf.add</code> where <code>bias</code> is restricted to 1-D.
Broadcasting is supported, so <code>value</code> may have any number of dimensions.
Unlike <code>tf.add</code>, the type of <code>bias</code> is allowed to differ from <code>value</code> in the
case where both types are quantized.</p>
<p>Args:
  value: A <code>Tensor</code> with type <code>float</code>, <code>double</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>,
    <code>int16</code>, <code>int8</code>, <code>complex64</code>, or <code>complex128</code>.
  bias: A 1-D <code>Tensor</code> with size matching the last dimension of <code>value</code>.
    Must be the same type as <code>value</code> unless <code>value</code> is a quantized type,
    in which case a different quantized type may be used.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with the same type as <code>value</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.bias_add_v1_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.bias_add_v1_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.bidirectional_rnn">
    <p>def <span class="ident">bidirectional_rnn</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.bidirectional_rnn, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.bidirectional_rnn</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.bidirectional_rnn</strong></p>
<div class="codehilite"><pre><span></span>def bidirectional_rnn(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.bidirectional_rnn</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.bidirectional_rnn</code></strong></p>
<div class="codehilite"><pre><span></span>def bidirectional_rnn(cell_fw, cell_bw, inputs, initial_state_fw=None, initial_state_bw=None, dtype=None, sequence_length=None, scope=None)
</pre></div>


<p>Creates a bidirectional recurrent neural network.</p>
<p>Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given.</p>
<p>Args:
  cell_fw: An instance of RNNCell, to be used for forward direction.
  cell_bw: An instance of RNNCell, to be used for backward direction.
  inputs: A length T list of inputs, each a tensor of shape
    [batch_size, input_size].
  initial_state_fw: (optional) An initial state for the forward RNN.
    This must be a tensor of appropriate type and shape
    <code>[batch_size x cell_fw.state_size]</code>.
    If <code>cell_fw.state_size</code> is a tuple, this should be a tuple of
    tensors having shapes <code>[batch_size, s] for s in cell_fw.state_size</code>.
  initial_state_bw: (optional) Same as for <code>initial_state_fw</code>, but using
    the corresponding properties of <code>cell_bw</code>.
  dtype: (optional) The data type for the initial state.  Required if
    either of the initial states are not provided.
  sequence_length: (optional) An int32/int64 vector, size <code>[batch_size]</code>,
    containing the actual lengths for each of the sequences.
  scope: VariableScope for the created subgraph; defaults to "BiRNN"</p>
<p>Returns:
  A tuple (outputs, output_state_fw, output_state_bw) where:
    outputs is a length <code>T</code> list of outputs (one for each input), which
      are depth-concatenated forward and backward outputs.
    output_state_fw is the final state of the forward rnn.
    output_state_bw is the final state of the backward rnn.</p>
<p>Raises:
  TypeError: If <code>cell_fw</code> or <code>cell_bw</code> is not an instance of <code>RNNCell</code>.
  ValueError: If inputs is None or an empty list.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.bidirectional_rnn', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.bidirectional_rnn" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.bidirectional_rnn_layer">
    <p>def <span class="ident">bidirectional_rnn_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.bidirectional_rnn_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.bidirectional_rnn_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.bidirectional_rnn_layer</strong></p>
<div class="codehilite"><pre><span></span>def bidirectional_rnn_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.bidirectional_rnn, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.bidirectional_rnn</strong></p>
<div class="codehilite"><pre><span></span>def bidirectional_rnn(cell_fw, cell_bw, inputs, initial_state_fw=None, initial_state_bw=None, dtype=None, sequence_length=None, scope=None):
</pre></div>


<p>Creates a bidirectional recurrent neural network.</p>
<p>Similar to the unidirectional case above (rnn) but takes input and builds
independent forward and backward RNNs with the final forward and backward
outputs depth-concatenated, such that the output will have the format
[time][batch][cell_fw.output_size + cell_bw.output_size]. The input_size of
forward and backward cell must match. The initial state for both directions
is zero by default (but can be set optionally) and no intermediate states are
ever returned -- the network is fully unrolled for the given (passed in)
length(s) of the sequence(s) or completely unrolled if length(s) is not given.</p>
<p>Args:
  cell_fw: An instance of RNNCell, to be used for forward direction.
  cell_bw: An instance of RNNCell, to be used for backward direction.
  inputs: A length T list of inputs, each a tensor of shape
    [batch_size, input_size].
  initial_state_fw: (optional) An initial state for the forward RNN.
    This must be a tensor of appropriate type and shape
    <code>[batch_size x cell_fw.state_size]</code>.
    If <code>cell_fw.state_size</code> is a tuple, this should be a tuple of
    tensors having shapes <code>[batch_size, s] for s in cell_fw.state_size</code>.
  initial_state_bw: (optional) Same as for <code>initial_state_fw</code>, but using
    the corresponding properties of <code>cell_bw</code>.
  dtype: (optional) The data type for the initial state.  Required if
    either of the initial states are not provided.
  sequence_length: (optional) An int32/int64 vector, size <code>[batch_size]</code>,
    containing the actual lengths for each of the sequences.
  scope: VariableScope for the created subgraph; defaults to "BiRNN"</p>
<p>Returns:
  A tuple (outputs, output_state_fw, output_state_bw) where:
    outputs is a length <code>T</code> list of outputs (one for each input), which
      are depth-concatenated forward and backward outputs.
    output_state_fw is the final state of the forward rnn.
    output_state_bw is the final state of the backward rnn.</p>
<p>Raises:
  TypeError: If <code>cell_fw</code> or <code>cell_bw</code> is not an instance of <code>RNNCell</code>.
  ValueError: If inputs is None or an empty list.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.bidirectional_rnn_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.bidirectional_rnn_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.bitcast">
    <p>def <span class="ident">bitcast</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.bitcast, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.bitcast</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.bitcast</strong></p>
<div class="codehilite"><pre><span></span>def bitcast(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.bitcast</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.bitcast</code></strong></p>
<div class="codehilite"><pre><span></span>def bitcast(input, type, name=None)
</pre></div>


<p>Bitcasts a tensor from one type to another without copying data.</p>
<p>Given a tensor <code>input</code>, this operation returns a tensor that has the same buffer
data as <code>input</code> with datatype <code>type</code>.</p>
<p>If the input datatype <code>T</code> is larger than the output datatype <code>type</code> then the
shape changes from [...] to [..., sizeof(<code>T</code>)/sizeof(<code>type</code>)].</p>
<p>If <code>T</code> is smaller than <code>type</code>, the operator requires that the rightmost
dimension be equal to sizeof(<code>type</code>)/sizeof(<code>T</code>). The shape then goes from
[..., sizeof(<code>type</code>)/sizeof(<code>T</code>)] to [...].</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  type: A <code>tf.DType</code> from: <code>tf.float32, tf.float64, tf.int64, tf.int32, tf.uint8, tf.uint16, tf.int16, tf.int8, tf.complex64, tf.complex128, tf.qint8, tf.quint8, tf.qint32, tf.half</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>type</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.bitcast', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.bitcast" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.bitcast_layer">
    <p>def <span class="ident">bitcast_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.bitcast_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.bitcast_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.bitcast_layer</strong></p>
<div class="codehilite"><pre><span></span>def bitcast_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.bitcast, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.bitcast</strong></p>
<div class="codehilite"><pre><span></span>def bitcast(input, type, name=None):
</pre></div>


<p>Bitcasts a tensor from one type to another without copying data.</p>
<p>Given a tensor <code>input</code>, this operation returns a tensor that has the same buffer
data as <code>input</code> with datatype <code>type</code>.</p>
<p>If the input datatype <code>T</code> is larger than the output datatype <code>type</code> then the
shape changes from [...] to [..., sizeof(<code>T</code>)/sizeof(<code>type</code>)].</p>
<p>If <code>T</code> is smaller than <code>type</code>, the operator requires that the rightmost
dimension be equal to sizeof(<code>type</code>)/sizeof(<code>T</code>). The shape then goes from
[..., sizeof(<code>type</code>)/sizeof(<code>T</code>)] to [...].</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  type: A <code>tf.DType</code> from: <code>tf.float32, tf.float64, tf.int64, tf.int32, tf.uint8, tf.uint16, tf.int16, tf.int8, tf.complex64, tf.complex128, tf.qint8, tf.quint8, tf.qint32, tf.half</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>type</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.bitcast_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.bitcast_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.boolean_mask">
    <p>def <span class="ident">boolean_mask</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.boolean_mask, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.boolean_mask</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.boolean_mask</strong></p>
<div class="codehilite"><pre><span></span>def boolean_mask(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.boolean_mask</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.boolean_mask</code></strong></p>
<div class="codehilite"><pre><span></span>def boolean_mask(tensor, mask, name=&quot;boolean_mask&quot;)
</pre></div>


<p>Apply boolean mask to tensor.  Numpy equivalent is <code>tensor[mask]</code>.</p>
<p>```python</p>
<h1>1-D example</h1>
<p>tensor = [0, 1, 2, 3]
mask = [True, False, True, False]
boolean_mask(tensor, mask) ==&gt; [0, 2]
```</p>
<p>In general, <code>0 &lt; dim(mask) = K &lt;= dim(tensor)</code>, and <code>mask</code>'s shape must match
the first K dimensions of <code>tensor</code>'s shape.  We then have:
  <code>boolean_mask(tensor, mask)[i, j1,...,jd] = tensor[i1,...,iK,j1,...,jd]</code>
where <code>(i1,...,iK)</code> is the ith <code>True</code> entry of <code>mask</code> (row-major order).</p>
<p>Args:
  tensor:  N-D tensor.
  mask:  K-D boolean tensor, K &lt;= N and K must be known statically.
  name:  A name for this operation (optional).</p>
<p>Returns:
  Tensor populated by entries in <code>tensor</code> corresponding to <code>True</code> values in
    <code>mask</code>.</p>
<p>Raises:
  ValueError:  If shapes do not conform.</p>
<p>Examples:</p>
<p>```python</p>
<h1>2-D example</h1>
<p>tensor = [[1, 2], [3, 4], [5, 6]]
mask = [True, False, True]
boolean_mask(tensor, mask) ==&gt; [[1, 2], [5, 6]]
```</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.boolean_mask', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.boolean_mask" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.boolean_mask_layer">
    <p>def <span class="ident">boolean_mask_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.boolean_mask_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.boolean_mask_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.boolean_mask_layer</strong></p>
<div class="codehilite"><pre><span></span>def boolean_mask_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.boolean_mask, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.boolean_mask</strong></p>
<div class="codehilite"><pre><span></span>def boolean_mask(tensor, mask, name=&quot;boolean_mask&quot;):
</pre></div>


<p>Apply boolean mask to tensor.  Numpy equivalent is <code>tensor[mask]</code>.</p>
<p>```python</p>
<h1>1-D example</h1>
<p>tensor = [0, 1, 2, 3]
mask = [True, False, True, False]
boolean_mask(tensor, mask) ==&gt; [0, 2]
```</p>
<p>In general, <code>0 &lt; dim(mask) = K &lt;= dim(tensor)</code>, and <code>mask</code>'s shape must match
the first K dimensions of <code>tensor</code>'s shape.  We then have:
  <code>boolean_mask(tensor, mask)[i, j1,...,jd] = tensor[i1,...,iK,j1,...,jd]</code>
where <code>(i1,...,iK)</code> is the ith <code>True</code> entry of <code>mask</code> (row-major order).</p>
<p>Args:
  tensor:  N-D tensor.
  mask:  K-D boolean tensor, K &lt;= N and K must be known statically.
  name:  A name for this operation (optional).</p>
<p>Returns:
  Tensor populated by entries in <code>tensor</code> corresponding to <code>True</code> values in
    <code>mask</code>.</p>
<p>Raises:
  ValueError:  If shapes do not conform.</p>
<p>Examples:</p>
<p>```python</p>
<h1>2-D example</h1>
<p>tensor = [[1, 2], [3, 4], [5, 6]]
mask = [True, False, True]
boolean_mask(tensor, mask) ==&gt; [[1, 2], [5, 6]]
```</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.boolean_mask_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.boolean_mask_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.branch">
    <p>def <span class="ident">branch</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.branch, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.branch</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.branch</strong></p>
<div class="codehilite"><pre><span></span>def branch(builder, fn):
</pre></div>


<p><code>@immutable</code></p>
<p>Expects a function <strong>fn</strong> with type <code>Builder -&gt; iterable( Builder | BuilderTree )</code>. This method enables you to <em>branch</em> the computational graph so you can easily create neural networks with more complex topologies.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>fn</code>: a function of type <code>Builder -&gt; iterable( Builder | BuilderTree )</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><code>tensorbuilder.core.builders.BuilderTree</code></li>
</ul>
<p><strong> Examples </strong></p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">h</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span>
        <span class="n">x</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">x</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">x</span><span class="o">.</span><span class="n">tanh_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">])</span>
    <span class="o">.</span><span class="n">softmax_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>


<p>Same with the DSL</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">h</span> <span class="o">=</span> <span class="n">tb</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="p">[</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">tanh_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">softmax_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.branch', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.branch" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.builders">
    <p>def <span class="ident">builders</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(BuilderTree.builders, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>BuilderTree.builders</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for BuilderTree.builders</strong></p>
<div class="codehilite"><pre><span></span>def builders(self):
</pre></div>


<p>Returns a flattened list <code>tensorbuilder.core.builders.Builder</code>s contained by this tree. The whole result is flattened in case of sub-elements are also <code>tensorbuilder.core.builders.BuilderTree</code>s.</p>
<p><strong>Return</strong></p>
<ul>
<li><code>list( tensorbuilder.core.builders.Builder )</code></li>
</ul>
<p><strong> Examples </strong></p>
<p>This examples creates a network to that solves the XOR problem using sigmoid units</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>


<span class="c1">#Network</span>
<span class="p">[</span><span class="n">activation_builder</span><span class="p">,</span> <span class="n">trainer_builder</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="k">lambda</span> <span class="n">logit</span><span class="p">:</span>
    <span class="p">[</span>
        <span class="n">logit</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span> <span class="c1"># activation</span>
    <span class="p">,</span>
        <span class="n">logit</span>
        <span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># loss</span>
        <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">)</span> <span class="c1"># trainer</span>
    <span class="p">])</span>
    <span class="o">.</span><span class="n">builders</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>


<p>Same example using the DSL</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>


<span class="c1">#Network</span>
<span class="p">[</span><span class="n">activation_builder</span><span class="p">,</span> <span class="n">trainer_builder</span><span class="p">]</span> <span class="o">=</span> <span class="n">tb</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
    <span class="p">[</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span> <span class="c1"># activation</span>
    <span class="p">,</span>
        <span class="n">tb</span>
        <span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># loss</span>
        <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">)</span> <span class="c1"># trainer</span>
    <span class="p">],</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">builders</span><span class="p">()</span>
<span class="p">)</span>
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.builders', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.builders" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.case">
    <p>def <span class="ident">case</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.case, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.case</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.case</strong></p>
<div class="codehilite"><pre><span></span>def case(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.case</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.case</code></strong></p>
<div class="codehilite"><pre><span></span>def case(pred_fn_pairs, default, exclusive=False, name=&quot;case&quot;)
</pre></div>


<p>Create a case operation.</p>
<p>The <code>pred_fn_pairs</code> parameter is a dict or list of pairs of size N.
Each pair contains a boolean scalar tensor and a python callable that
creates the tensors to be returned if the boolean evaluates to True.
<code>default</code> is a callable generating a list of tensors. All the callables
in <code>pred_fn_pairs</code> as well as <code>default</code> should return the same number
and types of tensors.</p>
<p>If <code>exclusive==True</code>, all predicates are evaluated, and a logging operation
with an error is returned if more than one of the predicates evaluates to
True. If <code>exclusive==False</code>, execution stops are the first predicate which
evaluates to True, and the tensors generated by the corresponding function
are returned immediately. If none of the predicates evaluate to True, this
operation returns the tensors generated by <code>default</code>.</p>
<p>Example 1:
  Pseudocode:
  <code>if (x &lt; y) return 17;
    else return 23;</code></p>
<p>Expressions:
  <code>f1 = lambda: tf.constant(17)
    f2 = lambda: tf.constant(23)
    r = case([(tf.less(x, y), f1)], default=f2)</code></p>
<p>Example 2:
  Pseudocode:
  <code>if (x &lt; y &amp;&amp; x &gt; z) raise OpError("Only one predicate may evaluate true");
    if (x &lt; y) return 17;
    else if (x &gt; z) return 23;
    else return -1;</code></p>
<p>Expressions:
  <code>x = tf.constant(0)
    y = tf.constant(1)
    z = tf.constant(2)
    def f1(): return tf.constant(17)
    def f2(): return tf.constant(23)
    def f3(): return tf.constant(-1)
    r = case({tf.less(x, y): f1, tf.greater(x, z): f2},
             default=f3, exclusive=True)</code></p>
<p>Args:
  pred_fn_pairs: Dict or list of pairs of a boolean scalar tensor and a
                 callable which returns a list of tensors.
  default: A callable that returns a list of tensors.
  exclusive: True iff more than one predicate is allowed to evaluate to True.
  name: A name for this operation (optional).</p>
<p>Returns:
  The tensors returned by the first pair whose predicate evaluated to True, or
  those returned by <code>default</code> if none does.</p>
<p>Raises:
  TypeError: If <code>pred_fn_pairs</code> is not a list/dictionary.
  TypeError: If <code>pred_fn_pairs</code> is a list but does not contain 2-tuples.
  TypeError: If <code>fns[i]</code> is not callable for any i, or <code>default</code> is not
             callable.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.case', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.case" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.case_layer">
    <p>def <span class="ident">case_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.case_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.case_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.case_layer</strong></p>
<div class="codehilite"><pre><span></span>def case_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.case, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.case</strong></p>
<div class="codehilite"><pre><span></span>def case(pred_fn_pairs, default, exclusive=False, name=&quot;case&quot;):
</pre></div>


<p>Create a case operation.</p>
<p>The <code>pred_fn_pairs</code> parameter is a dict or list of pairs of size N.
Each pair contains a boolean scalar tensor and a python callable that
creates the tensors to be returned if the boolean evaluates to True.
<code>default</code> is a callable generating a list of tensors. All the callables
in <code>pred_fn_pairs</code> as well as <code>default</code> should return the same number
and types of tensors.</p>
<p>If <code>exclusive==True</code>, all predicates are evaluated, and a logging operation
with an error is returned if more than one of the predicates evaluates to
True. If <code>exclusive==False</code>, execution stops are the first predicate which
evaluates to True, and the tensors generated by the corresponding function
are returned immediately. If none of the predicates evaluate to True, this
operation returns the tensors generated by <code>default</code>.</p>
<p>Example 1:
  Pseudocode:
  <code>if (x &lt; y) return 17;
    else return 23;</code></p>
<p>Expressions:
  <code>f1 = lambda: tf.constant(17)
    f2 = lambda: tf.constant(23)
    r = case([(tf.less(x, y), f1)], default=f2)</code></p>
<p>Example 2:
  Pseudocode:
  <code>if (x &lt; y &amp;&amp; x &gt; z) raise OpError("Only one predicate may evaluate true");
    if (x &lt; y) return 17;
    else if (x &gt; z) return 23;
    else return -1;</code></p>
<p>Expressions:
  <code>x = tf.constant(0)
    y = tf.constant(1)
    z = tf.constant(2)
    def f1(): return tf.constant(17)
    def f2(): return tf.constant(23)
    def f3(): return tf.constant(-1)
    r = case({tf.less(x, y): f1, tf.greater(x, z): f2},
             default=f3, exclusive=True)</code></p>
<p>Args:
  pred_fn_pairs: Dict or list of pairs of a boolean scalar tensor and a
                 callable which returns a list of tensors.
  default: A callable that returns a list of tensors.
  exclusive: True iff more than one predicate is allowed to evaluate to True.
  name: A name for this operation (optional).</p>
<p>Returns:
  The tensors returned by the first pair whose predicate evaluated to True, or
  those returned by <code>default</code> if none does.</p>
<p>Raises:
  TypeError: If <code>pred_fn_pairs</code> is not a list/dictionary.
  TypeError: If <code>pred_fn_pairs</code> is a list but does not contain 2-tuples.
  TypeError: If <code>fns[i]</code> is not callable for any i, or <code>default</code> is not
             callable.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.case_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.case_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.cast">
    <p>def <span class="ident">cast</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.cast, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.cast</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.cast</strong></p>
<div class="codehilite"><pre><span></span>def cast(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.cast</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.cast</code></strong></p>
<div class="codehilite"><pre><span></span>def cast(x, dtype, name=None)
</pre></div>


<p>Casts a tensor to a new type.</p>
<p>The operation casts <code>x</code> (in case of <code>Tensor</code>) or <code>x.values</code>
(in case of <code>SparseTensor</code>) to <code>dtype</code>.</p>
<p>For example:</p>
<p>```python</p>
<h1>tensor <code>a</code> is [1.8, 2.2], dtype=tf.float</h1>
<p>tf.cast(a, tf.int32) ==&gt; [1, 2]  # dtype=tf.int32
```</p>
<p>Args:
  x: A <code>Tensor</code> or <code>SparseTensor</code>.
  dtype: The destination type.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> or <code>SparseTensor</code> with same shape as <code>x</code>.</p>
<p>Raises:
  TypeError: If <code>x</code> cannot be cast to the <code>dtype</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.cast', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.cast" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.cast_layer">
    <p>def <span class="ident">cast_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.cast_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.cast_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.cast_layer</strong></p>
<div class="codehilite"><pre><span></span>def cast_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.cast, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.cast</strong></p>
<div class="codehilite"><pre><span></span>def cast(x, dtype, name=None):
</pre></div>


<p>Casts a tensor to a new type.</p>
<p>The operation casts <code>x</code> (in case of <code>Tensor</code>) or <code>x.values</code>
(in case of <code>SparseTensor</code>) to <code>dtype</code>.</p>
<p>For example:</p>
<p>```python</p>
<h1>tensor <code>a</code> is [1.8, 2.2], dtype=tf.float</h1>
<p>tf.cast(a, tf.int32) ==&gt; [1, 2]  # dtype=tf.int32
```</p>
<p>Args:
  x: A <code>Tensor</code> or <code>SparseTensor</code>.
  dtype: The destination type.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> or <code>SparseTensor</code> with same shape as <code>x</code>.</p>
<p>Raises:
  TypeError: If <code>x</code> cannot be cast to the <code>dtype</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.cast_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.cast_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ceil">
    <p>def <span class="ident">ceil</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ceil, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ceil</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ceil</strong></p>
<div class="codehilite"><pre><span></span>def ceil(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.ceil</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.ceil</code></strong></p>
<div class="codehilite"><pre><span></span>def ceil(x, name=None)
</pre></div>


<p>Returns element-wise smallest integer in not less than x.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ceil', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ceil" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ceil_layer">
    <p>def <span class="ident">ceil_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ceil_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ceil_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ceil_layer</strong></p>
<div class="codehilite"><pre><span></span>def ceil_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.ceil, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.ceil</strong></p>
<div class="codehilite"><pre><span></span>def ceil(x, name=None):
</pre></div>


<p>Returns element-wise smallest integer in not less than x.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ceil_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ceil_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.check_numerics">
    <p>def <span class="ident">check_numerics</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.check_numerics, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.check_numerics</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.check_numerics</strong></p>
<div class="codehilite"><pre><span></span>def check_numerics(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.check_numerics</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.check_numerics</code></strong></p>
<div class="codehilite"><pre><span></span>def check_numerics(tensor, message, name=None)
</pre></div>


<p>Checks a tensor for NaN and Inf values.</p>
<p>When run, reports an <code>InvalidArgument</code> error if <code>tensor</code> has any values
that are not a number (NaN) or infinity (Inf). Otherwise, passes <code>tensor</code> as-is.</p>
<p>Args:
  tensor: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  message: A <code>string</code>. Prefix of the error message.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.check_numerics', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.check_numerics" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.check_numerics_layer">
    <p>def <span class="ident">check_numerics_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.check_numerics_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.check_numerics_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.check_numerics_layer</strong></p>
<div class="codehilite"><pre><span></span>def check_numerics_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.check_numerics, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.check_numerics</strong></p>
<div class="codehilite"><pre><span></span>def check_numerics(tensor, message, name=None):
</pre></div>


<p>Checks a tensor for NaN and Inf values.</p>
<p>When run, reports an <code>InvalidArgument</code> error if <code>tensor</code> has any values
that are not a number (NaN) or infinity (Inf). Otherwise, passes <code>tensor</code> as-is.</p>
<p>Args:
  tensor: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  message: A <code>string</code>. Prefix of the error message.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.check_numerics_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.check_numerics_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.cholesky">
    <p>def <span class="ident">cholesky</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.cholesky, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.cholesky</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.cholesky</strong></p>
<div class="codehilite"><pre><span></span>def cholesky(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.cholesky</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.cholesky</code></strong></p>
<div class="codehilite"><pre><span></span>def cholesky(input, name=None)
</pre></div>


<p>Calculates the Cholesky decomposition of a square matrix.</p>
<p>The input has to be symmetric and positive definite. Only the lower-triangular
part of the input will be used for this operation. The upper-triangular part
will not be read.</p>
<p>The result is the lower-triangular matrix of the Cholesky decomposition of the
input, <code>L</code>, so that <code>input = L L^*</code>.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[M, M]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. Shape is <code>[M, M]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.cholesky', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.cholesky" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.cholesky_layer">
    <p>def <span class="ident">cholesky_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.cholesky_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.cholesky_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.cholesky_layer</strong></p>
<div class="codehilite"><pre><span></span>def cholesky_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.cholesky, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.cholesky</strong></p>
<div class="codehilite"><pre><span></span>def cholesky(input, name=None):
</pre></div>


<p>Calculates the Cholesky decomposition of a square matrix.</p>
<p>The input has to be symmetric and positive definite. Only the lower-triangular
part of the input will be used for this operation. The upper-triangular part
will not be read.</p>
<p>The result is the lower-triangular matrix of the Cholesky decomposition of the
input, <code>L</code>, so that <code>input = L L^*</code>.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[M, M]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. Shape is <code>[M, M]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.cholesky_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.cholesky_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.cholesky_solve">
    <p>def <span class="ident">cholesky_solve</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.cholesky_solve, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.cholesky_solve</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.cholesky_solve</strong></p>
<div class="codehilite"><pre><span></span>def cholesky_solve(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.cholesky_solve</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.cholesky_solve</code></strong></p>
<div class="codehilite"><pre><span></span>def cholesky_solve(chol, rhs, name=None)
</pre></div>


<p>Solve linear equations <code>A X = RHS</code>, given Cholesky factorization of <code>A</code>.</p>
<p>```python</p>
<h1>Solve one system of linear equations (K = 1).</h1>
<p>A = [[3, 1], [1, 3]]
RHS = [[2], [22]]  # shape 2 x 1
chol = tf.cholesky(A)
X = tf.cholesky_solve(chol, RHS)</p>
<h1>tf.matmul(A, X) ~ RHS</h1>
<p>X[:, 0]  # Solution to the linear system A x = RHS[:, 0]</p>
<h1>Solve five systems of linear equations (K = 5).</h1>
<p>A = [[3, 1], [1, 3]]
RHS = [[1, 2, 3, 4, 5], [11, 22, 33, 44, 55]]  # shape 2 x 5
...
X[:, 2]  # Solution to the linear system A x = RHS[:, 2]
```</p>
<p>Args:
  chol:  A <code>Tensor</code>.  Must be <code>float32</code> or <code>float64</code>, shape is <code>[M, M]</code>.
    Cholesky factorization of <code>A</code>, e.g. <code>chol = tf.cholesky(A)</code>.  For that
    reason, only the lower triangular part (including the diagonal) of <code>chol</code>
    is used.  The strictly upper part is assumed to be zero and not accessed.
  rhs:  A <code>Tensor</code>, same type as <code>chol</code>, shape is <code>[M, K]</code>, designating <code>K</code>
    systems of linear equations.
  name:  A name to give this <code>Op</code>.  Defaults to <code>cholesky_solve</code>.</p>
<p>Returns:
  Solution to <code>A X = RHS</code>, shape <code>[M, K]</code>.  The solutions to the <code>K</code> systems.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.cholesky_solve', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.cholesky_solve" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.cholesky_solve_layer">
    <p>def <span class="ident">cholesky_solve_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.cholesky_solve_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.cholesky_solve_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.cholesky_solve_layer</strong></p>
<div class="codehilite"><pre><span></span>def cholesky_solve_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.cholesky_solve, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.cholesky_solve</strong></p>
<div class="codehilite"><pre><span></span>def cholesky_solve(chol, rhs, name=None):
</pre></div>


<p>Solve linear equations <code>A X = RHS</code>, given Cholesky factorization of <code>A</code>.</p>
<p>```python</p>
<h1>Solve one system of linear equations (K = 1).</h1>
<p>A = [[3, 1], [1, 3]]
RHS = [[2], [22]]  # shape 2 x 1
chol = tf.cholesky(A)
X = tf.cholesky_solve(chol, RHS)</p>
<h1>tf.matmul(A, X) ~ RHS</h1>
<p>X[:, 0]  # Solution to the linear system A x = RHS[:, 0]</p>
<h1>Solve five systems of linear equations (K = 5).</h1>
<p>A = [[3, 1], [1, 3]]
RHS = [[1, 2, 3, 4, 5], [11, 22, 33, 44, 55]]  # shape 2 x 5
...
X[:, 2]  # Solution to the linear system A x = RHS[:, 2]
```</p>
<p>Args:
  chol:  A <code>Tensor</code>.  Must be <code>float32</code> or <code>float64</code>, shape is <code>[M, M]</code>.
    Cholesky factorization of <code>A</code>, e.g. <code>chol = tf.cholesky(A)</code>.  For that
    reason, only the lower triangular part (including the diagonal) of <code>chol</code>
    is used.  The strictly upper part is assumed to be zero and not accessed.
  rhs:  A <code>Tensor</code>, same type as <code>chol</code>, shape is <code>[M, K]</code>, designating <code>K</code>
    systems of linear equations.
  name:  A name to give this <code>Op</code>.  Defaults to <code>cholesky_solve</code>.</p>
<p>Returns:
  Solution to <code>A X = RHS</code>, shape <code>[M, K]</code>.  The solutions to the <code>K</code> systems.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.cholesky_solve_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.cholesky_solve_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.clip_by_average_norm">
    <p>def <span class="ident">clip_by_average_norm</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.clip_by_average_norm, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.clip_by_average_norm</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.clip_by_average_norm</strong></p>
<div class="codehilite"><pre><span></span>def clip_by_average_norm(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.clip_by_average_norm</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.clip_by_average_norm</code></strong></p>
<div class="codehilite"><pre><span></span>def clip_by_average_norm(t, clip_norm, name=None)
</pre></div>


<p>Clips tensor values to a maximum average L2-norm.</p>
<p>Given a tensor <code>t</code>, and a maximum clip value <code>clip_norm</code>, this operation
normalizes <code>t</code> so that its average L2-norm is less than or equal to
<code>clip_norm</code>. Specifically, if the average L2-norm is already less than or
equal to <code>clip_norm</code>, then <code>t</code> is not modified. If the average L2-norm is
greater than <code>clip_norm</code>, then this operation returns a tensor of the same
type and shape as <code>t</code> with its values set to:</p>
<p><code>t * clip_norm / l2norm_avg(t)</code></p>
<p>In this case, the average L2-norm of the output tensor is <code>clip_norm</code>.</p>
<p>This operation is typically used to clip gradients before applying them with
an optimizer.</p>
<p>Args:
  t: A <code>Tensor</code>.
  clip_norm: A 0-D (scalar) <code>Tensor</code> &gt; 0. A maximum clipping value.
  name: A name for the operation (optional).</p>
<p>Returns:
  A clipped <code>Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.clip_by_average_norm', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.clip_by_average_norm" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.clip_by_average_norm_layer">
    <p>def <span class="ident">clip_by_average_norm_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.clip_by_average_norm_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.clip_by_average_norm_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.clip_by_average_norm_layer</strong></p>
<div class="codehilite"><pre><span></span>def clip_by_average_norm_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.clip_by_average_norm, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.clip_by_average_norm</strong></p>
<div class="codehilite"><pre><span></span>def clip_by_average_norm(t, clip_norm, name=None):
</pre></div>


<p>Clips tensor values to a maximum average L2-norm.</p>
<p>Given a tensor <code>t</code>, and a maximum clip value <code>clip_norm</code>, this operation
normalizes <code>t</code> so that its average L2-norm is less than or equal to
<code>clip_norm</code>. Specifically, if the average L2-norm is already less than or
equal to <code>clip_norm</code>, then <code>t</code> is not modified. If the average L2-norm is
greater than <code>clip_norm</code>, then this operation returns a tensor of the same
type and shape as <code>t</code> with its values set to:</p>
<p><code>t * clip_norm / l2norm_avg(t)</code></p>
<p>In this case, the average L2-norm of the output tensor is <code>clip_norm</code>.</p>
<p>This operation is typically used to clip gradients before applying them with
an optimizer.</p>
<p>Args:
  t: A <code>Tensor</code>.
  clip_norm: A 0-D (scalar) <code>Tensor</code> &gt; 0. A maximum clipping value.
  name: A name for the operation (optional).</p>
<p>Returns:
  A clipped <code>Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.clip_by_average_norm_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.clip_by_average_norm_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.clip_by_global_norm">
    <p>def <span class="ident">clip_by_global_norm</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.clip_by_global_norm, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.clip_by_global_norm</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.clip_by_global_norm</strong></p>
<div class="codehilite"><pre><span></span>def clip_by_global_norm(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.clip_by_global_norm</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.clip_by_global_norm</code></strong></p>
<div class="codehilite"><pre><span></span>def clip_by_global_norm(t_list, clip_norm, use_norm=None, name=None)
</pre></div>


<p>Clips values of multiple tensors by the ratio of the sum of their norms.</p>
<p>Given a tuple or list of tensors <code>t_list</code>, and a clipping ratio <code>clip_norm</code>,
this operation returns a list of clipped tensors <code>list_clipped</code>
and the global norm (<code>global_norm</code>) of all tensors in <code>t_list</code>. Optionally,
if you've already computed the global norm for <code>t_list</code>, you can specify
the global norm with <code>use_norm</code>.</p>
<p>To perform the clipping, the values <code>t_list[i]</code> are set to:</p>
<div class="codehilite"><pre><span></span>t_list[i] * clip_norm / max(global_norm, clip_norm)
</pre></div>


<p>where:</p>
<div class="codehilite"><pre><span></span>global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))
</pre></div>


<p>If <code>clip_norm &gt; global_norm</code> then the entries in <code>t_list</code> remain as they are,
otherwise they're all shrunk by the global ratio.</p>
<p>Any of the entries of <code>t_list</code> that are of type <code>None</code> are ignored.</p>
<p>This is the correct way to perform gradient clipping (for example, see
<a href="http://arxiv.org/abs/1211.5063">Pascanu et al., 2012</a>
(<a href="http://arxiv.org/pdf/1211.5063.pdf">pdf</a>)).</p>
<p>However, it is slower than <code>clip_by_norm()</code> because all the parameters must be
ready before the clipping operation can be performed.</p>
<p>Args:
  t_list: A tuple or list of mixed <code>Tensors</code>, <code>IndexedSlices</code>, or None.
  clip_norm: A 0-D (scalar) <code>Tensor</code> &gt; 0. The clipping ratio.
  use_norm: A 0-D (scalar) <code>Tensor</code> of type <code>float</code> (optional). The global
    norm to use. If not provided, <code>global_norm()</code> is used to compute the norm.
  name: A name for the operation (optional).</p>
<p>Returns:
  list_clipped: A list of <code>Tensors</code> of the same type as <code>list_t</code>.
  global_norm: A 0-D (scalar) <code>Tensor</code> representing the global norm.</p>
<p>Raises:
  TypeError: If <code>t_list</code> is not a sequence.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.clip_by_global_norm', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.clip_by_global_norm" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.clip_by_global_norm_layer">
    <p>def <span class="ident">clip_by_global_norm_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.clip_by_global_norm_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.clip_by_global_norm_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.clip_by_global_norm_layer</strong></p>
<div class="codehilite"><pre><span></span>def clip_by_global_norm_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.clip_by_global_norm, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.clip_by_global_norm</strong></p>
<div class="codehilite"><pre><span></span>def clip_by_global_norm(t_list, clip_norm, use_norm=None, name=None):
</pre></div>


<p>Clips values of multiple tensors by the ratio of the sum of their norms.</p>
<p>Given a tuple or list of tensors <code>t_list</code>, and a clipping ratio <code>clip_norm</code>,
this operation returns a list of clipped tensors <code>list_clipped</code>
and the global norm (<code>global_norm</code>) of all tensors in <code>t_list</code>. Optionally,
if you've already computed the global norm for <code>t_list</code>, you can specify
the global norm with <code>use_norm</code>.</p>
<p>To perform the clipping, the values <code>t_list[i]</code> are set to:</p>
<div class="codehilite"><pre><span></span>t_list[i] * clip_norm / max(global_norm, clip_norm)
</pre></div>


<p>where:</p>
<div class="codehilite"><pre><span></span>global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))
</pre></div>


<p>If <code>clip_norm &gt; global_norm</code> then the entries in <code>t_list</code> remain as they are,
otherwise they're all shrunk by the global ratio.</p>
<p>Any of the entries of <code>t_list</code> that are of type <code>None</code> are ignored.</p>
<p>This is the correct way to perform gradient clipping (for example, see
<a href="http://arxiv.org/abs/1211.5063">Pascanu et al., 2012</a>
(<a href="http://arxiv.org/pdf/1211.5063.pdf">pdf</a>)).</p>
<p>However, it is slower than <code>clip_by_norm()</code> because all the parameters must be
ready before the clipping operation can be performed.</p>
<p>Args:
  t_list: A tuple or list of mixed <code>Tensors</code>, <code>IndexedSlices</code>, or None.
  clip_norm: A 0-D (scalar) <code>Tensor</code> &gt; 0. The clipping ratio.
  use_norm: A 0-D (scalar) <code>Tensor</code> of type <code>float</code> (optional). The global
    norm to use. If not provided, <code>global_norm()</code> is used to compute the norm.
  name: A name for the operation (optional).</p>
<p>Returns:
  list_clipped: A list of <code>Tensors</code> of the same type as <code>list_t</code>.
  global_norm: A 0-D (scalar) <code>Tensor</code> representing the global norm.</p>
<p>Raises:
  TypeError: If <code>t_list</code> is not a sequence.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.clip_by_global_norm_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.clip_by_global_norm_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.clip_by_norm">
    <p>def <span class="ident">clip_by_norm</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.clip_by_norm, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.clip_by_norm</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.clip_by_norm</strong></p>
<div class="codehilite"><pre><span></span>def clip_by_norm(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.clip_by_norm</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.clip_by_norm</code></strong></p>
<div class="codehilite"><pre><span></span>def clip_by_norm(t, clip_norm, name=None)
</pre></div>


<p>Clips tensor values to a maximum L2-norm.</p>
<p>Given a tensor <code>t</code>, and a maximum clip value <code>clip_norm</code>, this operation
normalizes <code>t</code> so that its L2-norm is less than or equal to <code>clip_norm</code>.
Specifically, if the L2-norm is already less than or equal to <code>clip_norm</code>,
then <code>t</code> is not modified. If the L2-norm is greater than <code>clip_norm</code>, then
this operation returns a tensor of the same type and shape as <code>t</code> with its
values set to:</p>
<p><code>t * clip_norm / l2norm(t)</code></p>
<p>In this case, the L2-norm of the output tensor is <code>clip_norm</code>.</p>
<p>This operation is typically used to clip gradients before applying them with
an optimizer.</p>
<p>Args:
  t: A <code>Tensor</code>.
  clip_norm: A 0-D (scalar) <code>Tensor</code> &gt; 0. A maximum clipping value.
  name: A name for the operation (optional).</p>
<p>Returns:
  A clipped <code>Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.clip_by_norm', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.clip_by_norm" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.clip_by_norm_layer">
    <p>def <span class="ident">clip_by_norm_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.clip_by_norm_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.clip_by_norm_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.clip_by_norm_layer</strong></p>
<div class="codehilite"><pre><span></span>def clip_by_norm_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.clip_by_norm, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.clip_by_norm</strong></p>
<div class="codehilite"><pre><span></span>def clip_by_norm(t, clip_norm, name=None):
</pre></div>


<p>Clips tensor values to a maximum L2-norm.</p>
<p>Given a tensor <code>t</code>, and a maximum clip value <code>clip_norm</code>, this operation
normalizes <code>t</code> so that its L2-norm is less than or equal to <code>clip_norm</code>.
Specifically, if the L2-norm is already less than or equal to <code>clip_norm</code>,
then <code>t</code> is not modified. If the L2-norm is greater than <code>clip_norm</code>, then
this operation returns a tensor of the same type and shape as <code>t</code> with its
values set to:</p>
<p><code>t * clip_norm / l2norm(t)</code></p>
<p>In this case, the L2-norm of the output tensor is <code>clip_norm</code>.</p>
<p>This operation is typically used to clip gradients before applying them with
an optimizer.</p>
<p>Args:
  t: A <code>Tensor</code>.
  clip_norm: A 0-D (scalar) <code>Tensor</code> &gt; 0. A maximum clipping value.
  name: A name for the operation (optional).</p>
<p>Returns:
  A clipped <code>Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.clip_by_norm_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.clip_by_norm_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.clip_by_value">
    <p>def <span class="ident">clip_by_value</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.clip_by_value, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.clip_by_value</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.clip_by_value</strong></p>
<div class="codehilite"><pre><span></span>def clip_by_value(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.clip_by_value</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.clip_by_value</code></strong></p>
<div class="codehilite"><pre><span></span>def clip_by_value(t, clip_value_min, clip_value_max, name=None)
</pre></div>


<p>Clips tensor values to a specified min and max.</p>
<p>Given a tensor <code>t</code>, this operation returns a tensor of the same type and
shape as <code>t</code> with its values clipped to <code>clip_value_min</code> and <code>clip_value_max</code>.
Any values less than <code>clip_value_min</code> are set to <code>clip_value_min</code>. Any values
greater than <code>clip_value_max</code> are set to <code>clip_value_max</code>.</p>
<p>Args:
  t: A <code>Tensor</code>.
  clip_value_min: A 0-D (scalar) <code>Tensor</code>. The minimum value to clip by.
  clip_value_max: A 0-D (scalar) <code>Tensor</code>. The maximum value to clip by.
  name: A name for the operation (optional).</p>
<p>Returns:
  A clipped <code>Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.clip_by_value', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.clip_by_value" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.clip_by_value_layer">
    <p>def <span class="ident">clip_by_value_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.clip_by_value_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.clip_by_value_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.clip_by_value_layer</strong></p>
<div class="codehilite"><pre><span></span>def clip_by_value_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.clip_by_value, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.clip_by_value</strong></p>
<div class="codehilite"><pre><span></span>def clip_by_value(t, clip_value_min, clip_value_max, name=None):
</pre></div>


<p>Clips tensor values to a specified min and max.</p>
<p>Given a tensor <code>t</code>, this operation returns a tensor of the same type and
shape as <code>t</code> with its values clipped to <code>clip_value_min</code> and <code>clip_value_max</code>.
Any values less than <code>clip_value_min</code> are set to <code>clip_value_min</code>. Any values
greater than <code>clip_value_max</code> are set to <code>clip_value_max</code>.</p>
<p>Args:
  t: A <code>Tensor</code>.
  clip_value_min: A 0-D (scalar) <code>Tensor</code>. The minimum value to clip by.
  clip_value_max: A 0-D (scalar) <code>Tensor</code>. The maximum value to clip by.
  name: A name for the operation (optional).</p>
<p>Returns:
  A clipped <code>Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.clip_by_value_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.clip_by_value_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.compile">
    <p>def <span class="ident">compile</span>(</p><p>self, *ast)</p>
    </div>
    

    
  
    <div class="desc"><p><code>compile</code> an object <code>ast</code> which must be part of the domain of the DSL and returns function. It applies the rules of the DSL to create an actual Python function that does what you intend. Normally you will just use pipe, which not only compiles the DSL it actually performs the computation to a given Tensor/Builder, however, it you are building and API this might be useful since you can create a function from an AST which can itself be used as an element of another AST since final elements of the DSL are functions.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>*ast</code>: a sequence of elements of the DSL.</li>
</ul>
<p><strong>Return</strong></p>
<p>A function</p>
<p><strong>Examples</strong></p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">f</span> <span class="o">=</span> <span class="n">tb</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">build</span><span class="p">,</span> <span class="c1">#accept a Tensor as a parameter and create a builder so you can use the rest of the methods</span>
    <span class="p">[</span>
        <span class="p">{</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/gpu:0&quot;</span><span class="p">):</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">,</span>
        <span class="p">{</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/gpu:1&quot;</span><span class="p">):</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">,</span>
        <span class="p">{</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/cpu:0&quot;</span><span class="p">):</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">tanh_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">],</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">h</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.compile', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.compile" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">compile</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">ast</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    `compile` an object `ast` which must be part of the domain of the DSL and returns function. It applies the rules of the DSL to create an actual Python function that does what you intend. Normally you will just use pipe, which not only compiles the DSL it actually performs the computation to a given Tensor/Builder, however, it you are building and API this might be useful since you can create a function from an AST which can itself be used as an element of another AST since final elements of the DSL are functions.</span>
<span class="sd">    **Arguments**</span>
<span class="sd">    * `*ast`: a sequence of elements of the DSL.</span>
<span class="sd">    **Return**</span>
<span class="sd">    A function</span>
<span class="sd">    **Examples**</span>
<span class="sd">        import tensorflow as tf</span>
<span class="sd">        from tensorbuilder import tb</span>
<span class="sd">        x = placeholder(tf.float32, shape=[None, 10])</span>
<span class="sd">        f = tb.compile(</span>
<span class="sd">            tb.build, #accept a Tensor as a parameter and create a builder so you can use the rest of the methods</span>
<span class="sd">            [</span>
<span class="sd">                { tf.device(&quot;/gpu:0&quot;):</span>
<span class="sd">                    tb.relu_layer(20)</span>
<span class="sd">                }</span>
<span class="sd">            ,</span>
<span class="sd">                { tf.device(&quot;/gpu:1&quot;):</span>
<span class="sd">                    tb.sigmoid_layer(20)</span>
<span class="sd">                }</span>
<span class="sd">            ,</span>
<span class="sd">                { tf.device(&quot;/cpu:0&quot;):</span>
<span class="sd">                    tb.tanh_layer(20)</span>
<span class="sd">                }</span>
<span class="sd">            ],</span>
<span class="sd">            tb.relu_layer(10)</span>
<span class="sd">            .tensor()</span>
<span class="sd">        )</span>
<span class="sd">        h = f(x)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_compile</span><span class="p">(</span><span class="n">ast</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.complex">
    <p>def <span class="ident">complex</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.complex, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.complex</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.complex</strong></p>
<div class="codehilite"><pre><span></span>def complex(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.complex</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.complex</code></strong></p>
<div class="codehilite"><pre><span></span>def complex(real, imag, name=None)
</pre></div>


<p>Converts two real numbers to a complex number.</p>
<p>Given a tensor <code>real</code> representing the real part of a complex number, and a
tensor <code>imag</code> representing the imaginary part of a complex number, this
operation returns complex numbers elementwise of the form (a + bj), where
<em>a</em> represents the <code>real</code> part and <em>b</em> represents the <code>imag</code> part.</p>
<p>The input tensors <code>real</code> and <code>imag</code> must have the same shape.</p>
<p>For example:</p>
<p>```</p>
<h1>tensor 'real' is [2.25, 3.25]</h1>
<h1>tensor <code>imag</code> is [4.75, 5.75]</h1>
<p>tf.complex(real, imag) ==&gt; [[2.25 + 4.75j], [3.25 + 5.75j]]
```</p>
<p>Args:
  real: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  imag: A <code>Tensor</code>. Must have the same type as <code>real</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code> or <code>complex128</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.complex', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.complex" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.complex_abs">
    <p>def <span class="ident">complex_abs</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.complex_abs, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.complex_abs</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.complex_abs</strong></p>
<div class="codehilite"><pre><span></span>def complex_abs(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.complex_abs</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.complex_abs</code></strong></p>
<div class="codehilite"><pre><span></span>def complex_abs(x, name=None)
</pre></div>


<p>Computes the complex absolute value of a tensor.</p>
<p>Given a tensor <code>x</code> of complex numbers, this operation returns a tensor of type
<code>float</code> or <code>double</code> that is the absolute value of each element in <code>x</code>. All
elements in <code>x</code> must be complex numbers of the form \(a + bj\). The
absolute value is computed as \( \sqrt{a^2 + b^2}\).</p>
<p>For example:</p>
<p>```</p>
<h1>tensor 'x' is [[-2.25 + 4.75j], [-3.25 + 5.75j]]</h1>
<p>tf.complex_abs(x) ==&gt; [5.25594902, 6.60492229]
```</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>complex64</code> or <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>float32</code> or <code>float64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.complex_abs', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.complex_abs" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.complex_abs_layer">
    <p>def <span class="ident">complex_abs_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.complex_abs_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.complex_abs_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.complex_abs_layer</strong></p>
<div class="codehilite"><pre><span></span>def complex_abs_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.complex_abs, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.complex_abs</strong></p>
<div class="codehilite"><pre><span></span>def complex_abs(x, name=None):
</pre></div>


<p>Computes the complex absolute value of a tensor.</p>
<p>Given a tensor <code>x</code> of complex numbers, this operation returns a tensor of type
<code>float</code> or <code>double</code> that is the absolute value of each element in <code>x</code>. All
elements in <code>x</code> must be complex numbers of the form \(a + bj\). The
absolute value is computed as \( \sqrt{a^2 + b^2}\).</p>
<p>For example:</p>
<p>```</p>
<h1>tensor 'x' is [[-2.25 + 4.75j], [-3.25 + 5.75j]]</h1>
<p>tf.complex_abs(x) ==&gt; [5.25594902, 6.60492229]
```</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>complex64</code> or <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>float32</code> or <code>float64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.complex_abs_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.complex_abs_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.complex_layer">
    <p>def <span class="ident">complex_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.complex_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.complex_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.complex_layer</strong></p>
<div class="codehilite"><pre><span></span>def complex_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.complex, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.complex</strong></p>
<div class="codehilite"><pre><span></span>def complex(real, imag, name=None):
</pre></div>


<p>Converts two real numbers to a complex number.</p>
<p>Given a tensor <code>real</code> representing the real part of a complex number, and a
tensor <code>imag</code> representing the imaginary part of a complex number, this
operation returns complex numbers elementwise of the form (a + bj), where
<em>a</em> represents the <code>real</code> part and <em>b</em> represents the <code>imag</code> part.</p>
<p>The input tensors <code>real</code> and <code>imag</code> must have the same shape.</p>
<p>For example:</p>
<p>```</p>
<h1>tensor 'real' is [2.25, 3.25]</h1>
<h1>tensor <code>imag</code> is [4.75, 5.75]</h1>
<p>tf.complex(real, imag) ==&gt; [[2.25 + 4.75j], [3.25 + 5.75j]]
```</p>
<p>Args:
  real: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  imag: A <code>Tensor</code>. Must have the same type as <code>real</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code> or <code>complex128</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.complex_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.complex_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.compose">
    <p>def <span class="ident">compose</span>(</p><p>app, g, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>Takes in a function <code>g</code> and composes it with <code>tensorbuilder.core.Applicative.f</code> as <code>g o f</code>. All *args and ** are forwarded to g. This is an essential method since most registered methods use this.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>g</code>: A function</li>
<li>All *args and ** are forwarded to <code>g</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Examples</strong></p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.compose', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.compose" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">compose</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="n">g</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Takes in a function `g` and composes it with `tensorbuilder.core.Applicative.f` as `g o f`. All \*args and \*\* are forwarded to g. This is an essential method since most registered methods use this.</span>
<span class="sd">    **Arguments**</span>
<span class="sd">    * `g`: A function</span>
<span class="sd">    * All \*args and \*\* are forwarded to `g`</span>
<span class="sd">    **Return**</span>
<span class="sd">    Applicative</span>
<span class="sd">    **Examples**</span>
<span class="sd">        import tensorflow as tf</span>
<span class="sd">        from tensorbuilder import tb</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">_unit</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">g</span><span class="p">(</span><span class="n">app</span><span class="o">.</span><span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.compute_accidental_hits">
    <p>def <span class="ident">compute_accidental_hits</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.compute_accidental_hits, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.compute_accidental_hits</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.compute_accidental_hits</strong></p>
<div class="codehilite"><pre><span></span>def compute_accidental_hits(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.compute_accidental_hits</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.compute_accidental_hits</code></strong></p>
<div class="codehilite"><pre><span></span>def compute_accidental_hits(true_classes, sampled_candidates, num_true, seed=None, name=None)
</pre></div>


<p>Compute the position ids in <code>sampled_candidates</code> matching <code>true_classes</code>.</p>
<p>In Candidate Sampling, this operation facilitates virtually removing
sampled classes which happen to match target classes.  This is done
in Sampled Softmax and Sampled Logistic.</p>
<p>See our <a href="http://www.tensorflow.org/extras/candidate_sampling.pdf">Candidate Sampling Algorithms
Reference</a>.</p>
<p>We presuppose that the <code>sampled_candidates</code> are unique.</p>
<p>We call it an 'accidental hit' when one of the target classes
matches one of the sampled classes.  This operation reports
accidental hits as triples <code>(index, id, weight)</code>, where <code>index</code>
represents the row number in <code>true_classes</code>, <code>id</code> represents the
position in <code>sampled_candidates</code>, and weight is <code>-FLOAT_MAX</code>.</p>
<p>The result of this op should be passed through a <code>sparse_to_dense</code>
operation, then added to the logits of the sampled classes. This
removes the contradictory effect of accidentally sampling the true
target classes as noise classes for the same example.</p>
<p>Args:
  true_classes: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
    num_true]</code>. The target classes.
  sampled_candidates: A tensor of type <code>int64</code> and shape <code>[num_sampled]</code>.
    The sampled_candidates output of CandidateSampler.
  num_true: An <code>int</code>.  The number of target classes per training example.
  seed: An <code>int</code>. An operation-specific seed. Default is 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  indices: A <code>Tensor</code> of type <code>int32</code> and shape <code>[num_accidental_hits]</code>.
    Values indicate rows in <code>true_classes</code>.
  ids: A <code>Tensor</code> of type <code>int64</code> and shape <code>[num_accidental_hits]</code>.
    Values indicate positions in <code>sampled_candidates</code>.
  weights: A <code>Tensor</code> of type <code>float</code> and shape <code>[num_accidental_hits]</code>.
    Each value is <code>-FLOAT_MAX</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.compute_accidental_hits', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.compute_accidental_hits" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.compute_accidental_hits_layer">
    <p>def <span class="ident">compute_accidental_hits_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.compute_accidental_hits_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.compute_accidental_hits_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.compute_accidental_hits_layer</strong></p>
<div class="codehilite"><pre><span></span>def compute_accidental_hits_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.compute_accidental_hits, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.compute_accidental_hits</strong></p>
<div class="codehilite"><pre><span></span>def compute_accidental_hits(true_classes, sampled_candidates, num_true, seed=None, name=None):
</pre></div>


<p>Compute the position ids in <code>sampled_candidates</code> matching <code>true_classes</code>.</p>
<p>In Candidate Sampling, this operation facilitates virtually removing
sampled classes which happen to match target classes.  This is done
in Sampled Softmax and Sampled Logistic.</p>
<p>See our <a href="http://www.tensorflow.org/extras/candidate_sampling.pdf">Candidate Sampling Algorithms
Reference</a>.</p>
<p>We presuppose that the <code>sampled_candidates</code> are unique.</p>
<p>We call it an 'accidental hit' when one of the target classes
matches one of the sampled classes.  This operation reports
accidental hits as triples <code>(index, id, weight)</code>, where <code>index</code>
represents the row number in <code>true_classes</code>, <code>id</code> represents the
position in <code>sampled_candidates</code>, and weight is <code>-FLOAT_MAX</code>.</p>
<p>The result of this op should be passed through a <code>sparse_to_dense</code>
operation, then added to the logits of the sampled classes. This
removes the contradictory effect of accidentally sampling the true
target classes as noise classes for the same example.</p>
<p>Args:
  true_classes: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
    num_true]</code>. The target classes.
  sampled_candidates: A tensor of type <code>int64</code> and shape <code>[num_sampled]</code>.
    The sampled_candidates output of CandidateSampler.
  num_true: An <code>int</code>.  The number of target classes per training example.
  seed: An <code>int</code>. An operation-specific seed. Default is 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  indices: A <code>Tensor</code> of type <code>int32</code> and shape <code>[num_accidental_hits]</code>.
    Values indicate rows in <code>true_classes</code>.
  ids: A <code>Tensor</code> of type <code>int64</code> and shape <code>[num_accidental_hits]</code>.
    Values indicate positions in <code>sampled_candidates</code>.
  weights: A <code>Tensor</code> of type <code>float</code> and shape <code>[num_accidental_hits]</code>.
    Each value is <code>-FLOAT_MAX</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.compute_accidental_hits_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.compute_accidental_hits_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.concat">
    <p>def <span class="ident">concat</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.concat, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.concat</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.concat</strong></p>
<div class="codehilite"><pre><span></span>def concat(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.concat</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.concat</code></strong></p>
<div class="codehilite"><pre><span></span>def concat(concat_dim, values, name=&quot;concat&quot;)
</pre></div>


<p>Concatenates tensors along one dimension.</p>
<p>Concatenates the list of tensors <code>values</code> along dimension <code>concat_dim</code>.  If
<code>values[i].shape = [D0, D1, ... Dconcat_dim(i), ...Dn]</code>, the concatenated
result has shape</p>
<div class="codehilite"><pre><span></span>[D0, D1, ... Rconcat_dim, ...Dn]
</pre></div>


<p>where</p>
<div class="codehilite"><pre><span></span>Rconcat_dim = sum(Dconcat_dim(i))
</pre></div>


<p>That is, the data from the input tensors is joined along the <code>concat_dim</code>
dimension.</p>
<p>The number of dimensions of the input tensors must match, and all dimensions
except <code>concat_dim</code> must be equal.</p>
<p>For example:</p>
<p>```python
t1 = [[1, 2, 3], [4, 5, 6]]
t2 = [[7, 8, 9], [10, 11, 12]]
tf.concat(0, [t1, t2]) ==&gt; [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]
tf.concat(1, [t1, t2]) ==&gt; [[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]]</p>
<h1>tensor t3 with shape [2, 3]</h1>
<h1>tensor t4 with shape [2, 3]</h1>
<p>tf.shape(tf.concat(0, [t3, t4])) ==&gt; [4, 3]
tf.shape(tf.concat(1, [t3, t4])) ==&gt; [2, 6]
```</p>
<p>Args:
  concat_dim: 0-D <code>int32</code> <code>Tensor</code>.  Dimension along which to concatenate.
  values: A list of <code>Tensor</code> objects or a single <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> resulting from concatenation of the input tensors.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.concat', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.concat" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.concat_layer">
    <p>def <span class="ident">concat_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.concat_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.concat_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.concat_layer</strong></p>
<div class="codehilite"><pre><span></span>def concat_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.concat, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.concat</strong></p>
<div class="codehilite"><pre><span></span>def concat(concat_dim, values, name=&quot;concat&quot;):
</pre></div>


<p>Concatenates tensors along one dimension.</p>
<p>Concatenates the list of tensors <code>values</code> along dimension <code>concat_dim</code>.  If
<code>values[i].shape = [D0, D1, ... Dconcat_dim(i), ...Dn]</code>, the concatenated
result has shape</p>
<div class="codehilite"><pre><span></span>[D0, D1, ... Rconcat_dim, ...Dn]
</pre></div>


<p>where</p>
<div class="codehilite"><pre><span></span>Rconcat_dim = sum(Dconcat_dim(i))
</pre></div>


<p>That is, the data from the input tensors is joined along the <code>concat_dim</code>
dimension.</p>
<p>The number of dimensions of the input tensors must match, and all dimensions
except <code>concat_dim</code> must be equal.</p>
<p>For example:</p>
<p>```python
t1 = [[1, 2, 3], [4, 5, 6]]
t2 = [[7, 8, 9], [10, 11, 12]]
tf.concat(0, [t1, t2]) ==&gt; [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]
tf.concat(1, [t1, t2]) ==&gt; [[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]]</p>
<h1>tensor t3 with shape [2, 3]</h1>
<h1>tensor t4 with shape [2, 3]</h1>
<p>tf.shape(tf.concat(0, [t3, t4])) ==&gt; [4, 3]
tf.shape(tf.concat(1, [t3, t4])) ==&gt; [2, 6]
```</p>
<p>Args:
  concat_dim: 0-D <code>int32</code> <code>Tensor</code>.  Dimension along which to concatenate.
  values: A list of <code>Tensor</code> objects or a single <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> resulting from concatenation of the input tensors.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.concat_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.concat_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.cond">
    <p>def <span class="ident">cond</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.cond, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.cond</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.cond</strong></p>
<div class="codehilite"><pre><span></span>def cond(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.cond</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.cond</code></strong></p>
<div class="codehilite"><pre><span></span>def cond(pred, fn1, fn2, name=None)
</pre></div>


<p>Return either fn1() or fn2() based on the boolean predicate <code>pred</code>.</p>
<p><code>fn1</code> and <code>fn2</code> both return lists of output tensors. <code>fn1</code> and <code>fn2</code> must have
the same non-zero number and type of outputs.</p>
<p>Note that the conditional execution applies only to the operations defined in
fn1 and fn2. Consider the following simple program:</p>
<p><code>python
z = tf.mul(a, b)
result = tf.cond(x &lt; y, lambda: tf.add(x, z), lambda: tf.square(y))</code></p>
<p>If x &lt; y, the tf.add operation will be executed and tf.square
operation will not be executed. Since z is needed for at least one
branch of the cond, the tf.mul operation is always executed, unconditionally.
Although this behavior is consistent with the dataflow model of TensorFlow,
it has occasionally surprised some users who expected a lazier semantics.</p>
<p>Args:
  pred: A scalar determining whether to return the result of <code>fn1</code> or <code>fn2</code>.
  fn1: The callable to be performed if pred is true.
  fn2: The callable to be performed if pref is false.
  name: Optional name prefix for the returned tensors.</p>
<p>Returns:
  Tensors returned by the call to either <code>fn1</code> or <code>fn2</code>. If the callables
  return a singleton list, the element is extracted from the list.</p>
<p>Raises:
  TypeError: if <code>fn1</code> or <code>fn2</code> is not callable.
  ValueError: if <code>fn1</code> and <code>fn2</code> do not return the same number of tensors, or
              return tensors of different types.</p>
<p>Example:</p>
<p><code>python
  x = tf.constant(2)
  y = tf.constant(5)
  def f1(): return tf.mul(x, 17)
  def f2(): return tf.add(y, 23)
  r = cond(tf.less(x, y), f1, f2)
  # r is set to f1().
  # Operations in f2 (e.g., tf.add) are not executed.</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.cond', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.cond" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.cond_layer">
    <p>def <span class="ident">cond_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.cond_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.cond_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.cond_layer</strong></p>
<div class="codehilite"><pre><span></span>def cond_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.cond, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.cond</strong></p>
<div class="codehilite"><pre><span></span>def cond(pred, fn1, fn2, name=None):
</pre></div>


<p>Return either fn1() or fn2() based on the boolean predicate <code>pred</code>.</p>
<p><code>fn1</code> and <code>fn2</code> both return lists of output tensors. <code>fn1</code> and <code>fn2</code> must have
the same non-zero number and type of outputs.</p>
<p>Note that the conditional execution applies only to the operations defined in
fn1 and fn2. Consider the following simple program:</p>
<p><code>python
z = tf.mul(a, b)
result = tf.cond(x &lt; y, lambda: tf.add(x, z), lambda: tf.square(y))</code></p>
<p>If x &lt; y, the tf.add operation will be executed and tf.square
operation will not be executed. Since z is needed for at least one
branch of the cond, the tf.mul operation is always executed, unconditionally.
Although this behavior is consistent with the dataflow model of TensorFlow,
it has occasionally surprised some users who expected a lazier semantics.</p>
<p>Args:
  pred: A scalar determining whether to return the result of <code>fn1</code> or <code>fn2</code>.
  fn1: The callable to be performed if pred is true.
  fn2: The callable to be performed if pref is false.
  name: Optional name prefix for the returned tensors.</p>
<p>Returns:
  Tensors returned by the call to either <code>fn1</code> or <code>fn2</code>. If the callables
  return a singleton list, the element is extracted from the list.</p>
<p>Raises:
  TypeError: if <code>fn1</code> or <code>fn2</code> is not callable.
  ValueError: if <code>fn1</code> and <code>fn2</code> do not return the same number of tensors, or
              return tensors of different types.</p>
<p>Example:</p>
<p><code>python
  x = tf.constant(2)
  y = tf.constant(5)
  def f1(): return tf.mul(x, 17)
  def f2(): return tf.add(y, 23)
  r = cond(tf.less(x, y), f1, f2)
  # r is set to f1().
  # Operations in f2 (e.g., tf.add) are not executed.</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.cond_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.cond_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conj">
    <p>def <span class="ident">conj</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conj, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conj</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conj</strong></p>
<div class="codehilite"><pre><span></span>def conj(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.conj</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.conj</code></strong></p>
<div class="codehilite"><pre><span></span>def conj(input, name=None)
</pre></div>


<p>Returns the complex conjugate of a complex number.</p>
<p>Given a tensor <code>input</code> of complex numbers, this operation returns a tensor of
complex numbers that are the complex conjugate of each element in <code>input</code>. The
complex numbers in <code>input</code> must be of the form \(a + bj\), where <em>a</em> is the
real part and <em>b</em> is the imaginary part.</p>
<p>The complex conjugate returned by this operation is of the form \(a - bj\).</p>
<p>For example:</p>
<p>```</p>
<h1>tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]</h1>
<p>tf.conj(input) ==&gt; [-2.25 - 4.75j, 3.25 - 5.75j]
```</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conj', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conj" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conj_layer">
    <p>def <span class="ident">conj_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conj_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conj_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conj_layer</strong></p>
<div class="codehilite"><pre><span></span>def conj_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.conj, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.conj</strong></p>
<div class="codehilite"><pre><span></span>def conj(input, name=None):
</pre></div>


<p>Returns the complex conjugate of a complex number.</p>
<p>Given a tensor <code>input</code> of complex numbers, this operation returns a tensor of
complex numbers that are the complex conjugate of each element in <code>input</code>. The
complex numbers in <code>input</code> must be of the form \(a + bj\), where <em>a</em> is the
real part and <em>b</em> is the imaginary part.</p>
<p>The complex conjugate returned by this operation is of the form \(a - bj\).</p>
<p>For example:</p>
<p>```</p>
<h1>tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]</h1>
<p>tf.conj(input) ==&gt; [-2.25 - 4.75j, 3.25 - 5.75j]
```</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conj_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conj_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.constant">
    <p>def <span class="ident">constant</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.constant, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.constant</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.constant</strong></p>
<div class="codehilite"><pre><span></span>def constant(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.constant</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.constant</code></strong></p>
<div class="codehilite"><pre><span></span>def constant(value, dtype=None, shape=None, name=&quot;Const&quot;)
</pre></div>


<p>Creates a constant tensor.</p>
<p>The resulting tensor is populated with values of type <code>dtype</code>, as
 specified by arguments <code>value</code> and (optionally) <code>shape</code> (see examples
 below).</p>
<p>The argument <code>value</code> can be a constant value, or a list of values of type
 <code>dtype</code>. If <code>value</code> is a list, then the length of the list must be less
 than or equal to the number of elements implied by the <code>shape</code> argument (if
 specified). In the case where the list length is less than the number of
 elements specified by <code>shape</code>, the last element in the list will be used
 to fill the remaining entries.</p>
<p>The argument <code>shape</code> is optional. If present, it specifies the dimensions of
 the resulting tensor. If not present, the shape of <code>value</code> is used.</p>
<p>If the argument <code>dtype</code> is not specified, then the type is inferred from
 the type of <code>value</code>.</p>
<p>For example:</p>
<p>```python
 # Constant 1-D Tensor populated with value list.
 tensor = tf.constant([1, 2, 3, 4, 5, 6, 7]) =&gt; [1 2 3 4 5 6 7]</p>
<p># Constant 2-D tensor populated with scalar value -1.
 tensor = tf.constant(-1.0, shape=[2, 3]) =&gt; [[-1. -1. -1.]
                                              [-1. -1. -1.]]
 ```</p>
<p>Args:
  value:     A constant value (or list) of output type <code>dtype</code>.</p>
<p>dtype:     The type of the elements of the resulting tensor.</p>
<p>shape:     Optional dimensions of resulting tensor.</p>
<p>name:      Optional name for the tensor.</p>
<p>Returns:
  A Constant Tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.constant', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.constant" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.constant_initializer">
    <p>def <span class="ident">constant_initializer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.constant_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.constant_initializer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.constant_initializer</strong></p>
<div class="codehilite"><pre><span></span>def constant_initializer(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.constant_initializer</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.constant_initializer</code></strong></p>
<div class="codehilite"><pre><span></span>def constant_initializer(value=0.0, dtype=&lt;dtype: &#39;float32&#39;&gt;)
</pre></div>


<p>Returns an initializer that generates tensors with a single value.</p>
<p>Args:
  value: A Python scalar. All elements of the initialized variable
    will be set to this value.
  dtype: The data type. Only floating point types are supported.</p>
<p>Returns:
  An initializer that generates tensors with a single value.</p>
<p>Raises:
  ValueError: if <code>dtype</code> is not a floating point type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.constant_initializer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.constant_initializer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.constant_initializer_layer">
    <p>def <span class="ident">constant_initializer_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.constant_initializer_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.constant_initializer_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.constant_initializer_layer</strong></p>
<div class="codehilite"><pre><span></span>def constant_initializer_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.constant_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.constant_initializer</strong></p>
<div class="codehilite"><pre><span></span>def constant_initializer(value=0.0, dtype=&lt;dtype: &#39;float32&#39;&gt;):
</pre></div>


<p>Returns an initializer that generates tensors with a single value.</p>
<p>Args:
  value: A Python scalar. All elements of the initialized variable
    will be set to this value.
  dtype: The data type. Only floating point types are supported.</p>
<p>Returns:
  An initializer that generates tensors with a single value.</p>
<p>Raises:
  ValueError: if <code>dtype</code> is not a floating point type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.constant_initializer_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.constant_initializer_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.constant_layer">
    <p>def <span class="ident">constant_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.constant_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.constant_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.constant_layer</strong></p>
<div class="codehilite"><pre><span></span>def constant_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.constant, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.constant</strong></p>
<div class="codehilite"><pre><span></span>def constant(value, dtype=None, shape=None, name=&quot;Const&quot;):
</pre></div>


<p>Creates a constant tensor.</p>
<p>The resulting tensor is populated with values of type <code>dtype</code>, as
 specified by arguments <code>value</code> and (optionally) <code>shape</code> (see examples
 below).</p>
<p>The argument <code>value</code> can be a constant value, or a list of values of type
 <code>dtype</code>. If <code>value</code> is a list, then the length of the list must be less
 than or equal to the number of elements implied by the <code>shape</code> argument (if
 specified). In the case where the list length is less than the number of
 elements specified by <code>shape</code>, the last element in the list will be used
 to fill the remaining entries.</p>
<p>The argument <code>shape</code> is optional. If present, it specifies the dimensions of
 the resulting tensor. If not present, the shape of <code>value</code> is used.</p>
<p>If the argument <code>dtype</code> is not specified, then the type is inferred from
 the type of <code>value</code>.</p>
<p>For example:</p>
<p>```python
 # Constant 1-D Tensor populated with value list.
 tensor = tf.constant([1, 2, 3, 4, 5, 6, 7]) =&gt; [1 2 3 4 5 6 7]</p>
<p># Constant 2-D tensor populated with scalar value -1.
 tensor = tf.constant(-1.0, shape=[2, 3]) =&gt; [[-1. -1. -1.]
                                              [-1. -1. -1.]]
 ```</p>
<p>Args:
  value:     A constant value (or list) of output type <code>dtype</code>.</p>
<p>dtype:     The type of the elements of the resulting tensor.</p>
<p>shape:     Optional dimensions of resulting tensor.</p>
<p>name:      Optional name for the tensor.</p>
<p>Returns:
  A Constant Tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.constant_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.constant_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.control_dependencies">
    <p>def <span class="ident">control_dependencies</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.control_dependencies, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.control_dependencies</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.control_dependencies</strong></p>
<div class="codehilite"><pre><span></span>def control_dependencies(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.control_dependencies</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.control_dependencies</code></strong></p>
<div class="codehilite"><pre><span></span>def control_dependencies(control_inputs)
</pre></div>


<p>Wrapper for <code>Graph.control_dependencies()</code> using the default graph.</p>
<p>See <a href="../../api_docs/python/framework.md#Graph.control_dependencies"><code>Graph.control_dependencies()</code></a>
for more details.</p>
<p>Args:
  control_inputs: A list of <code>Operation</code> or <code>Tensor</code> objects which
    must be executed or computed before running the operations
    defined in the context.  Can also be <code>None</code> to clear the control
    dependencies.</p>
<p>Returns:
 A context manager that specifies control dependencies for all
 operations constructed within the context.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.control_dependencies', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.control_dependencies" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.control_dependencies_layer">
    <p>def <span class="ident">control_dependencies_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.control_dependencies_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.control_dependencies_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.control_dependencies_layer</strong></p>
<div class="codehilite"><pre><span></span>def control_dependencies_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.control_dependencies, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.control_dependencies</strong></p>
<div class="codehilite"><pre><span></span>def control_dependencies(control_inputs):
</pre></div>


<p>Wrapper for <code>Graph.control_dependencies()</code> using the default graph.</p>
<p>See <a href="../../api_docs/python/framework.md#Graph.control_dependencies"><code>Graph.control_dependencies()</code></a>
for more details.</p>
<p>Args:
  control_inputs: A list of <code>Operation</code> or <code>Tensor</code> objects which
    must be executed or computed before running the operations
    defined in the context.  Can also be <code>None</code> to clear the control
    dependencies.</p>
<p>Returns:
 A context manager that specifies control dependencies for all
 operations constructed within the context.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.control_dependencies_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.control_dependencies_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv1d">
    <p>def <span class="ident">conv1d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv1d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv1d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv1d</strong></p>
<div class="codehilite"><pre><span></span>def conv1d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.conv1d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.conv1d</code></strong></p>
<div class="codehilite"><pre><span></span>def conv1d(value, filters, stride, padding, use_cudnn_on_gpu=None, data_format=None, name=None)
</pre></div>


<p>Computes a 1-D convolution given 3-D input and filter tensors.</p>
<p>Given an input tensor of shape [batch, in_width, in_channels]
and a filter / kernel tensor of shape
[filter_width, in_channels, out_channels], this op reshapes
the arguments to pass them to conv2d to perform the equivalent
convolution operation.</p>
<p>Internally, this op reshapes the input tensors and invokes
<code>tf.nn.conv2d</code>.  A tensor of shape [batch, in_width, in_channels]
is reshaped to [batch, 1, in_width, in_channels], and the filter
is reshaped to [1, filter_width, in_channels, out_channels].
The result is then reshaped back to [batch, out_width, out_channels]
(where out_width is a function of the stride and padding as in
conv2d) and returned to the caller.</p>
<p>Args:
  value: A 3D <code>Tensor</code>.  Must be of type <code>float32</code> or <code>float64</code>.
  filters: A 3D <code>Tensor</code>.  Must have the same type as <code>input</code>.
  stride: An <code>integer</code>.  The number of entries by which
    the filter is moved right at each step.
  padding: 'SAME' or 'VALID'
  use_cudnn_on_gpu: An optional <code>bool</code>.  Defaults to <code>True</code>.
  data_format: An optional <code>string</code> from <code>"NHWC", "NCHW"</code>.  Defaults
    to <code>"NHWC"</code>, the data is stored in the order of
    [batch, in_width, in_channels].  The <code>"NCHW"</code> format stores
    data as [batch, in_channels, in_width].
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>.  Has the same type as input.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv1d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv1d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv1d_layer">
    <p>def <span class="ident">conv1d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv1d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv1d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv1d_layer</strong></p>
<div class="codehilite"><pre><span></span>def conv1d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.conv1d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.conv1d</strong></p>
<div class="codehilite"><pre><span></span>def conv1d(value, filters, stride, padding, use_cudnn_on_gpu=None, data_format=None, name=None):
</pre></div>


<p>Computes a 1-D convolution given 3-D input and filter tensors.</p>
<p>Given an input tensor of shape [batch, in_width, in_channels]
and a filter / kernel tensor of shape
[filter_width, in_channels, out_channels], this op reshapes
the arguments to pass them to conv2d to perform the equivalent
convolution operation.</p>
<p>Internally, this op reshapes the input tensors and invokes
<code>tf.nn.conv2d</code>.  A tensor of shape [batch, in_width, in_channels]
is reshaped to [batch, 1, in_width, in_channels], and the filter
is reshaped to [1, filter_width, in_channels, out_channels].
The result is then reshaped back to [batch, out_width, out_channels]
(where out_width is a function of the stride and padding as in
conv2d) and returned to the caller.</p>
<p>Args:
  value: A 3D <code>Tensor</code>.  Must be of type <code>float32</code> or <code>float64</code>.
  filters: A 3D <code>Tensor</code>.  Must have the same type as <code>input</code>.
  stride: An <code>integer</code>.  The number of entries by which
    the filter is moved right at each step.
  padding: 'SAME' or 'VALID'
  use_cudnn_on_gpu: An optional <code>bool</code>.  Defaults to <code>True</code>.
  data_format: An optional <code>string</code> from <code>"NHWC", "NCHW"</code>.  Defaults
    to <code>"NHWC"</code>, the data is stored in the order of
    [batch, in_width, in_channels].  The <code>"NCHW"</code> format stores
    data as [batch, in_channels, in_width].
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>.  Has the same type as input.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv1d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv1d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv2d">
    <p>def <span class="ident">conv2d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv2d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv2d</strong></p>
<div class="codehilite"><pre><span></span>def conv2d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.conv2d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.conv2d</code></strong></p>
<div class="codehilite"><pre><span></span>def conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)
</pre></div>


<p>Computes a 2-D convolution given 4-D <code>input</code> and <code>filter</code> tensors.</p>
<p>Given an input tensor of shape <code>[batch, in_height, in_width, in_channels]</code>
and a filter / kernel tensor of shape
<code>[filter_height, filter_width, in_channels, out_channels]</code>, this op
performs the following:</p>
<ol>
<li>Flattens the filter to a 2-D matrix with shape
   <code>[filter_height * filter_width * in_channels, output_channels]</code>.</li>
<li>Extracts image patches from the input tensor to form a <em>virtual</em>
   tensor of shape <code>[batch, out_height, out_width,
   filter_height * filter_width * in_channels]</code>.</li>
<li>For each patch, right-multiplies the filter matrix and the image patch
   vector.</li>
</ol>
<p>In detail, with the default NHWC format,</p>
<div class="codehilite"><pre><span></span>output[b, i, j, k] =
    sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *
                    filter[di, dj, q, k]
</pre></div>


<p>Must have <code>strides[0] = strides[3] = 1</code>.  For the most common case of the same
horizontal and vertices strides, <code>strides = [1, stride, stride, 1]</code>.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
  strides: A list of <code>ints</code>.
    1-D of length 4.  The stride of the sliding window for each dimension
    of <code>input</code>. Must be in the same order as the dimension specified with format.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  use_cudnn_on_gpu: An optional <code>bool</code>. Defaults to <code>True</code>.
  data_format: An optional <code>string</code> from: <code>"NHWC", "NCHW"</code>. Defaults to <code>"NHWC"</code>.
    Specify the data format of the input and output data. With the
    default format "NHWC", the data is stored in the order of:
        [batch, in_height, in_width, in_channels].
    Alternatively, the format could be "NCHW", the data storage order of:
        [batch, in_channels, in_height, in_width].
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv2d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv2d_backprop_filter">
    <p>def <span class="ident">conv2d_backprop_filter</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv2d_backprop_filter, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv2d_backprop_filter</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv2d_backprop_filter</strong></p>
<div class="codehilite"><pre><span></span>def conv2d_backprop_filter(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.conv2d_backprop_filter</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.conv2d_backprop_filter</code></strong></p>
<div class="codehilite"><pre><span></span>def conv2d_backprop_filter(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)
</pre></div>


<p>Computes the gradients of convolution with respect to the filter.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
    4-D with shape <code>[batch, in_height, in_width, in_channels]</code>.
  filter_sizes: A <code>Tensor</code> of type <code>int32</code>.
    An integer vector representing the tensor shape of <code>filter</code>,
    where <code>filter</code> is a 4-D
    <code>[filter_height, filter_width, in_channels, out_channels]</code> tensor.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    4-D with shape <code>[batch, out_height, out_width, out_channels]</code>.
    Gradients w.r.t. the output of the convolution.
  strides: A list of <code>ints</code>.
    The stride of the sliding window for each dimension of the input
    of the convolution. Must be in the same order as the dimension specified with
    format.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  use_cudnn_on_gpu: An optional <code>bool</code>. Defaults to <code>True</code>.
  data_format: An optional <code>string</code> from: <code>"NHWC", "NCHW"</code>. Defaults to <code>"NHWC"</code>.
    Specify the data format of the input and output data. With the
    default format "NHWC", the data is stored in the order of:
        [batch, in_height, in_width, in_channels].
    Alternatively, the format could be "NCHW", the data storage order of:
        [batch, in_channels, in_height, in_width].
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. 4-D with shape
  <code>[filter_height, filter_width, in_channels, out_channels]</code>.  Gradient w.r.t.
  the <code>filter</code> input of the convolution.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv2d_backprop_filter', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv2d_backprop_filter" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv2d_backprop_filter_layer">
    <p>def <span class="ident">conv2d_backprop_filter_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv2d_backprop_filter_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv2d_backprop_filter_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv2d_backprop_filter_layer</strong></p>
<div class="codehilite"><pre><span></span>def conv2d_backprop_filter_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.conv2d_backprop_filter, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.conv2d_backprop_filter</strong></p>
<div class="codehilite"><pre><span></span>def conv2d_backprop_filter(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None):
</pre></div>


<p>Computes the gradients of convolution with respect to the filter.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
    4-D with shape <code>[batch, in_height, in_width, in_channels]</code>.
  filter_sizes: A <code>Tensor</code> of type <code>int32</code>.
    An integer vector representing the tensor shape of <code>filter</code>,
    where <code>filter</code> is a 4-D
    <code>[filter_height, filter_width, in_channels, out_channels]</code> tensor.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    4-D with shape <code>[batch, out_height, out_width, out_channels]</code>.
    Gradients w.r.t. the output of the convolution.
  strides: A list of <code>ints</code>.
    The stride of the sliding window for each dimension of the input
    of the convolution. Must be in the same order as the dimension specified with
    format.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  use_cudnn_on_gpu: An optional <code>bool</code>. Defaults to <code>True</code>.
  data_format: An optional <code>string</code> from: <code>"NHWC", "NCHW"</code>. Defaults to <code>"NHWC"</code>.
    Specify the data format of the input and output data. With the
    default format "NHWC", the data is stored in the order of:
        [batch, in_height, in_width, in_channels].
    Alternatively, the format could be "NCHW", the data storage order of:
        [batch, in_channels, in_height, in_width].
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. 4-D with shape
  <code>[filter_height, filter_width, in_channels, out_channels]</code>.  Gradient w.r.t.
  the <code>filter</code> input of the convolution.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv2d_backprop_filter_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv2d_backprop_filter_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv2d_backprop_input">
    <p>def <span class="ident">conv2d_backprop_input</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv2d_backprop_input, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv2d_backprop_input</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv2d_backprop_input</strong></p>
<div class="codehilite"><pre><span></span>def conv2d_backprop_input(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.conv2d_backprop_input</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.conv2d_backprop_input</code></strong></p>
<div class="codehilite"><pre><span></span>def conv2d_backprop_input(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)
</pre></div>


<p>Computes the gradients of convolution with respect to the input.</p>
<p>Args:
  input_sizes: A <code>Tensor</code> of type <code>int32</code>.
    An integer vector representing the shape of <code>input</code>,
    where <code>input</code> is a 4-D <code>[batch, height, width, channels]</code> tensor.
  filter: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
    4-D with shape
    <code>[filter_height, filter_width, in_channels, out_channels]</code>.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>filter</code>.
    4-D with shape <code>[batch, out_height, out_width, out_channels]</code>.
    Gradients w.r.t. the output of the convolution.
  strides: A list of <code>ints</code>.
    The stride of the sliding window for each dimension of the input
    of the convolution. Must be in the same order as the dimension specified with
    format.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  use_cudnn_on_gpu: An optional <code>bool</code>. Defaults to <code>True</code>.
  data_format: An optional <code>string</code> from: <code>"NHWC", "NCHW"</code>. Defaults to <code>"NHWC"</code>.
    Specify the data format of the input and output data. With the
    default format "NHWC", the data is stored in the order of:
        [batch, in_height, in_width, in_channels].
    Alternatively, the format could be "NCHW", the data storage order of:
        [batch, in_channels, in_height, in_width].
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>filter</code>.
  4-D with shape <code>[batch, in_height, in_width, in_channels]</code>.  Gradient
  w.r.t. the input of the convolution.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv2d_backprop_input', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv2d_backprop_input" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv2d_backprop_input_layer">
    <p>def <span class="ident">conv2d_backprop_input_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv2d_backprop_input_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv2d_backprop_input_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv2d_backprop_input_layer</strong></p>
<div class="codehilite"><pre><span></span>def conv2d_backprop_input_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.conv2d_backprop_input, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.conv2d_backprop_input</strong></p>
<div class="codehilite"><pre><span></span>def conv2d_backprop_input(input_sizes, filter, out_backprop, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None):
</pre></div>


<p>Computes the gradients of convolution with respect to the input.</p>
<p>Args:
  input_sizes: A <code>Tensor</code> of type <code>int32</code>.
    An integer vector representing the shape of <code>input</code>,
    where <code>input</code> is a 4-D <code>[batch, height, width, channels]</code> tensor.
  filter: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
    4-D with shape
    <code>[filter_height, filter_width, in_channels, out_channels]</code>.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>filter</code>.
    4-D with shape <code>[batch, out_height, out_width, out_channels]</code>.
    Gradients w.r.t. the output of the convolution.
  strides: A list of <code>ints</code>.
    The stride of the sliding window for each dimension of the input
    of the convolution. Must be in the same order as the dimension specified with
    format.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  use_cudnn_on_gpu: An optional <code>bool</code>. Defaults to <code>True</code>.
  data_format: An optional <code>string</code> from: <code>"NHWC", "NCHW"</code>. Defaults to <code>"NHWC"</code>.
    Specify the data format of the input and output data. With the
    default format "NHWC", the data is stored in the order of:
        [batch, in_height, in_width, in_channels].
    Alternatively, the format could be "NCHW", the data storage order of:
        [batch, in_channels, in_height, in_width].
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>filter</code>.
  4-D with shape <code>[batch, in_height, in_width, in_channels]</code>.  Gradient
  w.r.t. the input of the convolution.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv2d_backprop_input_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv2d_backprop_input_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv2d_layer">
    <p>def <span class="ident">conv2d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv2d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv2d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv2d_layer</strong></p>
<div class="codehilite"><pre><span></span>def conv2d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.conv2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.conv2d</strong></p>
<div class="codehilite"><pre><span></span>def conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None):
</pre></div>


<p>Computes a 2-D convolution given 4-D <code>input</code> and <code>filter</code> tensors.</p>
<p>Given an input tensor of shape <code>[batch, in_height, in_width, in_channels]</code>
and a filter / kernel tensor of shape
<code>[filter_height, filter_width, in_channels, out_channels]</code>, this op
performs the following:</p>
<ol>
<li>Flattens the filter to a 2-D matrix with shape
   <code>[filter_height * filter_width * in_channels, output_channels]</code>.</li>
<li>Extracts image patches from the input tensor to form a <em>virtual</em>
   tensor of shape <code>[batch, out_height, out_width,
   filter_height * filter_width * in_channels]</code>.</li>
<li>For each patch, right-multiplies the filter matrix and the image patch
   vector.</li>
</ol>
<p>In detail, with the default NHWC format,</p>
<div class="codehilite"><pre><span></span>output[b, i, j, k] =
    sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *
                    filter[di, dj, q, k]
</pre></div>


<p>Must have <code>strides[0] = strides[3] = 1</code>.  For the most common case of the same
horizontal and vertices strides, <code>strides = [1, stride, stride, 1]</code>.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
  strides: A list of <code>ints</code>.
    1-D of length 4.  The stride of the sliding window for each dimension
    of <code>input</code>. Must be in the same order as the dimension specified with format.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  use_cudnn_on_gpu: An optional <code>bool</code>. Defaults to <code>True</code>.
  data_format: An optional <code>string</code> from: <code>"NHWC", "NCHW"</code>. Defaults to <code>"NHWC"</code>.
    Specify the data format of the input and output data. With the
    default format "NHWC", the data is stored in the order of:
        [batch, in_height, in_width, in_channels].
    Alternatively, the format could be "NCHW", the data storage order of:
        [batch, in_channels, in_height, in_width].
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv2d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv2d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv2d_transpose">
    <p>def <span class="ident">conv2d_transpose</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv2d_transpose, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv2d_transpose</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv2d_transpose</strong></p>
<div class="codehilite"><pre><span></span>def conv2d_transpose(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.conv2d_transpose</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.conv2d_transpose</code></strong></p>
<div class="codehilite"><pre><span></span>def conv2d_transpose(value, filter, output_shape, strides, padding=&quot;SAME&quot;, name=None)
</pre></div>


<p>The transpose of <code>conv2d</code>.</p>
<p>This operation is sometimes called "deconvolution" after <a href="http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf">Deconvolutional
Networks</a>, but is
actually the transpose (gradient) of <code>conv2d</code> rather than an actual
deconvolution.</p>
<p>Args:
  value: A 4-D <code>Tensor</code> of type <code>float</code> and shape
    <code>[batch, height, width, in_channels]</code>.
  filter: A 4-D <code>Tensor</code> with the same type as <code>value</code> and shape
    <code>[height, width, output_channels, in_channels]</code>.  <code>filter</code>'s
    <code>in_channels</code> dimension must match that of <code>value</code>.
  output_shape: A 1-D <code>Tensor</code> representing the output shape of the
    deconvolution op.
  strides: A list of ints. The stride of the sliding window for each
    dimension of the input tensor.
  padding: A string, either <code>'VALID'</code> or <code>'SAME'</code>. The padding algorithm.
    See the <a href="https://www.tensorflow.org/api_docs/python/nn.html#convolution">comment here</a>
  name: Optional name for the returned tensor.</p>
<p>Returns:
  A <code>Tensor</code> with the same type as <code>value</code>.</p>
<p>Raises:
  ValueError: If input/output depth does not match <code>filter</code>'s shape, or if
    padding is other than <code>'VALID'</code> or <code>'SAME'</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv2d_transpose', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv2d_transpose" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv2d_transpose_layer">
    <p>def <span class="ident">conv2d_transpose_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv2d_transpose_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv2d_transpose_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv2d_transpose_layer</strong></p>
<div class="codehilite"><pre><span></span>def conv2d_transpose_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.conv2d_transpose, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.conv2d_transpose</strong></p>
<div class="codehilite"><pre><span></span>def conv2d_transpose(value, filter, output_shape, strides, padding=&quot;SAME&quot;, name=None):
</pre></div>


<p>The transpose of <code>conv2d</code>.</p>
<p>This operation is sometimes called "deconvolution" after <a href="http://www.matthewzeiler.com/pubs/cvpr2010/cvpr2010.pdf">Deconvolutional
Networks</a>, but is
actually the transpose (gradient) of <code>conv2d</code> rather than an actual
deconvolution.</p>
<p>Args:
  value: A 4-D <code>Tensor</code> of type <code>float</code> and shape
    <code>[batch, height, width, in_channels]</code>.
  filter: A 4-D <code>Tensor</code> with the same type as <code>value</code> and shape
    <code>[height, width, output_channels, in_channels]</code>.  <code>filter</code>'s
    <code>in_channels</code> dimension must match that of <code>value</code>.
  output_shape: A 1-D <code>Tensor</code> representing the output shape of the
    deconvolution op.
  strides: A list of ints. The stride of the sliding window for each
    dimension of the input tensor.
  padding: A string, either <code>'VALID'</code> or <code>'SAME'</code>. The padding algorithm.
    See the <a href="https://www.tensorflow.org/api_docs/python/nn.html#convolution">comment here</a>
  name: Optional name for the returned tensor.</p>
<p>Returns:
  A <code>Tensor</code> with the same type as <code>value</code>.</p>
<p>Raises:
  ValueError: If input/output depth does not match <code>filter</code>'s shape, or if
    padding is other than <code>'VALID'</code> or <code>'SAME'</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv2d_transpose_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv2d_transpose_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv3d">
    <p>def <span class="ident">conv3d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv3d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv3d</strong></p>
<div class="codehilite"><pre><span></span>def conv3d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.conv3d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.conv3d</code></strong></p>
<div class="codehilite"><pre><span></span>def conv3d(input, filter, strides, padding, name=None)
</pre></div>


<p>Computes a 3-D convolution given 5-D <code>input</code> and <code>filter</code> tensors.</p>
<p>In signal processing, cross-correlation is a measure of similarity of
two waveforms as a function of a time-lag applied to one of them. This
is also known as a sliding dot product or sliding inner-product.</p>
<p>Our Conv3D implements a form of cross-correlation.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Shape <code>[batch, in_depth, in_height, in_width, in_channels]</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    Shape <code>[filter_depth, filter_height, filter_width, in_channels, out_channels]</code>.
    <code>in_channels</code> must match between <code>input</code> and <code>filter</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv3d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv3d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv3d_backprop_filter">
    <p>def <span class="ident">conv3d_backprop_filter</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv3d_backprop_filter, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv3d_backprop_filter</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv3d_backprop_filter</strong></p>
<div class="codehilite"><pre><span></span>def conv3d_backprop_filter(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.conv3d_backprop_filter</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.conv3d_backprop_filter</code></strong></p>
<div class="codehilite"><pre><span></span>def conv3d_backprop_filter(input, filter, out_backprop, strides, padding, name=None)
</pre></div>


<p>Computes the gradients of 3D convolution with respect to the filter.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Shape <code>[batch, depth, rows, cols, in_channels]</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    Shape <code>[depth, rows, cols, in_channels, out_channels]</code>.
    <code>in_channels</code> must match between <code>input</code> and <code>filter</code>.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    Backprop signal of shape <code>[batch, out_depth, out_rows, out_cols, out_channels]</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv3d_backprop_filter', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv3d_backprop_filter" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv3d_backprop_filter_layer">
    <p>def <span class="ident">conv3d_backprop_filter_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv3d_backprop_filter_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv3d_backprop_filter_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv3d_backprop_filter_layer</strong></p>
<div class="codehilite"><pre><span></span>def conv3d_backprop_filter_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.conv3d_backprop_filter, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.conv3d_backprop_filter</strong></p>
<div class="codehilite"><pre><span></span>def conv3d_backprop_filter(input, filter, out_backprop, strides, padding, name=None):
</pre></div>


<p>Computes the gradients of 3D convolution with respect to the filter.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Shape <code>[batch, depth, rows, cols, in_channels]</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    Shape <code>[depth, rows, cols, in_channels, out_channels]</code>.
    <code>in_channels</code> must match between <code>input</code> and <code>filter</code>.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    Backprop signal of shape <code>[batch, out_depth, out_rows, out_cols, out_channels]</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv3d_backprop_filter_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv3d_backprop_filter_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv3d_backprop_input">
    <p>def <span class="ident">conv3d_backprop_input</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv3d_backprop_input, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv3d_backprop_input</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv3d_backprop_input</strong></p>
<div class="codehilite"><pre><span></span>def conv3d_backprop_input(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.conv3d_backprop_input</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.conv3d_backprop_input</code></strong></p>
<div class="codehilite"><pre><span></span>def conv3d_backprop_input(input, filter, out_backprop, strides, padding, name=None)
</pre></div>


<p>Computes the gradients of 3D convolution with respect to the input.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Shape <code>[batch, depth, rows, cols, in_channels]</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    Shape <code>[depth, rows, cols, in_channels, out_channels]</code>.
    <code>in_channels</code> must match between <code>input</code> and <code>filter</code>.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    Backprop signal of shape <code>[batch, out_depth, out_rows, out_cols, out_channels]</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv3d_backprop_input', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv3d_backprop_input" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv3d_backprop_input_layer">
    <p>def <span class="ident">conv3d_backprop_input_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv3d_backprop_input_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv3d_backprop_input_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv3d_backprop_input_layer</strong></p>
<div class="codehilite"><pre><span></span>def conv3d_backprop_input_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.conv3d_backprop_input, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.conv3d_backprop_input</strong></p>
<div class="codehilite"><pre><span></span>def conv3d_backprop_input(input, filter, out_backprop, strides, padding, name=None):
</pre></div>


<p>Computes the gradients of 3D convolution with respect to the input.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Shape <code>[batch, depth, rows, cols, in_channels]</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    Shape <code>[depth, rows, cols, in_channels, out_channels]</code>.
    <code>in_channels</code> must match between <code>input</code> and <code>filter</code>.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    Backprop signal of shape <code>[batch, out_depth, out_rows, out_cols, out_channels]</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv3d_backprop_input_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv3d_backprop_input_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.conv3d_layer">
    <p>def <span class="ident">conv3d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.conv3d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.conv3d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.conv3d_layer</strong></p>
<div class="codehilite"><pre><span></span>def conv3d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.conv3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.conv3d</strong></p>
<div class="codehilite"><pre><span></span>def conv3d(input, filter, strides, padding, name=None):
</pre></div>


<p>Computes a 3-D convolution given 5-D <code>input</code> and <code>filter</code> tensors.</p>
<p>In signal processing, cross-correlation is a measure of similarity of
two waveforms as a function of a time-lag applied to one of them. This
is also known as a sliding dot product or sliding inner-product.</p>
<p>Our Conv3D implements a form of cross-correlation.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Shape <code>[batch, in_depth, in_height, in_width, in_channels]</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    Shape <code>[filter_depth, filter_height, filter_width, in_channels, out_channels]</code>.
    <code>in_channels</code> must match between <code>input</code> and <code>filter</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.conv3d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.conv3d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.convert_to_tensor">
    <p>def <span class="ident">convert_to_tensor</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.convert_to_tensor, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.convert_to_tensor</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.convert_to_tensor</strong></p>
<div class="codehilite"><pre><span></span>def convert_to_tensor(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.convert_to_tensor</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.convert_to_tensor</code></strong></p>
<div class="codehilite"><pre><span></span>def convert_to_tensor(value, dtype=None, name=None, as_ref=False)
</pre></div>


<p>Converts the given <code>value</code> to a <code>Tensor</code>.</p>
<p>This function converts Python objects of various types to <code>Tensor</code>
objects. It accepts <code>Tensor</code> objects, numpy arrays, Python lists,
and Python scalars. For example:</p>
<p>```python
import numpy as np</p>
<p>def my_func(arg):
  arg = tf.convert_to_tensor(arg, dtype=tf.float32)
  return tf.matmul(arg, arg) + arg</p>
<h1>The following calls are equivalent.</h1>
<p>value_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))
value_2 = my_func([[1.0, 2.0], [3.0, 4.0]])
value_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))
```</p>
<p>This function can be useful when composing a new operation in Python
(such as <code>my_func</code> in the example above). All standard Python op
constructors apply this function to each of their Tensor-valued
inputs, which allows those ops to accept numpy arrays, Python lists,
and scalars in addition to <code>Tensor</code> objects.</p>
<p>Args:
  value: An object whose type has a registered <code>Tensor</code> conversion function.
  dtype: Optional element type for the returned tensor. If missing, the
    type is inferred from the type of <code>value</code>.
  name: Optional name to use if a new <code>Tensor</code> is created.
  as_ref: True if we want the result as a ref tensor. Only used if a new
    <code>Tensor</code> is created.</p>
<p>Returns:
  A <code>Tensor</code> based on <code>value</code>.</p>
<p>Raises:
  TypeError: If no conversion function is registered for <code>value</code>.
  RuntimeError: If a registered conversion function returns an invalid value.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.convert_to_tensor', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.convert_to_tensor" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.convert_to_tensor_layer">
    <p>def <span class="ident">convert_to_tensor_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.convert_to_tensor_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.convert_to_tensor_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.convert_to_tensor_layer</strong></p>
<div class="codehilite"><pre><span></span>def convert_to_tensor_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.convert_to_tensor, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.convert_to_tensor</strong></p>
<div class="codehilite"><pre><span></span>def convert_to_tensor(value, dtype=None, name=None, as_ref=False):
</pre></div>


<p>Converts the given <code>value</code> to a <code>Tensor</code>.</p>
<p>This function converts Python objects of various types to <code>Tensor</code>
objects. It accepts <code>Tensor</code> objects, numpy arrays, Python lists,
and Python scalars. For example:</p>
<p>```python
import numpy as np</p>
<p>def my_func(arg):
  arg = tf.convert_to_tensor(arg, dtype=tf.float32)
  return tf.matmul(arg, arg) + arg</p>
<h1>The following calls are equivalent.</h1>
<p>value_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))
value_2 = my_func([[1.0, 2.0], [3.0, 4.0]])
value_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))
```</p>
<p>This function can be useful when composing a new operation in Python
(such as <code>my_func</code> in the example above). All standard Python op
constructors apply this function to each of their Tensor-valued
inputs, which allows those ops to accept numpy arrays, Python lists,
and scalars in addition to <code>Tensor</code> objects.</p>
<p>Args:
  value: An object whose type has a registered <code>Tensor</code> conversion function.
  dtype: Optional element type for the returned tensor. If missing, the
    type is inferred from the type of <code>value</code>.
  name: Optional name to use if a new <code>Tensor</code> is created.
  as_ref: True if we want the result as a ref tensor. Only used if a new
    <code>Tensor</code> is created.</p>
<p>Returns:
  A <code>Tensor</code> based on <code>value</code>.</p>
<p>Raises:
  TypeError: If no conversion function is registered for <code>value</code>.
  RuntimeError: If a registered conversion function returns an invalid value.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.convert_to_tensor_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.convert_to_tensor_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.convert_to_tensor_or_indexed_slices">
    <p>def <span class="ident">convert_to_tensor_or_indexed_slices</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.convert_to_tensor_or_indexed_slices, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.convert_to_tensor_or_indexed_slices</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.convert_to_tensor_or_indexed_slices</strong></p>
<div class="codehilite"><pre><span></span>def convert_to_tensor_or_indexed_slices(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.convert_to_tensor_or_indexed_slices</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.convert_to_tensor_or_indexed_slices</code></strong></p>
<div class="codehilite"><pre><span></span>def convert_to_tensor_or_indexed_slices(value, dtype=None, name=None, as_ref=False)
</pre></div>


<p>Converts the given object to a <code>Tensor</code> or an <code>IndexedSlices</code>.</p>
<p>If <code>value</code> is an <code>IndexedSlices</code> or <code>SparseTensor</code> it is returned
unmodified. Otherwise, it is converted to a <code>Tensor</code> using
<code>convert_to_tensor()</code>.</p>
<p>Args:
  value: An <code>IndexedSlices</code>, <code>SparseTensor</code>, or an object that can be consumed
    by <code>convert_to_tensor()</code>.
  dtype: (Optional.) The required <code>DType</code> of the returned <code>Tensor</code> or
    <code>IndexedSlices</code>.
  name: (Optional.) A name to use if a new <code>Tensor</code> is created.
  as_ref: True if the caller wants the results as ref tensors.</p>
<p>Returns:
  An <code>Tensor</code>, <code>IndexedSlices</code>, or <code>SparseTensor</code> based on <code>value</code>.</p>
<p>Raises:
  ValueError: If <code>dtype</code> does not match the element type of <code>value</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.convert_to_tensor_or_indexed_slices', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.convert_to_tensor_or_indexed_slices" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.convert_to_tensor_or_indexed_slices_layer">
    <p>def <span class="ident">convert_to_tensor_or_indexed_slices_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.convert_to_tensor_or_indexed_slices_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.convert_to_tensor_or_indexed_slices_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.convert_to_tensor_or_indexed_slices_layer</strong></p>
<div class="codehilite"><pre><span></span>def convert_to_tensor_or_indexed_slices_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.convert_to_tensor_or_indexed_slices, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.convert_to_tensor_or_indexed_slices</strong></p>
<div class="codehilite"><pre><span></span>def convert_to_tensor_or_indexed_slices(value, dtype=None, name=None, as_ref=False):
</pre></div>


<p>Converts the given object to a <code>Tensor</code> or an <code>IndexedSlices</code>.</p>
<p>If <code>value</code> is an <code>IndexedSlices</code> or <code>SparseTensor</code> it is returned
unmodified. Otherwise, it is converted to a <code>Tensor</code> using
<code>convert_to_tensor()</code>.</p>
<p>Args:
  value: An <code>IndexedSlices</code>, <code>SparseTensor</code>, or an object that can be consumed
    by <code>convert_to_tensor()</code>.
  dtype: (Optional.) The required <code>DType</code> of the returned <code>Tensor</code> or
    <code>IndexedSlices</code>.
  name: (Optional.) A name to use if a new <code>Tensor</code> is created.
  as_ref: True if the caller wants the results as ref tensors.</p>
<p>Returns:
  An <code>Tensor</code>, <code>IndexedSlices</code>, or <code>SparseTensor</code> based on <code>value</code>.</p>
<p>Raises:
  ValueError: If <code>dtype</code> does not match the element type of <code>value</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.convert_to_tensor_or_indexed_slices_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.convert_to_tensor_or_indexed_slices_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.convolution2d">
    <p>def <span class="ident">convolution2d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.convolution2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.convolution2d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.convolution2d</strong></p>
<div class="codehilite"><pre><span></span>def convolution2d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.contrib.layers.convolution2d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.contrib.layers.convolution2d</code></strong></p>
<div class="codehilite"><pre><span></span>def convolution2d()
</pre></div>


<p>Adds a 2D convolution followed by an optional batch_norm layer.</p>
<p><code>convolution2d</code> creates a variable called <code>weights</code>, representing the
convolutional kernel, that is convolved with the <code>inputs</code> to produce a
<code>Tensor</code> of activations. If a <code>normalizer_fn</code> is provided (such as
<code>batch_norm</code>), it is then applied. Otherwise, if <code>normalizer_fn</code> is
None and a <code>biases_initializer</code> is provided then a <code>biases</code> variable would be
created and added the activations. Finally, if <code>activation_fn</code> is not <code>None</code>,
it is applied to the activations as well.</p>
<p>Args:
  inputs: a 4-D tensor  <code>[batch_size, height, width, channels]</code>.
  num_outputs: integer, the number of output filters.
  kernel_size: a list of length 2 <code>[kernel_height, kernel_width]</code> of
    of the filters. Can be an int if both values are the same.
  stride: a list of length 2 <code>[stride_height, stride_width]</code>.
    Can be an int if both strides are the same. Note that presently
    both strides must have the same value.
  padding: one of <code>VALID</code> or <code>SAME</code>.
  activation_fn: activation function.
  normalizer_fn: normalization function to use instead of <code>biases</code>. If
    <code>normalize_fn</code> is provided then <code>biases_initializer</code> and
    <code>biases_regularizer</code> are ignored and <code>biases</code> are not created nor added.
  normalizer_params: normalization function parameters.
  weights_initializer: An initializer for the weights.
  weights_regularizer: Optional regularizer for the weights.
  biases_initializer: An initializer for the biases. If None skip biases.
  biases_regularizer: Optional regularizer for the biases.
  reuse: whether or not the layer and its variables should be reused. To be
    able to reuse the layer scope must be given.
  variables_collections: optional list of collections for all the variables or
    a dictionay containing a different list of collection per variable.
  outputs_collections: collection to add the outputs.
  trainable: If <code>True</code> also add variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  scope: Optional scope for <code>variable_op_scope</code>.</p>
<p>Returns:
  a tensor representing the output of the operation.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.convolution2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.convolution2d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.copy">
    <p>def <span class="ident">copy</span>(</p><p>self)</p>
    </div>
    

    
  
    <div class="desc"><p>Returns a compy of the applicative</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.copy', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.copy" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">copy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns a compy of the applicative&quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_unit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">f</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.cos">
    <p>def <span class="ident">cos</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.cos, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.cos</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.cos</strong></p>
<div class="codehilite"><pre><span></span>def cos(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.cos</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.cos</code></strong></p>
<div class="codehilite"><pre><span></span>def cos(x, name=None)
</pre></div>


<p>Computes cos of x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.cos', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.cos" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.cos_layer">
    <p>def <span class="ident">cos_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.cos_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.cos_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.cos_layer</strong></p>
<div class="codehilite"><pre><span></span>def cos_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.cos, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.cos</strong></p>
<div class="codehilite"><pre><span></span>def cos(x, name=None):
</pre></div>


<p>Computes cos of x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.cos_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.cos_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.count_up_to">
    <p>def <span class="ident">count_up_to</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.count_up_to, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.count_up_to</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.count_up_to</strong></p>
<div class="codehilite"><pre><span></span>def count_up_to(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.count_up_to</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.count_up_to</code></strong></p>
<div class="codehilite"><pre><span></span>def count_up_to(ref, limit, name=None)
</pre></div>


<p>Increments 'ref' until it reaches 'limit'.</p>
<p>This operation outputs "ref" after the update is done.  This makes it
easier to chain operations that need to use the updated value.</p>
<p>Args:
  ref: A mutable <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    Should be from a scalar <code>Variable</code> node.
  limit: An <code>int</code>.
    If incrementing ref would bring it above limit, instead generates an
    'OutOfRange' error.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>ref</code>.
  A copy of the input before increment. If nothing else modifies the
  input, the values produced will all be distinct.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.count_up_to', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.count_up_to" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.count_up_to_layer">
    <p>def <span class="ident">count_up_to_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.count_up_to_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.count_up_to_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.count_up_to_layer</strong></p>
<div class="codehilite"><pre><span></span>def count_up_to_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.count_up_to, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.count_up_to</strong></p>
<div class="codehilite"><pre><span></span>def count_up_to(ref, limit, name=None):
</pre></div>


<p>Increments 'ref' until it reaches 'limit'.</p>
<p>This operation outputs "ref" after the update is done.  This makes it
easier to chain operations that need to use the updated value.</p>
<p>Args:
  ref: A mutable <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    Should be from a scalar <code>Variable</code> node.
  limit: An <code>int</code>.
    If incrementing ref would bring it above limit, instead generates an
    'OutOfRange' error.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>ref</code>.
  A copy of the input before increment. If nothing else modifies the
  input, the values produced will all be distinct.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.count_up_to_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.count_up_to_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.create_partitioned_variables">
    <p>def <span class="ident">create_partitioned_variables</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.create_partitioned_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.create_partitioned_variables</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.create_partitioned_variables</strong></p>
<div class="codehilite"><pre><span></span>def create_partitioned_variables(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.create_partitioned_variables</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.create_partitioned_variables</code></strong></p>
<div class="codehilite"><pre><span></span>def create_partitioned_variables(shape, slicing, initializer, dtype=&lt;dtype: &#39;float32&#39;&gt;, trainable=True, collections=None, name=None, reuse=None)
</pre></div>


<p>Create a list of partitioned variables according to the given <code>slicing</code>.</p>
<p>Currently only one dimension of the full variable can be sliced, and the
full variable can be reconstructed by the concatenation of the returned
list along that dimension.</p>
<p>Args:
  shape: List of integers.  The shape of the full variable.
  slicing: List of integers.  How to partition the variable.
    Must be of the same length as <code>shape</code>.  Each value
    indicate how many slices to create in the corresponding
    dimension.  Presently only one of the values can be more than 1;
    that is, the variable can only be sliced along one dimension.</p>
<div class="codehilite"><pre><span></span>For convenience, The requested number of partitions does not have to
divide the corresponding dimension evenly.  If it does not, the
shapes of the partitions are incremented by 1 starting from partition
0 until all slack is absorbed.  The adjustment rules may change in the
future, but as you can save/restore these variables with different
slicing specifications this should not be a problem.
</pre></div>


<p>initializer: A <code>Tensor</code> of shape <code>shape</code> or a variable initializer
    function.  If a function, it will be called once for each slice,
    passing the shape and data type of the slice as parameters.  The
    function must return a tensor with the same shape as the slice.
  dtype: Type of the variables. Ignored if <code>initializer</code> is a <code>Tensor</code>.
  trainable: If True also add all the variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code>.
  collections: List of graph collections keys to add the variables to.
    Defaults to <code>[GraphKeys.VARIABLES]</code>.
  name: Optional name for the full variable.  Defaults to
    <code>"PartitionedVariable"</code> and gets uniquified automatically.
  reuse: Boolean or <code>None</code>; if <code>True</code> and name is set, it would reuse
    previously created variables. if <code>False</code> it will create new variables.
    if <code>None</code>, it would inherit the parent scope reuse.</p>
<p>Returns:
  A list of Variables corresponding to the slicing.</p>
<p>Raises:
  ValueError: If any of the arguments is malformed.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.create_partitioned_variables', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.create_partitioned_variables" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.create_partitioned_variables_layer">
    <p>def <span class="ident">create_partitioned_variables_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.create_partitioned_variables_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.create_partitioned_variables_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.create_partitioned_variables_layer</strong></p>
<div class="codehilite"><pre><span></span>def create_partitioned_variables_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.create_partitioned_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.create_partitioned_variables</strong></p>
<div class="codehilite"><pre><span></span>def create_partitioned_variables(shape, slicing, initializer, dtype=&lt;dtype: &#39;float32&#39;&gt;, trainable=True, collections=None, name=None, reuse=None):
</pre></div>


<p>Create a list of partitioned variables according to the given <code>slicing</code>.</p>
<p>Currently only one dimension of the full variable can be sliced, and the
full variable can be reconstructed by the concatenation of the returned
list along that dimension.</p>
<p>Args:
  shape: List of integers.  The shape of the full variable.
  slicing: List of integers.  How to partition the variable.
    Must be of the same length as <code>shape</code>.  Each value
    indicate how many slices to create in the corresponding
    dimension.  Presently only one of the values can be more than 1;
    that is, the variable can only be sliced along one dimension.</p>
<div class="codehilite"><pre><span></span>For convenience, The requested number of partitions does not have to
divide the corresponding dimension evenly.  If it does not, the
shapes of the partitions are incremented by 1 starting from partition
0 until all slack is absorbed.  The adjustment rules may change in the
future, but as you can save/restore these variables with different
slicing specifications this should not be a problem.
</pre></div>


<p>initializer: A <code>Tensor</code> of shape <code>shape</code> or a variable initializer
    function.  If a function, it will be called once for each slice,
    passing the shape and data type of the slice as parameters.  The
    function must return a tensor with the same shape as the slice.
  dtype: Type of the variables. Ignored if <code>initializer</code> is a <code>Tensor</code>.
  trainable: If True also add all the variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code>.
  collections: List of graph collections keys to add the variables to.
    Defaults to <code>[GraphKeys.VARIABLES]</code>.
  name: Optional name for the full variable.  Defaults to
    <code>"PartitionedVariable"</code> and gets uniquified automatically.
  reuse: Boolean or <code>None</code>; if <code>True</code> and name is set, it would reuse
    previously created variables. if <code>False</code> it will create new variables.
    if <code>None</code>, it would inherit the parent scope reuse.</p>
<p>Returns:
  A list of Variables corresponding to the slicing.</p>
<p>Raises:
  ValueError: If any of the arguments is malformed.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.create_partitioned_variables_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.create_partitioned_variables_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.cross">
    <p>def <span class="ident">cross</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.cross, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.cross</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.cross</strong></p>
<div class="codehilite"><pre><span></span>def cross(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.cross</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.cross</code></strong></p>
<div class="codehilite"><pre><span></span>def cross(a, b, name=None)
</pre></div>


<p>Compute the pairwise cross product.</p>
<p><code>a</code> and <code>b</code> must be the same shape; they can either be simple 3-element vectors,
or any shape where the innermost dimension is 3. In the latter case, each pair
of corresponding 3-element vectors is cross-multiplied independently.</p>
<p>Args:
  a: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
    A tensor containing 3-element vectors.
  b: A <code>Tensor</code>. Must have the same type as <code>a</code>.
    Another tensor, of same type and shape as <code>a</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>a</code>.
  Pairwise cross product of the vectors in <code>a</code> and <code>b</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.cross', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.cross" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.cross_layer">
    <p>def <span class="ident">cross_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.cross_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.cross_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.cross_layer</strong></p>
<div class="codehilite"><pre><span></span>def cross_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.cross, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.cross</strong></p>
<div class="codehilite"><pre><span></span>def cross(a, b, name=None):
</pre></div>


<p>Compute the pairwise cross product.</p>
<p><code>a</code> and <code>b</code> must be the same shape; they can either be simple 3-element vectors,
or any shape where the innermost dimension is 3. In the latter case, each pair
of corresponding 3-element vectors is cross-multiplied independently.</p>
<p>Args:
  a: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
    A tensor containing 3-element vectors.
  b: A <code>Tensor</code>. Must have the same type as <code>a</code>.
    Another tensor, of same type and shape as <code>a</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>a</code>.
  Pairwise cross product of the vectors in <code>a</code> and <code>b</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.cross_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.cross_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.decode_csv">
    <p>def <span class="ident">decode_csv</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.decode_csv, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.decode_csv</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.decode_csv</strong></p>
<div class="codehilite"><pre><span></span>def decode_csv(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.decode_csv</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.decode_csv</code></strong></p>
<div class="codehilite"><pre><span></span>def decode_csv(records, record_defaults, field_delim=None, name=None)
</pre></div>


<p>Convert CSV records to tensors. Each column maps to one tensor.</p>
<p>RFC 4180 format is expected for the CSV records.
(https://tools.ietf.org/html/rfc4180)
Note that we allow leading and trailing spaces with int or float field.</p>
<p>Args:
  records: A <code>Tensor</code> of type <code>string</code>.
    Each string is a record/row in the csv and all records should have
    the same format.
  record_defaults: A list of <code>Tensor</code> objects with types from: <code>float32</code>, <code>int32</code>, <code>int64</code>, <code>string</code>.
    One tensor per column of the input record, with either a
    scalar default value for that column or empty if the column is required.
  field_delim: An optional <code>string</code>. Defaults to <code>","</code>.
    delimiter to separate fields in a record.
  name: A name for the operation (optional).</p>
<p>Returns:
  A list of <code>Tensor</code> objects. Has the same type as <code>record_defaults</code>.
  Each tensor will have the same shape as records.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.decode_csv', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.decode_csv" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.decode_csv_layer">
    <p>def <span class="ident">decode_csv_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.decode_csv_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.decode_csv_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.decode_csv_layer</strong></p>
<div class="codehilite"><pre><span></span>def decode_csv_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.decode_csv, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.decode_csv</strong></p>
<div class="codehilite"><pre><span></span>def decode_csv(records, record_defaults, field_delim=None, name=None):
</pre></div>


<p>Convert CSV records to tensors. Each column maps to one tensor.</p>
<p>RFC 4180 format is expected for the CSV records.
(https://tools.ietf.org/html/rfc4180)
Note that we allow leading and trailing spaces with int or float field.</p>
<p>Args:
  records: A <code>Tensor</code> of type <code>string</code>.
    Each string is a record/row in the csv and all records should have
    the same format.
  record_defaults: A list of <code>Tensor</code> objects with types from: <code>float32</code>, <code>int32</code>, <code>int64</code>, <code>string</code>.
    One tensor per column of the input record, with either a
    scalar default value for that column or empty if the column is required.
  field_delim: An optional <code>string</code>. Defaults to <code>","</code>.
    delimiter to separate fields in a record.
  name: A name for the operation (optional).</p>
<p>Returns:
  A list of <code>Tensor</code> objects. Has the same type as <code>record_defaults</code>.
  Each tensor will have the same shape as records.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.decode_csv_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.decode_csv_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.decode_json_example">
    <p>def <span class="ident">decode_json_example</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.decode_json_example, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.decode_json_example</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.decode_json_example</strong></p>
<div class="codehilite"><pre><span></span>def decode_json_example(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.decode_json_example</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.decode_json_example</code></strong></p>
<div class="codehilite"><pre><span></span>def decode_json_example(json_examples, name=None)
</pre></div>


<p>Convert JSON-encoded Example records to binary protocol buffer strings.</p>
<p>This op translates a tensor containing Example records, encoded using
the <a href="https://developers.google.com/protocol-buffers/docs/proto3#json">standard JSON
mapping</a>,
into a tensor containing the same records encoded as binary protocol
buffers. The resulting tensor can then be fed to any of the other
Example-parsing ops.</p>
<p>Args:
  json_examples: A <code>Tensor</code> of type <code>string</code>.
    Each string is a JSON object serialized according to the JSON
    mapping of the Example proto.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>string</code>.
  Each string is a binary Example protocol buffer corresponding
  to the respective element of <code>json_examples</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.decode_json_example', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.decode_json_example" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.decode_json_example_layer">
    <p>def <span class="ident">decode_json_example_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.decode_json_example_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.decode_json_example_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.decode_json_example_layer</strong></p>
<div class="codehilite"><pre><span></span>def decode_json_example_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.decode_json_example, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.decode_json_example</strong></p>
<div class="codehilite"><pre><span></span>def decode_json_example(json_examples, name=None):
</pre></div>


<p>Convert JSON-encoded Example records to binary protocol buffer strings.</p>
<p>This op translates a tensor containing Example records, encoded using
the <a href="https://developers.google.com/protocol-buffers/docs/proto3#json">standard JSON
mapping</a>,
into a tensor containing the same records encoded as binary protocol
buffers. The resulting tensor can then be fed to any of the other
Example-parsing ops.</p>
<p>Args:
  json_examples: A <code>Tensor</code> of type <code>string</code>.
    Each string is a JSON object serialized according to the JSON
    mapping of the Example proto.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>string</code>.
  Each string is a binary Example protocol buffer corresponding
  to the respective element of <code>json_examples</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.decode_json_example_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.decode_json_example_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.decode_raw">
    <p>def <span class="ident">decode_raw</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.decode_raw, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.decode_raw</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.decode_raw</strong></p>
<div class="codehilite"><pre><span></span>def decode_raw(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.decode_raw</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.decode_raw</code></strong></p>
<div class="codehilite"><pre><span></span>def decode_raw(bytes, out_type, little_endian=None, name=None)
</pre></div>


<p>Reinterpret the bytes of a string as a vector of numbers.</p>
<p>Args:
  bytes: A <code>Tensor</code> of type <code>string</code>.
    All the elements must have the same length.
  out_type: A <code>tf.DType</code> from: <code>tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.int64</code>.
  little_endian: An optional <code>bool</code>. Defaults to <code>True</code>.
    Whether the input <code>bytes</code> are in little-endian order.
    Ignored for <code>out_type</code> values that are stored in a single byte like
    <code>uint8</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>out_type</code>.
  A Tensor with one more dimension than the input <code>bytes</code>.  The
  added dimension will have size equal to the length of the elements
  of <code>bytes</code> divided by the number of bytes to represent <code>out_type</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.decode_raw', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.decode_raw" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.decode_raw_layer">
    <p>def <span class="ident">decode_raw_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.decode_raw_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.decode_raw_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.decode_raw_layer</strong></p>
<div class="codehilite"><pre><span></span>def decode_raw_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.decode_raw, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.decode_raw</strong></p>
<div class="codehilite"><pre><span></span>def decode_raw(bytes, out_type, little_endian=None, name=None):
</pre></div>


<p>Reinterpret the bytes of a string as a vector of numbers.</p>
<p>Args:
  bytes: A <code>Tensor</code> of type <code>string</code>.
    All the elements must have the same length.
  out_type: A <code>tf.DType</code> from: <code>tf.float32, tf.float64, tf.int32, tf.uint8, tf.int16, tf.int8, tf.int64</code>.
  little_endian: An optional <code>bool</code>. Defaults to <code>True</code>.
    Whether the input <code>bytes</code> are in little-endian order.
    Ignored for <code>out_type</code> values that are stored in a single byte like
    <code>uint8</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>out_type</code>.
  A Tensor with one more dimension than the input <code>bytes</code>.  The
  added dimension will have size equal to the length of the elements
  of <code>bytes</code> divided by the number of bytes to represent <code>out_type</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.decode_raw_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.decode_raw_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.delete_session_tensor">
    <p>def <span class="ident">delete_session_tensor</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.delete_session_tensor, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.delete_session_tensor</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.delete_session_tensor</strong></p>
<div class="codehilite"><pre><span></span>def delete_session_tensor(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.delete_session_tensor</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.delete_session_tensor</code></strong></p>
<div class="codehilite"><pre><span></span>def delete_session_tensor(name=None)
</pre></div>


<p>Delete the tensor by feeding a tensor handle.</p>
<p>This is EXPERIMENTAL and subject to change.</p>
<p>Delete the tensor of a given tensor handle. The tensor is produced
in a previous run() and stored in the state of the session.</p>
<p>Args:
  name: Optional name prefix for the return tensor.</p>
<p>Returns:
  A pair of graph elements. The first is a placeholder for feeding a
  tensor handle and the second is a deletion operation.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.delete_session_tensor', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.delete_session_tensor" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.delete_session_tensor_layer">
    <p>def <span class="ident">delete_session_tensor_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.delete_session_tensor_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.delete_session_tensor_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.delete_session_tensor_layer</strong></p>
<div class="codehilite"><pre><span></span>def delete_session_tensor_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.delete_session_tensor, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.delete_session_tensor</strong></p>
<div class="codehilite"><pre><span></span>def delete_session_tensor(name=None):
</pre></div>


<p>Delete the tensor by feeding a tensor handle.</p>
<p>This is EXPERIMENTAL and subject to change.</p>
<p>Delete the tensor of a given tensor handle. The tensor is produced
in a previous run() and stored in the state of the session.</p>
<p>Args:
  name: Optional name prefix for the return tensor.</p>
<p>Returns:
  A pair of graph elements. The first is a placeholder for feeding a
  tensor handle and the second is a deletion operation.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.delete_session_tensor_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.delete_session_tensor_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.depth_to_space">
    <p>def <span class="ident">depth_to_space</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.depth_to_space, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.depth_to_space</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.depth_to_space</strong></p>
<div class="codehilite"><pre><span></span>def depth_to_space(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.depth_to_space</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.depth_to_space</code></strong></p>
<div class="codehilite"><pre><span></span>def depth_to_space(input, block_size, name=None)
</pre></div>


<p>DepthToSpace for tensors of type T.</p>
<p>Rearranges data from depth into blocks of spatial data.
This is the reverse transformation of SpaceToDepth. More specifically,
this op outputs a copy of the input tensor where values from the <code>depth</code>
dimension are moved in spatial blocks to the <code>height</code> and <code>width</code> dimensions.
The attr <code>block_size</code> indicates the input block size and how the data is moved.</p>
<ul>
<li>Chunks of data of size <code>block_size * block_size</code> from depth are rearranged
    into non-overlapping blocks of size <code>block_size x block_size</code></li>
<li>The width the output tensor is <code>input_depth * block_size</code>, whereas the
    height is <code>input_height * block_size</code>.</li>
<li>The depth of the input tensor must be divisible by
    <code>block_size * block_size</code>.</li>
</ul>
<p>That is, assuming the input is in the shape:
<code>[batch, height, width, depth]</code>,
the shape of the output will be:
<code>[batch, height*block_size, width*block_size, depth/(block_size*block_size)]</code></p>
<p>This operation requires that the input tensor be of rank 4, and that
<code>block_size</code> be &gt;=1 and that <code>block_size * block_size</code> be a divisor of the
input depth.</p>
<p>This operation is useful for resizing the activations between convolutions
(but keeping all data), e.g. instead of pooling. It is also useful for training
purely convolutional models.</p>
<p>For example, given this input of shape <code>[1, 1, 1, 4]</code>, and a block size of 2:</p>
<p>```prettyprint
x = [[[[1, 2, 3, 4]]]]</p>
<p>```</p>
<p>This operation will output a tensor of shape <code>[1, 2, 2, 1]</code>:</p>
<p><code>prettyprint
   [[[[1], [2]],
     [[3], [4]]]]</code></p>
<p>Here, the input has a batch of 1 and each batch element has shape <code>[1, 1, 4]</code>,
the corresponding output will have 2x2 elements and will have a depth of
1 channel (1 = <code>4 / (block_size * block_size)</code>).
The output element shape is <code>[2, 2, 1]</code>.</p>
<p>For an input tensor with larger depth, here of shape <code>[1, 1, 1, 12]</code>, e.g.</p>
<p><code>prettyprint
x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]</code></p>
<p>This operation, for block size of 2, will return the following tensor of shape
<code>[1, 2, 2, 3]</code></p>
<p>```prettyprint
   [[[[1, 2, 3], [4, 5, 6]],
     [[7, 8, 9], [10, 11, 12]]]]</p>
<p>```</p>
<p>Similarly, for the following input of shape <code>[1 2 2 4]</code>, and a block size of 2:</p>
<p><code>prettyprint
x =  [[[[1, 2, 3, 4],
       [5, 6, 7, 8]],
      [[9, 10, 11, 12],
       [13, 14, 15, 16]]]]</code></p>
<p>the operator will return the following tensor of shape <code>[1 4 4 1]</code>:</p>
<p>```prettyprint
x = [[ [1],   [2],  [5],  [6]],
     [ [3],   [4],  [7],  [8]],
     [ [9],  [10], [13],  [14]],
     [ [11], [12], [15],  [16]]]</p>
<p>```</p>
<p>Args:
  input: A <code>Tensor</code>.
  block_size: An <code>int</code>.
    The size of the spatial block, same as in Space2Depth.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.depth_to_space', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.depth_to_space" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.depth_to_space_layer">
    <p>def <span class="ident">depth_to_space_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.depth_to_space_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.depth_to_space_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.depth_to_space_layer</strong></p>
<div class="codehilite"><pre><span></span>def depth_to_space_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.depth_to_space, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.depth_to_space</strong></p>
<div class="codehilite"><pre><span></span>def depth_to_space(input, block_size, name=None):
</pre></div>


<p>DepthToSpace for tensors of type T.</p>
<p>Rearranges data from depth into blocks of spatial data.
This is the reverse transformation of SpaceToDepth. More specifically,
this op outputs a copy of the input tensor where values from the <code>depth</code>
dimension are moved in spatial blocks to the <code>height</code> and <code>width</code> dimensions.
The attr <code>block_size</code> indicates the input block size and how the data is moved.</p>
<ul>
<li>Chunks of data of size <code>block_size * block_size</code> from depth are rearranged
    into non-overlapping blocks of size <code>block_size x block_size</code></li>
<li>The width the output tensor is <code>input_depth * block_size</code>, whereas the
    height is <code>input_height * block_size</code>.</li>
<li>The depth of the input tensor must be divisible by
    <code>block_size * block_size</code>.</li>
</ul>
<p>That is, assuming the input is in the shape:
<code>[batch, height, width, depth]</code>,
the shape of the output will be:
<code>[batch, height*block_size, width*block_size, depth/(block_size*block_size)]</code></p>
<p>This operation requires that the input tensor be of rank 4, and that
<code>block_size</code> be &gt;=1 and that <code>block_size * block_size</code> be a divisor of the
input depth.</p>
<p>This operation is useful for resizing the activations between convolutions
(but keeping all data), e.g. instead of pooling. It is also useful for training
purely convolutional models.</p>
<p>For example, given this input of shape <code>[1, 1, 1, 4]</code>, and a block size of 2:</p>
<p>```prettyprint
x = [[[[1, 2, 3, 4]]]]</p>
<p>```</p>
<p>This operation will output a tensor of shape <code>[1, 2, 2, 1]</code>:</p>
<p><code>prettyprint
   [[[[1], [2]],
     [[3], [4]]]]</code></p>
<p>Here, the input has a batch of 1 and each batch element has shape <code>[1, 1, 4]</code>,
the corresponding output will have 2x2 elements and will have a depth of
1 channel (1 = <code>4 / (block_size * block_size)</code>).
The output element shape is <code>[2, 2, 1]</code>.</p>
<p>For an input tensor with larger depth, here of shape <code>[1, 1, 1, 12]</code>, e.g.</p>
<p><code>prettyprint
x = [[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]</code></p>
<p>This operation, for block size of 2, will return the following tensor of shape
<code>[1, 2, 2, 3]</code></p>
<p>```prettyprint
   [[[[1, 2, 3], [4, 5, 6]],
     [[7, 8, 9], [10, 11, 12]]]]</p>
<p>```</p>
<p>Similarly, for the following input of shape <code>[1 2 2 4]</code>, and a block size of 2:</p>
<p><code>prettyprint
x =  [[[[1, 2, 3, 4],
       [5, 6, 7, 8]],
      [[9, 10, 11, 12],
       [13, 14, 15, 16]]]]</code></p>
<p>the operator will return the following tensor of shape <code>[1 4 4 1]</code>:</p>
<p>```prettyprint
x = [[ [1],   [2],  [5],  [6]],
     [ [3],   [4],  [7],  [8]],
     [ [9],  [10], [13],  [14]],
     [ [11], [12], [15],  [16]]]</p>
<p>```</p>
<p>Args:
  input: A <code>Tensor</code>.
  block_size: An <code>int</code>.
    The size of the spatial block, same as in Space2Depth.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.depth_to_space_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.depth_to_space_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.depthwise_conv2d">
    <p>def <span class="ident">depthwise_conv2d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.depthwise_conv2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.depthwise_conv2d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.depthwise_conv2d</strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.depthwise_conv2d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.depthwise_conv2d</code></strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d(input, filter, strides, padding, name=None)
</pre></div>


<p>Depthwise 2-D convolution.</p>
<p>Given an input tensor of shape <code>[batch, in_height, in_width, in_channels]</code>
and a filter tensor of shape
<code>[filter_height, filter_width, in_channels, channel_multiplier]</code>
containing <code>in_channels</code> convolutional filters of depth 1, <code>depthwise_conv2d</code>
applies a different filter to each input channel (expanding from 1 channel
to <code>channel_multiplier</code> channels for each), then concatenates the results
together.  The output has <code>in_channels * channel_multiplier</code> channels.</p>
<p>In detail,</p>
<div class="codehilite"><pre><span></span>output[b, i, j, k * channel_multiplier + q] =
    sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
                 filter[di, dj, k, q]
</pre></div>


<p>Must have <code>strides[0] = strides[3] = 1</code>.  For the most common case of the
same horizontal and vertical strides, <code>strides = [1, stride, stride, 1]</code>.</p>
<p>Args:
  input: 4-D with shape <code>[batch, in_height, in_width, in_channels]</code>.
  filter: 4-D with shape
    <code>[filter_height, filter_width, in_channels, channel_multiplier]</code>.
  strides: 1-D of size 4.  The stride of the sliding window for each
    dimension of <code>input</code>.
  padding: A string, either <code>'VALID'</code> or <code>'SAME'</code>.  The padding algorithm.
    See the <a href="https://www.tensorflow.org/api_docs/python/nn.html#convolution">comment here</a>
  name: A name for this operation (optional).</p>
<p>Returns:
  A 4-D <code>Tensor</code> of shape
  <code>[batch, out_height, out_width, in_channels * channel_multiplier].</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.depthwise_conv2d_layer">
    <p>def <span class="ident">depthwise_conv2d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.depthwise_conv2d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.depthwise_conv2d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.depthwise_conv2d_layer</strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.depthwise_conv2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.depthwise_conv2d</strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d(input, filter, strides, padding, name=None):
</pre></div>


<p>Depthwise 2-D convolution.</p>
<p>Given an input tensor of shape <code>[batch, in_height, in_width, in_channels]</code>
and a filter tensor of shape
<code>[filter_height, filter_width, in_channels, channel_multiplier]</code>
containing <code>in_channels</code> convolutional filters of depth 1, <code>depthwise_conv2d</code>
applies a different filter to each input channel (expanding from 1 channel
to <code>channel_multiplier</code> channels for each), then concatenates the results
together.  The output has <code>in_channels * channel_multiplier</code> channels.</p>
<p>In detail,</p>
<div class="codehilite"><pre><span></span>output[b, i, j, k * channel_multiplier + q] =
    sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
                 filter[di, dj, k, q]
</pre></div>


<p>Must have <code>strides[0] = strides[3] = 1</code>.  For the most common case of the
same horizontal and vertical strides, <code>strides = [1, stride, stride, 1]</code>.</p>
<p>Args:
  input: 4-D with shape <code>[batch, in_height, in_width, in_channels]</code>.
  filter: 4-D with shape
    <code>[filter_height, filter_width, in_channels, channel_multiplier]</code>.
  strides: 1-D of size 4.  The stride of the sliding window for each
    dimension of <code>input</code>.
  padding: A string, either <code>'VALID'</code> or <code>'SAME'</code>.  The padding algorithm.
    See the <a href="https://www.tensorflow.org/api_docs/python/nn.html#convolution">comment here</a>
  name: A name for this operation (optional).</p>
<p>Returns:
  A 4-D <code>Tensor</code> of shape
  <code>[batch, out_height, out_width, in_channels * channel_multiplier].</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native">
    <p>def <span class="ident">depthwise_conv2d_native</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.depthwise_conv2d_native, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.depthwise_conv2d_native</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.depthwise_conv2d_native</strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d_native(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.depthwise_conv2d_native</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.depthwise_conv2d_native</code></strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d_native(input, filter, strides, padding, name=None)
</pre></div>


<p>Computes a 2-D depthwise convolution given 4-D <code>input</code> and <code>filter</code> tensors.</p>
<p>Given an input tensor of shape <code>[batch, in_height, in_width, in_channels]</code>
and a filter / kernel tensor of shape
<code>[filter_height, filter_width, in_channels, channel_multiplier]</code>, containing
<code>in_channels</code> convolutional filters of depth 1, <code>depthwise_conv2d</code> applies
a different filter to each input channel (expanding from 1 channel to
<code>channel_multiplier</code> channels for each), then concatenates the results
together. Thus, the output has <code>in_channels * channel_multiplier</code> channels.</p>
<p>for k in 0..in_channels-1
  for q in 0..channel_multiplier-1
    output[b, i, j, k * channel_multiplier + q] =
      sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
                        filter[di, dj, k, q]</p>
<p>Must have <code>strides[0] = strides[3] = 1</code>.  For the most common case of the same
horizontal and vertices strides, <code>strides = [1, stride, stride, 1]</code>.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
  strides: A list of <code>ints</code>.
    1-D of length 4.  The stride of the sliding window for each dimension
    of <code>input</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_filter">
    <p>def <span class="ident">depthwise_conv2d_native_backprop_filter</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.depthwise_conv2d_native_backprop_filter, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.depthwise_conv2d_native_backprop_filter</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.depthwise_conv2d_native_backprop_filter</strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d_native_backprop_filter(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.depthwise_conv2d_native_backprop_filter</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.depthwise_conv2d_native_backprop_filter</code></strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d_native_backprop_filter(input, filter_sizes, out_backprop, strides, padding, name=None)
</pre></div>


<p>Computes the gradients of depthwise convolution with respect to the filter.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    4-D with shape <code>[batch, in_height, in_width, in_channels]</code>.
  filter_sizes: A <code>Tensor</code> of type <code>int32</code>.
    An integer vector representing the tensor shape of <code>filter</code>,
    where <code>filter</code> is a 4-D
    <code>[filter_height, filter_width, in_channels, depthwise_multiplier]</code> tensor.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    4-D with shape <code>[batch, out_height, out_width, out_channels]</code>.
    Gradients w.r.t. the output of the convolution.
  strides: A list of <code>ints</code>.
    The stride of the sliding window for each dimension of the input
    of the convolution.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. 4-D with shape
  <code>[filter_height, filter_width, in_channels, out_channels]</code>.  Gradient w.r.t.
  the <code>filter</code> input of the convolution.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_filter', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_filter" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_filter_layer">
    <p>def <span class="ident">depthwise_conv2d_native_backprop_filter_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.depthwise_conv2d_native_backprop_filter_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.depthwise_conv2d_native_backprop_filter_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.depthwise_conv2d_native_backprop_filter_layer</strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d_native_backprop_filter_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.depthwise_conv2d_native_backprop_filter, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.depthwise_conv2d_native_backprop_filter</strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d_native_backprop_filter(input, filter_sizes, out_backprop, strides, padding, name=None):
</pre></div>


<p>Computes the gradients of depthwise convolution with respect to the filter.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    4-D with shape <code>[batch, in_height, in_width, in_channels]</code>.
  filter_sizes: A <code>Tensor</code> of type <code>int32</code>.
    An integer vector representing the tensor shape of <code>filter</code>,
    where <code>filter</code> is a 4-D
    <code>[filter_height, filter_width, in_channels, depthwise_multiplier]</code> tensor.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    4-D with shape <code>[batch, out_height, out_width, out_channels]</code>.
    Gradients w.r.t. the output of the convolution.
  strides: A list of <code>ints</code>.
    The stride of the sliding window for each dimension of the input
    of the convolution.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. 4-D with shape
  <code>[filter_height, filter_width, in_channels, out_channels]</code>.  Gradient w.r.t.
  the <code>filter</code> input of the convolution.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_filter_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_filter_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_input">
    <p>def <span class="ident">depthwise_conv2d_native_backprop_input</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.depthwise_conv2d_native_backprop_input, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.depthwise_conv2d_native_backprop_input</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.depthwise_conv2d_native_backprop_input</strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d_native_backprop_input(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.depthwise_conv2d_native_backprop_input</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.depthwise_conv2d_native_backprop_input</code></strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d_native_backprop_input(input_sizes, filter, out_backprop, strides, padding, name=None)
</pre></div>


<p>Computes the gradients of depthwise convolution with respect to the input.</p>
<p>Args:
  input_sizes: A <code>Tensor</code> of type <code>int32</code>.
    An integer vector representing the shape of <code>input</code>,
    where <code>input</code> is a 4-D <code>[batch, height, width, channels]</code> tensor.
  filter: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    4-D with shape
    <code>[filter_height, filter_width, in_channels, depthwise_multiplier]</code>.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>filter</code>.
    4-D with shape <code>[batch, out_height, out_width, out_channels]</code>.
    Gradients w.r.t. the output of the convolution.
  strides: A list of <code>ints</code>.
    The stride of the sliding window for each dimension of the input
    of the convolution.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>filter</code>.
  4-D with shape <code>[batch, in_height, in_width, in_channels]</code>.  Gradient
  w.r.t. the input of the convolution.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_input', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_input" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_input_layer">
    <p>def <span class="ident">depthwise_conv2d_native_backprop_input_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.depthwise_conv2d_native_backprop_input_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.depthwise_conv2d_native_backprop_input_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.depthwise_conv2d_native_backprop_input_layer</strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d_native_backprop_input_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.depthwise_conv2d_native_backprop_input, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.depthwise_conv2d_native_backprop_input</strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d_native_backprop_input(input_sizes, filter, out_backprop, strides, padding, name=None):
</pre></div>


<p>Computes the gradients of depthwise convolution with respect to the input.</p>
<p>Args:
  input_sizes: A <code>Tensor</code> of type <code>int32</code>.
    An integer vector representing the shape of <code>input</code>,
    where <code>input</code> is a 4-D <code>[batch, height, width, channels]</code> tensor.
  filter: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    4-D with shape
    <code>[filter_height, filter_width, in_channels, depthwise_multiplier]</code>.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>filter</code>.
    4-D with shape <code>[batch, out_height, out_width, out_channels]</code>.
    Gradients w.r.t. the output of the convolution.
  strides: A list of <code>ints</code>.
    The stride of the sliding window for each dimension of the input
    of the convolution.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>filter</code>.
  4-D with shape <code>[batch, in_height, in_width, in_channels]</code>.  Gradient
  w.r.t. the input of the convolution.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_input_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_backprop_input_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_layer">
    <p>def <span class="ident">depthwise_conv2d_native_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.depthwise_conv2d_native_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.depthwise_conv2d_native_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.depthwise_conv2d_native_layer</strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d_native_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.depthwise_conv2d_native, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.depthwise_conv2d_native</strong></p>
<div class="codehilite"><pre><span></span>def depthwise_conv2d_native(input, filter, strides, padding, name=None):
</pre></div>


<p>Computes a 2-D depthwise convolution given 4-D <code>input</code> and <code>filter</code> tensors.</p>
<p>Given an input tensor of shape <code>[batch, in_height, in_width, in_channels]</code>
and a filter / kernel tensor of shape
<code>[filter_height, filter_width, in_channels, channel_multiplier]</code>, containing
<code>in_channels</code> convolutional filters of depth 1, <code>depthwise_conv2d</code> applies
a different filter to each input channel (expanding from 1 channel to
<code>channel_multiplier</code> channels for each), then concatenates the results
together. Thus, the output has <code>in_channels * channel_multiplier</code> channels.</p>
<p>for k in 0..in_channels-1
  for q in 0..channel_multiplier-1
    output[b, i, j, k * channel_multiplier + q] =
      sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *
                        filter[di, dj, k, q]</p>
<p>Must have <code>strides[0] = strides[3] = 1</code>.  For the most common case of the same
horizontal and vertices strides, <code>strides = [1, stride, stride, 1]</code>.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
  strides: A list of <code>ints</code>.
    1-D of length 4.  The stride of the sliding window for each dimension
    of <code>input</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.depthwise_conv2d_native_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.deserialize_many_sparse">
    <p>def <span class="ident">deserialize_many_sparse</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.deserialize_many_sparse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.deserialize_many_sparse</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.deserialize_many_sparse</strong></p>
<div class="codehilite"><pre><span></span>def deserialize_many_sparse(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.deserialize_many_sparse</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.deserialize_many_sparse</code></strong></p>
<div class="codehilite"><pre><span></span>def deserialize_many_sparse(serialized_sparse, dtype, rank=None, name=None)
</pre></div>


<p>Deserialize and concatenate <code>SparseTensors</code> from a serialized minibatch.</p>
<p>The input <code>serialized_sparse</code> must be a string matrix of shape <code>[N x 3]</code> where
<code>N</code> is the minibatch size and the rows correspond to packed outputs of
<code>serialize_sparse</code>.  The ranks of the original <code>SparseTensor</code> objects
must all match.  When the final <code>SparseTensor</code> is created, it has rank one
higher than the ranks of the incoming <code>SparseTensor</code> objects (they have been
concatenated along a new row dimension).</p>
<p>The output <code>SparseTensor</code> object's shape values for all dimensions but the
first are the max across the input <code>SparseTensor</code> objects' shape values
for the corresponding dimensions.  Its first shape value is <code>N</code>, the minibatch
size.</p>
<p>The input <code>SparseTensor</code> objects' indices are assumed ordered in
standard lexicographic order.  If this is not the case, after this
step run <code>sparse_reorder</code> to restore index ordering.</p>
<p>For example, if the serialized input is a <code>[2, 3]</code> matrix representing two
original <code>SparseTensor</code> objects:</p>
<div class="codehilite"><pre><span></span>index = [ 0]
        [10]
        [20]
values = [1, 2, 3]
shape = [50]
</pre></div>


<p>and</p>
<div class="codehilite"><pre><span></span>index = [ 2]
        [10]
values = [4, 5]
shape = [30]
</pre></div>


<p>then the final deserialized <code>SparseTensor</code> will be:</p>
<div class="codehilite"><pre><span></span>index = [0  0]
        [0 10]
        [0 20]
        [1  2]
        [1 10]
values = [1, 2, 3, 4, 5]
shape = [2 50]
</pre></div>


<p>Args:
  serialized_sparse: 2-D <code>Tensor</code> of type <code>string</code> of shape <code>[N, 3]</code>.
    The serialized and packed <code>SparseTensor</code> objects.
  dtype: The <code>dtype</code> of the serialized <code>SparseTensor</code> objects.
  rank: (optional) Python int, the rank of the <code>SparseTensor</code> objects.
  name: A name prefix for the returned tensors (optional)</p>
<p>Returns:
  A <code>SparseTensor</code> representing the deserialized <code>SparseTensor</code>s,
  concatenated along the <code>SparseTensor</code>s' first dimension.</p>
<p>All of the serialized <code>SparseTensor</code>s must have had the same rank and type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.deserialize_many_sparse', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.deserialize_many_sparse" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.deserialize_many_sparse_layer">
    <p>def <span class="ident">deserialize_many_sparse_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.deserialize_many_sparse_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.deserialize_many_sparse_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.deserialize_many_sparse_layer</strong></p>
<div class="codehilite"><pre><span></span>def deserialize_many_sparse_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.deserialize_many_sparse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.deserialize_many_sparse</strong></p>
<div class="codehilite"><pre><span></span>def deserialize_many_sparse(serialized_sparse, dtype, rank=None, name=None):
</pre></div>


<p>Deserialize and concatenate <code>SparseTensors</code> from a serialized minibatch.</p>
<p>The input <code>serialized_sparse</code> must be a string matrix of shape <code>[N x 3]</code> where
<code>N</code> is the minibatch size and the rows correspond to packed outputs of
<code>serialize_sparse</code>.  The ranks of the original <code>SparseTensor</code> objects
must all match.  When the final <code>SparseTensor</code> is created, it has rank one
higher than the ranks of the incoming <code>SparseTensor</code> objects (they have been
concatenated along a new row dimension).</p>
<p>The output <code>SparseTensor</code> object's shape values for all dimensions but the
first are the max across the input <code>SparseTensor</code> objects' shape values
for the corresponding dimensions.  Its first shape value is <code>N</code>, the minibatch
size.</p>
<p>The input <code>SparseTensor</code> objects' indices are assumed ordered in
standard lexicographic order.  If this is not the case, after this
step run <code>sparse_reorder</code> to restore index ordering.</p>
<p>For example, if the serialized input is a <code>[2, 3]</code> matrix representing two
original <code>SparseTensor</code> objects:</p>
<div class="codehilite"><pre><span></span>index = [ 0]
        [10]
        [20]
values = [1, 2, 3]
shape = [50]
</pre></div>


<p>and</p>
<div class="codehilite"><pre><span></span>index = [ 2]
        [10]
values = [4, 5]
shape = [30]
</pre></div>


<p>then the final deserialized <code>SparseTensor</code> will be:</p>
<div class="codehilite"><pre><span></span>index = [0  0]
        [0 10]
        [0 20]
        [1  2]
        [1 10]
values = [1, 2, 3, 4, 5]
shape = [2 50]
</pre></div>


<p>Args:
  serialized_sparse: 2-D <code>Tensor</code> of type <code>string</code> of shape <code>[N, 3]</code>.
    The serialized and packed <code>SparseTensor</code> objects.
  dtype: The <code>dtype</code> of the serialized <code>SparseTensor</code> objects.
  rank: (optional) Python int, the rank of the <code>SparseTensor</code> objects.
  name: A name prefix for the returned tensors (optional)</p>
<p>Returns:
  A <code>SparseTensor</code> representing the deserialized <code>SparseTensor</code>s,
  concatenated along the <code>SparseTensor</code>s' first dimension.</p>
<p>All of the serialized <code>SparseTensor</code>s must have had the same rank and type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.deserialize_many_sparse_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.deserialize_many_sparse_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.diag">
    <p>def <span class="ident">diag</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.diag, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.diag</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.diag</strong></p>
<div class="codehilite"><pre><span></span>def diag(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.diag</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.diag</code></strong></p>
<div class="codehilite"><pre><span></span>def diag(diagonal, name=None)
</pre></div>


<p>Returns a diagonal tensor with a given diagonal values.</p>
<p>Given a <code>diagonal</code>, this operation returns a tensor with the <code>diagonal</code> and
everything else padded with zeros. The diagonal is computed as follows:</p>
<p>Assume <code>diagonal</code> has dimensions [D1,..., Dk], then the output is a tensor of
rank 2k with dimensions [D1,..., Dk, D1,..., Dk] where:</p>
<p><code>output[i1,..., ik, i1,..., ik] = diagonal[i1, ..., ik]</code> and 0 everywhere else.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'diagonal' is [1, 2, 3, 4]</h1>
<p>tf.diag(diagonal) ==&gt; [[1, 0, 0, 0]
                       [0, 2, 0, 0]
                       [0, 0, 3, 0]
                       [0, 0, 0, 4]]
```</p>
<p>Args:
  diagonal: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>.
    Rank k tensor where k is at most 3.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>diagonal</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.diag', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.diag" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.diag_layer">
    <p>def <span class="ident">diag_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.diag_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.diag_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.diag_layer</strong></p>
<div class="codehilite"><pre><span></span>def diag_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.diag, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.diag</strong></p>
<div class="codehilite"><pre><span></span>def diag(diagonal, name=None):
</pre></div>


<p>Returns a diagonal tensor with a given diagonal values.</p>
<p>Given a <code>diagonal</code>, this operation returns a tensor with the <code>diagonal</code> and
everything else padded with zeros. The diagonal is computed as follows:</p>
<p>Assume <code>diagonal</code> has dimensions [D1,..., Dk], then the output is a tensor of
rank 2k with dimensions [D1,..., Dk, D1,..., Dk] where:</p>
<p><code>output[i1,..., ik, i1,..., ik] = diagonal[i1, ..., ik]</code> and 0 everywhere else.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'diagonal' is [1, 2, 3, 4]</h1>
<p>tf.diag(diagonal) ==&gt; [[1, 0, 0, 0]
                       [0, 2, 0, 0]
                       [0, 0, 3, 0]
                       [0, 0, 0, 4]]
```</p>
<p>Args:
  diagonal: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>.
    Rank k tensor where k is at most 3.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>diagonal</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.diag_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.diag_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.diag_part">
    <p>def <span class="ident">diag_part</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.diag_part, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.diag_part</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.diag_part</strong></p>
<div class="codehilite"><pre><span></span>def diag_part(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.diag_part</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.diag_part</code></strong></p>
<div class="codehilite"><pre><span></span>def diag_part(input, name=None)
</pre></div>


<p>Returns the diagonal part of the tensor.</p>
<p>This operation returns a tensor with the <code>diagonal</code> part
of the <code>input</code>. The <code>diagonal</code> part is computed as follows:</p>
<p>Assume <code>input</code> has dimensions <code>[D1,..., Dk, D1,..., Dk]</code>, then the output is a
tensor of rank <code>k</code> with dimensions <code>[D1,..., Dk]</code> where:</p>
<p><code>diagonal[i1,..., ik] = input[i1, ..., ik, i1,..., ik]</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'input' is [[1, 0, 0, 0]</h1>
<div class="codehilite"><pre><span></span>          [0, 2, 0, 0]
          [0, 0, 3, 0]
          [0, 0, 0, 4]]
</pre></div>


<p>tf.diag_part(input) ==&gt; [1, 2, 3, 4]
```</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>.
    Rank k tensor where k is 2, 4, or 6.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. The extracted diagonal.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.diag_part', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.diag_part" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.diag_part_layer">
    <p>def <span class="ident">diag_part_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.diag_part_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.diag_part_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.diag_part_layer</strong></p>
<div class="codehilite"><pre><span></span>def diag_part_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.diag_part, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.diag_part</strong></p>
<div class="codehilite"><pre><span></span>def diag_part(input, name=None):
</pre></div>


<p>Returns the diagonal part of the tensor.</p>
<p>This operation returns a tensor with the <code>diagonal</code> part
of the <code>input</code>. The <code>diagonal</code> part is computed as follows:</p>
<p>Assume <code>input</code> has dimensions <code>[D1,..., Dk, D1,..., Dk]</code>, then the output is a
tensor of rank <code>k</code> with dimensions <code>[D1,..., Dk]</code> where:</p>
<p><code>diagonal[i1,..., ik] = input[i1, ..., ik, i1,..., ik]</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'input' is [[1, 0, 0, 0]</h1>
<div class="codehilite"><pre><span></span>          [0, 2, 0, 0]
          [0, 0, 3, 0]
          [0, 0, 0, 4]]
</pre></div>


<p>tf.diag_part(input) ==&gt; [1, 2, 3, 4]
```</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>.
    Rank k tensor where k is 2, 4, or 6.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. The extracted diagonal.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.diag_part_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.diag_part_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.digamma">
    <p>def <span class="ident">digamma</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.digamma, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.digamma</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.digamma</strong></p>
<div class="codehilite"><pre><span></span>def digamma(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.digamma</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.digamma</code></strong></p>
<div class="codehilite"><pre><span></span>def digamma(x, name=None)
</pre></div>


<p>Computes Psi, the derivative of Lgamma (the log of the absolute value of</p>
<p><code>Gamma(x)</code>), element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.digamma', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.digamma" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.digamma_layer">
    <p>def <span class="ident">digamma_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.digamma_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.digamma_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.digamma_layer</strong></p>
<div class="codehilite"><pre><span></span>def digamma_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.digamma, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.digamma</strong></p>
<div class="codehilite"><pre><span></span>def digamma(x, name=None):
</pre></div>


<p>Computes Psi, the derivative of Lgamma (the log of the absolute value of</p>
<p><code>Gamma(x)</code>), element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.digamma_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.digamma_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dilation2d">
    <p>def <span class="ident">dilation2d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dilation2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dilation2d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dilation2d</strong></p>
<div class="codehilite"><pre><span></span>def dilation2d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.dilation2d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.dilation2d</code></strong></p>
<div class="codehilite"><pre><span></span>def dilation2d(input, filter, strides, rates, padding, name=None)
</pre></div>


<p>Computes the grayscale dilation of 4-D <code>input</code> and 3-D <code>filter</code> tensors.</p>
<p>The <code>input</code> tensor has shape <code>[batch, in_height, in_width, depth]</code> and the
<code>filter</code> tensor has shape <code>[filter_height, filter_width, depth]</code>, i.e., each
input channel is processed independently of the others with its own structuring
function. The <code>output</code> tensor has shape
<code>[batch, out_height, out_width, depth]</code>. The spatial dimensions of the output
tensor depend on the <code>padding</code> algorithm. We currently only support the default
"NHWC" <code>data_format</code>.</p>
<p>In detail, the grayscale morphological 2-D dilation is the max-sum correlation
(for consistency with <code>conv2d</code>, we use unmirrored filters):</p>
<div class="codehilite"><pre><span></span>output[b, y, x, c] =
   max_{dy, dx} input[b,
                      strides[1] * y + rates[1] * dy,
                      strides[2] * x + rates[2] * dx,
                      c] +
                filter[dy, dx, c]
</pre></div>


<p>Max-pooling is a special case when the filter has size equal to the pooling
kernel size and contains all zeros.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
  rates: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dilation2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dilation2d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dilation2d_backprop_filter">
    <p>def <span class="ident">dilation2d_backprop_filter</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dilation2d_backprop_filter, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dilation2d_backprop_filter</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dilation2d_backprop_filter</strong></p>
<div class="codehilite"><pre><span></span>def dilation2d_backprop_filter(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.dilation2d_backprop_filter</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.dilation2d_backprop_filter</code></strong></p>
<div class="codehilite"><pre><span></span>def dilation2d_backprop_filter(input, filter, out_backprop, strides, rates, padding, name=None)
</pre></div>


<p>Computes the gradient of morphological 2-D dilation with respect to the filter.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
    4-D with shape <code>[batch, in_height, in_width, depth]</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    3-D with shape <code>[filter_height, filter_width, depth]</code>.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    4-D with shape <code>[batch, out_height, out_width, depth]</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    1-D of length 4. The stride of the sliding window for each dimension of
    the input tensor. Must be: <code>[1, stride_height, stride_width, 1]</code>.
  rates: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    1-D of length 4. The input stride for atrous morphological dilation.
    Must be: <code>[1, rate_height, rate_width, 1]</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  3-D with shape <code>[filter_height, filter_width, depth]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dilation2d_backprop_filter', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dilation2d_backprop_filter" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dilation2d_backprop_filter_layer">
    <p>def <span class="ident">dilation2d_backprop_filter_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dilation2d_backprop_filter_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dilation2d_backprop_filter_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dilation2d_backprop_filter_layer</strong></p>
<div class="codehilite"><pre><span></span>def dilation2d_backprop_filter_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.dilation2d_backprop_filter, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.dilation2d_backprop_filter</strong></p>
<div class="codehilite"><pre><span></span>def dilation2d_backprop_filter(input, filter, out_backprop, strides, rates, padding, name=None):
</pre></div>


<p>Computes the gradient of morphological 2-D dilation with respect to the filter.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
    4-D with shape <code>[batch, in_height, in_width, depth]</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    3-D with shape <code>[filter_height, filter_width, depth]</code>.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    4-D with shape <code>[batch, out_height, out_width, depth]</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    1-D of length 4. The stride of the sliding window for each dimension of
    the input tensor. Must be: <code>[1, stride_height, stride_width, 1]</code>.
  rates: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    1-D of length 4. The input stride for atrous morphological dilation.
    Must be: <code>[1, rate_height, rate_width, 1]</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  3-D with shape <code>[filter_height, filter_width, depth]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dilation2d_backprop_filter_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dilation2d_backprop_filter_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dilation2d_backprop_input">
    <p>def <span class="ident">dilation2d_backprop_input</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dilation2d_backprop_input, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dilation2d_backprop_input</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dilation2d_backprop_input</strong></p>
<div class="codehilite"><pre><span></span>def dilation2d_backprop_input(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.dilation2d_backprop_input</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.dilation2d_backprop_input</code></strong></p>
<div class="codehilite"><pre><span></span>def dilation2d_backprop_input(input, filter, out_backprop, strides, rates, padding, name=None)
</pre></div>


<p>Computes the gradient of morphological 2-D dilation with respect to the input.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
    4-D with shape <code>[batch, in_height, in_width, depth]</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    3-D with shape <code>[filter_height, filter_width, depth]</code>.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    4-D with shape <code>[batch, out_height, out_width, depth]</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    1-D of length 4. The stride of the sliding window for each dimension of
    the input tensor. Must be: <code>[1, stride_height, stride_width, 1]</code>.
  rates: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    1-D of length 4. The input stride for atrous morphological dilation.
    Must be: <code>[1, rate_height, rate_width, 1]</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  4-D with shape <code>[batch, in_height, in_width, depth]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dilation2d_backprop_input', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dilation2d_backprop_input" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dilation2d_backprop_input_layer">
    <p>def <span class="ident">dilation2d_backprop_input_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dilation2d_backprop_input_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dilation2d_backprop_input_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dilation2d_backprop_input_layer</strong></p>
<div class="codehilite"><pre><span></span>def dilation2d_backprop_input_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.dilation2d_backprop_input, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.dilation2d_backprop_input</strong></p>
<div class="codehilite"><pre><span></span>def dilation2d_backprop_input(input, filter, out_backprop, strides, rates, padding, name=None):
</pre></div>


<p>Computes the gradient of morphological 2-D dilation with respect to the input.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
    4-D with shape <code>[batch, in_height, in_width, depth]</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    3-D with shape <code>[filter_height, filter_width, depth]</code>.
  out_backprop: A <code>Tensor</code>. Must have the same type as <code>input</code>.
    4-D with shape <code>[batch, out_height, out_width, depth]</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    1-D of length 4. The stride of the sliding window for each dimension of
    the input tensor. Must be: <code>[1, stride_height, stride_width, 1]</code>.
  rates: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    1-D of length 4. The input stride for atrous morphological dilation.
    Must be: <code>[1, rate_height, rate_width, 1]</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  4-D with shape <code>[batch, in_height, in_width, depth]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dilation2d_backprop_input_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dilation2d_backprop_input_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dilation2d_layer">
    <p>def <span class="ident">dilation2d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dilation2d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dilation2d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dilation2d_layer</strong></p>
<div class="codehilite"><pre><span></span>def dilation2d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.dilation2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.dilation2d</strong></p>
<div class="codehilite"><pre><span></span>def dilation2d(input, filter, strides, rates, padding, name=None):
</pre></div>


<p>Computes the grayscale dilation of 4-D <code>input</code> and 3-D <code>filter</code> tensors.</p>
<p>The <code>input</code> tensor has shape <code>[batch, in_height, in_width, depth]</code> and the
<code>filter</code> tensor has shape <code>[filter_height, filter_width, depth]</code>, i.e., each
input channel is processed independently of the others with its own structuring
function. The <code>output</code> tensor has shape
<code>[batch, out_height, out_width, depth]</code>. The spatial dimensions of the output
tensor depend on the <code>padding</code> algorithm. We currently only support the default
"NHWC" <code>data_format</code>.</p>
<p>In detail, the grayscale morphological 2-D dilation is the max-sum correlation
(for consistency with <code>conv2d</code>, we use unmirrored filters):</p>
<div class="codehilite"><pre><span></span>output[b, y, x, c] =
   max_{dy, dx} input[b,
                      strides[1] * y + rates[1] * dy,
                      strides[2] * x + rates[2] * dx,
                      c] +
                filter[dy, dx, c]
</pre></div>


<p>Max-pooling is a special case when the filter has size equal to the pooling
kernel size and contains all zeros.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  filter: A <code>Tensor</code>. Must have the same type as <code>input</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
  rates: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dilation2d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dilation2d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.div">
    <p>def <span class="ident">div</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.div, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.div</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.div</strong></p>
<div class="codehilite"><pre><span></span>def div(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.div</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.div</code></strong></p>
<div class="codehilite"><pre><span></span>def div(x, y, name=None)
</pre></div>


<p>Returns x / y element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.div', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.div" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.div_layer">
    <p>def <span class="ident">div_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.div_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.div_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.div_layer</strong></p>
<div class="codehilite"><pre><span></span>def div_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.div, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.div</strong></p>
<div class="codehilite"><pre><span></span>def div(x, y, name=None):
</pre></div>


<p>Returns x / y element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.div_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.div_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dropout">
    <p>def <span class="ident">dropout</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dropout, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dropout</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dropout</strong></p>
<div class="codehilite"><pre><span></span>def dropout(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.dropout</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.dropout</code></strong></p>
<div class="codehilite"><pre><span></span>def dropout(x, keep_prob, noise_shape=None, seed=None, name=None)
</pre></div>


<p>Computes dropout.</p>
<p>With probability <code>keep_prob</code>, outputs the input element scaled up by
<code>1 / keep_prob</code>, otherwise outputs <code>0</code>.  The scaling is so that the expected
sum is unchanged.</p>
<p>By default, each element is kept or dropped independently.  If <code>noise_shape</code>
is specified, it must be
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">broadcastable</a>
to the shape of <code>x</code>, and only dimensions with <code>noise_shape[i] == shape(x)[i]</code>
will make independent decisions.  For example, if <code>shape(x) = [k, l, m, n]</code>
and <code>noise_shape = [k, 1, 1, n]</code>, each batch and channel component will be
kept independently and each row and column will be kept or not kept together.</p>
<p>Args:
  x: A tensor.
  keep_prob: A scalar <code>Tensor</code> with the same type as x. The probability
    that each element is kept.
  noise_shape: A 1-D <code>Tensor</code> of type <code>int32</code>, representing the
    shape for randomly generated keep/drop flags.
  seed: A Python integer. Used to create random seeds. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: A name for this operation (optional).</p>
<p>Returns:
  A Tensor of the same shape of <code>x</code>.</p>
<p>Raises:
  ValueError: If <code>keep_prob</code> is not in <code>(0, 1]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dropout', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dropout" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dropout_layer">
    <p>def <span class="ident">dropout_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dropout_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dropout_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dropout_layer</strong></p>
<div class="codehilite"><pre><span></span>def dropout_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.dropout, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.dropout</strong></p>
<div class="codehilite"><pre><span></span>def dropout(x, keep_prob, noise_shape=None, seed=None, name=None):
</pre></div>


<p>Computes dropout.</p>
<p>With probability <code>keep_prob</code>, outputs the input element scaled up by
<code>1 / keep_prob</code>, otherwise outputs <code>0</code>.  The scaling is so that the expected
sum is unchanged.</p>
<p>By default, each element is kept or dropped independently.  If <code>noise_shape</code>
is specified, it must be
<a href="http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html">broadcastable</a>
to the shape of <code>x</code>, and only dimensions with <code>noise_shape[i] == shape(x)[i]</code>
will make independent decisions.  For example, if <code>shape(x) = [k, l, m, n]</code>
and <code>noise_shape = [k, 1, 1, n]</code>, each batch and channel component will be
kept independently and each row and column will be kept or not kept together.</p>
<p>Args:
  x: A tensor.
  keep_prob: A scalar <code>Tensor</code> with the same type as x. The probability
    that each element is kept.
  noise_shape: A 1-D <code>Tensor</code> of type <code>int32</code>, representing the
    shape for randomly generated keep/drop flags.
  seed: A Python integer. Used to create random seeds. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: A name for this operation (optional).</p>
<p>Returns:
  A Tensor of the same shape of <code>x</code>.</p>
<p>Raises:
  ValueError: If <code>keep_prob</code> is not in <code>(0, 1]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dropout_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dropout_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dynamic_partition">
    <p>def <span class="ident">dynamic_partition</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dynamic_partition, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dynamic_partition</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dynamic_partition</strong></p>
<div class="codehilite"><pre><span></span>def dynamic_partition(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.dynamic_partition</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.dynamic_partition</code></strong></p>
<div class="codehilite"><pre><span></span>def dynamic_partition(data, partitions, num_partitions, name=None)
</pre></div>


<p>Partitions <code>data</code> into <code>num_partitions</code> tensors using indices from <code>partitions</code>.</p>
<p>For each index tuple <code>js</code> of size <code>partitions.ndim</code>, the slice <code>data[js, ...]</code>
becomes part of <code>outputs[partitions[js]]</code>.  The slices with <code>partitions[js] = i</code>
are placed in <code>outputs[i]</code> in lexicographic order of <code>js</code>, and the first
dimension of <code>outputs[i]</code> is the number of entries in <code>partitions</code> equal to <code>i</code>.
In detail,</p>
<div class="codehilite"><pre><span></span>outputs[i].shape = [sum(partitions == i)] + data.shape[partitions.ndim:]

outputs[i] = pack([data[js, ...] for js if partitions[js] == i])
</pre></div>


<p><code>data.shape</code> must start with <code>partitions.shape</code>.</p>
<p>For example:</p>
<div class="codehilite"><pre><span></span># Scalar partitions
partitions = 1
num_partitions = 2
data = [10, 20]
outputs[0] = []  # Empty with shape [0, 2]
outputs[1] = [[10, 20]]

# Vector partitions
partitions = [0, 0, 1, 1, 0]
num_partitions = 2
data = [10, 20, 30, 40, 50]
outputs[0] = [10, 20, 50]
outputs[1] = [30, 40]
</pre></div>


<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/DynamicPartition.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>.
  partitions: A <code>Tensor</code> of type <code>int32</code>.
    Any shape.  Indices in the range <code>[0, num_partitions)</code>.
  num_partitions: An <code>int</code> that is <code>&gt;= 1</code>.
    The number of partitions to output.
  name: A name for the operation (optional).</p>
<p>Returns:
  A list of <code>num_partitions</code> <code>Tensor</code> objects of the same type as data.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dynamic_partition', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dynamic_partition" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dynamic_partition_layer">
    <p>def <span class="ident">dynamic_partition_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dynamic_partition_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dynamic_partition_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dynamic_partition_layer</strong></p>
<div class="codehilite"><pre><span></span>def dynamic_partition_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.dynamic_partition, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.dynamic_partition</strong></p>
<div class="codehilite"><pre><span></span>def dynamic_partition(data, partitions, num_partitions, name=None):
</pre></div>


<p>Partitions <code>data</code> into <code>num_partitions</code> tensors using indices from <code>partitions</code>.</p>
<p>For each index tuple <code>js</code> of size <code>partitions.ndim</code>, the slice <code>data[js, ...]</code>
becomes part of <code>outputs[partitions[js]]</code>.  The slices with <code>partitions[js] = i</code>
are placed in <code>outputs[i]</code> in lexicographic order of <code>js</code>, and the first
dimension of <code>outputs[i]</code> is the number of entries in <code>partitions</code> equal to <code>i</code>.
In detail,</p>
<div class="codehilite"><pre><span></span>outputs[i].shape = [sum(partitions == i)] + data.shape[partitions.ndim:]

outputs[i] = pack([data[js, ...] for js if partitions[js] == i])
</pre></div>


<p><code>data.shape</code> must start with <code>partitions.shape</code>.</p>
<p>For example:</p>
<div class="codehilite"><pre><span></span># Scalar partitions
partitions = 1
num_partitions = 2
data = [10, 20]
outputs[0] = []  # Empty with shape [0, 2]
outputs[1] = [[10, 20]]

# Vector partitions
partitions = [0, 0, 1, 1, 0]
num_partitions = 2
data = [10, 20, 30, 40, 50]
outputs[0] = [10, 20, 50]
outputs[1] = [30, 40]
</pre></div>


<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/DynamicPartition.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>.
  partitions: A <code>Tensor</code> of type <code>int32</code>.
    Any shape.  Indices in the range <code>[0, num_partitions)</code>.
  num_partitions: An <code>int</code> that is <code>&gt;= 1</code>.
    The number of partitions to output.
  name: A name for the operation (optional).</p>
<p>Returns:
  A list of <code>num_partitions</code> <code>Tensor</code> objects of the same type as data.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dynamic_partition_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dynamic_partition_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dynamic_rnn">
    <p>def <span class="ident">dynamic_rnn</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dynamic_rnn, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dynamic_rnn</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dynamic_rnn</strong></p>
<div class="codehilite"><pre><span></span>def dynamic_rnn(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.dynamic_rnn</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.dynamic_rnn</code></strong></p>
<div class="codehilite"><pre><span></span>def dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None, dtype=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None)
</pre></div>


<p>Creates a recurrent neural network specified by RNNCell <code>cell</code>.</p>
<p>This function is functionally identical to the function <code>rnn</code> above, but
performs fully dynamic unrolling of <code>inputs</code>.</p>
<p>Unlike <code>rnn</code>, the input <code>inputs</code> is not a Python list of <code>Tensors</code>.  Instead,
it is a single <code>Tensor</code> where the maximum time is either the first or second
dimension (see the parameter <code>time_major</code>).  The corresponding output is
a single <code>Tensor</code> having the same number of time steps and batch size.</p>
<p>The parameter <code>sequence_length</code> is required and dynamic calculation is
automatically performed.</p>
<p>Args:
  cell: An instance of RNNCell.
  inputs: The RNN inputs.
    If time_major == False (default), this must be a tensor of shape:
      <code>[batch_size, max_time, input_size]</code>.
    If time_major == True, this must be a tensor of shape:
      <code>[max_time, batch_size, input_size]</code>.
  sequence_length: (optional) An int32/int64 vector sized <code>[batch_size]</code>.
  initial_state: (optional) An initial state for the RNN.
    If <code>cell.state_size</code> is an integer, this must be
    a tensor of appropriate type and shape <code>[batch_size x cell.state_size]</code>.
    If <code>cell.state_size</code> is a tuple, this should be a tuple of
    tensors having shapes <code>[batch_size, s] for s in cell.state_size</code>.
  dtype: (optional) The data type for the initial state.  Required if
    initial_state is not provided.
  parallel_iterations: (Default: 32).  The number of iterations to run in
    parallel.  Those operations which do not have any temporal dependency
    and can be run in parallel, will be.  This parameter trades off
    time for space.  Values &gt;&gt; 1 use more memory but take less time,
    while smaller values use less memory but computations take longer.
  swap_memory: Transparently swap the tensors produced in forward inference
    but needed for back prop from GPU to CPU.  This allows training RNNs
    which would typically not fit on a single GPU, with very minimal (or no)
    performance penalty.
  time_major: The shape format of the <code>inputs</code> and <code>outputs</code> Tensors.
    If true, these <code>Tensors</code> must be shaped <code>[max_time, batch_size, depth]</code>.
    If false, these <code>Tensors</code> must be shaped <code>[batch_size, max_time, depth]</code>.
    Using <code>time_major = True</code> is a bit more efficient because it avoids
    transposes at the beginning and end of the RNN calculation.  However,
    most TensorFlow data is batch-major, so by default this function
    accepts input and emits output in batch-major form.
  scope: VariableScope for the created subgraph; defaults to "RNN".</p>
<p>Returns:
  A pair (outputs, state) where:
    outputs: The RNN output <code>Tensor</code>.
      If time_major == False (default), this will be a <code>Tensor</code> shaped:
        <code>[batch_size, max_time, cell.output_size]</code>.
      If time_major == True, this will be a <code>Tensor</code> shaped:
        <code>[max_time, batch_size, cell.output_size]</code>.
    state: The final state.  If <code>cell.state_size</code> is a <code>Tensor</code>, this
      will be shaped <code>[batch_size, cell.state_size]</code>.  If it is a tuple,
      this be a tuple with shapes <code>[batch_size, s] for s in cell.state_size</code>.</p>
<p>Raises:
  TypeError: If <code>cell</code> is not an instance of RNNCell.
  ValueError: If inputs is None or an empty list.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dynamic_rnn', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dynamic_rnn" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dynamic_rnn_layer">
    <p>def <span class="ident">dynamic_rnn_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dynamic_rnn_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dynamic_rnn_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dynamic_rnn_layer</strong></p>
<div class="codehilite"><pre><span></span>def dynamic_rnn_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.dynamic_rnn, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.dynamic_rnn</strong></p>
<div class="codehilite"><pre><span></span>def dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None, dtype=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None):
</pre></div>


<p>Creates a recurrent neural network specified by RNNCell <code>cell</code>.</p>
<p>This function is functionally identical to the function <code>rnn</code> above, but
performs fully dynamic unrolling of <code>inputs</code>.</p>
<p>Unlike <code>rnn</code>, the input <code>inputs</code> is not a Python list of <code>Tensors</code>.  Instead,
it is a single <code>Tensor</code> where the maximum time is either the first or second
dimension (see the parameter <code>time_major</code>).  The corresponding output is
a single <code>Tensor</code> having the same number of time steps and batch size.</p>
<p>The parameter <code>sequence_length</code> is required and dynamic calculation is
automatically performed.</p>
<p>Args:
  cell: An instance of RNNCell.
  inputs: The RNN inputs.
    If time_major == False (default), this must be a tensor of shape:
      <code>[batch_size, max_time, input_size]</code>.
    If time_major == True, this must be a tensor of shape:
      <code>[max_time, batch_size, input_size]</code>.
  sequence_length: (optional) An int32/int64 vector sized <code>[batch_size]</code>.
  initial_state: (optional) An initial state for the RNN.
    If <code>cell.state_size</code> is an integer, this must be
    a tensor of appropriate type and shape <code>[batch_size x cell.state_size]</code>.
    If <code>cell.state_size</code> is a tuple, this should be a tuple of
    tensors having shapes <code>[batch_size, s] for s in cell.state_size</code>.
  dtype: (optional) The data type for the initial state.  Required if
    initial_state is not provided.
  parallel_iterations: (Default: 32).  The number of iterations to run in
    parallel.  Those operations which do not have any temporal dependency
    and can be run in parallel, will be.  This parameter trades off
    time for space.  Values &gt;&gt; 1 use more memory but take less time,
    while smaller values use less memory but computations take longer.
  swap_memory: Transparently swap the tensors produced in forward inference
    but needed for back prop from GPU to CPU.  This allows training RNNs
    which would typically not fit on a single GPU, with very minimal (or no)
    performance penalty.
  time_major: The shape format of the <code>inputs</code> and <code>outputs</code> Tensors.
    If true, these <code>Tensors</code> must be shaped <code>[max_time, batch_size, depth]</code>.
    If false, these <code>Tensors</code> must be shaped <code>[batch_size, max_time, depth]</code>.
    Using <code>time_major = True</code> is a bit more efficient because it avoids
    transposes at the beginning and end of the RNN calculation.  However,
    most TensorFlow data is batch-major, so by default this function
    accepts input and emits output in batch-major form.
  scope: VariableScope for the created subgraph; defaults to "RNN".</p>
<p>Returns:
  A pair (outputs, state) where:
    outputs: The RNN output <code>Tensor</code>.
      If time_major == False (default), this will be a <code>Tensor</code> shaped:
        <code>[batch_size, max_time, cell.output_size]</code>.
      If time_major == True, this will be a <code>Tensor</code> shaped:
        <code>[max_time, batch_size, cell.output_size]</code>.
    state: The final state.  If <code>cell.state_size</code> is a <code>Tensor</code>, this
      will be shaped <code>[batch_size, cell.state_size]</code>.  If it is a tuple,
      this be a tuple with shapes <code>[batch_size, s] for s in cell.state_size</code>.</p>
<p>Raises:
  TypeError: If <code>cell</code> is not an instance of RNNCell.
  ValueError: If inputs is None or an empty list.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dynamic_rnn_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dynamic_rnn_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dynamic_stitch">
    <p>def <span class="ident">dynamic_stitch</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dynamic_stitch, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dynamic_stitch</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dynamic_stitch</strong></p>
<div class="codehilite"><pre><span></span>def dynamic_stitch(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.dynamic_stitch</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.dynamic_stitch</code></strong></p>
<div class="codehilite"><pre><span></span>def dynamic_stitch(indices, data, name=None)
</pre></div>


<p>Interleave the values from the <code>data</code> tensors into a single tensor.</p>
<p>Builds a merged tensor such that</p>
<div class="codehilite"><pre><span></span>merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]
</pre></div>


<p>For example, if each <code>indices[m]</code> is scalar or vector, we have</p>
<div class="codehilite"><pre><span></span># Scalar indices
merged[indices[m], ...] = data[m][...]

# Vector indices
merged[indices[m][i], ...] = data[m][i, ...]
</pre></div>


<p>Each <code>data[i].shape</code> must start with the corresponding <code>indices[i].shape</code>,
and the rest of <code>data[i].shape</code> must be constant w.r.t. <code>i</code>.  That is, we
must have <code>data[i].shape = indices[i].shape + constant</code>.  In terms of this
<code>constant</code>, the output shape is</p>
<div class="codehilite"><pre><span></span>merged.shape = [max(indices)] + constant
</pre></div>


<p>Values are merged in order, so if an index appears in both <code>indices[m][i]</code> and
<code>indices[n][j]</code> for <code>(m,i) &lt; (n,j)</code> the slice <code>data[n][j]</code> will appear in the
merged result.</p>
<p>For example:</p>
<div class="codehilite"><pre><span></span>indices[0] = 6
indices[1] = [4, 1]
indices[2] = [[5, 2], [0, 3]]
data[0] = [61, 62]
data[1] = [[41, 42], [11, 12]]
data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]
merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],
          [51, 52], [61, 62]]
</pre></div>


<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/DynamicStitch.png" alt>
</div>

<p>Args:
  indices: A list of at least 2 <code>Tensor</code> objects of type <code>int32</code>.
  data: A list with the same number of <code>Tensor</code> objects as <code>indices</code> of <code>Tensor</code> objects of the same type.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dynamic_stitch', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dynamic_stitch" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.dynamic_stitch_layer">
    <p>def <span class="ident">dynamic_stitch_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.dynamic_stitch_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.dynamic_stitch_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.dynamic_stitch_layer</strong></p>
<div class="codehilite"><pre><span></span>def dynamic_stitch_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.dynamic_stitch, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.dynamic_stitch</strong></p>
<div class="codehilite"><pre><span></span>def dynamic_stitch(indices, data, name=None):
</pre></div>


<p>Interleave the values from the <code>data</code> tensors into a single tensor.</p>
<p>Builds a merged tensor such that</p>
<div class="codehilite"><pre><span></span>merged[indices[m][i, ..., j], ...] = data[m][i, ..., j, ...]
</pre></div>


<p>For example, if each <code>indices[m]</code> is scalar or vector, we have</p>
<div class="codehilite"><pre><span></span># Scalar indices
merged[indices[m], ...] = data[m][...]

# Vector indices
merged[indices[m][i], ...] = data[m][i, ...]
</pre></div>


<p>Each <code>data[i].shape</code> must start with the corresponding <code>indices[i].shape</code>,
and the rest of <code>data[i].shape</code> must be constant w.r.t. <code>i</code>.  That is, we
must have <code>data[i].shape = indices[i].shape + constant</code>.  In terms of this
<code>constant</code>, the output shape is</p>
<div class="codehilite"><pre><span></span>merged.shape = [max(indices)] + constant
</pre></div>


<p>Values are merged in order, so if an index appears in both <code>indices[m][i]</code> and
<code>indices[n][j]</code> for <code>(m,i) &lt; (n,j)</code> the slice <code>data[n][j]</code> will appear in the
merged result.</p>
<p>For example:</p>
<div class="codehilite"><pre><span></span>indices[0] = 6
indices[1] = [4, 1]
indices[2] = [[5, 2], [0, 3]]
data[0] = [61, 62]
data[1] = [[41, 42], [11, 12]]
data[2] = [[[51, 52], [21, 22]], [[1, 2], [31, 32]]]
merged = [[1, 2], [11, 12], [21, 22], [31, 32], [41, 42],
          [51, 52], [61, 62]]
</pre></div>


<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/DynamicStitch.png" alt>
</div>

<p>Args:
  indices: A list of at least 2 <code>Tensor</code> objects of type <code>int32</code>.
  data: A list with the same number of <code>Tensor</code> objects as <code>indices</code> of <code>Tensor</code> objects of the same type.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.dynamic_stitch_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.dynamic_stitch_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.edit_distance">
    <p>def <span class="ident">edit_distance</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.edit_distance, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.edit_distance</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.edit_distance</strong></p>
<div class="codehilite"><pre><span></span>def edit_distance(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.edit_distance</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.edit_distance</code></strong></p>
<div class="codehilite"><pre><span></span>def edit_distance(hypothesis, truth, normalize=True, name=&quot;edit_distance&quot;)
</pre></div>


<p>Computes the Levenshtein distance between sequences.</p>
<p>This operation takes variable-length sequences (<code>hypothesis</code> and <code>truth</code>),
each provided as a <code>SparseTensor</code>, and computes the Levenshtein distance.
You can normalize the edit distance by length of <code>truth</code> by setting
<code>normalize</code> to true.</p>
<p>For example, given the following input:</p>
<p>```python</p>
<h1>'hypothesis' is a tensor of shape <code>[2, 1]</code> with variable-length values:</h1>
<h1>(0,0) = ["a"]</h1>
<h1>(1,0) = ["b"]</h1>
<p>hypothesis = tf.SparseTensor(
    [[0, 0, 0],
     [1, 0, 0]],
    ["a", "b"]
    (2, 1, 1))</p>
<h1>'truth' is a tensor of shape <code>[2, 2]</code> with variable-length values:</h1>
<h1>(0,0) = []</h1>
<h1>(0,1) = ["a"]</h1>
<h1>(1,0) = ["b", "c"]</h1>
<h1>(1,1) = ["a"]</h1>
<p>truth = tf.SparseTensor(
    [[0, 1, 0],
     [1, 0, 0],
     [1, 0, 1],
     [1, 1, 0]]
    ["a", "b", "c", "a"],
    (2, 2, 2))</p>
<p>normalize = True
```</p>
<p>This operation would return the following:</p>
<p>```python</p>
<h1>'output' is a tensor of shape <code>[2, 2]</code> with edit distances normalized</h1>
<h1>by 'truth' lengths.</h1>
<p>output ==&gt; [[inf, 1.0],  # (0,0): no truth, (0,1): no hypothesis
           [0.5, 1.0]]  # (1,0): addition, (1,1): no hypothesis
```</p>
<p>Args:
  hypothesis: A <code>SparseTensor</code> containing hypothesis sequences.
  truth: A <code>SparseTensor</code> containing truth sequences.
  normalize: A <code>bool</code>. If <code>True</code>, normalizes the Levenshtein distance by
    length of <code>truth.</code>
  name: A name for the operation (optional).</p>
<p>Returns:
  A dense <code>Tensor</code> with rank <code>R - 1</code>, where R is the rank of the
  <code>SparseTensor</code> inputs <code>hypothesis</code> and <code>truth</code>.</p>
<p>Raises:
  TypeError: If either <code>hypothesis</code> or <code>truth</code> are not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.edit_distance', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.edit_distance" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.edit_distance_layer">
    <p>def <span class="ident">edit_distance_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.edit_distance_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.edit_distance_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.edit_distance_layer</strong></p>
<div class="codehilite"><pre><span></span>def edit_distance_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.edit_distance, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.edit_distance</strong></p>
<div class="codehilite"><pre><span></span>def edit_distance(hypothesis, truth, normalize=True, name=&quot;edit_distance&quot;):
</pre></div>


<p>Computes the Levenshtein distance between sequences.</p>
<p>This operation takes variable-length sequences (<code>hypothesis</code> and <code>truth</code>),
each provided as a <code>SparseTensor</code>, and computes the Levenshtein distance.
You can normalize the edit distance by length of <code>truth</code> by setting
<code>normalize</code> to true.</p>
<p>For example, given the following input:</p>
<p>```python</p>
<h1>'hypothesis' is a tensor of shape <code>[2, 1]</code> with variable-length values:</h1>
<h1>(0,0) = ["a"]</h1>
<h1>(1,0) = ["b"]</h1>
<p>hypothesis = tf.SparseTensor(
    [[0, 0, 0],
     [1, 0, 0]],
    ["a", "b"]
    (2, 1, 1))</p>
<h1>'truth' is a tensor of shape <code>[2, 2]</code> with variable-length values:</h1>
<h1>(0,0) = []</h1>
<h1>(0,1) = ["a"]</h1>
<h1>(1,0) = ["b", "c"]</h1>
<h1>(1,1) = ["a"]</h1>
<p>truth = tf.SparseTensor(
    [[0, 1, 0],
     [1, 0, 0],
     [1, 0, 1],
     [1, 1, 0]]
    ["a", "b", "c", "a"],
    (2, 2, 2))</p>
<p>normalize = True
```</p>
<p>This operation would return the following:</p>
<p>```python</p>
<h1>'output' is a tensor of shape <code>[2, 2]</code> with edit distances normalized</h1>
<h1>by 'truth' lengths.</h1>
<p>output ==&gt; [[inf, 1.0],  # (0,0): no truth, (0,1): no hypothesis
           [0.5, 1.0]]  # (1,0): addition, (1,1): no hypothesis
```</p>
<p>Args:
  hypothesis: A <code>SparseTensor</code> containing hypothesis sequences.
  truth: A <code>SparseTensor</code> containing truth sequences.
  normalize: A <code>bool</code>. If <code>True</code>, normalizes the Levenshtein distance by
    length of <code>truth.</code>
  name: A name for the operation (optional).</p>
<p>Returns:
  A dense <code>Tensor</code> with rank <code>R - 1</code>, where R is the rank of the
  <code>SparseTensor</code> inputs <code>hypothesis</code> and <code>truth</code>.</p>
<p>Raises:
  TypeError: If either <code>hypothesis</code> or <code>truth</code> are not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.edit_distance_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.edit_distance_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.elu">
    <p>def <span class="ident">elu</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.elu, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.elu</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.elu</strong></p>
<div class="codehilite"><pre><span></span>def elu(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.elu</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.elu</code></strong></p>
<div class="codehilite"><pre><span></span>def elu(features, name=None)
</pre></div>


<p>Computes exponential linear: <code>exp(features) - 1</code> if &lt; 0, <code>features</code> otherwise.</p>
<p>See <a href="http://arxiv.org/abs/1511.07289">Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)
</a></p>
<p>Args:
  features: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>features</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.elu', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.elu" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.elu_layer">
    <p>def <span class="ident">elu_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.elu_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.elu_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.elu_layer</strong></p>
<div class="codehilite"><pre><span></span>def elu_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.elu, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.elu</strong></p>
<div class="codehilite"><pre><span></span>def elu(features, name=None):
</pre></div>


<p>Computes exponential linear: <code>exp(features) - 1</code> if &lt; 0, <code>features</code> otherwise.</p>
<p>See <a href="http://arxiv.org/abs/1511.07289">Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)
</a></p>
<p>Args:
  features: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>features</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.elu_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.elu_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.embedding_lookup">
    <p>def <span class="ident">embedding_lookup</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.embedding_lookup, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.embedding_lookup</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.embedding_lookup</strong></p>
<div class="codehilite"><pre><span></span>def embedding_lookup(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.embedding_lookup</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.embedding_lookup</code></strong></p>
<div class="codehilite"><pre><span></span>def embedding_lookup(params, ids, partition_strategy=&quot;mod&quot;, name=None, validate_indices=True)
</pre></div>


<p>Looks up <code>ids</code> in a list of embedding tensors.</p>
<p>This function is used to perform parallel lookups on the list of
tensors in <code>params</code>.  It is a generalization of
<a href="../../api_docs/python/array_ops.md#gather"><code>tf.gather()</code></a>, where <code>params</code> is
interpreted as a partition of a larger embedding tensor.</p>
<p>If <code>len(params) &gt; 1</code>, each element <code>id</code> of <code>ids</code> is partitioned between
the elements of <code>params</code> according to the <code>partition_strategy</code>.
In all strategies, if the id space does not evenly divide the number of
partitions, each of the first <code>(max_id + 1) % len(params)</code> partitions will
be assigned one more id.</p>
<p>If <code>partition_strategy</code> is <code>"mod"</code>, we assign each id to partition
<code>p = id % len(params)</code>. For instance,
13 ids are split across 5 partitions as:
<code>[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]</code></p>
<p>If <code>partition_strategy</code> is <code>"div"</code>, we assign ids to partitions in a
contiguous manner. In this case, 13 ids are split across 5 partitions as:
<code>[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]</code></p>
<p>The results of the lookup are concatenated into a dense
tensor. The returned tensor has shape <code>shape(ids) + shape(params)[1:]</code>.</p>
<p>Args:
  params: A list of tensors with the same type and which can be concatenated
    along dimension 0. Each <code>Tensor</code> must be appropriately sized for the given
    <code>partition_strategy</code>.
  ids: A <code>Tensor</code> with type <code>int32</code> or <code>int64</code> containing the ids to be looked
    up in <code>params</code>.
  partition_strategy: A string specifying the partitioning strategy, relevant
    if <code>len(params) &gt; 1</code>. Currently <code>"div"</code> and <code>"mod"</code> are supported. Default
    is <code>"mod"</code>.
  name: A name for the operation (optional).
  validate_indices: Whether or not to validate gather indices.</p>
<p>Returns:
  A <code>Tensor</code> with the same type as the tensors in <code>params</code>.</p>
<p>Raises:
  ValueError: If <code>params</code> is empty.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.embedding_lookup', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.embedding_lookup" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.embedding_lookup_layer">
    <p>def <span class="ident">embedding_lookup_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.embedding_lookup_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.embedding_lookup_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.embedding_lookup_layer</strong></p>
<div class="codehilite"><pre><span></span>def embedding_lookup_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.embedding_lookup, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.embedding_lookup</strong></p>
<div class="codehilite"><pre><span></span>def embedding_lookup(params, ids, partition_strategy=&quot;mod&quot;, name=None, validate_indices=True):
</pre></div>


<p>Looks up <code>ids</code> in a list of embedding tensors.</p>
<p>This function is used to perform parallel lookups on the list of
tensors in <code>params</code>.  It is a generalization of
<a href="../../api_docs/python/array_ops.md#gather"><code>tf.gather()</code></a>, where <code>params</code> is
interpreted as a partition of a larger embedding tensor.</p>
<p>If <code>len(params) &gt; 1</code>, each element <code>id</code> of <code>ids</code> is partitioned between
the elements of <code>params</code> according to the <code>partition_strategy</code>.
In all strategies, if the id space does not evenly divide the number of
partitions, each of the first <code>(max_id + 1) % len(params)</code> partitions will
be assigned one more id.</p>
<p>If <code>partition_strategy</code> is <code>"mod"</code>, we assign each id to partition
<code>p = id % len(params)</code>. For instance,
13 ids are split across 5 partitions as:
<code>[[0, 5, 10], [1, 6, 11], [2, 7, 12], [3, 8], [4, 9]]</code></p>
<p>If <code>partition_strategy</code> is <code>"div"</code>, we assign ids to partitions in a
contiguous manner. In this case, 13 ids are split across 5 partitions as:
<code>[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10], [11, 12]]</code></p>
<p>The results of the lookup are concatenated into a dense
tensor. The returned tensor has shape <code>shape(ids) + shape(params)[1:]</code>.</p>
<p>Args:
  params: A list of tensors with the same type and which can be concatenated
    along dimension 0. Each <code>Tensor</code> must be appropriately sized for the given
    <code>partition_strategy</code>.
  ids: A <code>Tensor</code> with type <code>int32</code> or <code>int64</code> containing the ids to be looked
    up in <code>params</code>.
  partition_strategy: A string specifying the partitioning strategy, relevant
    if <code>len(params) &gt; 1</code>. Currently <code>"div"</code> and <code>"mod"</code> are supported. Default
    is <code>"mod"</code>.
  name: A name for the operation (optional).
  validate_indices: Whether or not to validate gather indices.</p>
<p>Returns:
  A <code>Tensor</code> with the same type as the tensors in <code>params</code>.</p>
<p>Raises:
  ValueError: If <code>params</code> is empty.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.embedding_lookup_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.embedding_lookup_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.embedding_lookup_sparse">
    <p>def <span class="ident">embedding_lookup_sparse</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.embedding_lookup_sparse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.embedding_lookup_sparse</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.embedding_lookup_sparse</strong></p>
<div class="codehilite"><pre><span></span>def embedding_lookup_sparse(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.embedding_lookup_sparse</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.embedding_lookup_sparse</code></strong></p>
<div class="codehilite"><pre><span></span>def embedding_lookup_sparse(params, sp_ids, sp_weights, partition_strategy=&quot;mod&quot;, name=None, combiner=&quot;mean&quot;)
</pre></div>


<p>Computes embeddings for the given ids and weights.</p>
<p>This op assumes that there is at least one id for each row in the dense tensor
represented by sp_ids (i.e. there are no rows with empty features), and that
all the indices of sp_ids are in canonical row-major order.</p>
<p>It also assumes that all id values lie in the range [0, p0), where p0
is the sum of the size of params along dimension 0.</p>
<p>Args:
  params: A single tensor representing the complete embedding tensor,
    or a list of P tensors all of same shape except for the first dimension,
    representing sharded embedding tensors.
  sp_ids: N x M SparseTensor of int64 ids (typically from FeatureValueToId),
    where N is typically batch size and M is arbitrary.
  sp_weights: either a SparseTensor of float / double weights, or None to
    indicate all weights should be taken to be 1. If specified, sp_weights
    must have exactly the same shape and indices as sp_ids.
  partition_strategy: A string specifying the partitioning strategy, relevant
    if <code>len(params) &gt; 1</code>. Currently <code>"div"</code> and <code>"mod"</code> are supported. Default
    is <code>"mod"</code>. See <code>tf.nn.embedding_lookup</code> for more details.
  name: Optional name for the op.
  combiner: A string specifying the reduction op. Currently "mean", "sqrtn"
    and "sum" are supported.
    "sum" computes the weighted sum of the embedding results for each row.
    "mean" is the weighted sum divided by the total weight.
    "sqrtn" is the weighted sum divided by the square root of the sum of the
    squares of the weights.</p>
<p>Returns:
  A dense tensor representing the combined embeddings for the
  sparse ids. For each row in the dense tensor represented by sp_ids, the op
  looks up the embeddings for all ids in that row, multiplies them by the
  corresponding weight, and combines these embeddings as specified.</p>
<p>In other words, if
    shape(combined params) = [p0, p1, ..., pm]
  and
    shape(sp_ids) = shape(sp_weights) = [d0, d1, ..., dn]
  then
    shape(output) = [d0, d1, ..., dn-1, p1, ..., pm].</p>
<p>For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are</p>
<div class="codehilite"><pre><span></span>[0, 0]: id 1, weight 2.0
[0, 1]: id 3, weight 0.5
[1, 0]: id 0, weight 1.0
[2, 3]: id 1, weight 3.0
</pre></div>


<p>with combiner="mean", then the output will be a 3x20 matrix where
    output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)
    output[1, :] = params[0, :] * 1.0
    output[2, :] = params[1, :] * 3.0</p>
<p>Raises:
  TypeError: If sp_ids is not a SparseTensor, or if sp_weights is neither
    None nor SparseTensor.
  ValueError: If combiner is not one of {"mean", "sqrtn", "sum"}.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.embedding_lookup_sparse', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.embedding_lookup_sparse" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.embedding_lookup_sparse_layer">
    <p>def <span class="ident">embedding_lookup_sparse_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.embedding_lookup_sparse_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.embedding_lookup_sparse_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.embedding_lookup_sparse_layer</strong></p>
<div class="codehilite"><pre><span></span>def embedding_lookup_sparse_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.embedding_lookup_sparse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.embedding_lookup_sparse</strong></p>
<div class="codehilite"><pre><span></span>def embedding_lookup_sparse(params, sp_ids, sp_weights, partition_strategy=&quot;mod&quot;, name=None, combiner=&quot;mean&quot;):
</pre></div>


<p>Computes embeddings for the given ids and weights.</p>
<p>This op assumes that there is at least one id for each row in the dense tensor
represented by sp_ids (i.e. there are no rows with empty features), and that
all the indices of sp_ids are in canonical row-major order.</p>
<p>It also assumes that all id values lie in the range [0, p0), where p0
is the sum of the size of params along dimension 0.</p>
<p>Args:
  params: A single tensor representing the complete embedding tensor,
    or a list of P tensors all of same shape except for the first dimension,
    representing sharded embedding tensors.
  sp_ids: N x M SparseTensor of int64 ids (typically from FeatureValueToId),
    where N is typically batch size and M is arbitrary.
  sp_weights: either a SparseTensor of float / double weights, or None to
    indicate all weights should be taken to be 1. If specified, sp_weights
    must have exactly the same shape and indices as sp_ids.
  partition_strategy: A string specifying the partitioning strategy, relevant
    if <code>len(params) &gt; 1</code>. Currently <code>"div"</code> and <code>"mod"</code> are supported. Default
    is <code>"mod"</code>. See <code>tf.nn.embedding_lookup</code> for more details.
  name: Optional name for the op.
  combiner: A string specifying the reduction op. Currently "mean", "sqrtn"
    and "sum" are supported.
    "sum" computes the weighted sum of the embedding results for each row.
    "mean" is the weighted sum divided by the total weight.
    "sqrtn" is the weighted sum divided by the square root of the sum of the
    squares of the weights.</p>
<p>Returns:
  A dense tensor representing the combined embeddings for the
  sparse ids. For each row in the dense tensor represented by sp_ids, the op
  looks up the embeddings for all ids in that row, multiplies them by the
  corresponding weight, and combines these embeddings as specified.</p>
<p>In other words, if
    shape(combined params) = [p0, p1, ..., pm]
  and
    shape(sp_ids) = shape(sp_weights) = [d0, d1, ..., dn]
  then
    shape(output) = [d0, d1, ..., dn-1, p1, ..., pm].</p>
<p>For instance, if params is a 10x20 matrix, and sp_ids / sp_weights are</p>
<div class="codehilite"><pre><span></span>[0, 0]: id 1, weight 2.0
[0, 1]: id 3, weight 0.5
[1, 0]: id 0, weight 1.0
[2, 3]: id 1, weight 3.0
</pre></div>


<p>with combiner="mean", then the output will be a 3x20 matrix where
    output[0, :] = (params[1, :] * 2.0 + params[3, :] * 0.5) / (2.0 + 0.5)
    output[1, :] = params[0, :] * 1.0
    output[2, :] = params[1, :] * 3.0</p>
<p>Raises:
  TypeError: If sp_ids is not a SparseTensor, or if sp_weights is neither
    None nor SparseTensor.
  ValueError: If combiner is not one of {"mean", "sqrtn", "sum"}.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.embedding_lookup_sparse_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.embedding_lookup_sparse_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.equal">
    <p>def <span class="ident">equal</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.equal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.equal</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.equal</strong></p>
<div class="codehilite"><pre><span></span>def equal(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.equal</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.equal</code></strong></p>
<div class="codehilite"><pre><span></span>def equal(x, y, name=None)
</pre></div>


<p>Returns the truth value of (x == y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>quint8</code>, <code>qint8</code>, <code>qint32</code>, <code>string</code>, <code>bool</code>, <code>complex128</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.equal', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.equal" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.equal_layer">
    <p>def <span class="ident">equal_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.equal_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.equal_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.equal_layer</strong></p>
<div class="codehilite"><pre><span></span>def equal_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.equal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.equal</strong></p>
<div class="codehilite"><pre><span></span>def equal(x, y, name=None):
</pre></div>


<p>Returns the truth value of (x == y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>quint8</code>, <code>qint8</code>, <code>qint32</code>, <code>string</code>, <code>bool</code>, <code>complex128</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.equal_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.equal_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.erf">
    <p>def <span class="ident">erf</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.erf, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.erf</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.erf</strong></p>
<div class="codehilite"><pre><span></span>def erf(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.erf</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.erf</code></strong></p>
<div class="codehilite"><pre><span></span>def erf(x, name=None)
</pre></div>


<p>Computes the Gauss error function of <code>x</code> element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.erf', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.erf" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.erf_layer">
    <p>def <span class="ident">erf_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.erf_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.erf_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.erf_layer</strong></p>
<div class="codehilite"><pre><span></span>def erf_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.erf, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.erf</strong></p>
<div class="codehilite"><pre><span></span>def erf(x, name=None):
</pre></div>


<p>Computes the Gauss error function of <code>x</code> element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.erf_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.erf_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.erfc">
    <p>def <span class="ident">erfc</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.erfc, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.erfc</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.erfc</strong></p>
<div class="codehilite"><pre><span></span>def erfc(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.erfc</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.erfc</code></strong></p>
<div class="codehilite"><pre><span></span>def erfc(x, name=None)
</pre></div>


<p>Computes the complementary error function of <code>x</code> element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.erfc', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.erfc" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.erfc_layer">
    <p>def <span class="ident">erfc_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.erfc_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.erfc_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.erfc_layer</strong></p>
<div class="codehilite"><pre><span></span>def erfc_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.erfc, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.erfc</strong></p>
<div class="codehilite"><pre><span></span>def erfc(x, name=None):
</pre></div>


<p>Computes the complementary error function of <code>x</code> element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.erfc_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.erfc_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.erosion2d">
    <p>def <span class="ident">erosion2d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.erosion2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.erosion2d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.erosion2d</strong></p>
<div class="codehilite"><pre><span></span>def erosion2d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.erosion2d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.erosion2d</code></strong></p>
<div class="codehilite"><pre><span></span>def erosion2d(value, kernel, strides, rates, padding, name=None)
</pre></div>


<p>Computes the grayscale erosion of 4-D <code>value</code> and 3-D <code>kernel</code> tensors.</p>
<p>The <code>value</code> tensor has shape <code>[batch, in_height, in_width, depth]</code> and the
<code>kernel</code> tensor has shape <code>[kernel_height, kernel_width, depth]</code>, i.e.,
each input channel is processed independently of the others with its own
structuring function. The <code>output</code> tensor has shape
<code>[batch, out_height, out_width, depth]</code>. The spatial dimensions of the
output tensor depend on the <code>padding</code> algorithm. We currently only support the
default "NHWC" <code>data_format</code>.</p>
<p>In detail, the grayscale morphological 2-D erosion is given by:</p>
<div class="codehilite"><pre><span></span>output[b, y, x, c] =
   min_{dy, dx} value[b,
                      strides[1] * y - rates[1] * dy,
                      strides[2] * x - rates[2] * dx,
                      c] -
                kernel[dy, dx, c]
</pre></div>


<p>Duality: The erosion of <code>value</code> by the <code>kernel</code> is equal to the negation of
the dilation of <code>-value</code> by the reflected <code>kernel</code>.</p>
<p>Args:
  value: A <code>Tensor</code>. 4-D with shape <code>[batch, in_height, in_width, depth]</code>.
  kernel: A <code>Tensor</code>. Must have the same type as <code>value</code>.
    3-D with shape <code>[kernel_height, kernel_width, depth]</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    1-D of length 4. The stride of the sliding window for each dimension of
    the input tensor. Must be: <code>[1, stride_height, stride_width, 1]</code>.
  rates: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    1-D of length 4. The input stride for atrous morphological dilation.
    Must be: <code>[1, rate_height, rate_width, 1]</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional). If not specified "erosion2d"
    is used.</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>value</code>.
  4-D with shape <code>[batch, out_height, out_width, depth]</code>.</p>
<p>Raises:
  ValueError: If the <code>value</code> depth does not match <code>kernel</code>' shape, or if
    padding is other than <code>'VALID'</code> or <code>'SAME'</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.erosion2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.erosion2d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.erosion2d_layer">
    <p>def <span class="ident">erosion2d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.erosion2d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.erosion2d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.erosion2d_layer</strong></p>
<div class="codehilite"><pre><span></span>def erosion2d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.erosion2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.erosion2d</strong></p>
<div class="codehilite"><pre><span></span>def erosion2d(value, kernel, strides, rates, padding, name=None):
</pre></div>


<p>Computes the grayscale erosion of 4-D <code>value</code> and 3-D <code>kernel</code> tensors.</p>
<p>The <code>value</code> tensor has shape <code>[batch, in_height, in_width, depth]</code> and the
<code>kernel</code> tensor has shape <code>[kernel_height, kernel_width, depth]</code>, i.e.,
each input channel is processed independently of the others with its own
structuring function. The <code>output</code> tensor has shape
<code>[batch, out_height, out_width, depth]</code>. The spatial dimensions of the
output tensor depend on the <code>padding</code> algorithm. We currently only support the
default "NHWC" <code>data_format</code>.</p>
<p>In detail, the grayscale morphological 2-D erosion is given by:</p>
<div class="codehilite"><pre><span></span>output[b, y, x, c] =
   min_{dy, dx} value[b,
                      strides[1] * y - rates[1] * dy,
                      strides[2] * x - rates[2] * dx,
                      c] -
                kernel[dy, dx, c]
</pre></div>


<p>Duality: The erosion of <code>value</code> by the <code>kernel</code> is equal to the negation of
the dilation of <code>-value</code> by the reflected <code>kernel</code>.</p>
<p>Args:
  value: A <code>Tensor</code>. 4-D with shape <code>[batch, in_height, in_width, depth]</code>.
  kernel: A <code>Tensor</code>. Must have the same type as <code>value</code>.
    3-D with shape <code>[kernel_height, kernel_width, depth]</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    1-D of length 4. The stride of the sliding window for each dimension of
    the input tensor. Must be: <code>[1, stride_height, stride_width, 1]</code>.
  rates: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    1-D of length 4. The input stride for atrous morphological dilation.
    Must be: <code>[1, rate_height, rate_width, 1]</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional). If not specified "erosion2d"
    is used.</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>value</code>.
  4-D with shape <code>[batch, out_height, out_width, depth]</code>.</p>
<p>Raises:
  ValueError: If the <code>value</code> depth does not match <code>kernel</code>' shape, or if
    padding is other than <code>'VALID'</code> or <code>'SAME'</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.erosion2d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.erosion2d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.exp">
    <p>def <span class="ident">exp</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.exp, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.exp</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.exp</strong></p>
<div class="codehilite"><pre><span></span>def exp(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.exp</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.exp</code></strong></p>
<div class="codehilite"><pre><span></span>def exp(x, name=None)
</pre></div>


<p>Computes exponential of x element-wise.  \(y = e^x\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.exp', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.exp" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.exp_layer">
    <p>def <span class="ident">exp_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.exp_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.exp_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.exp_layer</strong></p>
<div class="codehilite"><pre><span></span>def exp_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.exp, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.exp</strong></p>
<div class="codehilite"><pre><span></span>def exp(x, name=None):
</pre></div>


<p>Computes exponential of x element-wise.  \(y = e^x\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.exp_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.exp_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.expand_dims">
    <p>def <span class="ident">expand_dims</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.expand_dims, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.expand_dims</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.expand_dims</strong></p>
<div class="codehilite"><pre><span></span>def expand_dims(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.expand_dims</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.expand_dims</code></strong></p>
<div class="codehilite"><pre><span></span>def expand_dims(input, dim, name=None)
</pre></div>


<p>Inserts a dimension of 1 into a tensor's shape.</p>
<p>Given a tensor <code>input</code>, this operation inserts a dimension of 1 at the
dimension index <code>dim</code> of <code>input</code>'s shape. The dimension index <code>dim</code> starts at
zero; if you specify a negative number for <code>dim</code> it is counted backward from
the end.</p>
<p>This operation is useful if you want to add a batch dimension to a single
element. For example, if you have a single image of shape <code>[height, width,
channels]</code>, you can make it a batch of 1 image with <code>expand_dims(image, 0)</code>,
which will make the shape <code>[1, height, width, channels]</code>.</p>
<p>Other examples:</p>
<p>```prettyprint</p>
<h1>'t' is a tensor of shape [2]</h1>
<p>shape(expand_dims(t, 0)) ==&gt; [1, 2]
shape(expand_dims(t, 1)) ==&gt; [2, 1]
shape(expand_dims(t, -1)) ==&gt; [2, 1]</p>
<h1>'t2' is a tensor of shape [2, 3, 5]</h1>
<p>shape(expand_dims(t2, 0)) ==&gt; [1, 2, 3, 5]
shape(expand_dims(t2, 2)) ==&gt; [2, 3, 1, 5]
shape(expand_dims(t2, 3)) ==&gt; [2, 3, 5, 1]
```</p>
<p>This operation requires that:</p>
<p><code>-1-input.dims() &lt;= dim &lt;= input.dims()</code></p>
<p>This operation is related to <code>squeeze()</code>, which removes dimensions of
size 1.</p>
<p>Args:
  input: A <code>Tensor</code>.
  dim: A <code>Tensor</code> of type <code>int32</code>.
    0-D (scalar). Specifies the dimension index at which to
    expand the shape of <code>input</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  Contains the same data as <code>input</code>, but its shape has an additional
  dimension of size 1 added.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.expand_dims', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.expand_dims" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.expand_dims_layer">
    <p>def <span class="ident">expand_dims_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.expand_dims_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.expand_dims_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.expand_dims_layer</strong></p>
<div class="codehilite"><pre><span></span>def expand_dims_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.expand_dims, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.expand_dims</strong></p>
<div class="codehilite"><pre><span></span>def expand_dims(input, dim, name=None):
</pre></div>


<p>Inserts a dimension of 1 into a tensor's shape.</p>
<p>Given a tensor <code>input</code>, this operation inserts a dimension of 1 at the
dimension index <code>dim</code> of <code>input</code>'s shape. The dimension index <code>dim</code> starts at
zero; if you specify a negative number for <code>dim</code> it is counted backward from
the end.</p>
<p>This operation is useful if you want to add a batch dimension to a single
element. For example, if you have a single image of shape <code>[height, width,
channels]</code>, you can make it a batch of 1 image with <code>expand_dims(image, 0)</code>,
which will make the shape <code>[1, height, width, channels]</code>.</p>
<p>Other examples:</p>
<p>```prettyprint</p>
<h1>'t' is a tensor of shape [2]</h1>
<p>shape(expand_dims(t, 0)) ==&gt; [1, 2]
shape(expand_dims(t, 1)) ==&gt; [2, 1]
shape(expand_dims(t, -1)) ==&gt; [2, 1]</p>
<h1>'t2' is a tensor of shape [2, 3, 5]</h1>
<p>shape(expand_dims(t2, 0)) ==&gt; [1, 2, 3, 5]
shape(expand_dims(t2, 2)) ==&gt; [2, 3, 1, 5]
shape(expand_dims(t2, 3)) ==&gt; [2, 3, 5, 1]
```</p>
<p>This operation requires that:</p>
<p><code>-1-input.dims() &lt;= dim &lt;= input.dims()</code></p>
<p>This operation is related to <code>squeeze()</code>, which removes dimensions of
size 1.</p>
<p>Args:
  input: A <code>Tensor</code>.
  dim: A <code>Tensor</code> of type <code>int32</code>.
    0-D (scalar). Specifies the dimension index at which to
    expand the shape of <code>input</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  Contains the same data as <code>input</code>, but its shape has an additional
  dimension of size 1 added.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.expand_dims_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.expand_dims_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.extract">
    <p>def <span class="ident">extract</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(BuilderTree.extract, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>BuilderTree.extract</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for BuilderTree.extract</strong></p>
<div class="codehilite"><pre><span></span>def extract(tree, fn):
</pre></div>


<p><code>@immutable</code></p>
<p>Expects a function <strong>fn</strong> with type <code>list( Tensor ) -&gt; Tensor</code> and applies this function to <code>tensorbuilder.core.builders.BuilderTree.tensors</code>, the resulting Tensor is wrapped in Builder. This function</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>fn</code>: a function of type <code>list( Tensor ) -&gt; Tensor</code>.</li>
<li>All additional *args and **kwargs are forwarded to <code>fn</code></li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><code>tensorbuilder.core.builders.Builder</code></li>
</ul>
<p><strong> Example </strong></p>
<p>Lets redu the example in <code>tensorbuilder.core.builders.BuilderTree.map_each</code> using <code>extract</code></p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">h</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span>
        <span class="n">x</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">x</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">x</span><span class="o">.</span><span class="n">tanh_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">])</span>
    <span class="o">.</span><span class="n">map_each</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    <span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="k">lambda</span> <span class="n">tensors</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span><span class="n">tensors</span><span class="p">))</span> <span class="c1">#or just .extract(tf.add_n)</span>
    <span class="o">.</span><span class="n">softmax</span><span class="p">()</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>


<p>Same example using the DSL</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">h</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="p">[</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">tanh_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">map_each</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    <span class="o">.</span><span class="n">extract</span><span class="p">(</span><span class="k">lambda</span> <span class="n">tensors</span><span class="p">:</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">(</span><span class="n">tensors</span><span class="p">))</span> <span class="c1">#or just .extract(tf.add_n)</span>
    <span class="o">.</span><span class="n">softmax</span><span class="p">()</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.extract', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.extract" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.extract_image_patches">
    <p>def <span class="ident">extract_image_patches</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.extract_image_patches, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.extract_image_patches</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.extract_image_patches</strong></p>
<div class="codehilite"><pre><span></span>def extract_image_patches(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.extract_image_patches</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.extract_image_patches</code></strong></p>
<div class="codehilite"><pre><span></span>def extract_image_patches(images, padding, ksizes=None, strides=None, rates=None, name=None)
</pre></div>


<p>Extract <code>patches</code> from <code>images</code> and puth them in the "depth" output dimension.</p>
<p>Args:
  images: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
    4-D Tensor with shape <code>[batch, in_rows, in_cols, depth]</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.</p>
<div class="codehilite"><pre><span></span>We specify the size-related attributes as:

      ksizes = [1, ksize_rows, ksize_cols, 1]
      strides = [1, strides_rows, strides_cols, 1]
      rates = [1, rates_rows, rates_cols, 1]
</pre></div>


<p>ksizes: An optional list of <code>ints</code>. Defaults to <code>[]</code>.
    The size of the sliding window for each dimension of <code>images</code>.
  strides: An optional list of <code>ints</code>. Defaults to <code>[]</code>.
    1-D of length 4. How far the centers of two consecutive patches are in
    the images. Must be: <code>[1, stride_rows, stride_cols, 1]</code>.
  rates: An optional list of <code>ints</code>. Defaults to <code>[]</code>.
    1-D of length 4. Must be: <code>[1, rate_rows, rate_cols, 1]</code>. This is the
    input stride, specifying how far two consecutive patch samples are in the
    input. Equivalent to extracting patches with
    <code>patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1), followed by
    subsampling them spatially by a factor of</code>rates`.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>images</code>.
  4-D Tensor with shape <code>[batch, out_rows, out_cols, ksize_rows *
  ksize_cols * depth]</code> containing image patches with size
  <code>ksize_rows x ksize_cols x depth</code> vectorized in the "depth" dimension.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.extract_image_patches', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.extract_image_patches" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.extract_image_patches_layer">
    <p>def <span class="ident">extract_image_patches_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.extract_image_patches_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.extract_image_patches_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.extract_image_patches_layer</strong></p>
<div class="codehilite"><pre><span></span>def extract_image_patches_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.extract_image_patches, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.extract_image_patches</strong></p>
<div class="codehilite"><pre><span></span>def extract_image_patches(images, padding, ksizes=None, strides=None, rates=None, name=None):
</pre></div>


<p>Extract <code>patches</code> from <code>images</code> and puth them in the "depth" output dimension.</p>
<p>Args:
  images: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
    4-D Tensor with shape <code>[batch, in_rows, in_cols, depth]</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.</p>
<div class="codehilite"><pre><span></span>We specify the size-related attributes as:

      ksizes = [1, ksize_rows, ksize_cols, 1]
      strides = [1, strides_rows, strides_cols, 1]
      rates = [1, rates_rows, rates_cols, 1]
</pre></div>


<p>ksizes: An optional list of <code>ints</code>. Defaults to <code>[]</code>.
    The size of the sliding window for each dimension of <code>images</code>.
  strides: An optional list of <code>ints</code>. Defaults to <code>[]</code>.
    1-D of length 4. How far the centers of two consecutive patches are in
    the images. Must be: <code>[1, stride_rows, stride_cols, 1]</code>.
  rates: An optional list of <code>ints</code>. Defaults to <code>[]</code>.
    1-D of length 4. Must be: <code>[1, rate_rows, rate_cols, 1]</code>. This is the
    input stride, specifying how far two consecutive patch samples are in the
    input. Equivalent to extracting patches with
    <code>patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1), followed by
    subsampling them spatially by a factor of</code>rates`.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>images</code>.
  4-D Tensor with shape <code>[batch, out_rows, out_cols, ksize_rows *
  ksize_cols * depth]</code> containing image patches with size
  <code>ksize_rows x ksize_cols x depth</code> vectorized in the "depth" dimension.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.extract_image_patches_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.extract_image_patches_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.fft">
    <p>def <span class="ident">fft</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.fft, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.fft</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.fft</strong></p>
<div class="codehilite"><pre><span></span>def fft(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.fft</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.fft</code></strong></p>
<div class="codehilite"><pre><span></span>def fft(input, name=None)
</pre></div>


<p>Compute the 1-dimensional discrete Fourier Transform.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 vector.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>. The 1D Fourier Transform of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.fft', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.fft" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.fft2d">
    <p>def <span class="ident">fft2d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.fft2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.fft2d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.fft2d</strong></p>
<div class="codehilite"><pre><span></span>def fft2d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.fft2d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.fft2d</code></strong></p>
<div class="codehilite"><pre><span></span>def fft2d(input, name=None)
</pre></div>


<p>Compute the 2-dimensional discrete Fourier Transform.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 matrix.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>. The 2D Fourier Transform of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.fft2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.fft2d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.fft2d_layer">
    <p>def <span class="ident">fft2d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.fft2d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.fft2d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.fft2d_layer</strong></p>
<div class="codehilite"><pre><span></span>def fft2d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.fft2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.fft2d</strong></p>
<div class="codehilite"><pre><span></span>def fft2d(input, name=None):
</pre></div>


<p>Compute the 2-dimensional discrete Fourier Transform.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 matrix.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>. The 2D Fourier Transform of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.fft2d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.fft2d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.fft3d">
    <p>def <span class="ident">fft3d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.fft3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.fft3d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.fft3d</strong></p>
<div class="codehilite"><pre><span></span>def fft3d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.fft3d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.fft3d</code></strong></p>
<div class="codehilite"><pre><span></span>def fft3d(input, name=None)
</pre></div>


<p>Compute the 3-dimensional discrete Fourier Transform.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 3-D tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>. The 3D Fourier Transform of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.fft3d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.fft3d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.fft3d_layer">
    <p>def <span class="ident">fft3d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.fft3d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.fft3d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.fft3d_layer</strong></p>
<div class="codehilite"><pre><span></span>def fft3d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.fft3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.fft3d</strong></p>
<div class="codehilite"><pre><span></span>def fft3d(input, name=None):
</pre></div>


<p>Compute the 3-dimensional discrete Fourier Transform.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 3-D tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>. The 3D Fourier Transform of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.fft3d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.fft3d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.fft_layer">
    <p>def <span class="ident">fft_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.fft_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.fft_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.fft_layer</strong></p>
<div class="codehilite"><pre><span></span>def fft_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.fft, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.fft</strong></p>
<div class="codehilite"><pre><span></span>def fft(input, name=None):
</pre></div>


<p>Compute the 1-dimensional discrete Fourier Transform.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 vector.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>. The 1D Fourier Transform of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.fft_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.fft_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.fill">
    <p>def <span class="ident">fill</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.fill, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.fill</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.fill</strong></p>
<div class="codehilite"><pre><span></span>def fill(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.fill</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.fill</code></strong></p>
<div class="codehilite"><pre><span></span>def fill(dims, value, name=None)
</pre></div>


<p>Creates a tensor filled with a scalar value.</p>
<p>This operation creates a tensor of shape <code>dims</code> and fills it with <code>value</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>Output tensor has shape [2, 3].</h1>
<p>fill([2, 3], 9) ==&gt; [[9, 9, 9]
                     [9, 9, 9]]
```</p>
<p>Args:
  dims: A <code>Tensor</code> of type <code>int32</code>.
    1-D. Represents the shape of the output tensor.
  value: A <code>Tensor</code>. 0-D (scalar). Value to fill the returned tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>value</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.fill', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.fill" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.fill_layer">
    <p>def <span class="ident">fill_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.fill_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.fill_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.fill_layer</strong></p>
<div class="codehilite"><pre><span></span>def fill_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.fill, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.fill</strong></p>
<div class="codehilite"><pre><span></span>def fill(dims, value, name=None):
</pre></div>


<p>Creates a tensor filled with a scalar value.</p>
<p>This operation creates a tensor of shape <code>dims</code> and fills it with <code>value</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>Output tensor has shape [2, 3].</h1>
<p>fill([2, 3], 9) ==&gt; [[9, 9, 9]
                     [9, 9, 9]]
```</p>
<p>Args:
  dims: A <code>Tensor</code> of type <code>int32</code>.
    1-D. Represents the shape of the output tensor.
  value: A <code>Tensor</code>. 0-D (scalar). Value to fill the returned tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>value</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.fill_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.fill_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.fixed_unigram_candidate_sampler">
    <p>def <span class="ident">fixed_unigram_candidate_sampler</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.fixed_unigram_candidate_sampler, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.fixed_unigram_candidate_sampler</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.fixed_unigram_candidate_sampler</strong></p>
<div class="codehilite"><pre><span></span>def fixed_unigram_candidate_sampler(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.fixed_unigram_candidate_sampler</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.fixed_unigram_candidate_sampler</code></strong></p>
<div class="codehilite"><pre><span></span>def fixed_unigram_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, vocab_file=&quot;&quot;, distortion=1.0, num_reserved_ids=0, num_shards=1, shard=0, unigrams=(), seed=None, name=None)
</pre></div>


<p>Samples a set of classes using the provided (fixed) base distribution.</p>
<p>This operation randomly samples a tensor of sampled classes
(<code>sampled_candidates</code>) from the range of integers <code>[0, range_max)</code>.</p>
<p>The elements of <code>sampled_candidates</code> are drawn without replacement
(if <code>unique=True</code>) or with replacement (if <code>unique=False</code>) from
the base distribution.</p>
<p>The base distribution is read from a file or passed in as an
in-memory array. There is also an option to skew the distribution by
applying a distortion power to the weights.</p>
<p>In addition, this operation returns tensors <code>true_expected_count</code>
and <code>sampled_expected_count</code> representing the number of times each
of the target classes (<code>true_classes</code>) and the sampled
classes (<code>sampled_candidates</code>) is expected to occur in an average
tensor of sampled classes.  These values correspond to <code>Q(y|x)</code>
defined in <a href="http://www.tensorflow.org/extras/candidate_sampling.pdf">this
document</a>.
If <code>unique=True</code>, then these are post-rejection probabilities and we
compute them approximately.</p>
<p>Args:
  true_classes: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
    num_true]</code>. The target classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  num_sampled: An <code>int</code>.  The number of classes to randomly sample per batch.
  unique: A <code>bool</code>. Determines whether all sampled classes in a batch are
    unique.
  range_max: An <code>int</code>. The number of possible classes.
  vocab_file: Each valid line in this file (which should have a CSV-like
    format) corresponds to a valid word ID. IDs are in sequential order,
    starting from num_reserved_ids. The last entry in each line is expected
    to be a value corresponding to the count or relative probability. Exactly
    one of <code>vocab_file</code> and <code>unigrams</code> needs to be passed to this operation.
  distortion: The distortion is used to skew the unigram probability
    distribution.  Each weight is first raised to the distortion's power
    before adding to the internal unigram distribution. As a result,
    <code>distortion = 1.0</code> gives regular unigram sampling (as defined by the vocab
    file), and <code>distortion = 0.0</code> gives a uniform distribution.
  num_reserved_ids: Optionally some reserved IDs can be added in the range
    <code>[0, num_reserved_ids]</code> by the users. One use case is that a special
    unknown word token is used as ID 0. These IDs will have a sampling
    probability of 0.
  num_shards: A sampler can be used to sample from a subset of the original
    range in order to speed up the whole computation through parallelism. This
    parameter (together with <code>shard</code>) indicates the number of partitions that
    are being used in the overall computation.
  shard: A sampler can be used to sample from a subset of the original range
    in order to speed up the whole computation through parallelism. This
    parameter (together with <code>num_shards</code>) indicates the particular partition
    number of the operation, when partitioning is being used.
  unigrams: A list of unigram counts or probabilities, one per ID in
    sequential order. Exactly one of <code>vocab_file</code> and <code>unigrams</code> should be
    passed to this operation.
  seed: An <code>int</code>. An operation-specific seed. Default is 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  sampled_candidates: A tensor of type <code>int64</code> and shape <code>[num_sampled]</code>.
    The sampled classes.
  true_expected_count: A tensor of type <code>float</code>.  Same shape as
    <code>true_classes</code>. The expected counts under the sampling distribution
    of each of <code>true_classes</code>.
  sampled_expected_count: A tensor of type <code>float</code>. Same shape as
    <code>sampled_candidates</code>. The expected counts under the sampling distribution
    of each of <code>sampled_candidates</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.fixed_unigram_candidate_sampler', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.fixed_unigram_candidate_sampler" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.fixed_unigram_candidate_sampler_layer">
    <p>def <span class="ident">fixed_unigram_candidate_sampler_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.fixed_unigram_candidate_sampler_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.fixed_unigram_candidate_sampler_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.fixed_unigram_candidate_sampler_layer</strong></p>
<div class="codehilite"><pre><span></span>def fixed_unigram_candidate_sampler_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.fixed_unigram_candidate_sampler, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.fixed_unigram_candidate_sampler</strong></p>
<div class="codehilite"><pre><span></span>def fixed_unigram_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, vocab_file=&quot;&quot;, distortion=1.0, num_reserved_ids=0, num_shards=1, shard=0, unigrams=(), seed=None, name=None):
</pre></div>


<p>Samples a set of classes using the provided (fixed) base distribution.</p>
<p>This operation randomly samples a tensor of sampled classes
(<code>sampled_candidates</code>) from the range of integers <code>[0, range_max)</code>.</p>
<p>The elements of <code>sampled_candidates</code> are drawn without replacement
(if <code>unique=True</code>) or with replacement (if <code>unique=False</code>) from
the base distribution.</p>
<p>The base distribution is read from a file or passed in as an
in-memory array. There is also an option to skew the distribution by
applying a distortion power to the weights.</p>
<p>In addition, this operation returns tensors <code>true_expected_count</code>
and <code>sampled_expected_count</code> representing the number of times each
of the target classes (<code>true_classes</code>) and the sampled
classes (<code>sampled_candidates</code>) is expected to occur in an average
tensor of sampled classes.  These values correspond to <code>Q(y|x)</code>
defined in <a href="http://www.tensorflow.org/extras/candidate_sampling.pdf">this
document</a>.
If <code>unique=True</code>, then these are post-rejection probabilities and we
compute them approximately.</p>
<p>Args:
  true_classes: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
    num_true]</code>. The target classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  num_sampled: An <code>int</code>.  The number of classes to randomly sample per batch.
  unique: A <code>bool</code>. Determines whether all sampled classes in a batch are
    unique.
  range_max: An <code>int</code>. The number of possible classes.
  vocab_file: Each valid line in this file (which should have a CSV-like
    format) corresponds to a valid word ID. IDs are in sequential order,
    starting from num_reserved_ids. The last entry in each line is expected
    to be a value corresponding to the count or relative probability. Exactly
    one of <code>vocab_file</code> and <code>unigrams</code> needs to be passed to this operation.
  distortion: The distortion is used to skew the unigram probability
    distribution.  Each weight is first raised to the distortion's power
    before adding to the internal unigram distribution. As a result,
    <code>distortion = 1.0</code> gives regular unigram sampling (as defined by the vocab
    file), and <code>distortion = 0.0</code> gives a uniform distribution.
  num_reserved_ids: Optionally some reserved IDs can be added in the range
    <code>[0, num_reserved_ids]</code> by the users. One use case is that a special
    unknown word token is used as ID 0. These IDs will have a sampling
    probability of 0.
  num_shards: A sampler can be used to sample from a subset of the original
    range in order to speed up the whole computation through parallelism. This
    parameter (together with <code>shard</code>) indicates the number of partitions that
    are being used in the overall computation.
  shard: A sampler can be used to sample from a subset of the original range
    in order to speed up the whole computation through parallelism. This
    parameter (together with <code>num_shards</code>) indicates the particular partition
    number of the operation, when partitioning is being used.
  unigrams: A list of unigram counts or probabilities, one per ID in
    sequential order. Exactly one of <code>vocab_file</code> and <code>unigrams</code> should be
    passed to this operation.
  seed: An <code>int</code>. An operation-specific seed. Default is 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  sampled_candidates: A tensor of type <code>int64</code> and shape <code>[num_sampled]</code>.
    The sampled classes.
  true_expected_count: A tensor of type <code>float</code>.  Same shape as
    <code>true_classes</code>. The expected counts under the sampling distribution
    of each of <code>true_classes</code>.
  sampled_expected_count: A tensor of type <code>float</code>. Same shape as
    <code>sampled_candidates</code>. The expected counts under the sampling distribution
    of each of <code>sampled_candidates</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.fixed_unigram_candidate_sampler_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.fixed_unigram_candidate_sampler_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.flatten">
    <p>def <span class="ident">flatten</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.flatten, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.flatten</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.flatten</strong></p>
<div class="codehilite"><pre><span></span>def flatten(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tflearn.layers.core.flatten.flatten</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tflearn.layers.core.flatten.flatten</code></strong></p>
<div class="codehilite"><pre><span></span>def flatten(incoming, name=&quot;Flatten&quot;)
</pre></div>


<p>Flatten.</p>
<p>Flatten the incoming Tensor.</p>
<p>Input:
    (2+)-D <code>Tensor</code>.</p>
<p>Output:
    2-D <code>Tensor</code> [batch, flatten_dims].</p>
<p>Arguments:
    incoming: <code>Tensor</code>. The incoming tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.flatten', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.flatten" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.floor">
    <p>def <span class="ident">floor</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.floor, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.floor</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.floor</strong></p>
<div class="codehilite"><pre><span></span>def floor(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.floor</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.floor</code></strong></p>
<div class="codehilite"><pre><span></span>def floor(x, name=None)
</pre></div>


<p>Returns element-wise largest integer not greater than x.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.floor', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.floor" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.floor_layer">
    <p>def <span class="ident">floor_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.floor_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.floor_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.floor_layer</strong></p>
<div class="codehilite"><pre><span></span>def floor_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.floor, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.floor</strong></p>
<div class="codehilite"><pre><span></span>def floor(x, name=None):
</pre></div>


<p>Returns element-wise largest integer not greater than x.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.floor_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.floor_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.floordiv">
    <p>def <span class="ident">floordiv</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.floordiv, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.floordiv</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.floordiv</strong></p>
<div class="codehilite"><pre><span></span>def floordiv(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.floordiv</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.floordiv</code></strong></p>
<div class="codehilite"><pre><span></span>def floordiv(x, y, name=None)
</pre></div>


<p>Divides <code>x / y</code> elementwise, rounding down for floating point.</p>
<p>The same as <code>tf.div(x,y)</code> for integers, but uses <code>tf.floor(tf.div(x,y))</code> for
floating point arguments so that the result is always an integer (though
possibly an integer represented as floating point).  This op is generated by
<code>x // y</code> floor division in Python 3 and in Python 2.7 with
<code>from __future__ import division</code>.</p>
<p>Note that for efficiency, <code>floordiv</code> uses C semantics for negative numbers
(unlike Python and Numpy).</p>
<p><code>x</code> and <code>y</code> must have the same type, and the result will have the same type
as well.</p>
<p>Args:
  x: <code>Tensor</code> numerator of real numeric type.
  y: <code>Tensor</code> denominator of real numeric type.
  name: A name for the operation (optional).</p>
<p>Returns:
  <code>x / y</code> rounded down (except possibly towards zero for negative integers).</p>
<p>Raises:
  TypeError: If the inputs are complex.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.floordiv', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.floordiv" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.floordiv_layer">
    <p>def <span class="ident">floordiv_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.floordiv_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.floordiv_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.floordiv_layer</strong></p>
<div class="codehilite"><pre><span></span>def floordiv_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.floordiv, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.floordiv</strong></p>
<div class="codehilite"><pre><span></span>def floordiv(x, y, name=None):
</pre></div>


<p>Divides <code>x / y</code> elementwise, rounding down for floating point.</p>
<p>The same as <code>tf.div(x,y)</code> for integers, but uses <code>tf.floor(tf.div(x,y))</code> for
floating point arguments so that the result is always an integer (though
possibly an integer represented as floating point).  This op is generated by
<code>x // y</code> floor division in Python 3 and in Python 2.7 with
<code>from __future__ import division</code>.</p>
<p>Note that for efficiency, <code>floordiv</code> uses C semantics for negative numbers
(unlike Python and Numpy).</p>
<p><code>x</code> and <code>y</code> must have the same type, and the result will have the same type
as well.</p>
<p>Args:
  x: <code>Tensor</code> numerator of real numeric type.
  y: <code>Tensor</code> denominator of real numeric type.
  name: A name for the operation (optional).</p>
<p>Returns:
  <code>x / y</code> rounded down (except possibly towards zero for negative integers).</p>
<p>Raises:
  TypeError: If the inputs are complex.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.floordiv_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.floordiv_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.foldl">
    <p>def <span class="ident">foldl</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.foldl, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.foldl</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.foldl</strong></p>
<div class="codehilite"><pre><span></span>def foldl(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.foldl</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.foldl</code></strong></p>
<div class="codehilite"><pre><span></span>def foldl(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)
</pre></div>


<p>foldl on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p>This foldl operator repeatedly applies the callable <code>fn</code> to a sequence
of elements from first to last. The elements are made of the tensors
unpacked from <code>elems</code> on dimension 0. The callable fn takes two tensors as
arguments. The first argument is the accumulated value computed from the
preceding invocation of fn. If <code>initializer</code> is None, <code>elems</code> must contain
at least one element, and its first element is used as the initializer.</p>
<p>Suppose that <code>elems</code> is unpacked into <code>values</code>, a list of tensors. The shape
of the result tensor is fn(initializer, values[0]).shape`.</p>
<p>Args:
  fn: The callable to be performed.
  elems: A tensor to be unpacked on dimension 0.
  initializer: (optional) The initial value for the accumulator.
  parallel_iterations: (optional) The number of iterations allowed to run
                       in parallel.
  back_prop: (optional) True enables back propagation.
  swap_memory: (optional) True enables GPU-CPU memory swapping.
  name: (optional) Name prefix for the returned tensors.</p>
<p>Returns:
  A tensor resulting from applying <code>fn</code> consecutively to the list of tensors
  unpacked from <code>elems</code>, from first to last.</p>
<p>Raises:
  TypeError: if <code>fn</code> is not callable.</p>
<p>Example:
  <code>python
  elems = [1, 2, 3, 4, 5, 6]
  sum = foldl(lambda a, x: a + x, elems)
  # sum == 21</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.foldl', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.foldl" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.foldl_layer">
    <p>def <span class="ident">foldl_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.foldl_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.foldl_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.foldl_layer</strong></p>
<div class="codehilite"><pre><span></span>def foldl_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.foldl, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.foldl</strong></p>
<div class="codehilite"><pre><span></span>def foldl(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None):
</pre></div>


<p>foldl on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p>This foldl operator repeatedly applies the callable <code>fn</code> to a sequence
of elements from first to last. The elements are made of the tensors
unpacked from <code>elems</code> on dimension 0. The callable fn takes two tensors as
arguments. The first argument is the accumulated value computed from the
preceding invocation of fn. If <code>initializer</code> is None, <code>elems</code> must contain
at least one element, and its first element is used as the initializer.</p>
<p>Suppose that <code>elems</code> is unpacked into <code>values</code>, a list of tensors. The shape
of the result tensor is fn(initializer, values[0]).shape`.</p>
<p>Args:
  fn: The callable to be performed.
  elems: A tensor to be unpacked on dimension 0.
  initializer: (optional) The initial value for the accumulator.
  parallel_iterations: (optional) The number of iterations allowed to run
                       in parallel.
  back_prop: (optional) True enables back propagation.
  swap_memory: (optional) True enables GPU-CPU memory swapping.
  name: (optional) Name prefix for the returned tensors.</p>
<p>Returns:
  A tensor resulting from applying <code>fn</code> consecutively to the list of tensors
  unpacked from <code>elems</code>, from first to last.</p>
<p>Raises:
  TypeError: if <code>fn</code> is not callable.</p>
<p>Example:
  <code>python
  elems = [1, 2, 3, 4, 5, 6]
  sum = foldl(lambda a, x: a + x, elems)
  # sum == 21</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.foldl_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.foldl_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.foldr">
    <p>def <span class="ident">foldr</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.foldr, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.foldr</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.foldr</strong></p>
<div class="codehilite"><pre><span></span>def foldr(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.foldr</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.foldr</code></strong></p>
<div class="codehilite"><pre><span></span>def foldr(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)
</pre></div>


<p>foldr on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p>This foldr operator repeatedly applies the callable <code>fn</code> to a sequence
of elements from last to first. The elements are made of the tensors
unpacked from <code>elems</code>. The callable fn takes two tensors as arguments.
The first argument is the accumulated value computed from the preceding
invocation of fn. If <code>initializer</code> is None, <code>elems</code> must contain at least
one element, and its first element is used as the initializer.</p>
<p>Suppose that <code>elems</code> is unpacked into <code>values</code>, a list of tensors. The shape
of the result tensor is <code>fn(initializer, values[0]).shape</code>.</p>
<p>Args:
  fn: The callable to be performed.
  elems: A tensor that is unpacked into a sequence of tensors to apply <code>fn</code>.
  initializer: (optional) The initial value for the accumulator.
  parallel_iterations: (optional) The number of iterations allowed to run
                       in parallel.
  back_prop: (optional) True enables back propagation.
  swap_memory: (optional) True enables GPU-CPU memory swapping.
  name: (optional) Name prefix for the returned tensors.</p>
<p>Returns:
  A tensor resulting from applying <code>fn</code> consecutively to the list of tensors
  unpacked from <code>elems</code>, from last to first.</p>
<p>Raises:
  TypeError: if <code>fn</code> is not callable.</p>
<p>Example:
  <code>python
  elems = [1, 2, 3, 4, 5, 6]
  sum = foldr(lambda a, x: a + x, elems)
  # sum == 21</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.foldr', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.foldr" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.foldr_layer">
    <p>def <span class="ident">foldr_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.foldr_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.foldr_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.foldr_layer</strong></p>
<div class="codehilite"><pre><span></span>def foldr_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.foldr, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.foldr</strong></p>
<div class="codehilite"><pre><span></span>def foldr(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None):
</pre></div>


<p>foldr on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p>This foldr operator repeatedly applies the callable <code>fn</code> to a sequence
of elements from last to first. The elements are made of the tensors
unpacked from <code>elems</code>. The callable fn takes two tensors as arguments.
The first argument is the accumulated value computed from the preceding
invocation of fn. If <code>initializer</code> is None, <code>elems</code> must contain at least
one element, and its first element is used as the initializer.</p>
<p>Suppose that <code>elems</code> is unpacked into <code>values</code>, a list of tensors. The shape
of the result tensor is <code>fn(initializer, values[0]).shape</code>.</p>
<p>Args:
  fn: The callable to be performed.
  elems: A tensor that is unpacked into a sequence of tensors to apply <code>fn</code>.
  initializer: (optional) The initial value for the accumulator.
  parallel_iterations: (optional) The number of iterations allowed to run
                       in parallel.
  back_prop: (optional) True enables back propagation.
  swap_memory: (optional) True enables GPU-CPU memory swapping.
  name: (optional) Name prefix for the returned tensors.</p>
<p>Returns:
  A tensor resulting from applying <code>fn</code> consecutively to the list of tensors
  unpacked from <code>elems</code>, from last to first.</p>
<p>Raises:
  TypeError: if <code>fn</code> is not callable.</p>
<p>Example:
  <code>python
  elems = [1, 2, 3, 4, 5, 6]
  sum = foldr(lambda a, x: a + x, elems)
  # sum == 21</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.foldr_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.foldr_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.fully_connected">
    <p>def <span class="ident">fully_connected</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.fully_connected, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.fully_connected</strong></p>
<div class="codehilite"><pre><span></span>def fully_connected(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.contrib.layers.fully_connected</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.contrib.layers.fully_connected</code></strong></p>
<div class="codehilite"><pre><span></span>def fully_connected()
</pre></div>


<p>Adds a fully connected layer.</p>
<p><code>fully_connected</code> creates a variable called <code>weights</code>, representing a fully
connected weight matrix, which is multiplied by the <code>inputs</code> to produce a
<code>Tensor</code> of hidden units. If a <code>normalizer_fn</code> is provided (such as
<code>batch_norm</code>), it is then applied. Otherwise, if <code>normalizer_fn</code> is
None and a <code>biases_initializer</code> is provided then a <code>biases</code> variable would be
created and added the hidden units. Finally, if <code>activation_fn</code> is not <code>None</code>,
it is applied to the hidden units as well.</p>
<p>Note: that if <code>inputs</code> have a rank greater than 2, then <code>inputs</code> is flattened
prior to the initial matrix multiply by <code>weights</code>.</p>
<p>Args:
  inputs: A tensor of with at least rank 2 and value for the last dimension,
    i.e. <code>[batch_size, depth]</code>, <code>[None, None, None, channels]</code>.
  num_outputs: Integer, the number of output units in the layer.
  activation_fn: activation function.
  normalizer_fn: normalization function to use instead of <code>biases</code>. If
    <code>normalize_fn</code> is provided then <code>biases_initializer</code> and
    <code>biases_regularizer</code> are ignored and <code>biases</code> are not created nor added.
  normalizer_params: normalization function parameters.
  weights_initializer: An initializer for the weights.
  weights_regularizer: Optional regularizer for the weights.
  biases_initializer: An initializer for the biases. If None skip biases.
  biases_regularizer: Optional regularizer for the biases.
  reuse: whether or not the layer and its variables should be reused. To be
    able to reuse the layer scope must be given.
  variables_collections: Optional list of collections for all the variables or
    a dictionary containing a different list of collections per variable.
  outputs_collections: collection to add the outputs.
  trainable: If <code>True</code> also add variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  scope: Optional scope for variable_op_scope.</p>
<p>Returns:
   the tensor variable representing the result of the series of operations.</p>
<p>Raises:
  ValueError: if x has rank less than 2 or if its last dimension is not set.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.fully_connected', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.fully_connected" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.gather">
    <p>def <span class="ident">gather</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.gather, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.gather</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.gather</strong></p>
<div class="codehilite"><pre><span></span>def gather(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.gather</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.gather</code></strong></p>
<div class="codehilite"><pre><span></span>def gather(params, indices, validate_indices=None, name=None)
</pre></div>


<p>Gather slices from <code>params</code> according to <code>indices</code>.</p>
<p><code>indices</code> must be an integer tensor of any dimension (usually 0-D or 1-D).
Produces an output tensor with shape <code>indices.shape + params.shape[1:]</code> where:</p>
<div class="codehilite"><pre><span></span># Scalar indices
output[:, ..., :] = params[indices, :, ... :]

# Vector indices
output[i, :, ..., :] = params[indices[i], :, ... :]

# Higher rank indices
output[i, ..., j, :, ... :] = params[indices[i, ..., j], :, ..., :]
</pre></div>


<p>If <code>indices</code> is a permutation and <code>len(indices) == params.shape[0]</code> then
this operation will permute <code>params</code> accordingly.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/Gather.png" alt>
</div>

<p>Args:
  params: A <code>Tensor</code>.
  indices: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
  validate_indices: An optional <code>bool</code>. Defaults to <code>True</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>params</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.gather', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.gather" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.gather_layer">
    <p>def <span class="ident">gather_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.gather_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.gather_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.gather_layer</strong></p>
<div class="codehilite"><pre><span></span>def gather_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.gather, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.gather</strong></p>
<div class="codehilite"><pre><span></span>def gather(params, indices, validate_indices=None, name=None):
</pre></div>


<p>Gather slices from <code>params</code> according to <code>indices</code>.</p>
<p><code>indices</code> must be an integer tensor of any dimension (usually 0-D or 1-D).
Produces an output tensor with shape <code>indices.shape + params.shape[1:]</code> where:</p>
<div class="codehilite"><pre><span></span># Scalar indices
output[:, ..., :] = params[indices, :, ... :]

# Vector indices
output[i, :, ..., :] = params[indices[i], :, ... :]

# Higher rank indices
output[i, ..., j, :, ... :] = params[indices[i, ..., j], :, ..., :]
</pre></div>


<p>If <code>indices</code> is a permutation and <code>len(indices) == params.shape[0]</code> then
this operation will permute <code>params</code> accordingly.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/Gather.png" alt>
</div>

<p>Args:
  params: A <code>Tensor</code>.
  indices: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
  validate_indices: An optional <code>bool</code>. Defaults to <code>True</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>params</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.gather_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.gather_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.gather_nd">
    <p>def <span class="ident">gather_nd</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.gather_nd, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.gather_nd</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.gather_nd</strong></p>
<div class="codehilite"><pre><span></span>def gather_nd(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.gather_nd</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.gather_nd</code></strong></p>
<div class="codehilite"><pre><span></span>def gather_nd(params, indices, name=None)
</pre></div>


<p>Gather values from <code>params</code> according to <code>indices</code>.</p>
<p><code>indices</code> must be integer tensor, containing indices into <code>params</code>.
It must be shape <code>[d_0, ..., d_N, R]</code> where <code>R</code> is the rank of <code>params</code>.
The innermost dimension of <code>indices</code> (with length <code>R</code>) corresponds to the
indices of <code>params</code>.</p>
<p>Produces an output tensor with shape <code>[d_0, ..., d_{n-1}]</code> where:</p>
<div class="codehilite"><pre><span></span>output[i, j, k, ...] = params[indices[i, j, k, ..., :]]
</pre></div>


<p>e.g. for <code>indices</code> a matrix:</p>
<div class="codehilite"><pre><span></span>output[i] = params[indices[i, :]]
</pre></div>


<p>Args:
  params: A <code>Tensor</code>. R-D.  The tensor from which to gather values.
  indices: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    (N+1)-D.  Index tensor having shape <code>[d_0, ..., d_N, R]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>params</code>.
  N-D.  Values from <code>params</code> gathered from indices given by <code>indices</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.gather_nd', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.gather_nd" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.gather_nd_layer">
    <p>def <span class="ident">gather_nd_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.gather_nd_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.gather_nd_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.gather_nd_layer</strong></p>
<div class="codehilite"><pre><span></span>def gather_nd_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.gather_nd, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.gather_nd</strong></p>
<div class="codehilite"><pre><span></span>def gather_nd(params, indices, name=None):
</pre></div>


<p>Gather values from <code>params</code> according to <code>indices</code>.</p>
<p><code>indices</code> must be integer tensor, containing indices into <code>params</code>.
It must be shape <code>[d_0, ..., d_N, R]</code> where <code>R</code> is the rank of <code>params</code>.
The innermost dimension of <code>indices</code> (with length <code>R</code>) corresponds to the
indices of <code>params</code>.</p>
<p>Produces an output tensor with shape <code>[d_0, ..., d_{n-1}]</code> where:</p>
<div class="codehilite"><pre><span></span>output[i, j, k, ...] = params[indices[i, j, k, ..., :]]
</pre></div>


<p>e.g. for <code>indices</code> a matrix:</p>
<div class="codehilite"><pre><span></span>output[i] = params[indices[i, :]]
</pre></div>


<p>Args:
  params: A <code>Tensor</code>. R-D.  The tensor from which to gather values.
  indices: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    (N+1)-D.  Index tensor having shape <code>[d_0, ..., d_N, R]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>params</code>.
  N-D.  Values from <code>params</code> gathered from indices given by <code>indices</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.gather_nd_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.gather_nd_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_collection">
    <p>def <span class="ident">get_collection</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_collection, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_collection</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_collection</strong></p>
<div class="codehilite"><pre><span></span>def get_collection(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.get_collection</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.get_collection</code></strong></p>
<div class="codehilite"><pre><span></span>def get_collection(key, scope=None)
</pre></div>


<p>Wrapper for <code>Graph.get_collection()</code> using the default graph.</p>
<p>See <a href="../../api_docs/python/framework.md#Graph.get_collection"><code>Graph.get_collection()</code></a>
for more details.</p>
<p>Args:
  key: The key for the collection. For example, the <code>GraphKeys</code> class
    contains many standard names for collections.
  scope: (Optional.) If supplied, the resulting list is filtered to include
    only items whose <code>name</code> attribute matches using <code>re.match</code>. Items
    without a <code>name</code> attribute are never returned if a scope is supplied and
    the choice or <code>re.match</code> means that a <code>scope</code> without special tokens
    filters by prefix.</p>
<p>Returns:
  The list of values in the collection with the given <code>name</code>, or
  an empty list if no value has been added to that collection. The
  list contains the values in the order under which they were
  collected.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_collection', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_collection" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_collection_layer">
    <p>def <span class="ident">get_collection_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_collection_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_collection_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_collection_layer</strong></p>
<div class="codehilite"><pre><span></span>def get_collection_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.get_collection, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.get_collection</strong></p>
<div class="codehilite"><pre><span></span>def get_collection(key, scope=None):
</pre></div>


<p>Wrapper for <code>Graph.get_collection()</code> using the default graph.</p>
<p>See <a href="../../api_docs/python/framework.md#Graph.get_collection"><code>Graph.get_collection()</code></a>
for more details.</p>
<p>Args:
  key: The key for the collection. For example, the <code>GraphKeys</code> class
    contains many standard names for collections.
  scope: (Optional.) If supplied, the resulting list is filtered to include
    only items whose <code>name</code> attribute matches using <code>re.match</code>. Items
    without a <code>name</code> attribute are never returned if a scope is supplied and
    the choice or <code>re.match</code> means that a <code>scope</code> without special tokens
    filters by prefix.</p>
<p>Returns:
  The list of values in the collection with the given <code>name</code>, or
  an empty list if no value has been added to that collection. The
  list contains the values in the order under which they were
  collected.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_collection_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_collection_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_collection_ref">
    <p>def <span class="ident">get_collection_ref</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_collection_ref, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_collection_ref</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_collection_ref</strong></p>
<div class="codehilite"><pre><span></span>def get_collection_ref(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.get_collection_ref</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.get_collection_ref</code></strong></p>
<div class="codehilite"><pre><span></span>def get_collection_ref(key)
</pre></div>


<p>Wrapper for <code>Graph.get_collection_ref()</code> using the default graph.</p>
<p>See <a href="../../api_docs/python/framework.md#Graph.get_collection_ref"><code>Graph.get_collection_ref()</code></a>
for more details.</p>
<p>Args:
  key: The key for the collection. For example, the <code>GraphKeys</code> class
    contains many standard names for collections.</p>
<p>Returns:
  The list of values in the collection with the given <code>name</code>, or an empty
  list if no value has been added to that collection.  Note that this returns
  the collection list itself, which can be modified in place to change the
  collection.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_collection_ref', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_collection_ref" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_collection_ref_layer">
    <p>def <span class="ident">get_collection_ref_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_collection_ref_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_collection_ref_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_collection_ref_layer</strong></p>
<div class="codehilite"><pre><span></span>def get_collection_ref_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.get_collection_ref, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.get_collection_ref</strong></p>
<div class="codehilite"><pre><span></span>def get_collection_ref(key):
</pre></div>


<p>Wrapper for <code>Graph.get_collection_ref()</code> using the default graph.</p>
<p>See <a href="../../api_docs/python/framework.md#Graph.get_collection_ref"><code>Graph.get_collection_ref()</code></a>
for more details.</p>
<p>Args:
  key: The key for the collection. For example, the <code>GraphKeys</code> class
    contains many standard names for collections.</p>
<p>Returns:
  The list of values in the collection with the given <code>name</code>, or an empty
  list if no value has been added to that collection.  Note that this returns
  the collection list itself, which can be modified in place to change the
  collection.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_collection_ref_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_collection_ref_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_default_graph">
    <p>def <span class="ident">get_default_graph</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_default_graph, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_default_graph</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_default_graph</strong></p>
<div class="codehilite"><pre><span></span>def get_default_graph(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.get_default_graph</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.get_default_graph</code></strong></p>
<div class="codehilite"><pre><span></span>def get_default_graph()
</pre></div>


<p>Returns the default graph for the current thread.</p>
<p>The returned graph will be the innermost graph on which a
<code>Graph.as_default()</code> context has been entered, or a global default
graph if none has been explicitly created.</p>
<p>NOTE: The default graph is a property of the current thread. If you
create a new thread, and wish to use the default graph in that
thread, you must explicitly add a <code>with g.as_default():</code> in that
thread's function.</p>
<p>Returns:
  The default <code>Graph</code> being used in the current thread.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_default_graph', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_default_graph" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_default_graph_layer">
    <p>def <span class="ident">get_default_graph_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_default_graph_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_default_graph_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_default_graph_layer</strong></p>
<div class="codehilite"><pre><span></span>def get_default_graph_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.get_default_graph, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.get_default_graph</strong></p>
<div class="codehilite"><pre><span></span>def get_default_graph():
</pre></div>


<p>Returns the default graph for the current thread.</p>
<p>The returned graph will be the innermost graph on which a
<code>Graph.as_default()</code> context has been entered, or a global default
graph if none has been explicitly created.</p>
<p>NOTE: The default graph is a property of the current thread. If you
create a new thread, and wish to use the default graph in that
thread, you must explicitly add a <code>with g.as_default():</code> in that
thread's function.</p>
<p>Returns:
  The default <code>Graph</code> being used in the current thread.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_default_graph_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_default_graph_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_default_session">
    <p>def <span class="ident">get_default_session</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_default_session, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_default_session</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_default_session</strong></p>
<div class="codehilite"><pre><span></span>def get_default_session(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.get_default_session</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.get_default_session</code></strong></p>
<div class="codehilite"><pre><span></span>def get_default_session()
</pre></div>


<p>Returns the default session for the current thread.</p>
<p>The returned <code>Session</code> will be the innermost session on which a
<code>Session</code> or <code>Session.as_default()</code> context has been entered.</p>
<p>NOTE: The default session is a property of the current thread. If you
create a new thread, and wish to use the default session in that
thread, you must explicitly add a <code>with sess.as_default():</code> in that
thread's function.</p>
<p>Returns:
  The default <code>Session</code> being used in the current thread.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_default_session', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_default_session" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_default_session_layer">
    <p>def <span class="ident">get_default_session_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_default_session_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_default_session_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_default_session_layer</strong></p>
<div class="codehilite"><pre><span></span>def get_default_session_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.get_default_session, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.get_default_session</strong></p>
<div class="codehilite"><pre><span></span>def get_default_session():
</pre></div>


<p>Returns the default session for the current thread.</p>
<p>The returned <code>Session</code> will be the innermost session on which a
<code>Session</code> or <code>Session.as_default()</code> context has been entered.</p>
<p>NOTE: The default session is a property of the current thread. If you
create a new thread, and wish to use the default session in that
thread, you must explicitly add a <code>with sess.as_default():</code> in that
thread's function.</p>
<p>Returns:
  The default <code>Session</code> being used in the current thread.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_default_session_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_default_session_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_seed">
    <p>def <span class="ident">get_seed</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_seed, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_seed</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_seed</strong></p>
<div class="codehilite"><pre><span></span>def get_seed(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.get_seed</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.get_seed</code></strong></p>
<div class="codehilite"><pre><span></span>def get_seed(op_seed)
</pre></div>


<p>Returns the local seeds an operation should use given an op-specific seed.</p>
<p>Given operation-specific seed, <code>op_seed</code>, this helper function returns two
seeds derived from graph-level and op-level seeds. Many random operations
internally use the two seeds to allow user to change the seed globally for a
graph, or for only specific operations.</p>
<p>For details on how the graph-level seed interacts with op seeds, see
<a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>.</p>
<p>Args:
  op_seed: integer.</p>
<p>Returns:
  A tuple of two integers that should be used for the local seed of this
  operation.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_seed', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_seed" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_seed_layer">
    <p>def <span class="ident">get_seed_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_seed_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_seed_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_seed_layer</strong></p>
<div class="codehilite"><pre><span></span>def get_seed_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.get_seed, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.get_seed</strong></p>
<div class="codehilite"><pre><span></span>def get_seed(op_seed):
</pre></div>


<p>Returns the local seeds an operation should use given an op-specific seed.</p>
<p>Given operation-specific seed, <code>op_seed</code>, this helper function returns two
seeds derived from graph-level and op-level seeds. Many random operations
internally use the two seeds to allow user to change the seed globally for a
graph, or for only specific operations.</p>
<p>For details on how the graph-level seed interacts with op seeds, see
<a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>.</p>
<p>Args:
  op_seed: integer.</p>
<p>Returns:
  A tuple of two integers that should be used for the local seed of this
  operation.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_seed_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_seed_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_session_handle">
    <p>def <span class="ident">get_session_handle</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_session_handle, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_session_handle</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_session_handle</strong></p>
<div class="codehilite"><pre><span></span>def get_session_handle(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.get_session_handle</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.get_session_handle</code></strong></p>
<div class="codehilite"><pre><span></span>def get_session_handle(data, name=None)
</pre></div>


<p>Return the handle of <code>data</code>.</p>
<p>This is EXPERIMENTAL and subject to change.</p>
<p>Keep <code>data</code> "in-place" in the runtime and create a handle that can be
used to retrieve <code>data</code> in a subsequent run().</p>
<p>Combined with <code>get_session_tensor</code>, we can keep a tensor produced in
one run call in place, and use it as the input in a future run call.
Below is a simple example:</p>
<p>```python
c = tf.mul(a, b)
h = tf.get_session_handle(c)
h = sess.run(h)</p>
<p>p, a = tf.get_session_tensor(tf.float32)
b = tf.mul(a, 10)
c = sess.run(b, feed_dict={p: h.handle})
```</p>
<p>Args:
  data: A tensor to be stored in the session.
  name: Optional name prefix for the return tensor.</p>
<p>Returns:
  A scalar string tensor representing a unique handle for <code>data</code>.</p>
<p>Raises:
  TypeError: if <code>data</code> is not a Tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_session_handle', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_session_handle" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_session_handle_layer">
    <p>def <span class="ident">get_session_handle_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_session_handle_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_session_handle_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_session_handle_layer</strong></p>
<div class="codehilite"><pre><span></span>def get_session_handle_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.get_session_handle, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.get_session_handle</strong></p>
<div class="codehilite"><pre><span></span>def get_session_handle(data, name=None):
</pre></div>


<p>Return the handle of <code>data</code>.</p>
<p>This is EXPERIMENTAL and subject to change.</p>
<p>Keep <code>data</code> "in-place" in the runtime and create a handle that can be
used to retrieve <code>data</code> in a subsequent run().</p>
<p>Combined with <code>get_session_tensor</code>, we can keep a tensor produced in
one run call in place, and use it as the input in a future run call.
Below is a simple example:</p>
<p>```python
c = tf.mul(a, b)
h = tf.get_session_handle(c)
h = sess.run(h)</p>
<p>p, a = tf.get_session_tensor(tf.float32)
b = tf.mul(a, 10)
c = sess.run(b, feed_dict={p: h.handle})
```</p>
<p>Args:
  data: A tensor to be stored in the session.
  name: Optional name prefix for the return tensor.</p>
<p>Returns:
  A scalar string tensor representing a unique handle for <code>data</code>.</p>
<p>Raises:
  TypeError: if <code>data</code> is not a Tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_session_handle_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_session_handle_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_session_tensor">
    <p>def <span class="ident">get_session_tensor</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_session_tensor, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_session_tensor</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_session_tensor</strong></p>
<div class="codehilite"><pre><span></span>def get_session_tensor(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.get_session_tensor</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.get_session_tensor</code></strong></p>
<div class="codehilite"><pre><span></span>def get_session_tensor(dtype, name=None)
</pre></div>


<p>Get the tensor of type <code>dtype</code> by feeding a tensor handle.</p>
<p>This is EXPERIMENTAL and subject to change.</p>
<p>Get the value of the tensor from a tensor handle. The tensor
is produced in a previous run() and stored in the state of the
session.</p>
<p>Args:
  dtype: The type of the output tensor.
  name: Optional name prefix for the return tensor.</p>
<p>Returns:
  A pair of tensors. The first is a placeholder for feeding a
  tensor handle and the second is the tensor in the session state
  keyed by the tensor handle.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_session_tensor', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_session_tensor" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_session_tensor_layer">
    <p>def <span class="ident">get_session_tensor_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_session_tensor_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_session_tensor_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_session_tensor_layer</strong></p>
<div class="codehilite"><pre><span></span>def get_session_tensor_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.get_session_tensor, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.get_session_tensor</strong></p>
<div class="codehilite"><pre><span></span>def get_session_tensor(dtype, name=None):
</pre></div>


<p>Get the tensor of type <code>dtype</code> by feeding a tensor handle.</p>
<p>This is EXPERIMENTAL and subject to change.</p>
<p>Get the value of the tensor from a tensor handle. The tensor
is produced in a previous run() and stored in the state of the
session.</p>
<p>Args:
  dtype: The type of the output tensor.
  name: Optional name prefix for the return tensor.</p>
<p>Returns:
  A pair of tensors. The first is a placeholder for feeding a
  tensor handle and the second is the tensor in the session state
  keyed by the tensor handle.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_session_tensor_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_session_tensor_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_variable">
    <p>def <span class="ident">get_variable</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_variable, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_variable</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_variable</strong></p>
<div class="codehilite"><pre><span></span>def get_variable(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.get_variable</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.get_variable</code></strong></p>
<div class="codehilite"><pre><span></span>def get_variable(name, shape=None, dtype=&lt;dtype: &#39;float32&#39;&gt;, initializer=None, regularizer=None, trainable=True, collections=None, caching_device=None, partitioner=None, validate_shape=True)
</pre></div>


<p>Gets an existing variable with these parameters or create a new one.</p>
<p>This function prefixes the name with the current variable scope
and performs reuse checks. See the
<a href="../../how_tos/variable_scope/index.md">Variable Scope How To</a>
for an extensive description of how reusing works. Here is a basic example:</p>
<p><code>python
with tf.variable_scope("foo"):
    v = tf.get_variable("v", [1])  # v.name == "foo/v:0"
    w = tf.get_variable("w", [1])  # w.name == "foo/w:0"
with tf.variable_scope("foo", reuse=True)
    v1 = tf.get_variable("v")  # The same as v above.</code></p>
<p>If initializer is <code>None</code> (the default), the default initializer passed in
the variable scope will be used. If that one is <code>None</code> too, a
<code>UniformUnitScalingInitializer</code> will be used. The initializer can also be
a Tensor, in which case the variable is initialized to this value and shape.</p>
<p>Similarly, if the regularizer is <code>None</code> (the default), the default regularizer
passed in the variable scope will be used (if that is <code>None</code> too,
then by default no regularization is performed).</p>
<p>If a partitioner is provided, first a sharded <code>Variable</code> is created
via <code>_get_partitioned_variable</code>, and the return value is a
<code>Tensor</code> composed of the shards concatenated along the partition axis.</p>
<p>Some useful partitioners are available.  See, e.g.,
<code>variable_axis_size_partitioner</code>.</p>
<p>Args:
  name: The name of the new or existing variable.
  shape: Shape of the new or existing variable.
  dtype: Type of the new or existing variable (defaults to <code>DT_FLOAT</code>).
  initializer: Initializer for the variable if one is created.
  regularizer: A (Tensor -&gt; Tensor or None) function; the result of
    applying it on a newly created variable will be added to the collection
    GraphKeys.REGULARIZATION_LOSSES and can be used for regularization.
  trainable: If <code>True</code> also add the variable to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  collections: List of graph collections keys to add the Variable to.
    Defaults to <code>[GraphKeys.VARIABLES]</code> (see tf.Variable).
  caching_device: Optional device string or function describing where the
    Variable should be cached for reading.  Defaults to the Variable's
    device.  If not <code>None</code>, caches on another device.  Typical use is to
    cache on the device where the Ops using the Variable reside, to
    deduplicate copying through <code>Switch</code> and other conditional statements.
  partitioner: Optional callable that accepts a fully defined <code>TensorShape</code>
    and <code>dtype</code> of the Variable to be created, and returns a list of
    partitions for each axis (currently only one axis can be partitioned).
  validate_shape: If False, allows the variable to be initialized with a
      value of unknown shape. If True, the default, the shape of initial_value
      must be known.</p>
<p>Returns:
  The created or existing variable.</p>
<p>Raises:
  ValueError: when creating a new variable and shape is not declared,
    or when violating reuse during variable creation. Reuse is set inside
    <code>variable_scope</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_variable', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_variable" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_variable_layer">
    <p>def <span class="ident">get_variable_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_variable_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_variable_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_variable_layer</strong></p>
<div class="codehilite"><pre><span></span>def get_variable_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.get_variable, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.get_variable</strong></p>
<div class="codehilite"><pre><span></span>def get_variable(name, shape=None, dtype=&lt;dtype: &#39;float32&#39;&gt;, initializer=None, regularizer=None, trainable=True, collections=None, caching_device=None, partitioner=None, validate_shape=True):
</pre></div>


<p>Gets an existing variable with these parameters or create a new one.</p>
<p>This function prefixes the name with the current variable scope
and performs reuse checks. See the
<a href="../../how_tos/variable_scope/index.md">Variable Scope How To</a>
for an extensive description of how reusing works. Here is a basic example:</p>
<p><code>python
with tf.variable_scope("foo"):
    v = tf.get_variable("v", [1])  # v.name == "foo/v:0"
    w = tf.get_variable("w", [1])  # w.name == "foo/w:0"
with tf.variable_scope("foo", reuse=True)
    v1 = tf.get_variable("v")  # The same as v above.</code></p>
<p>If initializer is <code>None</code> (the default), the default initializer passed in
the variable scope will be used. If that one is <code>None</code> too, a
<code>UniformUnitScalingInitializer</code> will be used. The initializer can also be
a Tensor, in which case the variable is initialized to this value and shape.</p>
<p>Similarly, if the regularizer is <code>None</code> (the default), the default regularizer
passed in the variable scope will be used (if that is <code>None</code> too,
then by default no regularization is performed).</p>
<p>If a partitioner is provided, first a sharded <code>Variable</code> is created
via <code>_get_partitioned_variable</code>, and the return value is a
<code>Tensor</code> composed of the shards concatenated along the partition axis.</p>
<p>Some useful partitioners are available.  See, e.g.,
<code>variable_axis_size_partitioner</code>.</p>
<p>Args:
  name: The name of the new or existing variable.
  shape: Shape of the new or existing variable.
  dtype: Type of the new or existing variable (defaults to <code>DT_FLOAT</code>).
  initializer: Initializer for the variable if one is created.
  regularizer: A (Tensor -&gt; Tensor or None) function; the result of
    applying it on a newly created variable will be added to the collection
    GraphKeys.REGULARIZATION_LOSSES and can be used for regularization.
  trainable: If <code>True</code> also add the variable to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  collections: List of graph collections keys to add the Variable to.
    Defaults to <code>[GraphKeys.VARIABLES]</code> (see tf.Variable).
  caching_device: Optional device string or function describing where the
    Variable should be cached for reading.  Defaults to the Variable's
    device.  If not <code>None</code>, caches on another device.  Typical use is to
    cache on the device where the Ops using the Variable reside, to
    deduplicate copying through <code>Switch</code> and other conditional statements.
  partitioner: Optional callable that accepts a fully defined <code>TensorShape</code>
    and <code>dtype</code> of the Variable to be created, and returns a list of
    partitions for each axis (currently only one axis can be partitioned).
  validate_shape: If False, allows the variable to be initialized with a
      value of unknown shape. If True, the default, the shape of initial_value
      must be known.</p>
<p>Returns:
  The created or existing variable.</p>
<p>Raises:
  ValueError: when creating a new variable and shape is not declared,
    or when violating reuse during variable creation. Reuse is set inside
    <code>variable_scope</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_variable_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_variable_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_variable_scope">
    <p>def <span class="ident">get_variable_scope</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_variable_scope, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_variable_scope</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_variable_scope</strong></p>
<div class="codehilite"><pre><span></span>def get_variable_scope(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.get_variable_scope</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.get_variable_scope</code></strong></p>
<div class="codehilite"><pre><span></span>def get_variable_scope()
</pre></div>


<p>Returns the current variable scope.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_variable_scope', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_variable_scope" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.get_variable_scope_layer">
    <p>def <span class="ident">get_variable_scope_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.get_variable_scope_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.get_variable_scope_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.get_variable_scope_layer</strong></p>
<div class="codehilite"><pre><span></span>def get_variable_scope_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.get_variable_scope, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.get_variable_scope</strong></p>
<div class="codehilite"><pre><span></span>def get_variable_scope():
</pre></div>


<p>Returns the current variable scope.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.get_variable_scope_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.get_variable_scope_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.global_norm">
    <p>def <span class="ident">global_norm</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.global_norm, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.global_norm</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.global_norm</strong></p>
<div class="codehilite"><pre><span></span>def global_norm(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.global_norm</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.global_norm</code></strong></p>
<div class="codehilite"><pre><span></span>def global_norm(t_list, name=None)
</pre></div>


<p>Computes the global norm of multiple tensors.</p>
<p>Given a tuple or list of tensors <code>t_list</code>, this operation returns the
global norm of the elements in all tensors in <code>t_list</code>. The global norm is
computed as:</p>
<p><code>global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))</code></p>
<p>Any entries in <code>t_list</code> that are of type None are ignored.</p>
<p>Args:
  t_list: A tuple or list of mixed <code>Tensors</code>, <code>IndexedSlices</code>, or None.
  name: A name for the operation (optional).</p>
<p>Returns:
  A 0-D (scalar) <code>Tensor</code> of type <code>float</code>.</p>
<p>Raises:
  TypeError: If <code>t_list</code> is not a sequence.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.global_norm', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.global_norm" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.global_norm_layer">
    <p>def <span class="ident">global_norm_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.global_norm_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.global_norm_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.global_norm_layer</strong></p>
<div class="codehilite"><pre><span></span>def global_norm_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.global_norm, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.global_norm</strong></p>
<div class="codehilite"><pre><span></span>def global_norm(t_list, name=None):
</pre></div>


<p>Computes the global norm of multiple tensors.</p>
<p>Given a tuple or list of tensors <code>t_list</code>, this operation returns the
global norm of the elements in all tensors in <code>t_list</code>. The global norm is
computed as:</p>
<p><code>global_norm = sqrt(sum([l2norm(t)**2 for t in t_list]))</code></p>
<p>Any entries in <code>t_list</code> that are of type None are ignored.</p>
<p>Args:
  t_list: A tuple or list of mixed <code>Tensors</code>, <code>IndexedSlices</code>, or None.
  name: A name for the operation (optional).</p>
<p>Returns:
  A 0-D (scalar) <code>Tensor</code> of type <code>float</code>.</p>
<p>Raises:
  TypeError: If <code>t_list</code> is not a sequence.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.global_norm_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.global_norm_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.gradients">
    <p>def <span class="ident">gradients</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.gradients, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.gradients</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.gradients</strong></p>
<div class="codehilite"><pre><span></span>def gradients(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.gradients</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.gradients</code></strong></p>
<div class="codehilite"><pre><span></span>def gradients(ys, xs, grad_ys=None, name=&quot;gradients&quot;, colocate_gradients_with_ops=False, gate_gradients=False, aggregation_method=None)
</pre></div>


<p>Constructs symbolic partial derivatives of sum of <code>ys</code> w.r.t. x in <code>xs</code>.</p>
<p><code>ys</code> and <code>xs</code> are each a <code>Tensor</code> or a list of tensors.  <code>grad_ys</code>
is a list of <code>Tensor</code>, holding the gradients received by the
<code>ys</code>. The list must be the same length as <code>ys</code>.</p>
<p><code>gradients()</code> adds ops to the graph to output the partial
derivatives of <code>ys</code> with respect to <code>xs</code>.  It returns a list of
<code>Tensor</code> of length <code>len(xs)</code> where each tensor is the <code>sum(dy/dx)</code>
for y in <code>ys</code>.</p>
<p><code>grad_ys</code> is a list of tensors of the same length as <code>ys</code> that holds
the initial gradients for each y in <code>ys</code>.  When <code>grad_ys</code> is None,
we fill in a tensor of '1's of the shape of y for each y in <code>ys</code>.  A
user can provide their own initial <code>grad_ys</code> to compute the
derivatives using a different initial gradient for each y (e.g., if
one wanted to weight the gradient differently for each value in
each y).</p>
<p>Args:
  ys: A <code>Tensor</code> or list of tensors to be differentiated.
  xs: A <code>Tensor</code> or list of tensors to be used for differentiation.
  grad_ys: Optional. A <code>Tensor</code> or list of tensors the same size as
    <code>ys</code> and holding the gradients computed for each y in <code>ys</code>.
  name: Optional name to use for grouping all the gradient ops together.
    defaults to 'gradients'.
  colocate_gradients_with_ops: If True, try colocating gradients with
    the corresponding op.
  gate_gradients: If True, add a tuple around the gradients returned
    for an operations.  This avoids some race conditions.
  aggregation_method: Specifies the method used to combine gradient terms.
    Accepted values are constants defined in the class <code>AggregationMethod</code>.</p>
<p>Returns:
  A list of <code>sum(dy/dx)</code> for each x in <code>xs</code>.</p>
<p>Raises:
  LookupError: if one of the operations between <code>x</code> and <code>y</code> does not
    have a registered gradient function.
  ValueError: if the arguments are invalid.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.gradients', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.gradients" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.gradients_layer">
    <p>def <span class="ident">gradients_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.gradients_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.gradients_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.gradients_layer</strong></p>
<div class="codehilite"><pre><span></span>def gradients_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.gradients, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.gradients</strong></p>
<div class="codehilite"><pre><span></span>def gradients(ys, xs, grad_ys=None, name=&quot;gradients&quot;, colocate_gradients_with_ops=False, gate_gradients=False, aggregation_method=None):
</pre></div>


<p>Constructs symbolic partial derivatives of sum of <code>ys</code> w.r.t. x in <code>xs</code>.</p>
<p><code>ys</code> and <code>xs</code> are each a <code>Tensor</code> or a list of tensors.  <code>grad_ys</code>
is a list of <code>Tensor</code>, holding the gradients received by the
<code>ys</code>. The list must be the same length as <code>ys</code>.</p>
<p><code>gradients()</code> adds ops to the graph to output the partial
derivatives of <code>ys</code> with respect to <code>xs</code>.  It returns a list of
<code>Tensor</code> of length <code>len(xs)</code> where each tensor is the <code>sum(dy/dx)</code>
for y in <code>ys</code>.</p>
<p><code>grad_ys</code> is a list of tensors of the same length as <code>ys</code> that holds
the initial gradients for each y in <code>ys</code>.  When <code>grad_ys</code> is None,
we fill in a tensor of '1's of the shape of y for each y in <code>ys</code>.  A
user can provide their own initial <code>grad_ys</code> to compute the
derivatives using a different initial gradient for each y (e.g., if
one wanted to weight the gradient differently for each value in
each y).</p>
<p>Args:
  ys: A <code>Tensor</code> or list of tensors to be differentiated.
  xs: A <code>Tensor</code> or list of tensors to be used for differentiation.
  grad_ys: Optional. A <code>Tensor</code> or list of tensors the same size as
    <code>ys</code> and holding the gradients computed for each y in <code>ys</code>.
  name: Optional name to use for grouping all the gradient ops together.
    defaults to 'gradients'.
  colocate_gradients_with_ops: If True, try colocating gradients with
    the corresponding op.
  gate_gradients: If True, add a tuple around the gradients returned
    for an operations.  This avoids some race conditions.
  aggregation_method: Specifies the method used to combine gradient terms.
    Accepted values are constants defined in the class <code>AggregationMethod</code>.</p>
<p>Returns:
  A list of <code>sum(dy/dx)</code> for each x in <code>xs</code>.</p>
<p>Raises:
  LookupError: if one of the operations between <code>x</code> and <code>y</code> does not
    have a registered gradient function.
  ValueError: if the arguments are invalid.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.gradients_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.gradients_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.greater">
    <p>def <span class="ident">greater</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.greater, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.greater</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.greater</strong></p>
<div class="codehilite"><pre><span></span>def greater(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.greater</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.greater</code></strong></p>
<div class="codehilite"><pre><span></span>def greater(x, y, name=None)
</pre></div>


<p>Returns the truth value of (x &gt; y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.greater', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.greater" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.greater_equal">
    <p>def <span class="ident">greater_equal</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.greater_equal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.greater_equal</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.greater_equal</strong></p>
<div class="codehilite"><pre><span></span>def greater_equal(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.greater_equal</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.greater_equal</code></strong></p>
<div class="codehilite"><pre><span></span>def greater_equal(x, y, name=None)
</pre></div>


<p>Returns the truth value of (x &gt;= y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.greater_equal', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.greater_equal" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.greater_equal_layer">
    <p>def <span class="ident">greater_equal_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.greater_equal_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.greater_equal_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.greater_equal_layer</strong></p>
<div class="codehilite"><pre><span></span>def greater_equal_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.greater_equal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.greater_equal</strong></p>
<div class="codehilite"><pre><span></span>def greater_equal(x, y, name=None):
</pre></div>


<p>Returns the truth value of (x &gt;= y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.greater_equal_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.greater_equal_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.greater_layer">
    <p>def <span class="ident">greater_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.greater_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.greater_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.greater_layer</strong></p>
<div class="codehilite"><pre><span></span>def greater_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.greater, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.greater</strong></p>
<div class="codehilite"><pre><span></span>def greater(x, y, name=None):
</pre></div>


<p>Returns the truth value of (x &gt; y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.greater_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.greater_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.group">
    <p>def <span class="ident">group</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.group, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.group</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.group</strong></p>
<div class="codehilite"><pre><span></span>def group(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.group</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.group</code></strong></p>
<div class="codehilite"><pre><span></span>def group()
</pre></div>


<p>Create an op that groups multiple operations.</p>
<p>When this op finishes, all ops in <code>input</code> have finished. This op has no
output.</p>
<p>See also <code>tuple</code> and <code>with_dependencies</code>.</p>
<p>Args:
  <em>inputs: Zero or more tensors to group.
  </em>*kwargs: Optional parameters to pass when constructing the NodeDef.
  name: A name for this operation (optional).</p>
<p>Returns:
  An Operation that executes all its inputs.</p>
<p>Raises:
  ValueError: If an unknown keyword argument is provided.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.group', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.group" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.group_layer">
    <p>def <span class="ident">group_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.group_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.group_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.group_layer</strong></p>
<div class="codehilite"><pre><span></span>def group_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.group, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.group</strong></p>
<div class="codehilite"><pre><span></span>def group():
</pre></div>


<p>Create an op that groups multiple operations.</p>
<p>When this op finishes, all ops in <code>input</code> have finished. This op has no
output.</p>
<p>See also <code>tuple</code> and <code>with_dependencies</code>.</p>
<p>Args:
  <em>inputs: Zero or more tensors to group.
  </em>*kwargs: Optional parameters to pass when constructing the NodeDef.
  name: A name for this operation (optional).</p>
<p>Returns:
  An Operation that executes all its inputs.</p>
<p>Raises:
  ValueError: If an unknown keyword argument is provided.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.group_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.group_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.histogram_fixed_width">
    <p>def <span class="ident">histogram_fixed_width</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.histogram_fixed_width, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.histogram_fixed_width</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.histogram_fixed_width</strong></p>
<div class="codehilite"><pre><span></span>def histogram_fixed_width(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.histogram_fixed_width</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.histogram_fixed_width</code></strong></p>
<div class="codehilite"><pre><span></span>def histogram_fixed_width(values, value_range, nbins=100, dtype=&lt;dtype: &#39;int32&#39;&gt;, name=None)
</pre></div>


<p>Return histogram of values.</p>
<p>Given the tensor <code>values</code>, this operation returns a rank 1 histogram counting
the number of entries in <code>values</code> that fell into every bin.  The bins are
equal width and determined by the arguments <code>value_range</code> and <code>nbins</code>.</p>
<p>Args:
  values:  Numeric <code>Tensor</code>.
  value_range:  Shape [2] <code>Tensor</code>.  new_values &lt;= value_range[0] will be
    mapped to hist[0], values &gt;= value_range[1] will be mapped to hist[-1].
    Must be same dtype as new_values.
  nbins:  Scalar <code>int32 Tensor</code>.  Number of histogram bins.
  dtype:  dtype for returned histogram.
  name:  A name for this operation (defaults to 'histogram_fixed_width').</p>
<p>Returns:
  A 1-D <code>Tensor</code> holding histogram of values.</p>
<p>Examples:</p>
<p>```python</p>
<h1>Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)</h1>
<p>nbins = 5
value_range = [0.0, 5.0]
new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]</p>
<p>with tf.default_session() as sess:
  hist = tf.histogram_fixed_width(new_values, value_range, nbins=5)
  variables.initialize_all_variables().run()
  sess.run(hist) =&gt; [2, 1, 1, 0, 2]
```</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.histogram_fixed_width', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.histogram_fixed_width" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.histogram_fixed_width_layer">
    <p>def <span class="ident">histogram_fixed_width_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.histogram_fixed_width_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.histogram_fixed_width_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.histogram_fixed_width_layer</strong></p>
<div class="codehilite"><pre><span></span>def histogram_fixed_width_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.histogram_fixed_width, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.histogram_fixed_width</strong></p>
<div class="codehilite"><pre><span></span>def histogram_fixed_width(values, value_range, nbins=100, dtype=&lt;dtype: &#39;int32&#39;&gt;, name=None):
</pre></div>


<p>Return histogram of values.</p>
<p>Given the tensor <code>values</code>, this operation returns a rank 1 histogram counting
the number of entries in <code>values</code> that fell into every bin.  The bins are
equal width and determined by the arguments <code>value_range</code> and <code>nbins</code>.</p>
<p>Args:
  values:  Numeric <code>Tensor</code>.
  value_range:  Shape [2] <code>Tensor</code>.  new_values &lt;= value_range[0] will be
    mapped to hist[0], values &gt;= value_range[1] will be mapped to hist[-1].
    Must be same dtype as new_values.
  nbins:  Scalar <code>int32 Tensor</code>.  Number of histogram bins.
  dtype:  dtype for returned histogram.
  name:  A name for this operation (defaults to 'histogram_fixed_width').</p>
<p>Returns:
  A 1-D <code>Tensor</code> holding histogram of values.</p>
<p>Examples:</p>
<p>```python</p>
<h1>Bins will be:  (-inf, 1), [1, 2), [2, 3), [3, 4), [4, inf)</h1>
<p>nbins = 5
value_range = [0.0, 5.0]
new_values = [-1.0, 0.0, 1.5, 2.0, 5.0, 15]</p>
<p>with tf.default_session() as sess:
  hist = tf.histogram_fixed_width(new_values, value_range, nbins=5)
  variables.initialize_all_variables().run()
  sess.run(hist) =&gt; [2, 1, 1, 0, 2]
```</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.histogram_fixed_width_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.histogram_fixed_width_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.histogram_summary">
    <p>def <span class="ident">histogram_summary</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.histogram_summary, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.histogram_summary</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.histogram_summary</strong></p>
<div class="codehilite"><pre><span></span>def histogram_summary(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.histogram_summary</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.histogram_summary</code></strong></p>
<div class="codehilite"><pre><span></span>def histogram_summary(tag, values, collections=None, name=None)
</pre></div>


<p>Outputs a <code>Summary</code> protocol buffer with a histogram.</p>
<p>The generated
<a href="https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto"><code>Summary</code></a>
has one summary value containing a histogram for <code>values</code>.</p>
<p>This op reports an <code>InvalidArgument</code> error if any value is not finite.</p>
<p>Args:
  tag: A <code>string</code> <code>Tensor</code>. 0-D.  Tag to use for the summary value.
  values: A real numeric <code>Tensor</code>. Any shape. Values to use to
    build the histogram.
  collections: Optional list of graph collections keys. The new summary op is
    added to these collections. Defaults to <code>[GraphKeys.SUMMARIES]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A scalar <code>Tensor</code> of type <code>string</code>. The serialized <code>Summary</code> protocol
  buffer.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.histogram_summary', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.histogram_summary" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.histogram_summary_layer">
    <p>def <span class="ident">histogram_summary_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.histogram_summary_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.histogram_summary_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.histogram_summary_layer</strong></p>
<div class="codehilite"><pre><span></span>def histogram_summary_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.histogram_summary, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.histogram_summary</strong></p>
<div class="codehilite"><pre><span></span>def histogram_summary(tag, values, collections=None, name=None):
</pre></div>


<p>Outputs a <code>Summary</code> protocol buffer with a histogram.</p>
<p>The generated
<a href="https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto"><code>Summary</code></a>
has one summary value containing a histogram for <code>values</code>.</p>
<p>This op reports an <code>InvalidArgument</code> error if any value is not finite.</p>
<p>Args:
  tag: A <code>string</code> <code>Tensor</code>. 0-D.  Tag to use for the summary value.
  values: A real numeric <code>Tensor</code>. Any shape. Values to use to
    build the histogram.
  collections: Optional list of graph collections keys. The new summary op is
    added to these collections. Defaults to <code>[GraphKeys.SUMMARIES]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A scalar <code>Tensor</code> of type <code>string</code>. The serialized <code>Summary</code> protocol
  buffer.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.histogram_summary_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.histogram_summary_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.identity">
    <p>def <span class="ident">identity</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.identity, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.identity</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.identity</strong></p>
<div class="codehilite"><pre><span></span>def identity(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.identity</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.identity</code></strong></p>
<div class="codehilite"><pre><span></span>def identity(input, name=None)
</pre></div>


<p>Return a tensor with the same shape and contents as the input tensor or value.</p>
<p>Args:
  input: A <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.identity', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.identity" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.identity_layer">
    <p>def <span class="ident">identity_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.identity_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.identity_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.identity_layer</strong></p>
<div class="codehilite"><pre><span></span>def identity_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.identity, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.identity</strong></p>
<div class="codehilite"><pre><span></span>def identity(input, name=None):
</pre></div>


<p>Return a tensor with the same shape and contents as the input tensor or value.</p>
<p>Args:
  input: A <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.identity_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.identity_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ifft">
    <p>def <span class="ident">ifft</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ifft, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ifft</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ifft</strong></p>
<div class="codehilite"><pre><span></span>def ifft(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.ifft</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.ifft</code></strong></p>
<div class="codehilite"><pre><span></span>def ifft(input, name=None)
</pre></div>


<p>Compute the inverse 1-dimensional discrete Fourier Transform.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 vector.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  The inverse 1D Fourier Transform of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ifft', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ifft" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ifft2d">
    <p>def <span class="ident">ifft2d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ifft2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ifft2d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ifft2d</strong></p>
<div class="codehilite"><pre><span></span>def ifft2d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.ifft2d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.ifft2d</code></strong></p>
<div class="codehilite"><pre><span></span>def ifft2d(input, name=None)
</pre></div>


<p>Compute the inverse 2-dimensional discrete Fourier Transform.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 matrix.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  The inverse 2D Fourier Transform of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ifft2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ifft2d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ifft2d_layer">
    <p>def <span class="ident">ifft2d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ifft2d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ifft2d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ifft2d_layer</strong></p>
<div class="codehilite"><pre><span></span>def ifft2d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.ifft2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.ifft2d</strong></p>
<div class="codehilite"><pre><span></span>def ifft2d(input, name=None):
</pre></div>


<p>Compute the inverse 2-dimensional discrete Fourier Transform.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 matrix.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  The inverse 2D Fourier Transform of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ifft2d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ifft2d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ifft3d">
    <p>def <span class="ident">ifft3d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ifft3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ifft3d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ifft3d</strong></p>
<div class="codehilite"><pre><span></span>def ifft3d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.ifft3d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.ifft3d</code></strong></p>
<div class="codehilite"><pre><span></span>def ifft3d(input, name=None)
</pre></div>


<p>Compute the inverse 3-dimensional discrete Fourier Transform.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 3-D tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  The inverse 3D Fourier Transform of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ifft3d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ifft3d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ifft3d_layer">
    <p>def <span class="ident">ifft3d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ifft3d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ifft3d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ifft3d_layer</strong></p>
<div class="codehilite"><pre><span></span>def ifft3d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.ifft3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.ifft3d</strong></p>
<div class="codehilite"><pre><span></span>def ifft3d(input, name=None):
</pre></div>


<p>Compute the inverse 3-dimensional discrete Fourier Transform.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 3-D tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  The inverse 3D Fourier Transform of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ifft3d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ifft3d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ifft_layer">
    <p>def <span class="ident">ifft_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ifft_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ifft_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ifft_layer</strong></p>
<div class="codehilite"><pre><span></span>def ifft_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.ifft, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.ifft</strong></p>
<div class="codehilite"><pre><span></span>def ifft(input, name=None):
</pre></div>


<p>Compute the inverse 1-dimensional discrete Fourier Transform.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>complex64</code>. A complex64 vector.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>complex64</code>.
  The inverse 1D Fourier Transform of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ifft_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ifft_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.igamma">
    <p>def <span class="ident">igamma</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.igamma, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.igamma</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.igamma</strong></p>
<div class="codehilite"><pre><span></span>def igamma(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.igamma</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.igamma</code></strong></p>
<div class="codehilite"><pre><span></span>def igamma(a, x, name=None)
</pre></div>


<p>Compute the lower regularized incomplete Gamma function <code>Q(a, x)</code>.</p>
<p>The lower regularized incomplete Gamma function is defined as:</p>
<p><code>P(a, x) = gamma(a, x) / Gamma(x) = 1 - Q(a, x)</code>
where
<code>gamma(a, x) = int_{0}^{x} t^{a-1} exp(-t) dt</code>
is the lower incomplete Gamma function.</p>
<p>Note, above <code>Q(a, x)</code> (<code>Igammac</code>) is the upper regularized complete
Gamma function.</p>
<p>Args:
  a: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  x: A <code>Tensor</code>. Must have the same type as <code>a</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>a</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.igamma', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.igamma" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.igamma_layer">
    <p>def <span class="ident">igamma_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.igamma_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.igamma_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.igamma_layer</strong></p>
<div class="codehilite"><pre><span></span>def igamma_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.igamma, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.igamma</strong></p>
<div class="codehilite"><pre><span></span>def igamma(a, x, name=None):
</pre></div>


<p>Compute the lower regularized incomplete Gamma function <code>Q(a, x)</code>.</p>
<p>The lower regularized incomplete Gamma function is defined as:</p>
<p><code>P(a, x) = gamma(a, x) / Gamma(x) = 1 - Q(a, x)</code>
where
<code>gamma(a, x) = int_{0}^{x} t^{a-1} exp(-t) dt</code>
is the lower incomplete Gamma function.</p>
<p>Note, above <code>Q(a, x)</code> (<code>Igammac</code>) is the upper regularized complete
Gamma function.</p>
<p>Args:
  a: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  x: A <code>Tensor</code>. Must have the same type as <code>a</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>a</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.igamma_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.igamma_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.igammac">
    <p>def <span class="ident">igammac</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.igammac, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.igammac</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.igammac</strong></p>
<div class="codehilite"><pre><span></span>def igammac(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.igammac</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.igammac</code></strong></p>
<div class="codehilite"><pre><span></span>def igammac(a, x, name=None)
</pre></div>


<p>Compute the upper regularized incomplete Gamma function <code>Q(a, x)</code>.</p>
<p>The upper regularized incomplete Gamma function is defined as:</p>
<p><code>Q(a, x) = Gamma(a, x) / Gamma(x) = 1 - P(a, x)</code>
where
<code>Gamma(a, x) = int_{x}^{\infty} t^{a-1} exp(-t) dt</code>
is the upper incomplete Gama function.</p>
<p>Note, above <code>P(a, x)</code> (<code>Igamma</code>) is the lower regularized complete
Gamma function.</p>
<p>Args:
  a: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  x: A <code>Tensor</code>. Must have the same type as <code>a</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>a</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.igammac', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.igammac" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.igammac_layer">
    <p>def <span class="ident">igammac_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.igammac_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.igammac_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.igammac_layer</strong></p>
<div class="codehilite"><pre><span></span>def igammac_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.igammac, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.igammac</strong></p>
<div class="codehilite"><pre><span></span>def igammac(a, x, name=None):
</pre></div>


<p>Compute the upper regularized incomplete Gamma function <code>Q(a, x)</code>.</p>
<p>The upper regularized incomplete Gamma function is defined as:</p>
<p><code>Q(a, x) = Gamma(a, x) / Gamma(x) = 1 - P(a, x)</code>
where
<code>Gamma(a, x) = int_{x}^{\infty} t^{a-1} exp(-t) dt</code>
is the upper incomplete Gama function.</p>
<p>Note, above <code>P(a, x)</code> (<code>Igamma</code>) is the lower regularized complete
Gamma function.</p>
<p>Args:
  a: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  x: A <code>Tensor</code>. Must have the same type as <code>a</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>a</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.igammac_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.igammac_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.imag">
    <p>def <span class="ident">imag</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.imag, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.imag</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.imag</strong></p>
<div class="codehilite"><pre><span></span>def imag(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.imag</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.imag</code></strong></p>
<div class="codehilite"><pre><span></span>def imag(input, name=None)
</pre></div>


<p>Returns the imaginary part of a complex number.</p>
<p>Given a tensor <code>input</code> of complex numbers, this operation returns a tensor of
type <code>float</code> or <code>double</code> that is the imaginary part of each element in
<code>input</code>. All elements in <code>input</code> must be complex numbers of the form (a +
bj), where <em>a</em> is the real part and <em>b</em> is the imaginary part returned by
this operation.</p>
<p>For example:</p>
<p>```</p>
<h1>tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]</h1>
<p>tf.imag(input) ==&gt; [4.75, 5.75]
```</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>float</code> or <code>double</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.imag', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.imag" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.imag_layer">
    <p>def <span class="ident">imag_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.imag_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.imag_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.imag_layer</strong></p>
<div class="codehilite"><pre><span></span>def imag_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.imag, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.imag</strong></p>
<div class="codehilite"><pre><span></span>def imag(input, name=None):
</pre></div>


<p>Returns the imaginary part of a complex number.</p>
<p>Given a tensor <code>input</code> of complex numbers, this operation returns a tensor of
type <code>float</code> or <code>double</code> that is the imaginary part of each element in
<code>input</code>. All elements in <code>input</code> must be complex numbers of the form (a +
bj), where <em>a</em> is the real part and <em>b</em> is the imaginary part returned by
this operation.</p>
<p>For example:</p>
<p>```</p>
<h1>tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]</h1>
<p>tf.imag(input) ==&gt; [4.75, 5.75]
```</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>float</code> or <code>double</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.imag_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.imag_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.image_summary">
    <p>def <span class="ident">image_summary</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.image_summary, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.image_summary</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.image_summary</strong></p>
<div class="codehilite"><pre><span></span>def image_summary(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.image_summary</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.image_summary</code></strong></p>
<div class="codehilite"><pre><span></span>def image_summary(tag, tensor, max_images=3, collections=None, name=None)
</pre></div>


<p>Outputs a <code>Summary</code> protocol buffer with images.</p>
<p>The summary has up to <code>max_images</code> summary values containing images. The
images are built from <code>tensor</code> which must be 4-D with shape <code>[batch_size,
height, width, channels]</code> and where <code>channels</code> can be:</p>
<ul>
<li>1: <code>tensor</code> is interpreted as Grayscale.</li>
<li>3: <code>tensor</code> is interpreted as RGB.</li>
<li>4: <code>tensor</code> is interpreted as RGBA.</li>
</ul>
<p>The images have the same number of channels as the input tensor. For float
input, the values are normalized one image at a time to fit in the range
<code>[0, 255]</code>.  <code>uint8</code> values are unchanged.  The op uses two different
normalization algorithms:</p>
<ul>
<li>
<p>If the input values are all positive, they are rescaled so the largest one
   is 255.</p>
</li>
<li>
<p>If any input value is negative, the values are shifted so input value 0.0
   is at 127.  They are then rescaled so that either the smallest value is 0,
   or the largest one is 255.</p>
</li>
</ul>
<p>The <code>tag</code> argument is a scalar <code>Tensor</code> of type <code>string</code>.  It is used to
build the <code>tag</code> of the summary values:</p>
<ul>
<li>If <code>max_images</code> is 1, the summary value tag is '<em>tag</em>/image'.</li>
<li>If <code>max_images</code> is greater than 1, the summary value tags are
   generated sequentially as '<em>tag</em>/image/0', '<em>tag</em>/image/1', etc.</li>
</ul>
<p>Args:
  tag: A scalar <code>Tensor</code> of type <code>string</code>. Used to build the <code>tag</code>
    of the summary values.
  tensor: A 4-D <code>uint8</code> or <code>float32</code> <code>Tensor</code> of shape <code>[batch_size, height,
    width, channels]</code> where <code>channels</code> is 1, 3, or 4.
  max_images: Max number of batch elements to generate images for.
  collections: Optional list of ops.GraphKeys.  The collections to add the
    summary to.  Defaults to [ops.GraphKeys.SUMMARIES]
  name: A name for the operation (optional).</p>
<p>Returns:
  A scalar <code>Tensor</code> of type <code>string</code>. The serialized <code>Summary</code> protocol
  buffer.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.image_summary', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.image_summary" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.image_summary_layer">
    <p>def <span class="ident">image_summary_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.image_summary_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.image_summary_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.image_summary_layer</strong></p>
<div class="codehilite"><pre><span></span>def image_summary_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.image_summary, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.image_summary</strong></p>
<div class="codehilite"><pre><span></span>def image_summary(tag, tensor, max_images=3, collections=None, name=None):
</pre></div>


<p>Outputs a <code>Summary</code> protocol buffer with images.</p>
<p>The summary has up to <code>max_images</code> summary values containing images. The
images are built from <code>tensor</code> which must be 4-D with shape <code>[batch_size,
height, width, channels]</code> and where <code>channels</code> can be:</p>
<ul>
<li>1: <code>tensor</code> is interpreted as Grayscale.</li>
<li>3: <code>tensor</code> is interpreted as RGB.</li>
<li>4: <code>tensor</code> is interpreted as RGBA.</li>
</ul>
<p>The images have the same number of channels as the input tensor. For float
input, the values are normalized one image at a time to fit in the range
<code>[0, 255]</code>.  <code>uint8</code> values are unchanged.  The op uses two different
normalization algorithms:</p>
<ul>
<li>
<p>If the input values are all positive, they are rescaled so the largest one
   is 255.</p>
</li>
<li>
<p>If any input value is negative, the values are shifted so input value 0.0
   is at 127.  They are then rescaled so that either the smallest value is 0,
   or the largest one is 255.</p>
</li>
</ul>
<p>The <code>tag</code> argument is a scalar <code>Tensor</code> of type <code>string</code>.  It is used to
build the <code>tag</code> of the summary values:</p>
<ul>
<li>If <code>max_images</code> is 1, the summary value tag is '<em>tag</em>/image'.</li>
<li>If <code>max_images</code> is greater than 1, the summary value tags are
   generated sequentially as '<em>tag</em>/image/0', '<em>tag</em>/image/1', etc.</li>
</ul>
<p>Args:
  tag: A scalar <code>Tensor</code> of type <code>string</code>. Used to build the <code>tag</code>
    of the summary values.
  tensor: A 4-D <code>uint8</code> or <code>float32</code> <code>Tensor</code> of shape <code>[batch_size, height,
    width, channels]</code> where <code>channels</code> is 1, 3, or 4.
  max_images: Max number of batch elements to generate images for.
  collections: Optional list of ops.GraphKeys.  The collections to add the
    summary to.  Defaults to [ops.GraphKeys.SUMMARIES]
  name: A name for the operation (optional).</p>
<p>Returns:
  A scalar <code>Tensor</code> of type <code>string</code>. The serialized <code>Summary</code> protocol
  buffer.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.image_summary_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.image_summary_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.import_graph_def">
    <p>def <span class="ident">import_graph_def</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.import_graph_def, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.import_graph_def</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.import_graph_def</strong></p>
<div class="codehilite"><pre><span></span>def import_graph_def(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.import_graph_def</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.import_graph_def</code></strong></p>
<div class="codehilite"><pre><span></span>def import_graph_def(graph_def, input_map=None, return_elements=None, name=None, op_dict=None, producer_op_list=None)
</pre></div>


<p>Imports the TensorFlow graph in <code>graph_def</code> into the Python <code>Graph</code>.</p>
<p>This function provides a way to import a serialized TensorFlow
<a href="https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto"><code>GraphDef</code></a>
protocol buffer, and extract individual objects in the <code>GraphDef</code> as
<a href="#Tensor"><code>Tensor</code></a> and <a href="#Operation"><code>Operation</code></a> objects. See
<a href="#Graph.as_graph_def"><code>Graph.as_graph_def()</code></a> for a way to create a
<code>GraphDef</code> proto.</p>
<p>Args:
  graph_def: A <code>GraphDef</code> proto containing operations to be imported into
    the default graph.
  input_map: A dictionary mapping input names (as strings) in <code>graph_def</code>
    to <code>Tensor</code> objects. The values of the named input tensors in the
    imported graph will be re-mapped to the respective <code>Tensor</code> values.
  return_elements: A list of strings containing operation names in
    <code>graph_def</code> that will be returned as <code>Operation</code> objects; and/or
    tensor names in <code>graph_def</code> that will be returned as <code>Tensor</code> objects.
  name: (Optional.) A prefix that will be prepended to the names in
    <code>graph_def</code>. Defaults to <code>"import"</code>.
  op_dict: (Optional.) A dictionary mapping op type names to <code>OpDef</code> protos.
    Must contain an <code>OpDef</code> proto for each op type named in <code>graph_def</code>.
    If omitted, uses the <code>OpDef</code> protos registered in the global registry.
  producer_op_list: (Optional.) An <code>OpList</code> proto with the (possibly stripped)
    list of <code>OpDef</code>s used by the producer of the graph. If provided, attrs
    for ops in <code>graph_def</code> that are not in <code>op_dict</code> that have their default
    value according to <code>producer_op_list</code> will be removed. This will allow
    some more <code>GraphDef</code>s produced by later binaries to be accepted by
    earlier binaries.</p>
<p>Returns:
  A list of <code>Operation</code> and/or <code>Tensor</code> objects from the imported graph,
  corresponding to the names in <code>return_elements</code>.</p>
<p>Raises:
  TypeError: If <code>graph_def</code> is not a <code>GraphDef</code> proto,
    <code>input_map</code> is not a dictionary mapping strings to <code>Tensor</code> objects,
    or <code>return_elements</code> is not a list of strings.
  ValueError: If <code>input_map</code>, or <code>return_elements</code> contains names that
    do not appear in <code>graph_def</code>, or <code>graph_def</code> is not well-formed (e.g.
    it refers to an unknown tensor).</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.import_graph_def', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.import_graph_def" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.import_graph_def_layer">
    <p>def <span class="ident">import_graph_def_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.import_graph_def_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.import_graph_def_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.import_graph_def_layer</strong></p>
<div class="codehilite"><pre><span></span>def import_graph_def_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.import_graph_def, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.import_graph_def</strong></p>
<div class="codehilite"><pre><span></span>def import_graph_def(graph_def, input_map=None, return_elements=None, name=None, op_dict=None, producer_op_list=None):
</pre></div>


<p>Imports the TensorFlow graph in <code>graph_def</code> into the Python <code>Graph</code>.</p>
<p>This function provides a way to import a serialized TensorFlow
<a href="https://www.tensorflow.org/code/tensorflow/core/framework/graph.proto"><code>GraphDef</code></a>
protocol buffer, and extract individual objects in the <code>GraphDef</code> as
<a href="#Tensor"><code>Tensor</code></a> and <a href="#Operation"><code>Operation</code></a> objects. See
<a href="#Graph.as_graph_def"><code>Graph.as_graph_def()</code></a> for a way to create a
<code>GraphDef</code> proto.</p>
<p>Args:
  graph_def: A <code>GraphDef</code> proto containing operations to be imported into
    the default graph.
  input_map: A dictionary mapping input names (as strings) in <code>graph_def</code>
    to <code>Tensor</code> objects. The values of the named input tensors in the
    imported graph will be re-mapped to the respective <code>Tensor</code> values.
  return_elements: A list of strings containing operation names in
    <code>graph_def</code> that will be returned as <code>Operation</code> objects; and/or
    tensor names in <code>graph_def</code> that will be returned as <code>Tensor</code> objects.
  name: (Optional.) A prefix that will be prepended to the names in
    <code>graph_def</code>. Defaults to <code>"import"</code>.
  op_dict: (Optional.) A dictionary mapping op type names to <code>OpDef</code> protos.
    Must contain an <code>OpDef</code> proto for each op type named in <code>graph_def</code>.
    If omitted, uses the <code>OpDef</code> protos registered in the global registry.
  producer_op_list: (Optional.) An <code>OpList</code> proto with the (possibly stripped)
    list of <code>OpDef</code>s used by the producer of the graph. If provided, attrs
    for ops in <code>graph_def</code> that are not in <code>op_dict</code> that have their default
    value according to <code>producer_op_list</code> will be removed. This will allow
    some more <code>GraphDef</code>s produced by later binaries to be accepted by
    earlier binaries.</p>
<p>Returns:
  A list of <code>Operation</code> and/or <code>Tensor</code> objects from the imported graph,
  corresponding to the names in <code>return_elements</code>.</p>
<p>Raises:
  TypeError: If <code>graph_def</code> is not a <code>GraphDef</code> proto,
    <code>input_map</code> is not a dictionary mapping strings to <code>Tensor</code> objects,
    or <code>return_elements</code> is not a list of strings.
  ValueError: If <code>input_map</code>, or <code>return_elements</code> contains names that
    do not appear in <code>graph_def</code>, or <code>graph_def</code> is not well-formed (e.g.
    it refers to an unknown tensor).</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.import_graph_def_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.import_graph_def_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.in_top_k">
    <p>def <span class="ident">in_top_k</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.in_top_k, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.in_top_k</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.in_top_k</strong></p>
<div class="codehilite"><pre><span></span>def in_top_k(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.in_top_k</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.in_top_k</code></strong></p>
<div class="codehilite"><pre><span></span>def in_top_k(predictions, targets, k, name=None)
</pre></div>


<p>Says whether the targets are in the top <code>K</code> predictions.</p>
<p>This outputs a <code>batch_size</code> bool array, an entry <code>out[i]</code> is <code>true</code> if the
prediction for the target class is among the top <code>k</code> predictions among
all predictions for example <code>i</code>. Note that the behavior of <code>InTopK</code> differs
from the <code>TopK</code> op in its handling of ties; if multiple classes have the
same prediction value and straddle the top-<code>k</code> boundary, all of those
classes are considered to be in the top <code>k</code>.</p>
<p>More formally, let</p>
<p>\(predictions_i\) be the predictions for all classes for example <code>i</code>,
  \(targets_i\) be the target class for example <code>i</code>,
  \(out_i\) be the output for example <code>i</code>,</p>
<p>$$out_i = predictions_{i, targets_i} \in TopKIncludingTies(predictions_i)$$</p>
<p>Args:
  predictions: A <code>Tensor</code> of type <code>float32</code>.
    A <code>batch_size</code> x <code>classes</code> tensor.
  targets: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A <code>batch_size</code> vector of class ids.
  k: An <code>int</code>. Number of top elements to look at for computing precision.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>. Computed Precision at <code>k</code> as a <code>bool Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.in_top_k', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.in_top_k" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.in_top_k_layer">
    <p>def <span class="ident">in_top_k_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.in_top_k_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.in_top_k_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.in_top_k_layer</strong></p>
<div class="codehilite"><pre><span></span>def in_top_k_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.in_top_k, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.in_top_k</strong></p>
<div class="codehilite"><pre><span></span>def in_top_k(predictions, targets, k, name=None):
</pre></div>


<p>Says whether the targets are in the top <code>K</code> predictions.</p>
<p>This outputs a <code>batch_size</code> bool array, an entry <code>out[i]</code> is <code>true</code> if the
prediction for the target class is among the top <code>k</code> predictions among
all predictions for example <code>i</code>. Note that the behavior of <code>InTopK</code> differs
from the <code>TopK</code> op in its handling of ties; if multiple classes have the
same prediction value and straddle the top-<code>k</code> boundary, all of those
classes are considered to be in the top <code>k</code>.</p>
<p>More formally, let</p>
<p>\(predictions_i\) be the predictions for all classes for example <code>i</code>,
  \(targets_i\) be the target class for example <code>i</code>,
  \(out_i\) be the output for example <code>i</code>,</p>
<p>$$out_i = predictions_{i, targets_i} \in TopKIncludingTies(predictions_i)$$</p>
<p>Args:
  predictions: A <code>Tensor</code> of type <code>float32</code>.
    A <code>batch_size</code> x <code>classes</code> tensor.
  targets: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A <code>batch_size</code> vector of class ids.
  k: An <code>int</code>. Number of top elements to look at for computing precision.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>. Computed Precision at <code>k</code> as a <code>bool Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.in_top_k_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.in_top_k_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.initialize_all_tables">
    <p>def <span class="ident">initialize_all_tables</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.initialize_all_tables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.initialize_all_tables</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.initialize_all_tables</strong></p>
<div class="codehilite"><pre><span></span>def initialize_all_tables(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.initialize_all_tables</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.initialize_all_tables</code></strong></p>
<div class="codehilite"><pre><span></span>def initialize_all_tables(name=&quot;init_all_tables&quot;)
</pre></div>


<p>Returns an Op that initializes all tables of the default graph.</p>
<p>Args:
  name: Optional name for the initialization op.</p>
<p>Returns:
  An Op that initializes all tables.  Note that if there are
  not tables the returned Op is a NoOp.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.initialize_all_tables', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.initialize_all_tables" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.initialize_all_tables_layer">
    <p>def <span class="ident">initialize_all_tables_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.initialize_all_tables_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.initialize_all_tables_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.initialize_all_tables_layer</strong></p>
<div class="codehilite"><pre><span></span>def initialize_all_tables_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.initialize_all_tables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.initialize_all_tables</strong></p>
<div class="codehilite"><pre><span></span>def initialize_all_tables(name=&quot;init_all_tables&quot;):
</pre></div>


<p>Returns an Op that initializes all tables of the default graph.</p>
<p>Args:
  name: Optional name for the initialization op.</p>
<p>Returns:
  An Op that initializes all tables.  Note that if there are
  not tables the returned Op is a NoOp.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.initialize_all_tables_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.initialize_all_tables_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.initialize_all_variables">
    <p>def <span class="ident">initialize_all_variables</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.initialize_all_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.initialize_all_variables</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.initialize_all_variables</strong></p>
<div class="codehilite"><pre><span></span>def initialize_all_variables(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.initialize_all_variables</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.initialize_all_variables</code></strong></p>
<div class="codehilite"><pre><span></span>def initialize_all_variables()
</pre></div>


<p>Returns an Op that initializes all variables.</p>
<p>This is just a shortcut for <code>initialize_variables(all_variables())</code></p>
<p>Returns:
  An Op that initializes all variables in the graph.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.initialize_all_variables', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.initialize_all_variables" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.initialize_all_variables_layer">
    <p>def <span class="ident">initialize_all_variables_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.initialize_all_variables_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.initialize_all_variables_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.initialize_all_variables_layer</strong></p>
<div class="codehilite"><pre><span></span>def initialize_all_variables_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.initialize_all_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.initialize_all_variables</strong></p>
<div class="codehilite"><pre><span></span>def initialize_all_variables():
</pre></div>


<p>Returns an Op that initializes all variables.</p>
<p>This is just a shortcut for <code>initialize_variables(all_variables())</code></p>
<p>Returns:
  An Op that initializes all variables in the graph.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.initialize_all_variables_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.initialize_all_variables_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.initialize_local_variables">
    <p>def <span class="ident">initialize_local_variables</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.initialize_local_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.initialize_local_variables</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.initialize_local_variables</strong></p>
<div class="codehilite"><pre><span></span>def initialize_local_variables(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.initialize_local_variables</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.initialize_local_variables</code></strong></p>
<div class="codehilite"><pre><span></span>def initialize_local_variables()
</pre></div>


<p>Returns an Op that initializes all local variables.</p>
<p>This is just a shortcut for <code>initialize_variables(local_variables())</code></p>
<p>Returns:
  An Op that initializes all local variables in the graph.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.initialize_local_variables', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.initialize_local_variables" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.initialize_local_variables_layer">
    <p>def <span class="ident">initialize_local_variables_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.initialize_local_variables_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.initialize_local_variables_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.initialize_local_variables_layer</strong></p>
<div class="codehilite"><pre><span></span>def initialize_local_variables_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.initialize_local_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.initialize_local_variables</strong></p>
<div class="codehilite"><pre><span></span>def initialize_local_variables():
</pre></div>


<p>Returns an Op that initializes all local variables.</p>
<p>This is just a shortcut for <code>initialize_variables(local_variables())</code></p>
<p>Returns:
  An Op that initializes all local variables in the graph.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.initialize_local_variables_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.initialize_local_variables_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.initialize_variables">
    <p>def <span class="ident">initialize_variables</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.initialize_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.initialize_variables</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.initialize_variables</strong></p>
<div class="codehilite"><pre><span></span>def initialize_variables(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.initialize_variables</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.initialize_variables</code></strong></p>
<div class="codehilite"><pre><span></span>def initialize_variables(var_list, name=&quot;init&quot;)
</pre></div>


<p>Returns an Op that initializes a list of variables.</p>
<p>After you launch the graph in a session, you can run the returned Op to
initialize all the variables in <code>var_list</code>. This Op runs all the
initializers of the variables in <code>var_list</code> in parallel.</p>
<p>Calling <code>initialize_variables()</code> is equivalent to passing the list of
initializers to <code>Group()</code>.</p>
<p>If <code>var_list</code> is empty, however, the function still returns an Op that can
be run. That Op just has no effect.</p>
<p>Args:
  var_list: List of <code>Variable</code> objects to initialize.
  name: Optional name for the returned operation.</p>
<p>Returns:
  An Op that run the initializers of all the specified variables.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.initialize_variables', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.initialize_variables" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.initialize_variables_layer">
    <p>def <span class="ident">initialize_variables_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.initialize_variables_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.initialize_variables_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.initialize_variables_layer</strong></p>
<div class="codehilite"><pre><span></span>def initialize_variables_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.initialize_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.initialize_variables</strong></p>
<div class="codehilite"><pre><span></span>def initialize_variables(var_list, name=&quot;init&quot;):
</pre></div>


<p>Returns an Op that initializes a list of variables.</p>
<p>After you launch the graph in a session, you can run the returned Op to
initialize all the variables in <code>var_list</code>. This Op runs all the
initializers of the variables in <code>var_list</code> in parallel.</p>
<p>Calling <code>initialize_variables()</code> is equivalent to passing the list of
initializers to <code>Group()</code>.</p>
<p>If <code>var_list</code> is empty, however, the function still returns an Op that can
be run. That Op just has no effect.</p>
<p>Args:
  var_list: List of <code>Variable</code> objects to initialize.
  name: Optional name for the returned operation.</p>
<p>Returns:
  An Op that run the initializers of all the specified variables.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.initialize_variables_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.initialize_variables_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.inv">
    <p>def <span class="ident">inv</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.inv, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.inv</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.inv</strong></p>
<div class="codehilite"><pre><span></span>def inv(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.inv</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.inv</code></strong></p>
<div class="codehilite"><pre><span></span>def inv(x, name=None)
</pre></div>


<p>Computes the reciprocal of x element-wise.</p>
<p>I.e., \(y = 1 / x\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.inv', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.inv" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.inv_layer">
    <p>def <span class="ident">inv_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.inv_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.inv_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.inv_layer</strong></p>
<div class="codehilite"><pre><span></span>def inv_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.inv, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.inv</strong></p>
<div class="codehilite"><pre><span></span>def inv(x, name=None):
</pre></div>


<p>Computes the reciprocal of x element-wise.</p>
<p>I.e., \(y = 1 / x\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.inv_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.inv_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.invert_permutation">
    <p>def <span class="ident">invert_permutation</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.invert_permutation, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.invert_permutation</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.invert_permutation</strong></p>
<div class="codehilite"><pre><span></span>def invert_permutation(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.invert_permutation</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.invert_permutation</code></strong></p>
<div class="codehilite"><pre><span></span>def invert_permutation(x, name=None)
</pre></div>


<p>Computes the inverse permutation of a tensor.</p>
<p>This operation computes the inverse of an index permutation. It takes a 1-D
integer tensor <code>x</code>, which represents the indices of a zero-based array, and
swaps each value with its index position. In other words, for an output tensor
<code>y</code> and an input tensor <code>x</code>, this operation computes the following:</p>
<p><code>y[x[i]] = i for i in [0, 1, ..., len(x) - 1]</code></p>
<p>The values must include 0. There can be no duplicate values or negative values.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>tensor <code>x</code> is [3, 4, 0, 2, 1]</h1>
<p>invert_permutation(x) ==&gt; [2, 4, 3, 0, 1]
```</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>int32</code>. 1-D.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int32</code>. 1-D.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.invert_permutation', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.invert_permutation" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.invert_permutation_layer">
    <p>def <span class="ident">invert_permutation_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.invert_permutation_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.invert_permutation_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.invert_permutation_layer</strong></p>
<div class="codehilite"><pre><span></span>def invert_permutation_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.invert_permutation, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.invert_permutation</strong></p>
<div class="codehilite"><pre><span></span>def invert_permutation(x, name=None):
</pre></div>


<p>Computes the inverse permutation of a tensor.</p>
<p>This operation computes the inverse of an index permutation. It takes a 1-D
integer tensor <code>x</code>, which represents the indices of a zero-based array, and
swaps each value with its index position. In other words, for an output tensor
<code>y</code> and an input tensor <code>x</code>, this operation computes the following:</p>
<p><code>y[x[i]] = i for i in [0, 1, ..., len(x) - 1]</code></p>
<p>The values must include 0. There can be no duplicate values or negative values.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>tensor <code>x</code> is [3, 4, 0, 2, 1]</h1>
<p>invert_permutation(x) ==&gt; [2, 4, 3, 0, 1]
```</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>int32</code>. 1-D.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int32</code>. 1-D.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.invert_permutation_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.invert_permutation_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_finite">
    <p>def <span class="ident">is_finite</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_finite, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_finite</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_finite</strong></p>
<div class="codehilite"><pre><span></span>def is_finite(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.is_finite</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.is_finite</code></strong></p>
<div class="codehilite"><pre><span></span>def is_finite(x, name=None)
</pre></div>


<p>Returns which elements of x are finite.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_finite', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_finite" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_finite_layer">
    <p>def <span class="ident">is_finite_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_finite_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_finite_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_finite_layer</strong></p>
<div class="codehilite"><pre><span></span>def is_finite_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.is_finite, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.is_finite</strong></p>
<div class="codehilite"><pre><span></span>def is_finite(x, name=None):
</pre></div>


<p>Returns which elements of x are finite.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_finite_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_finite_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_inf">
    <p>def <span class="ident">is_inf</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_inf, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_inf</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_inf</strong></p>
<div class="codehilite"><pre><span></span>def is_inf(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.is_inf</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.is_inf</code></strong></p>
<div class="codehilite"><pre><span></span>def is_inf(x, name=None)
</pre></div>


<p>Returns which elements of x are Inf.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_inf', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_inf" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_inf_layer">
    <p>def <span class="ident">is_inf_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_inf_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_inf_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_inf_layer</strong></p>
<div class="codehilite"><pre><span></span>def is_inf_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.is_inf, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.is_inf</strong></p>
<div class="codehilite"><pre><span></span>def is_inf(x, name=None):
</pre></div>


<p>Returns which elements of x are Inf.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_inf_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_inf_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_nan">
    <p>def <span class="ident">is_nan</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_nan, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_nan</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_nan</strong></p>
<div class="codehilite"><pre><span></span>def is_nan(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.is_nan</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.is_nan</code></strong></p>
<div class="codehilite"><pre><span></span>def is_nan(x, name=None)
</pre></div>


<p>Returns which elements of x are NaN.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_nan', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_nan" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_nan_layer">
    <p>def <span class="ident">is_nan_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_nan_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_nan_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_nan_layer</strong></p>
<div class="codehilite"><pre><span></span>def is_nan_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.is_nan, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.is_nan</strong></p>
<div class="codehilite"><pre><span></span>def is_nan(x, name=None):
</pre></div>


<p>Returns which elements of x are NaN.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_nan_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_nan_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_non_decreasing">
    <p>def <span class="ident">is_non_decreasing</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_non_decreasing, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_non_decreasing</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_non_decreasing</strong></p>
<div class="codehilite"><pre><span></span>def is_non_decreasing(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.is_non_decreasing</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.is_non_decreasing</code></strong></p>
<div class="codehilite"><pre><span></span>def is_non_decreasing(x, name=None)
</pre></div>


<p>Returns <code>True</code> if <code>x</code> is non-decreasing.</p>
<p>Elements of <code>x</code> are compared in row-major order.  The tensor <code>[x[0],...]</code>
is non-decreasing if for every adjacent pair we have <code>x[i] &lt;= x[i+1]</code>.
If <code>x</code> has less than two elements, it is trivially non-decreasing.</p>
<p>See also:  <code>is_strictly_increasing</code></p>
<p>Args:
  x: Numeric <code>Tensor</code>.
  name: A name for this operation (optional).  Defaults to "is_non_decreasing"</p>
<p>Returns:
  Boolean <code>Tensor</code>, equal to <code>True</code> iff <code>x</code> is non-decreasing.</p>
<p>Raises:
  TypeError: if <code>x</code> is not a numeric tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_non_decreasing', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_non_decreasing" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_non_decreasing_layer">
    <p>def <span class="ident">is_non_decreasing_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_non_decreasing_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_non_decreasing_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_non_decreasing_layer</strong></p>
<div class="codehilite"><pre><span></span>def is_non_decreasing_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.is_non_decreasing, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.is_non_decreasing</strong></p>
<div class="codehilite"><pre><span></span>def is_non_decreasing(x, name=None):
</pre></div>


<p>Returns <code>True</code> if <code>x</code> is non-decreasing.</p>
<p>Elements of <code>x</code> are compared in row-major order.  The tensor <code>[x[0],...]</code>
is non-decreasing if for every adjacent pair we have <code>x[i] &lt;= x[i+1]</code>.
If <code>x</code> has less than two elements, it is trivially non-decreasing.</p>
<p>See also:  <code>is_strictly_increasing</code></p>
<p>Args:
  x: Numeric <code>Tensor</code>.
  name: A name for this operation (optional).  Defaults to "is_non_decreasing"</p>
<p>Returns:
  Boolean <code>Tensor</code>, equal to <code>True</code> iff <code>x</code> is non-decreasing.</p>
<p>Raises:
  TypeError: if <code>x</code> is not a numeric tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_non_decreasing_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_non_decreasing_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_numeric_tensor">
    <p>def <span class="ident">is_numeric_tensor</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_numeric_tensor, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_numeric_tensor</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_numeric_tensor</strong></p>
<div class="codehilite"><pre><span></span>def is_numeric_tensor(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.is_numeric_tensor</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.is_numeric_tensor</code></strong></p>
<div class="codehilite"><pre><span></span>def is_numeric_tensor(tensor)
</pre></div>


<p>None</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_numeric_tensor', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_numeric_tensor" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_numeric_tensor_layer">
    <p>def <span class="ident">is_numeric_tensor_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_numeric_tensor_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_numeric_tensor_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_numeric_tensor_layer</strong></p>
<div class="codehilite"><pre><span></span>def is_numeric_tensor_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.is_numeric_tensor, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.is_numeric_tensor</strong></p>
<div class="codehilite"><pre><span></span>def is_numeric_tensor(tensor):
</pre></div>


<p>None</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_numeric_tensor_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_numeric_tensor_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_strictly_increasing">
    <p>def <span class="ident">is_strictly_increasing</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_strictly_increasing, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_strictly_increasing</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_strictly_increasing</strong></p>
<div class="codehilite"><pre><span></span>def is_strictly_increasing(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.is_strictly_increasing</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.is_strictly_increasing</code></strong></p>
<div class="codehilite"><pre><span></span>def is_strictly_increasing(x, name=None)
</pre></div>


<p>Returns <code>True</code> if <code>x</code> is strictly increasing.</p>
<p>Elements of <code>x</code> are compared in row-major order.  The tensor <code>[x[0],...]</code>
is strictly increasing if for every adjacent pair we have <code>x[i] &lt; x[i+1]</code>.
If <code>x</code> has less than two elements, it is trivially strictly increasing.</p>
<p>See also:  <code>is_non_decreasing</code></p>
<p>Args:
  x: Numeric <code>Tensor</code>.
  name: A name for this operation (optional).
    Defaults to "is_strictly_increasing"</p>
<p>Returns:
  Boolean <code>Tensor</code>, equal to <code>True</code> iff <code>x</code> is strictly increasing.</p>
<p>Raises:
  TypeError: if <code>x</code> is not a numeric tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_strictly_increasing', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_strictly_increasing" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_strictly_increasing_layer">
    <p>def <span class="ident">is_strictly_increasing_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_strictly_increasing_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_strictly_increasing_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_strictly_increasing_layer</strong></p>
<div class="codehilite"><pre><span></span>def is_strictly_increasing_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.is_strictly_increasing, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.is_strictly_increasing</strong></p>
<div class="codehilite"><pre><span></span>def is_strictly_increasing(x, name=None):
</pre></div>


<p>Returns <code>True</code> if <code>x</code> is strictly increasing.</p>
<p>Elements of <code>x</code> are compared in row-major order.  The tensor <code>[x[0],...]</code>
is strictly increasing if for every adjacent pair we have <code>x[i] &lt; x[i+1]</code>.
If <code>x</code> has less than two elements, it is trivially strictly increasing.</p>
<p>See also:  <code>is_non_decreasing</code></p>
<p>Args:
  x: Numeric <code>Tensor</code>.
  name: A name for this operation (optional).
    Defaults to "is_strictly_increasing"</p>
<p>Returns:
  Boolean <code>Tensor</code>, equal to <code>True</code> iff <code>x</code> is strictly increasing.</p>
<p>Raises:
  TypeError: if <code>x</code> is not a numeric tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_strictly_increasing_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_strictly_increasing_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_variable_initialized">
    <p>def <span class="ident">is_variable_initialized</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_variable_initialized, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_variable_initialized</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_variable_initialized</strong></p>
<div class="codehilite"><pre><span></span>def is_variable_initialized(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.is_variable_initialized</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.is_variable_initialized</code></strong></p>
<div class="codehilite"><pre><span></span>def is_variable_initialized(variable)
</pre></div>


<p>Tests if a variable has been initialized.</p>
<p>Args:
  variable: A <code>Variable</code>.</p>
<p>Returns:
  Returns a scalar boolean Tensor, <code>True</code> if the variable has been
  initialized, <code>False</code> otherwise.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_variable_initialized', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_variable_initialized" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.is_variable_initialized_layer">
    <p>def <span class="ident">is_variable_initialized_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.is_variable_initialized_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.is_variable_initialized_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.is_variable_initialized_layer</strong></p>
<div class="codehilite"><pre><span></span>def is_variable_initialized_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.is_variable_initialized, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.is_variable_initialized</strong></p>
<div class="codehilite"><pre><span></span>def is_variable_initialized(variable):
</pre></div>


<p>Tests if a variable has been initialized.</p>
<p>Args:
  variable: A <code>Variable</code>.</p>
<p>Returns:
  Returns a scalar boolean Tensor, <code>True</code> if the variable has been
  initialized, <code>False</code> otherwise.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.is_variable_initialized_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.is_variable_initialized_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.l2_loss">
    <p>def <span class="ident">l2_loss</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.l2_loss, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.l2_loss</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.l2_loss</strong></p>
<div class="codehilite"><pre><span></span>def l2_loss(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.l2_loss</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.l2_loss</code></strong></p>
<div class="codehilite"><pre><span></span>def l2_loss(t, name=None)
</pre></div>


<p>L2 Loss.</p>
<p>Computes half the L2 norm of a tensor without the <code>sqrt</code>:</p>
<div class="codehilite"><pre><span></span>output = sum(t ** 2) / 2
</pre></div>


<p>Args:
  t: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Typically 2-D, but may have any dimensions.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>t</code>. 0-D.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.l2_loss', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.l2_loss" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.l2_loss_layer">
    <p>def <span class="ident">l2_loss_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.l2_loss_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.l2_loss_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.l2_loss_layer</strong></p>
<div class="codehilite"><pre><span></span>def l2_loss_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.l2_loss, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.l2_loss</strong></p>
<div class="codehilite"><pre><span></span>def l2_loss(t, name=None):
</pre></div>


<p>L2 Loss.</p>
<p>Computes half the L2 norm of a tensor without the <code>sqrt</code>:</p>
<div class="codehilite"><pre><span></span>output = sum(t ** 2) / 2
</pre></div>


<p>Args:
  t: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Typically 2-D, but may have any dimensions.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>t</code>. 0-D.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.l2_loss_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.l2_loss_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.l2_normalize">
    <p>def <span class="ident">l2_normalize</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.l2_normalize, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.l2_normalize</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.l2_normalize</strong></p>
<div class="codehilite"><pre><span></span>def l2_normalize(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.l2_normalize</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.l2_normalize</code></strong></p>
<div class="codehilite"><pre><span></span>def l2_normalize(x, dim, epsilon=1e-12, name=None)
</pre></div>


<p>Normalizes along dimension <code>dim</code> using an L2 norm.</p>
<p>For a 1-D tensor with <code>dim = 0</code>, computes</p>
<div class="codehilite"><pre><span></span>output = x / sqrt(max(sum(x**2), epsilon))
</pre></div>


<p>For <code>x</code> with more dimensions, independently normalizes each 1-D slice along
dimension <code>dim</code>.</p>
<p>Args:
  x: A <code>Tensor</code>.
  dim: Dimension along which to normalize.
  epsilon: A lower bound value for the norm. Will use <code>sqrt(epsilon)</code> as the
    divisor if <code>norm &lt; sqrt(epsilon)</code>.
  name: A name for this operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with the same shape as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.l2_normalize', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.l2_normalize" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.l2_normalize_layer">
    <p>def <span class="ident">l2_normalize_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.l2_normalize_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.l2_normalize_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.l2_normalize_layer</strong></p>
<div class="codehilite"><pre><span></span>def l2_normalize_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.l2_normalize, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.l2_normalize</strong></p>
<div class="codehilite"><pre><span></span>def l2_normalize(x, dim, epsilon=1e-12, name=None):
</pre></div>


<p>Normalizes along dimension <code>dim</code> using an L2 norm.</p>
<p>For a 1-D tensor with <code>dim = 0</code>, computes</p>
<div class="codehilite"><pre><span></span>output = x / sqrt(max(sum(x**2), epsilon))
</pre></div>


<p>For <code>x</code> with more dimensions, independently normalizes each 1-D slice along
dimension <code>dim</code>.</p>
<p>Args:
  x: A <code>Tensor</code>.
  dim: Dimension along which to normalize.
  epsilon: A lower bound value for the norm. Will use <code>sqrt(epsilon)</code> as the
    divisor if <code>norm &lt; sqrt(epsilon)</code>.
  name: A name for this operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with the same shape as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.l2_normalize_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.l2_normalize_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.lbeta">
    <p>def <span class="ident">lbeta</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.lbeta, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.lbeta</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.lbeta</strong></p>
<div class="codehilite"><pre><span></span>def lbeta(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.lbeta</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.lbeta</code></strong></p>
<div class="codehilite"><pre><span></span>def lbeta(x, name=&quot;lbeta&quot;)
</pre></div>


<p>Computes <code>ln(|Beta(x)|)</code>, reducing along the last dimension.</p>
<p>Given one-dimensional <code>z = [z_0,...,z_{K-1}]</code>, we define</p>
<p><code>Beta(z) = \prod_j Gamma(z_j) / Gamma(\sum_j z_j)</code></p>
<p>And for <code>n + 1</code> dimensional <code>x</code> with shape <code>[N1, ..., Nn, K]</code>, we define
<code>lbeta(x)[i1, ..., in] = Log(|Beta(x[i1, ..., in, :])|)</code>.  In other words,
the last dimension is treated as the <code>z</code> vector.</p>
<p>Note that if <code>z = [u, v]</code>, then
<code>Beta(z) = int_0^1 t^{u-1} (1 - t)^{v-1} dt</code>, which defines the traditional
bivariate beta function.</p>
<p>Args:
  x: A rank <code>n + 1</code> <code>Tensor</code> with type <code>float</code>, or <code>double</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  The logarithm of <code>|Beta(x)|</code> reducing along the last dimension.</p>
<p>Raises:
  ValueError:  If <code>x</code> is empty with rank one or less.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.lbeta', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.lbeta" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.lbeta_layer">
    <p>def <span class="ident">lbeta_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.lbeta_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.lbeta_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.lbeta_layer</strong></p>
<div class="codehilite"><pre><span></span>def lbeta_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.lbeta, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.lbeta</strong></p>
<div class="codehilite"><pre><span></span>def lbeta(x, name=&quot;lbeta&quot;):
</pre></div>


<p>Computes <code>ln(|Beta(x)|)</code>, reducing along the last dimension.</p>
<p>Given one-dimensional <code>z = [z_0,...,z_{K-1}]</code>, we define</p>
<p><code>Beta(z) = \prod_j Gamma(z_j) / Gamma(\sum_j z_j)</code></p>
<p>And for <code>n + 1</code> dimensional <code>x</code> with shape <code>[N1, ..., Nn, K]</code>, we define
<code>lbeta(x)[i1, ..., in] = Log(|Beta(x[i1, ..., in, :])|)</code>.  In other words,
the last dimension is treated as the <code>z</code> vector.</p>
<p>Note that if <code>z = [u, v]</code>, then
<code>Beta(z) = int_0^1 t^{u-1} (1 - t)^{v-1} dt</code>, which defines the traditional
bivariate beta function.</p>
<p>Args:
  x: A rank <code>n + 1</code> <code>Tensor</code> with type <code>float</code>, or <code>double</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  The logarithm of <code>|Beta(x)|</code> reducing along the last dimension.</p>
<p>Raises:
  ValueError:  If <code>x</code> is empty with rank one or less.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.lbeta_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.lbeta_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.learned_unigram_candidate_sampler">
    <p>def <span class="ident">learned_unigram_candidate_sampler</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.learned_unigram_candidate_sampler, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.learned_unigram_candidate_sampler</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.learned_unigram_candidate_sampler</strong></p>
<div class="codehilite"><pre><span></span>def learned_unigram_candidate_sampler(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.learned_unigram_candidate_sampler</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.learned_unigram_candidate_sampler</code></strong></p>
<div class="codehilite"><pre><span></span>def learned_unigram_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, seed=None, name=None)
</pre></div>


<p>Samples a set of classes from a distribution learned during training.</p>
<p>This operation randomly samples a tensor of sampled classes
(<code>sampled_candidates</code>) from the range of integers <code>[0, range_max)</code>.</p>
<p>The elements of <code>sampled_candidates</code> are drawn without replacement
(if <code>unique=True</code>) or with replacement (if <code>unique=False</code>) from
the base distribution.</p>
<p>The base distribution for this operation is constructed on the fly
during training.  It is a unigram distribution over the target
classes seen so far during training.  Every integer in <code>[0, range_max)</code>
begins with a weight of 1, and is incremented by 1 each time it is
seen as a target class.  The base distribution is not saved to checkpoints,
so it is reset when the model is reloaded.</p>
<p>In addition, this operation returns tensors <code>true_expected_count</code>
and <code>sampled_expected_count</code> representing the number of times each
of the target classes (<code>true_classes</code>) and the sampled
classes (<code>sampled_candidates</code>) is expected to occur in an average
tensor of sampled classes.  These values correspond to <code>Q(y|x)</code>
defined in <a href="http://www.tensorflow.org/extras/candidate_sampling.pdf">this
document</a>.
If <code>unique=True</code>, then these are post-rejection probabilities and we
compute them approximately.</p>
<p>Args:
  true_classes: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
    num_true]</code>. The target classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  num_sampled: An <code>int</code>.  The number of classes to randomly sample per batch.
  unique: A <code>bool</code>. Determines whether all sampled classes in a batch are
    unique.
  range_max: An <code>int</code>. The number of possible classes.
  seed: An <code>int</code>. An operation-specific seed. Default is 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  sampled_candidates: A tensor of type <code>int64</code> and shape <code>[num_sampled]</code>.
    The sampled classes.
  true_expected_count: A tensor of type <code>float</code>.  Same shape as
    <code>true_classes</code>. The expected counts under the sampling distribution
    of each of <code>true_classes</code>.
  sampled_expected_count: A tensor of type <code>float</code>. Same shape as
    <code>sampled_candidates</code>. The expected counts under the sampling distribution
    of each of <code>sampled_candidates</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.learned_unigram_candidate_sampler', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.learned_unigram_candidate_sampler" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.learned_unigram_candidate_sampler_layer">
    <p>def <span class="ident">learned_unigram_candidate_sampler_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.learned_unigram_candidate_sampler_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.learned_unigram_candidate_sampler_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.learned_unigram_candidate_sampler_layer</strong></p>
<div class="codehilite"><pre><span></span>def learned_unigram_candidate_sampler_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.learned_unigram_candidate_sampler, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.learned_unigram_candidate_sampler</strong></p>
<div class="codehilite"><pre><span></span>def learned_unigram_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, seed=None, name=None):
</pre></div>


<p>Samples a set of classes from a distribution learned during training.</p>
<p>This operation randomly samples a tensor of sampled classes
(<code>sampled_candidates</code>) from the range of integers <code>[0, range_max)</code>.</p>
<p>The elements of <code>sampled_candidates</code> are drawn without replacement
(if <code>unique=True</code>) or with replacement (if <code>unique=False</code>) from
the base distribution.</p>
<p>The base distribution for this operation is constructed on the fly
during training.  It is a unigram distribution over the target
classes seen so far during training.  Every integer in <code>[0, range_max)</code>
begins with a weight of 1, and is incremented by 1 each time it is
seen as a target class.  The base distribution is not saved to checkpoints,
so it is reset when the model is reloaded.</p>
<p>In addition, this operation returns tensors <code>true_expected_count</code>
and <code>sampled_expected_count</code> representing the number of times each
of the target classes (<code>true_classes</code>) and the sampled
classes (<code>sampled_candidates</code>) is expected to occur in an average
tensor of sampled classes.  These values correspond to <code>Q(y|x)</code>
defined in <a href="http://www.tensorflow.org/extras/candidate_sampling.pdf">this
document</a>.
If <code>unique=True</code>, then these are post-rejection probabilities and we
compute them approximately.</p>
<p>Args:
  true_classes: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
    num_true]</code>. The target classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  num_sampled: An <code>int</code>.  The number of classes to randomly sample per batch.
  unique: A <code>bool</code>. Determines whether all sampled classes in a batch are
    unique.
  range_max: An <code>int</code>. The number of possible classes.
  seed: An <code>int</code>. An operation-specific seed. Default is 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  sampled_candidates: A tensor of type <code>int64</code> and shape <code>[num_sampled]</code>.
    The sampled classes.
  true_expected_count: A tensor of type <code>float</code>.  Same shape as
    <code>true_classes</code>. The expected counts under the sampling distribution
    of each of <code>true_classes</code>.
  sampled_expected_count: A tensor of type <code>float</code>. Same shape as
    <code>sampled_candidates</code>. The expected counts under the sampling distribution
    of each of <code>sampled_candidates</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.learned_unigram_candidate_sampler_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.learned_unigram_candidate_sampler_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.less">
    <p>def <span class="ident">less</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.less, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.less</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.less</strong></p>
<div class="codehilite"><pre><span></span>def less(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.less</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.less</code></strong></p>
<div class="codehilite"><pre><span></span>def less(x, y, name=None)
</pre></div>


<p>Returns the truth value of (x &lt; y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.less', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.less" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.less_equal">
    <p>def <span class="ident">less_equal</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.less_equal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.less_equal</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.less_equal</strong></p>
<div class="codehilite"><pre><span></span>def less_equal(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.less_equal</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.less_equal</code></strong></p>
<div class="codehilite"><pre><span></span>def less_equal(x, y, name=None)
</pre></div>


<p>Returns the truth value of (x &lt;= y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.less_equal', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.less_equal" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.less_equal_layer">
    <p>def <span class="ident">less_equal_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.less_equal_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.less_equal_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.less_equal_layer</strong></p>
<div class="codehilite"><pre><span></span>def less_equal_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.less_equal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.less_equal</strong></p>
<div class="codehilite"><pre><span></span>def less_equal(x, y, name=None):
</pre></div>


<p>Returns the truth value of (x &lt;= y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.less_equal_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.less_equal_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.less_layer">
    <p>def <span class="ident">less_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.less_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.less_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.less_layer</strong></p>
<div class="codehilite"><pre><span></span>def less_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.less, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.less</strong></p>
<div class="codehilite"><pre><span></span>def less(x, y, name=None):
</pre></div>


<p>Returns the truth value of (x &lt; y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.less_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.less_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.lgamma">
    <p>def <span class="ident">lgamma</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.lgamma, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.lgamma</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.lgamma</strong></p>
<div class="codehilite"><pre><span></span>def lgamma(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.lgamma</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.lgamma</code></strong></p>
<div class="codehilite"><pre><span></span>def lgamma(x, name=None)
</pre></div>


<p>Computes the log of the absolute value of <code>Gamma(x)</code> element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.lgamma', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.lgamma" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.lgamma_layer">
    <p>def <span class="ident">lgamma_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.lgamma_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.lgamma_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.lgamma_layer</strong></p>
<div class="codehilite"><pre><span></span>def lgamma_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.lgamma, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.lgamma</strong></p>
<div class="codehilite"><pre><span></span>def lgamma(x, name=None):
</pre></div>


<p>Computes the log of the absolute value of <code>Gamma(x)</code> element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.lgamma_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.lgamma_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.lin_space">
    <p>def <span class="ident">lin_space</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.lin_space, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.lin_space</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.lin_space</strong></p>
<div class="codehilite"><pre><span></span>def lin_space(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.lin_space</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.lin_space</code></strong></p>
<div class="codehilite"><pre><span></span>def lin_space(start, stop, num, name=None)
</pre></div>


<p>Generates values in an interval.</p>
<p>A sequence of <code>num</code> evenly-spaced values are generated beginning at <code>start</code>.
If <code>num &gt; 1</code>, the values in the sequence increase by <code>stop - start / num - 1</code>,
so that the last one is exactly <code>stop</code>.</p>
<p>For example:</p>
<p><code>tf.linspace(10.0, 12.0, 3, name="linspace") =&gt; [ 10.0  11.0  12.0]</code></p>
<p>Args:
  start: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    First entry in the range.
  stop: A <code>Tensor</code>. Must have the same type as <code>start</code>.
    Last entry in the range.
  num: A <code>Tensor</code> of type <code>int32</code>. Number of values to generate.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>start</code>. 1-D. The generated values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.lin_space', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.lin_space" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.lin_space_layer">
    <p>def <span class="ident">lin_space_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.lin_space_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.lin_space_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.lin_space_layer</strong></p>
<div class="codehilite"><pre><span></span>def lin_space_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.lin_space, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.lin_space</strong></p>
<div class="codehilite"><pre><span></span>def lin_space(start, stop, num, name=None):
</pre></div>


<p>Generates values in an interval.</p>
<p>A sequence of <code>num</code> evenly-spaced values are generated beginning at <code>start</code>.
If <code>num &gt; 1</code>, the values in the sequence increase by <code>stop - start / num - 1</code>,
so that the last one is exactly <code>stop</code>.</p>
<p>For example:</p>
<p><code>tf.linspace(10.0, 12.0, 3, name="linspace") =&gt; [ 10.0  11.0  12.0]</code></p>
<p>Args:
  start: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    First entry in the range.
  stop: A <code>Tensor</code>. Must have the same type as <code>start</code>.
    Last entry in the range.
  num: A <code>Tensor</code> of type <code>int32</code>. Number of values to generate.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>start</code>. 1-D. The generated values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.lin_space_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.lin_space_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.linear_layer">
    <p>def <span class="ident">linear_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.linear_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.linear_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.linear_layer</strong></p>
<div class="codehilite"><pre><span></span>def linear_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method the same as <code>tensorbuilder.linear_layer</code>.</p>
<p><strong> Original Documentation for <code>tensorbuilder.linear_layer</code></strong></p>
<div class="codehilite"><pre><span></span>def linear_layer(builder, size)
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method the same as <code>tensorbuilder.linear_layer</code>.</p>
<p><strong> Original Documentation for <code>tensorbuilder.linear_layer</code></strong></p>
<div class="codehilite"><pre><span></span>def linear_layer(builder, size)
</pre></div>


<p>Alias for <code>.fully_connected(size, activation_fn = None, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.linear_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.linear_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.linspace_layer">
    <p>def <span class="ident">linspace_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.linspace_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.linspace_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.linspace_layer</strong></p>
<div class="codehilite"><pre><span></span>def linspace_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.linspace, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.linspace</strong></p>
<div class="codehilite"><pre><span></span>def lin_space(start, stop, num, name=None):
</pre></div>


<p>Generates values in an interval.</p>
<p>A sequence of <code>num</code> evenly-spaced values are generated beginning at <code>start</code>.
If <code>num &gt; 1</code>, the values in the sequence increase by <code>stop - start / num - 1</code>,
so that the last one is exactly <code>stop</code>.</p>
<p>For example:</p>
<p><code>tf.linspace(10.0, 12.0, 3, name="linspace") =&gt; [ 10.0  11.0  12.0]</code></p>
<p>Args:
  start: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    First entry in the range.
  stop: A <code>Tensor</code>. Must have the same type as <code>start</code>.
    Last entry in the range.
  num: A <code>Tensor</code> of type <code>int32</code>. Number of values to generate.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>start</code>. 1-D. The generated values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.linspace_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.linspace_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.list_diff">
    <p>def <span class="ident">list_diff</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.list_diff, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.list_diff</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.list_diff</strong></p>
<div class="codehilite"><pre><span></span>def list_diff(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.list_diff</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.list_diff</code></strong></p>
<div class="codehilite"><pre><span></span>def list_diff(x, y, name=None)
</pre></div>


<p>Computes the difference between two lists of numbers or strings.</p>
<p>Given a list <code>x</code> and a list <code>y</code>, this operation returns a list <code>out</code> that
represents all values that are in <code>x</code> but not in <code>y</code>. The returned list <code>out</code>
is sorted in the same order that the numbers appear in <code>x</code> (duplicates are
preserved). This operation also returns a list <code>idx</code> that represents the
position of each <code>out</code> element in <code>x</code>. In other words:</p>
<p><code>out[i] = x[idx[i]] for i in [0, 1, ..., len(out) - 1]</code></p>
<p>For example, given this input:</p>
<p><code>prettyprint
x = [1, 2, 3, 4, 5, 6]
y = [1, 3, 5]</code></p>
<p>This operation would return:</p>
<p><code>prettyprint
out ==&gt; [2, 4, 6]
idx ==&gt; [1, 3, 5]</code></p>
<p>Args:
  x: A <code>Tensor</code>. 1-D. Values to keep.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>. 1-D. Values to remove.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tuple of <code>Tensor</code> objects (out, idx).
  out: A <code>Tensor</code>. Has the same type as <code>x</code>. 1-D. Values present in <code>x</code> but not in <code>y</code>.
  idx: A <code>Tensor</code> of type <code>int32</code>. 1-D. Positions of <code>x</code> values preserved in <code>out</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.list_diff', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.list_diff" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.list_diff_layer">
    <p>def <span class="ident">list_diff_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.list_diff_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.list_diff_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.list_diff_layer</strong></p>
<div class="codehilite"><pre><span></span>def list_diff_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.list_diff, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.list_diff</strong></p>
<div class="codehilite"><pre><span></span>def list_diff(x, y, name=None):
</pre></div>


<p>Computes the difference between two lists of numbers or strings.</p>
<p>Given a list <code>x</code> and a list <code>y</code>, this operation returns a list <code>out</code> that
represents all values that are in <code>x</code> but not in <code>y</code>. The returned list <code>out</code>
is sorted in the same order that the numbers appear in <code>x</code> (duplicates are
preserved). This operation also returns a list <code>idx</code> that represents the
position of each <code>out</code> element in <code>x</code>. In other words:</p>
<p><code>out[i] = x[idx[i]] for i in [0, 1, ..., len(out) - 1]</code></p>
<p>For example, given this input:</p>
<p><code>prettyprint
x = [1, 2, 3, 4, 5, 6]
y = [1, 3, 5]</code></p>
<p>This operation would return:</p>
<p><code>prettyprint
out ==&gt; [2, 4, 6]
idx ==&gt; [1, 3, 5]</code></p>
<p>Args:
  x: A <code>Tensor</code>. 1-D. Values to keep.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>. 1-D. Values to remove.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tuple of <code>Tensor</code> objects (out, idx).
  out: A <code>Tensor</code>. Has the same type as <code>x</code>. 1-D. Values present in <code>x</code> but not in <code>y</code>.
  idx: A <code>Tensor</code> of type <code>int32</code>. 1-D. Positions of <code>x</code> values preserved in <code>out</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.list_diff_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.list_diff_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.listdiff_layer">
    <p>def <span class="ident">listdiff_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.listdiff_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.listdiff_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.listdiff_layer</strong></p>
<div class="codehilite"><pre><span></span>def listdiff_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.listdiff, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.listdiff</strong></p>
<div class="codehilite"><pre><span></span>def list_diff(x, y, name=None):
</pre></div>


<p>Computes the difference between two lists of numbers or strings.</p>
<p>Given a list <code>x</code> and a list <code>y</code>, this operation returns a list <code>out</code> that
represents all values that are in <code>x</code> but not in <code>y</code>. The returned list <code>out</code>
is sorted in the same order that the numbers appear in <code>x</code> (duplicates are
preserved). This operation also returns a list <code>idx</code> that represents the
position of each <code>out</code> element in <code>x</code>. In other words:</p>
<p><code>out[i] = x[idx[i]] for i in [0, 1, ..., len(out) - 1]</code></p>
<p>For example, given this input:</p>
<p><code>prettyprint
x = [1, 2, 3, 4, 5, 6]
y = [1, 3, 5]</code></p>
<p>This operation would return:</p>
<p><code>prettyprint
out ==&gt; [2, 4, 6]
idx ==&gt; [1, 3, 5]</code></p>
<p>Args:
  x: A <code>Tensor</code>. 1-D. Values to keep.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>. 1-D. Values to remove.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tuple of <code>Tensor</code> objects (out, idx).
  out: A <code>Tensor</code>. Has the same type as <code>x</code>. 1-D. Values present in <code>x</code> but not in <code>y</code>.
  idx: A <code>Tensor</code> of type <code>int32</code>. 1-D. Positions of <code>x</code> values preserved in <code>out</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.listdiff_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.listdiff_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.load_file_system_library">
    <p>def <span class="ident">load_file_system_library</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.load_file_system_library, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.load_file_system_library</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.load_file_system_library</strong></p>
<div class="codehilite"><pre><span></span>def load_file_system_library(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.load_file_system_library</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.load_file_system_library</code></strong></p>
<div class="codehilite"><pre><span></span>def load_file_system_library(library_filename)
</pre></div>


<p>Loads a TensorFlow plugin, containing file system implementation.</p>
<p>Pass <code>library_filename</code> to a platform-specific mechanism for dynamically
loading a library. The rules for determining the exact location of the
library are platform-specific and are not documented here.</p>
<p>Args:
  library_filename: Path to the plugin.
    Relative or absolute filesystem path to a dynamic library file.</p>
<p>Returns:
  None.</p>
<p>Raises:
  RuntimeError: when unable to load the library.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.load_file_system_library', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.load_file_system_library" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.load_file_system_library_layer">
    <p>def <span class="ident">load_file_system_library_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.load_file_system_library_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.load_file_system_library_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.load_file_system_library_layer</strong></p>
<div class="codehilite"><pre><span></span>def load_file_system_library_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.load_file_system_library, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.load_file_system_library</strong></p>
<div class="codehilite"><pre><span></span>def load_file_system_library(library_filename):
</pre></div>


<p>Loads a TensorFlow plugin, containing file system implementation.</p>
<p>Pass <code>library_filename</code> to a platform-specific mechanism for dynamically
loading a library. The rules for determining the exact location of the
library are platform-specific and are not documented here.</p>
<p>Args:
  library_filename: Path to the plugin.
    Relative or absolute filesystem path to a dynamic library file.</p>
<p>Returns:
  None.</p>
<p>Raises:
  RuntimeError: when unable to load the library.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.load_file_system_library_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.load_file_system_library_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.load_op_library">
    <p>def <span class="ident">load_op_library</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.load_op_library, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.load_op_library</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.load_op_library</strong></p>
<div class="codehilite"><pre><span></span>def load_op_library(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.load_op_library</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.load_op_library</code></strong></p>
<div class="codehilite"><pre><span></span>def load_op_library(library_filename)
</pre></div>


<p>Loads a TensorFlow plugin, containing custom ops and kernels.</p>
<p>Pass "library_filename" to a platform-specific mechanism for dynamically
loading a library. The rules for determining the exact location of the
library are platform-specific and are not documented here.</p>
<p>Args:
  library_filename: Path to the plugin.
    Relative or absolute filesystem path to a dynamic library file.</p>
<p>Returns:
  A python module containing the Python wrappers for Ops defined in
  the plugin.</p>
<p>Raises:
  RuntimeError: when unable to load the library or get the python wrappers.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.load_op_library', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.load_op_library" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.load_op_library_layer">
    <p>def <span class="ident">load_op_library_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.load_op_library_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.load_op_library_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.load_op_library_layer</strong></p>
<div class="codehilite"><pre><span></span>def load_op_library_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.load_op_library, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.load_op_library</strong></p>
<div class="codehilite"><pre><span></span>def load_op_library(library_filename):
</pre></div>


<p>Loads a TensorFlow plugin, containing custom ops and kernels.</p>
<p>Pass "library_filename" to a platform-specific mechanism for dynamically
loading a library. The rules for determining the exact location of the
library are platform-specific and are not documented here.</p>
<p>Args:
  library_filename: Path to the plugin.
    Relative or absolute filesystem path to a dynamic library file.</p>
<p>Returns:
  A python module containing the Python wrappers for Ops defined in
  the plugin.</p>
<p>Raises:
  RuntimeError: when unable to load the library or get the python wrappers.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.load_op_library_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.load_op_library_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.local_response_normalization_layer">
    <p>def <span class="ident">local_response_normalization_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.local_response_normalization_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.local_response_normalization_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.local_response_normalization_layer</strong></p>
<div class="codehilite"><pre><span></span>def local_response_normalization_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.local_response_normalization, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.local_response_normalization</strong></p>
<div class="codehilite"><pre><span></span>def lrn(input, depth_radius=None, bias=None, alpha=None, beta=None, name=None):
</pre></div>


<p>Local Response Normalization.</p>
<p>The 4-D <code>input</code> tensor is treated as a 3-D array of 1-D vectors (along the last
dimension), and each vector is normalized independently.  Within a given vector,
each component is divided by the weighted, squared sum of inputs within
<code>depth_radius</code>.  In detail,</p>
<div class="codehilite"><pre><span></span>sqr_sum[a, b, c, d] =
    sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ** 2)
output = input / (bias + alpha * sqr_sum) ** beta
</pre></div>


<p>For details, see [Krizhevsky et al., ImageNet classification with deep
convolutional neural networks (NIPS 2012)]
(http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks).</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>float32</code>. 4-D.
  depth_radius: An optional <code>int</code>. Defaults to <code>5</code>.
    0-D.  Half-width of the 1-D normalization window.
  bias: An optional <code>float</code>. Defaults to <code>1</code>.
    An offset (usually positive to avoid dividing by 0).
  alpha: An optional <code>float</code>. Defaults to <code>1</code>.
    A scale factor, usually positive.
  beta: An optional <code>float</code>. Defaults to <code>0.5</code>. An exponent.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>float32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.local_response_normalization_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.local_response_normalization_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.local_variables">
    <p>def <span class="ident">local_variables</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.local_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.local_variables</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.local_variables</strong></p>
<div class="codehilite"><pre><span></span>def local_variables(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.local_variables</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.local_variables</code></strong></p>
<div class="codehilite"><pre><span></span>def local_variables()
</pre></div>


<p>Returns all variables created with collection=[LOCAL_VARIABLES].</p>
<p>Returns:
  A list of local Variable objects.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.local_variables', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.local_variables" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.local_variables_layer">
    <p>def <span class="ident">local_variables_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.local_variables_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.local_variables_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.local_variables_layer</strong></p>
<div class="codehilite"><pre><span></span>def local_variables_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.local_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.local_variables</strong></p>
<div class="codehilite"><pre><span></span>def local_variables():
</pre></div>


<p>Returns all variables created with collection=[LOCAL_VARIABLES].</p>
<p>Returns:
  A list of local Variable objects.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.local_variables_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.local_variables_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.log">
    <p>def <span class="ident">log</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.log, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.log</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.log</strong></p>
<div class="codehilite"><pre><span></span>def log(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.log</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.log</code></strong></p>
<div class="codehilite"><pre><span></span>def log(x, name=None)
</pre></div>


<p>Computes natural logarithm of x element-wise.</p>
<p>I.e., \(y = \log_e x\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.log', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.log" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.log_layer">
    <p>def <span class="ident">log_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.log_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.log_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.log_layer</strong></p>
<div class="codehilite"><pre><span></span>def log_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.log, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.log</strong></p>
<div class="codehilite"><pre><span></span>def log(x, name=None):
</pre></div>


<p>Computes natural logarithm of x element-wise.</p>
<p>I.e., \(y = \log_e x\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.log_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.log_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.log_softmax">
    <p>def <span class="ident">log_softmax</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.log_softmax, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.log_softmax</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.log_softmax</strong></p>
<div class="codehilite"><pre><span></span>def log_softmax(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.log_softmax</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.log_softmax</code></strong></p>
<div class="codehilite"><pre><span></span>def log_softmax(logits, name=None)
</pre></div>


<p>Computes log softmax activations.</p>
<p>For each batch <code>i</code> and class <code>j</code> we have</p>
<div class="codehilite"><pre><span></span>logsoftmax[i, j] = logits[i, j] - log(sum(exp(logits[i])))
</pre></div>


<p>Args:
  logits: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
    2-D with shape <code>[batch_size, num_classes]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>logits</code>. Same shape as <code>logits</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.log_softmax', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.log_softmax" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.log_softmax_layer">
    <p>def <span class="ident">log_softmax_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.log_softmax_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.log_softmax_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.log_softmax_layer</strong></p>
<div class="codehilite"><pre><span></span>def log_softmax_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.log_softmax, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.log_softmax</strong></p>
<div class="codehilite"><pre><span></span>def log_softmax(logits, name=None):
</pre></div>


<p>Computes log softmax activations.</p>
<p>For each batch <code>i</code> and class <code>j</code> we have</p>
<div class="codehilite"><pre><span></span>logsoftmax[i, j] = logits[i, j] - log(sum(exp(logits[i])))
</pre></div>


<p>Args:
  logits: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
    2-D with shape <code>[batch_size, num_classes]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>logits</code>. Same shape as <code>logits</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.log_softmax_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.log_softmax_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.log_uniform_candidate_sampler">
    <p>def <span class="ident">log_uniform_candidate_sampler</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.log_uniform_candidate_sampler, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.log_uniform_candidate_sampler</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.log_uniform_candidate_sampler</strong></p>
<div class="codehilite"><pre><span></span>def log_uniform_candidate_sampler(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.log_uniform_candidate_sampler</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.log_uniform_candidate_sampler</code></strong></p>
<div class="codehilite"><pre><span></span>def log_uniform_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, seed=None, name=None)
</pre></div>


<p>Samples a set of classes using a log-uniform (Zipfian) base distribution.</p>
<p>This operation randomly samples a tensor of sampled classes
(<code>sampled_candidates</code>) from the range of integers <code>[0, range_max)</code>.</p>
<p>The elements of <code>sampled_candidates</code> are drawn without replacement
(if <code>unique=True</code>) or with replacement (if <code>unique=False</code>) from
the base distribution.</p>
<p>The base distribution for this operation is an approximately log-uniform
or Zipfian distribution:</p>
<p><code>P(class) = (log(class + 2) - log(class + 1)) / log(range_max + 1)</code></p>
<p>This sampler is useful when the target classes approximately follow such
a distribution - for example, if the classes represent words in a lexicon
sorted in decreasing order of frequency. If your classes are not ordered by
decreasing frequency, do not use this op.</p>
<p>In addition, this operation returns tensors <code>true_expected_count</code>
and <code>sampled_expected_count</code> representing the number of times each
of the target classes (<code>true_classes</code>) and the sampled
classes (<code>sampled_candidates</code>) is expected to occur in an average
tensor of sampled classes.  These values correspond to <code>Q(y|x)</code>
defined in <a href="http://www.tensorflow.org/extras/candidate_sampling.pdf">this
document</a>.
If <code>unique=True</code>, then these are post-rejection probabilities and we
compute them approximately.</p>
<p>Args:
  true_classes: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
    num_true]</code>. The target classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  num_sampled: An <code>int</code>.  The number of classes to randomly sample per batch.
  unique: A <code>bool</code>. Determines whether all sampled classes in a batch are
    unique.
  range_max: An <code>int</code>. The number of possible classes.
  seed: An <code>int</code>. An operation-specific seed. Default is 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  sampled_candidates: A tensor of type <code>int64</code> and shape <code>[num_sampled]</code>.
    The sampled classes.
  true_expected_count: A tensor of type <code>float</code>.  Same shape as
    <code>true_classes</code>. The expected counts under the sampling distribution
    of each of <code>true_classes</code>.
  sampled_expected_count: A tensor of type <code>float</code>. Same shape as
    <code>sampled_candidates</code>. The expected counts under the sampling distribution
    of each of <code>sampled_candidates</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.log_uniform_candidate_sampler', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.log_uniform_candidate_sampler" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.log_uniform_candidate_sampler_layer">
    <p>def <span class="ident">log_uniform_candidate_sampler_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.log_uniform_candidate_sampler_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.log_uniform_candidate_sampler_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.log_uniform_candidate_sampler_layer</strong></p>
<div class="codehilite"><pre><span></span>def log_uniform_candidate_sampler_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.log_uniform_candidate_sampler, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.log_uniform_candidate_sampler</strong></p>
<div class="codehilite"><pre><span></span>def log_uniform_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, seed=None, name=None):
</pre></div>


<p>Samples a set of classes using a log-uniform (Zipfian) base distribution.</p>
<p>This operation randomly samples a tensor of sampled classes
(<code>sampled_candidates</code>) from the range of integers <code>[0, range_max)</code>.</p>
<p>The elements of <code>sampled_candidates</code> are drawn without replacement
(if <code>unique=True</code>) or with replacement (if <code>unique=False</code>) from
the base distribution.</p>
<p>The base distribution for this operation is an approximately log-uniform
or Zipfian distribution:</p>
<p><code>P(class) = (log(class + 2) - log(class + 1)) / log(range_max + 1)</code></p>
<p>This sampler is useful when the target classes approximately follow such
a distribution - for example, if the classes represent words in a lexicon
sorted in decreasing order of frequency. If your classes are not ordered by
decreasing frequency, do not use this op.</p>
<p>In addition, this operation returns tensors <code>true_expected_count</code>
and <code>sampled_expected_count</code> representing the number of times each
of the target classes (<code>true_classes</code>) and the sampled
classes (<code>sampled_candidates</code>) is expected to occur in an average
tensor of sampled classes.  These values correspond to <code>Q(y|x)</code>
defined in <a href="http://www.tensorflow.org/extras/candidate_sampling.pdf">this
document</a>.
If <code>unique=True</code>, then these are post-rejection probabilities and we
compute them approximately.</p>
<p>Args:
  true_classes: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
    num_true]</code>. The target classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  num_sampled: An <code>int</code>.  The number of classes to randomly sample per batch.
  unique: A <code>bool</code>. Determines whether all sampled classes in a batch are
    unique.
  range_max: An <code>int</code>. The number of possible classes.
  seed: An <code>int</code>. An operation-specific seed. Default is 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  sampled_candidates: A tensor of type <code>int64</code> and shape <code>[num_sampled]</code>.
    The sampled classes.
  true_expected_count: A tensor of type <code>float</code>.  Same shape as
    <code>true_classes</code>. The expected counts under the sampling distribution
    of each of <code>true_classes</code>.
  sampled_expected_count: A tensor of type <code>float</code>. Same shape as
    <code>sampled_candidates</code>. The expected counts under the sampling distribution
    of each of <code>sampled_candidates</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.log_uniform_candidate_sampler_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.log_uniform_candidate_sampler_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.logical_and">
    <p>def <span class="ident">logical_and</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.logical_and, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.logical_and</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.logical_and</strong></p>
<div class="codehilite"><pre><span></span>def logical_and(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.logical_and</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.logical_and</code></strong></p>
<div class="codehilite"><pre><span></span>def logical_and(x, y, name=None)
</pre></div>


<p>Returns the truth value of x AND y element-wise.</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>bool</code>.
  y: A <code>Tensor</code> of type <code>bool</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.logical_and', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.logical_and" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.logical_and_layer">
    <p>def <span class="ident">logical_and_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.logical_and_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.logical_and_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.logical_and_layer</strong></p>
<div class="codehilite"><pre><span></span>def logical_and_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.logical_and, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.logical_and</strong></p>
<div class="codehilite"><pre><span></span>def logical_and(x, y, name=None):
</pre></div>


<p>Returns the truth value of x AND y element-wise.</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>bool</code>.
  y: A <code>Tensor</code> of type <code>bool</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.logical_and_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.logical_and_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.logical_not">
    <p>def <span class="ident">logical_not</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.logical_not, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.logical_not</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.logical_not</strong></p>
<div class="codehilite"><pre><span></span>def logical_not(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.logical_not</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.logical_not</code></strong></p>
<div class="codehilite"><pre><span></span>def logical_not(x, name=None)
</pre></div>


<p>Returns the truth value of NOT x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>bool</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.logical_not', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.logical_not" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.logical_not_layer">
    <p>def <span class="ident">logical_not_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.logical_not_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.logical_not_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.logical_not_layer</strong></p>
<div class="codehilite"><pre><span></span>def logical_not_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.logical_not, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.logical_not</strong></p>
<div class="codehilite"><pre><span></span>def logical_not(x, name=None):
</pre></div>


<p>Returns the truth value of NOT x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>bool</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.logical_not_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.logical_not_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.logical_or">
    <p>def <span class="ident">logical_or</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.logical_or, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.logical_or</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.logical_or</strong></p>
<div class="codehilite"><pre><span></span>def logical_or(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.logical_or</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.logical_or</code></strong></p>
<div class="codehilite"><pre><span></span>def logical_or(x, y, name=None)
</pre></div>


<p>Returns the truth value of x OR y element-wise.</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>bool</code>.
  y: A <code>Tensor</code> of type <code>bool</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.logical_or', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.logical_or" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.logical_or_layer">
    <p>def <span class="ident">logical_or_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.logical_or_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.logical_or_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.logical_or_layer</strong></p>
<div class="codehilite"><pre><span></span>def logical_or_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.logical_or, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.logical_or</strong></p>
<div class="codehilite"><pre><span></span>def logical_or(x, y, name=None):
</pre></div>


<p>Returns the truth value of x OR y element-wise.</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>bool</code>.
  y: A <code>Tensor</code> of type <code>bool</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.logical_or_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.logical_or_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.logical_xor">
    <p>def <span class="ident">logical_xor</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.logical_xor, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.logical_xor</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.logical_xor</strong></p>
<div class="codehilite"><pre><span></span>def logical_xor(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.logical_xor</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.logical_xor</code></strong></p>
<div class="codehilite"><pre><span></span>def logical_xor(x, y, name=&quot;LogicalXor&quot;)
</pre></div>


<p>x ^ y = (x | y) &amp; ~(x &amp; y).</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.logical_xor', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.logical_xor" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.logical_xor_layer">
    <p>def <span class="ident">logical_xor_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.logical_xor_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.logical_xor_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.logical_xor_layer</strong></p>
<div class="codehilite"><pre><span></span>def logical_xor_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.logical_xor, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.logical_xor</strong></p>
<div class="codehilite"><pre><span></span>def logical_xor(x, y, name=&quot;LogicalXor&quot;):
</pre></div>


<p>x ^ y = (x | y) &amp; ~(x &amp; y).</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.logical_xor_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.logical_xor_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.lrn">
    <p>def <span class="ident">lrn</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.lrn, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.lrn</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.lrn</strong></p>
<div class="codehilite"><pre><span></span>def lrn(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.lrn</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.lrn</code></strong></p>
<div class="codehilite"><pre><span></span>def lrn(input, depth_radius=None, bias=None, alpha=None, beta=None, name=None)
</pre></div>


<p>Local Response Normalization.</p>
<p>The 4-D <code>input</code> tensor is treated as a 3-D array of 1-D vectors (along the last
dimension), and each vector is normalized independently.  Within a given vector,
each component is divided by the weighted, squared sum of inputs within
<code>depth_radius</code>.  In detail,</p>
<div class="codehilite"><pre><span></span>sqr_sum[a, b, c, d] =
    sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ** 2)
output = input / (bias + alpha * sqr_sum) ** beta
</pre></div>


<p>For details, see [Krizhevsky et al., ImageNet classification with deep
convolutional neural networks (NIPS 2012)]
(http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks).</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>float32</code>. 4-D.
  depth_radius: An optional <code>int</code>. Defaults to <code>5</code>.
    0-D.  Half-width of the 1-D normalization window.
  bias: An optional <code>float</code>. Defaults to <code>1</code>.
    An offset (usually positive to avoid dividing by 0).
  alpha: An optional <code>float</code>. Defaults to <code>1</code>.
    A scale factor, usually positive.
  beta: An optional <code>float</code>. Defaults to <code>0.5</code>. An exponent.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>float32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.lrn', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.lrn" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.lrn_layer">
    <p>def <span class="ident">lrn_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.lrn_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.lrn_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.lrn_layer</strong></p>
<div class="codehilite"><pre><span></span>def lrn_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.lrn, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.lrn</strong></p>
<div class="codehilite"><pre><span></span>def lrn(input, depth_radius=None, bias=None, alpha=None, beta=None, name=None):
</pre></div>


<p>Local Response Normalization.</p>
<p>The 4-D <code>input</code> tensor is treated as a 3-D array of 1-D vectors (along the last
dimension), and each vector is normalized independently.  Within a given vector,
each component is divided by the weighted, squared sum of inputs within
<code>depth_radius</code>.  In detail,</p>
<div class="codehilite"><pre><span></span>sqr_sum[a, b, c, d] =
    sum(input[a, b, c, d - depth_radius : d + depth_radius + 1] ** 2)
output = input / (bias + alpha * sqr_sum) ** beta
</pre></div>


<p>For details, see [Krizhevsky et al., ImageNet classification with deep
convolutional neural networks (NIPS 2012)]
(http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks).</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>float32</code>. 4-D.
  depth_radius: An optional <code>int</code>. Defaults to <code>5</code>.
    0-D.  Half-width of the 1-D normalization window.
  bias: An optional <code>float</code>. Defaults to <code>1</code>.
    An offset (usually positive to avoid dividing by 0).
  alpha: An optional <code>float</code>. Defaults to <code>1</code>.
    A scale factor, usually positive.
  beta: An optional <code>float</code>. Defaults to <code>0.5</code>. An exponent.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>float32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.lrn_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.lrn_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.make_all">
    <p>def <span class="ident">make_all</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.make_all, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.make_all</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.make_all</strong></p>
<div class="codehilite"><pre><span></span>def make_all(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.make_all</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.make_all</code></strong></p>
<div class="codehilite"><pre><span></span>def make_all(module_name, doc_string_modules=None)
</pre></div>


<p>Generate <code>__all__</code> from the docstring of one or more modules.</p>
<p>Usage: <code>make_all(__name__)</code> or
<code>make_all(__name__, [sys.modules(__name__), other_module])</code>. The doc string
modules must each a docstring, and <code>__all__</code> will contain all symbols with
<code>@@</code> references, where that symbol currently exists in the module named
<code>module_name</code>.</p>
<p>Args:
  module_name: The name of the module (usually <code>__name__</code>).
  doc_string_modules: a list of modules from which to take docstring.
  If None, then a list containing only the module named <code>module_name</code> is used.</p>
<p>Returns:
  A list suitable for use as <code>__all__</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.make_all', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.make_all" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.make_all_layer">
    <p>def <span class="ident">make_all_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.make_all_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.make_all_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.make_all_layer</strong></p>
<div class="codehilite"><pre><span></span>def make_all_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.make_all, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.make_all</strong></p>
<div class="codehilite"><pre><span></span>def make_all(module_name, doc_string_modules=None):
</pre></div>


<p>Generate <code>__all__</code> from the docstring of one or more modules.</p>
<p>Usage: <code>make_all(__name__)</code> or
<code>make_all(__name__, [sys.modules(__name__), other_module])</code>. The doc string
modules must each a docstring, and <code>__all__</code> will contain all symbols with
<code>@@</code> references, where that symbol currently exists in the module named
<code>module_name</code>.</p>
<p>Args:
  module_name: The name of the module (usually <code>__name__</code>).
  doc_string_modules: a list of modules from which to take docstring.
  If None, then a list containing only the module named <code>module_name</code> is used.</p>
<p>Returns:
  A list suitable for use as <code>__all__</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.make_all_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.make_all_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.make_template">
    <p>def <span class="ident">make_template</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.make_template, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.make_template</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.make_template</strong></p>
<div class="codehilite"><pre><span></span>def make_template(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.make_template</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.make_template</code></strong></p>
<div class="codehilite"><pre><span></span>def make_template(name_, func_, create_scope_now_=False)
</pre></div>


<p>Given an arbitrary function, wrap it so that it does variable sharing.</p>
<p>This wraps <code>func_</code> in a Template and partially evaluates it. Templates are
functions that create variables the first time they are called and reuse them
thereafter. In order for <code>func_</code> to be compatible with a <code>Template</code> it must
have the following properties:</p>
<ul>
<li>The function should create all trainable variables and any variables that
   should be reused by calling <code>tf.get_variable</code>. If a trainable variable is
   created using <code>tf.Variable</code>, then a ValueError will be thrown. Variables
   that are intended to be locals can be created by specifying
   <code>tf.Variable(..., trainable=false)</code>.</li>
<li>The function may use variable scopes and other templates internally to
    create and reuse variables, but it shouldn't use <code>tf.get_variables</code> to
    capture variables that are defined outside of the scope of the function.</li>
<li>Internal scopes and variable names should not depend on any arguments that
    are not supplied to <code>make_template</code>. In general you will get a ValueError
    telling you that you are trying to reuse a variable that doesn't exist
    if you make a mistake.</li>
</ul>
<p>In the following example, both <code>z</code> and <code>w</code> will be scaled by the same <code>y</code>. It
is important to note that if we didn't assign <code>scalar_name</code> and used a
different name for z and w that a <code>ValueError</code> would be thrown because it
couldn't reuse the variable.</p>
<p>```python
def my_op(x, scalar_name):
  var1 = tf.get_variable(scalar_name,
                         shape=[],
                         initializer=tf.constant_initializer(1))
  return x * var1</p>
<p>scale_by_y = tf.make_template('scale_by_y', my_op, scalar_name='y')</p>
<p>z = scale_by_y(input1)
w = scale_by_y(input2)
```</p>
<p>As a safe-guard, the returned function will raise a <code>ValueError</code> after the
first call if trainable variables are created by calling <code>tf.Variable</code>.</p>
<p>If all of these are true, then 2 properties are enforced by the template:</p>
<ol>
<li>Calling the same template multiple times will share all non-local
    variables.</li>
<li>Two different templates are guaranteed to be unique, unless you reenter the
    same variable scope as the initial definition of a template and redefine
    it. An examples of this exception:</li>
</ol>
<p>```python
def my_op(x, scalar_name):
  var1 = tf.get_variable(scalar_name,
                         shape=[],
                         initializer=tf.constant_initializer(1))
  return x * var1</p>
<p>with tf.variable_scope('scope') as vs:
  scale_by_y = tf.make_template('scale_by_y', my_op, scalar_name='y')
  z = scale_by_y(input1)
  w = scale_by_y(input2)</p>
<h1>Creates a template that reuses the variables above.</h1>
<p>with tf.variable_scope(vs, reuse=True):
  scale_by_y2 = tf.make_template('scale_by_y', my_op, scalar_name='y')
  z2 = scale_by_y2(input1)
  w2 = scale_by_y2(input2)
```</p>
<p>Depending on the value of <code>create_scope_now_</code>, the full variable scope may be
captured either at the time of first call or at the time of construction. If
this option is set to True, then all Tensors created by repeated calls to the
template will have an extra trailing _N+1 to their name, as the first time the
scope is entered in the Template constructor no Tensors are created.</p>
<p>Note: <code>name_</code>, <code>func_</code> and <code>create_scope_now_</code> have a trailing underscore to
reduce the likelihood of collisions with kwargs.</p>
<p>Args:
  name_: A name for the scope created by this template. If necessary, the name
    will be made unique by appending <code>_N</code> to the name.
  func_: The function to wrap.
  create_scope_now_: Boolean controlling whether the scope should be created
    when the template is constructed or when the template is called. Default
    is False, meaning the scope is created when the template is called.
  **kwargs: Keyword arguments to apply to <code>func_</code>.</p>
<p>Returns:
  A function to encapsulate a set of variables which should be created once
  and reused. An enclosing scope will created, either where <code>make_template</code>
  is called, or wherever the result is called, depending on the value of
  <code>create_scope_now_</code>. Regardless of the value, the first time the template
  is called it will enter the scope with no reuse, and call <code>func_</code> to create
  variables, which are guaranteed to be unique. All subsequent calls will
  re-enter the scope and reuse those variables.</p>
<p>Raises:
  ValueError: if the name is None.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.make_template', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.make_template" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.make_template_layer">
    <p>def <span class="ident">make_template_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.make_template_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.make_template_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.make_template_layer</strong></p>
<div class="codehilite"><pre><span></span>def make_template_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.make_template, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.make_template</strong></p>
<div class="codehilite"><pre><span></span>def make_template(name_, func_, create_scope_now_=False):
</pre></div>


<p>Given an arbitrary function, wrap it so that it does variable sharing.</p>
<p>This wraps <code>func_</code> in a Template and partially evaluates it. Templates are
functions that create variables the first time they are called and reuse them
thereafter. In order for <code>func_</code> to be compatible with a <code>Template</code> it must
have the following properties:</p>
<ul>
<li>The function should create all trainable variables and any variables that
   should be reused by calling <code>tf.get_variable</code>. If a trainable variable is
   created using <code>tf.Variable</code>, then a ValueError will be thrown. Variables
   that are intended to be locals can be created by specifying
   <code>tf.Variable(..., trainable=false)</code>.</li>
<li>The function may use variable scopes and other templates internally to
    create and reuse variables, but it shouldn't use <code>tf.get_variables</code> to
    capture variables that are defined outside of the scope of the function.</li>
<li>Internal scopes and variable names should not depend on any arguments that
    are not supplied to <code>make_template</code>. In general you will get a ValueError
    telling you that you are trying to reuse a variable that doesn't exist
    if you make a mistake.</li>
</ul>
<p>In the following example, both <code>z</code> and <code>w</code> will be scaled by the same <code>y</code>. It
is important to note that if we didn't assign <code>scalar_name</code> and used a
different name for z and w that a <code>ValueError</code> would be thrown because it
couldn't reuse the variable.</p>
<p>```python
def my_op(x, scalar_name):
  var1 = tf.get_variable(scalar_name,
                         shape=[],
                         initializer=tf.constant_initializer(1))
  return x * var1</p>
<p>scale_by_y = tf.make_template('scale_by_y', my_op, scalar_name='y')</p>
<p>z = scale_by_y(input1)
w = scale_by_y(input2)
```</p>
<p>As a safe-guard, the returned function will raise a <code>ValueError</code> after the
first call if trainable variables are created by calling <code>tf.Variable</code>.</p>
<p>If all of these are true, then 2 properties are enforced by the template:</p>
<ol>
<li>Calling the same template multiple times will share all non-local
    variables.</li>
<li>Two different templates are guaranteed to be unique, unless you reenter the
    same variable scope as the initial definition of a template and redefine
    it. An examples of this exception:</li>
</ol>
<p>```python
def my_op(x, scalar_name):
  var1 = tf.get_variable(scalar_name,
                         shape=[],
                         initializer=tf.constant_initializer(1))
  return x * var1</p>
<p>with tf.variable_scope('scope') as vs:
  scale_by_y = tf.make_template('scale_by_y', my_op, scalar_name='y')
  z = scale_by_y(input1)
  w = scale_by_y(input2)</p>
<h1>Creates a template that reuses the variables above.</h1>
<p>with tf.variable_scope(vs, reuse=True):
  scale_by_y2 = tf.make_template('scale_by_y', my_op, scalar_name='y')
  z2 = scale_by_y2(input1)
  w2 = scale_by_y2(input2)
```</p>
<p>Depending on the value of <code>create_scope_now_</code>, the full variable scope may be
captured either at the time of first call or at the time of construction. If
this option is set to True, then all Tensors created by repeated calls to the
template will have an extra trailing _N+1 to their name, as the first time the
scope is entered in the Template constructor no Tensors are created.</p>
<p>Note: <code>name_</code>, <code>func_</code> and <code>create_scope_now_</code> have a trailing underscore to
reduce the likelihood of collisions with kwargs.</p>
<p>Args:
  name_: A name for the scope created by this template. If necessary, the name
    will be made unique by appending <code>_N</code> to the name.
  func_: The function to wrap.
  create_scope_now_: Boolean controlling whether the scope should be created
    when the template is constructed or when the template is called. Default
    is False, meaning the scope is created when the template is called.
  **kwargs: Keyword arguments to apply to <code>func_</code>.</p>
<p>Returns:
  A function to encapsulate a set of variables which should be created once
  and reused. An enclosing scope will created, either where <code>make_template</code>
  is called, or wherever the result is called, depending on the value of
  <code>create_scope_now_</code>. Regardless of the value, the first time the template
  is called it will enter the scope with no reuse, and call <code>func_</code> to create
  variables, which are guaranteed to be unique. All subsequent calls will
  re-enter the scope and reuse those variables.</p>
<p>Raises:
  ValueError: if the name is None.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.make_template_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.make_template_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.map">
    <p>def <span class="ident">map</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.map, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.map</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.map</strong></p>
<div class="codehilite"><pre><span></span>def map(builder, fn):
</pre></div>


<p><code>@immutable</code></p>
<p>Let <strong>x</strong> be Tensor inside a Builder <code>builder</code> and <strong>fn</strong> be a function from a tensor to a tensor, then <code>builder.map(fn, \*args, **kwargs)</code> computes <code>fn(x, *args, **kwargs) and stores the result inside a Builder</code>. The Builder class comes with a lot of <strong>patched</strong> methods that help you do things quickly and make the syntax nicer, but if we don't have the method you need just pass the function you want to use to <code>map</code>, or even consider using <code>tensorbuilder.core.builders.Builder.register_map_method</code>.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>fn</code>: a function of type <code>tensor -&gt; tensor</code>.</li>
<li>All extra positional and named arguments are forwarded to <code>fn</code></li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><code>tensorbuilder.core.builders.Builder</code></li>
</ul>
<p><strong>Examples</strong></p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">40</span><span class="p">])</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">h</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">)</span>
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div>


<p>Same using the DSL</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">40</span><span class="p">])</span>
<span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">h</span> <span class="o">=</span> <span class="n">tb</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">tanh</span><span class="p">)</span>
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dropout</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">)</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.map', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.map" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.map_each">
    <p>def <span class="ident">map_each</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(BuilderTree.map_each, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>BuilderTree.map_each</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for BuilderTree.map_each</strong></p>
<div class="codehilite"><pre><span></span>def map_each(tree, fn):
</pre></div>


<p><code>@immutable</code></p>
<p>Expects a function <strong>fn</strong> with type <code>Tensor -&gt; Tensor</code> and applies this function to all leaf Tensors separately, resulting in a new BuilderTree.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>fn</code>: a function of type <code>Tensor -&gt; Tensor</code>.</li>
<li>All additional *args and **kwargs are forwarded to <code>fn</code></li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><code>tensorbuilder.core.builders.BuilderTree</code></li>
</ul>
<p><strong> Example </strong></p>
<p>Lets redu the example in <code>tensorbuilder.core.builders.BuilderTree.reduce</code> using <code>map_each</code> to reduce some code</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">h</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span>
        <span class="n">x</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">x</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">x</span><span class="o">.</span><span class="n">tanh_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">])</span>
    <span class="o">.</span><span class="n">map_each</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    <span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">)</span>
    <span class="o">.</span><span class="n">softmax</span><span class="p">()</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>


<p>Remember that this</p>
<div class="codehilite"><pre><span></span><span class="na">.map_each</span><span class="p">(</span><span class="no">tf.contrib.layers.fully_connected</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="no">activation_fn</span><span class="err">=</span><span class="no">None</span><span class="p">)</span>
<span class="na">.reduce</span><span class="p">(</span><span class="no">tf.add</span><span class="p">)</span>
<span class="na">.softmax</span><span class="p">()</span>
</pre></div>


<p>is equivalent to just</p>
<div class="codehilite"><pre><span></span><span class="na">.softmax_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>


<p>for <code>BuilderTree</code>s. Same example using the DSL</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">h</span> <span class="o">=</span> <span class="n">tb</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="p">[</span>
        <span class="n">x</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">x</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">x</span><span class="o">.</span><span class="n">tanh_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">map_each</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    <span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">)</span>
    <span class="o">.</span><span class="n">softmax</span><span class="p">()</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.map_each', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.map_each" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.map_fn">
    <p>def <span class="ident">map_fn</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.map_fn, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.map_fn</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.map_fn</strong></p>
<div class="codehilite"><pre><span></span>def map_fn(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.map_fn</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.map_fn</code></strong></p>
<div class="codehilite"><pre><span></span>def map_fn(fn, elems, dtype=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)
</pre></div>


<p>map on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p>This map operator repeatedly applies the callable <code>fn</code> to a sequence of
elements from first to last. The elements are made of the tensors unpacked
from <code>elems</code>. <code>dtype</code> is the data type of the return value of <code>fn</code>. Users
must provide <code>dtype</code> if it is different from the data type of <code>elems</code>.</p>
<p>Suppose that <code>elems</code> is unpacked into <code>values</code>, a list of tensors. The shape
of the result tensor is <code>[len(values)] + fn(values[0]).shape</code>.</p>
<p>Args:
  fn: The callable to be performed.
  elems: A tensor to be unpacked to apply <code>fn</code>.
  dtype: (optional) The output type of <code>fn</code>.
  parallel_iterations: (optional) The number of iterations allowed to run
                       in parallel.
  back_prop: (optional) True enables back propagation.
  swap_memory: (optional) True enables GPU-CPU memory swapping.
  name: (optional) Name prefix for the returned tensors.</p>
<p>Returns:
  A tensor that packs the results of applying <code>fn</code> to the list of tensors
  unpacked from <code>elems</code>, from first to last.</p>
<p>Raises:
  TypeError: if <code>fn</code> is not callable.</p>
<p>Example:
  <code>python
  elems = [1, 2, 3, 4, 5, 6]
  squares = map_fn(lambda x: x * x, elems)
  # squares == [1, 4, 9, 16, 25, 36]</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.map_fn', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.map_fn" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.map_fn_layer">
    <p>def <span class="ident">map_fn_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.map_fn_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.map_fn_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.map_fn_layer</strong></p>
<div class="codehilite"><pre><span></span>def map_fn_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.map_fn, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.map_fn</strong></p>
<div class="codehilite"><pre><span></span>def map_fn(fn, elems, dtype=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None):
</pre></div>


<p>map on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p>This map operator repeatedly applies the callable <code>fn</code> to a sequence of
elements from first to last. The elements are made of the tensors unpacked
from <code>elems</code>. <code>dtype</code> is the data type of the return value of <code>fn</code>. Users
must provide <code>dtype</code> if it is different from the data type of <code>elems</code>.</p>
<p>Suppose that <code>elems</code> is unpacked into <code>values</code>, a list of tensors. The shape
of the result tensor is <code>[len(values)] + fn(values[0]).shape</code>.</p>
<p>Args:
  fn: The callable to be performed.
  elems: A tensor to be unpacked to apply <code>fn</code>.
  dtype: (optional) The output type of <code>fn</code>.
  parallel_iterations: (optional) The number of iterations allowed to run
                       in parallel.
  back_prop: (optional) True enables back propagation.
  swap_memory: (optional) True enables GPU-CPU memory swapping.
  name: (optional) Name prefix for the returned tensors.</p>
<p>Returns:
  A tensor that packs the results of applying <code>fn</code> to the list of tensors
  unpacked from <code>elems</code>, from first to last.</p>
<p>Raises:
  TypeError: if <code>fn</code> is not callable.</p>
<p>Example:
  <code>python
  elems = [1, 2, 3, 4, 5, 6]
  squares = map_fn(lambda x: x * x, elems)
  # squares == [1, 4, 9, 16, 25, 36]</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.map_fn_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.map_fn_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matching_files">
    <p>def <span class="ident">matching_files</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matching_files, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matching_files</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matching_files</strong></p>
<div class="codehilite"><pre><span></span>def matching_files(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.matching_files</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.matching_files</code></strong></p>
<div class="codehilite"><pre><span></span>def matching_files(pattern, name=None)
</pre></div>


<p>Returns the set of files matching a pattern.</p>
<p>Note that this routine only supports wildcard characters in the
basename portion of the pattern, not in the directory portion.</p>
<p>Args:
  pattern: A <code>Tensor</code> of type <code>string</code>. A (scalar) shell wildcard pattern.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>string</code>. A vector of matching filenames.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matching_files', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matching_files" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matching_files_layer">
    <p>def <span class="ident">matching_files_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matching_files_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matching_files_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matching_files_layer</strong></p>
<div class="codehilite"><pre><span></span>def matching_files_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.matching_files, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.matching_files</strong></p>
<div class="codehilite"><pre><span></span>def matching_files(pattern, name=None):
</pre></div>


<p>Returns the set of files matching a pattern.</p>
<p>Note that this routine only supports wildcard characters in the
basename portion of the pattern, not in the directory portion.</p>
<p>Args:
  pattern: A <code>Tensor</code> of type <code>string</code>. A (scalar) shell wildcard pattern.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>string</code>. A vector of matching filenames.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matching_files_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matching_files_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matmul">
    <p>def <span class="ident">matmul</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matmul, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matmul</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matmul</strong></p>
<div class="codehilite"><pre><span></span>def matmul(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.matmul</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.matmul</code></strong></p>
<div class="codehilite"><pre><span></span>def matmul(a, b, transpose_a=False, transpose_b=False, a_is_sparse=False, b_is_sparse=False, name=None)
</pre></div>


<p>Multiplies matrix <code>a</code> by matrix <code>b</code>, producing <code>a</code> * <code>b</code>.</p>
<p>The inputs must be two-dimensional matrices, with matching inner dimensions,
possibly after transposition.</p>
<p>Both matrices must be of the same type. The supported types are:
<code>float</code>, <code>double</code>, <code>int32</code>, <code>complex64</code>.</p>
<p>Either matrix can be transposed on the fly by setting the corresponding flag
to <code>True</code>. This is <code>False</code> by default.</p>
<p>If one or both of the matrices contain a lot of zeros, a more efficient
multiplication algorithm can be used by setting the corresponding
<code>a_is_sparse</code> or <code>b_is_sparse</code> flag to <code>True</code>. These are <code>False</code> by default.</p>
<p>For example:</p>
<p>```python</p>
<h1>2-D tensor <code>a</code></h1>
<p>a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3]) =&gt; [[1. 2. 3.]
                                                      [4. 5. 6.]]</p>
<h1>2-D tensor <code>b</code></h1>
<p>b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2]) =&gt; [[7. 8.]
                                                         [9. 10.]
                                                         [11. 12.]]
c = tf.matmul(a, b) =&gt; [[58 64]
                        [139 154]]
```</p>
<p>Args:
  a: <code>Tensor</code> of type <code>float</code>, <code>double</code>, <code>int32</code> or <code>complex64</code>.
  b: <code>Tensor</code> with same type as <code>a</code>.
  transpose_a: If <code>True</code>, <code>a</code> is transposed before multiplication.
  transpose_b: If <code>True</code>, <code>b</code> is transposed before multiplication.
  a_is_sparse: If <code>True</code>, <code>a</code> is treated as a sparse matrix.
  b_is_sparse: If <code>True</code>, <code>b</code> is treated as a sparse matrix.
  name: Name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of the same type as <code>a</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matmul', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matmul" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matmul_layer">
    <p>def <span class="ident">matmul_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matmul_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matmul_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matmul_layer</strong></p>
<div class="codehilite"><pre><span></span>def matmul_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.matmul, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.matmul</strong></p>
<div class="codehilite"><pre><span></span>def matmul(a, b, transpose_a=False, transpose_b=False, a_is_sparse=False, b_is_sparse=False, name=None):
</pre></div>


<p>Multiplies matrix <code>a</code> by matrix <code>b</code>, producing <code>a</code> * <code>b</code>.</p>
<p>The inputs must be two-dimensional matrices, with matching inner dimensions,
possibly after transposition.</p>
<p>Both matrices must be of the same type. The supported types are:
<code>float</code>, <code>double</code>, <code>int32</code>, <code>complex64</code>.</p>
<p>Either matrix can be transposed on the fly by setting the corresponding flag
to <code>True</code>. This is <code>False</code> by default.</p>
<p>If one or both of the matrices contain a lot of zeros, a more efficient
multiplication algorithm can be used by setting the corresponding
<code>a_is_sparse</code> or <code>b_is_sparse</code> flag to <code>True</code>. These are <code>False</code> by default.</p>
<p>For example:</p>
<p>```python</p>
<h1>2-D tensor <code>a</code></h1>
<p>a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3]) =&gt; [[1. 2. 3.]
                                                      [4. 5. 6.]]</p>
<h1>2-D tensor <code>b</code></h1>
<p>b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2]) =&gt; [[7. 8.]
                                                         [9. 10.]
                                                         [11. 12.]]
c = tf.matmul(a, b) =&gt; [[58 64]
                        [139 154]]
```</p>
<p>Args:
  a: <code>Tensor</code> of type <code>float</code>, <code>double</code>, <code>int32</code> or <code>complex64</code>.
  b: <code>Tensor</code> with same type as <code>a</code>.
  transpose_a: If <code>True</code>, <code>a</code> is transposed before multiplication.
  transpose_b: If <code>True</code>, <code>b</code> is transposed before multiplication.
  a_is_sparse: If <code>True</code>, <code>a</code> is treated as a sparse matrix.
  b_is_sparse: If <code>True</code>, <code>b</code> is treated as a sparse matrix.
  name: Name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of the same type as <code>a</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matmul_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matmul_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matrix_determinant">
    <p>def <span class="ident">matrix_determinant</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matrix_determinant, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matrix_determinant</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matrix_determinant</strong></p>
<div class="codehilite"><pre><span></span>def matrix_determinant(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.matrix_determinant</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.matrix_determinant</code></strong></p>
<div class="codehilite"><pre><span></span>def matrix_determinant(input, name=None)
</pre></div>


<p>Calculates the determinant of a square matrix.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    A tensor of shape <code>[M, M]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  A scalar, equal to the determinant of the input.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matrix_determinant', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matrix_determinant" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matrix_determinant_layer">
    <p>def <span class="ident">matrix_determinant_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matrix_determinant_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matrix_determinant_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matrix_determinant_layer</strong></p>
<div class="codehilite"><pre><span></span>def matrix_determinant_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.matrix_determinant, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.matrix_determinant</strong></p>
<div class="codehilite"><pre><span></span>def matrix_determinant(input, name=None):
</pre></div>


<p>Calculates the determinant of a square matrix.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    A tensor of shape <code>[M, M]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  A scalar, equal to the determinant of the input.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matrix_determinant_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matrix_determinant_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matrix_inverse">
    <p>def <span class="ident">matrix_inverse</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matrix_inverse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matrix_inverse</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matrix_inverse</strong></p>
<div class="codehilite"><pre><span></span>def matrix_inverse(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.matrix_inverse</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.matrix_inverse</code></strong></p>
<div class="codehilite"><pre><span></span>def matrix_inverse(input, adjoint=None, name=None)
</pre></div>


<p>Calculates the inverse of a square invertible matrix or its adjoint (conjugate</p>
<p>transpose).</p>
<p>The op uses LU decomposition with partial pivoting to compute the inverse.</p>
<p>If the matrix is not invertible there is no guarantee what the op does. It
may detect the condition and raise an exception or it may simply return a
garbage result.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[M, M]</code>.
  adjoint: An optional <code>bool</code>. Defaults to <code>False</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  Shape is <code>[M, M]</code>. If <code>adjoint</code> is <code>False</code> then <code>output</code> contains the
  matrix inverse of <code>input</code>. If <code>adjoint</code> is <code>True</code> then <code>output</code> contains the
  matrix inverse of the adjoint of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matrix_inverse', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matrix_inverse" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matrix_inverse_layer">
    <p>def <span class="ident">matrix_inverse_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matrix_inverse_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matrix_inverse_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matrix_inverse_layer</strong></p>
<div class="codehilite"><pre><span></span>def matrix_inverse_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.matrix_inverse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.matrix_inverse</strong></p>
<div class="codehilite"><pre><span></span>def matrix_inverse(input, adjoint=None, name=None):
</pre></div>


<p>Calculates the inverse of a square invertible matrix or its adjoint (conjugate</p>
<p>transpose).</p>
<p>The op uses LU decomposition with partial pivoting to compute the inverse.</p>
<p>If the matrix is not invertible there is no guarantee what the op does. It
may detect the condition and raise an exception or it may simply return a
garbage result.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[M, M]</code>.
  adjoint: An optional <code>bool</code>. Defaults to <code>False</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  Shape is <code>[M, M]</code>. If <code>adjoint</code> is <code>False</code> then <code>output</code> contains the
  matrix inverse of <code>input</code>. If <code>adjoint</code> is <code>True</code> then <code>output</code> contains the
  matrix inverse of the adjoint of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matrix_inverse_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matrix_inverse_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matrix_solve">
    <p>def <span class="ident">matrix_solve</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matrix_solve, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matrix_solve</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matrix_solve</strong></p>
<div class="codehilite"><pre><span></span>def matrix_solve(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.matrix_solve</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.matrix_solve</code></strong></p>
<div class="codehilite"><pre><span></span>def matrix_solve(matrix, rhs, adjoint=None, name=None)
</pre></div>


<p>Solves a system of linear equations. Checks for invertibility.</p>
<p>Args:
  matrix: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[M, M]</code>.
  rhs: A <code>Tensor</code>. Must have the same type as <code>matrix</code>. Shape is <code>[M, K]</code>.
  adjoint: An optional <code>bool</code>. Defaults to <code>False</code>.
    Boolean indicating whether to solve with <code>matrix</code> or its adjoint.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>matrix</code>.
  Shape is <code>[M, K]</code>. If <code>adjoint</code> is <code>False</code> then <code>output</code> that solves
  <code>matrix</code> * <code>output</code> = <code>rhs</code>. If <code>adjoint</code> is <code>True</code> then <code>output</code> that solves
  <code>adjoint(matrix)</code> * <code>output</code> = <code>rhs</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matrix_solve', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matrix_solve" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matrix_solve_layer">
    <p>def <span class="ident">matrix_solve_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matrix_solve_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matrix_solve_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matrix_solve_layer</strong></p>
<div class="codehilite"><pre><span></span>def matrix_solve_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.matrix_solve, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.matrix_solve</strong></p>
<div class="codehilite"><pre><span></span>def matrix_solve(matrix, rhs, adjoint=None, name=None):
</pre></div>


<p>Solves a system of linear equations. Checks for invertibility.</p>
<p>Args:
  matrix: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[M, M]</code>.
  rhs: A <code>Tensor</code>. Must have the same type as <code>matrix</code>. Shape is <code>[M, K]</code>.
  adjoint: An optional <code>bool</code>. Defaults to <code>False</code>.
    Boolean indicating whether to solve with <code>matrix</code> or its adjoint.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>matrix</code>.
  Shape is <code>[M, K]</code>. If <code>adjoint</code> is <code>False</code> then <code>output</code> that solves
  <code>matrix</code> * <code>output</code> = <code>rhs</code>. If <code>adjoint</code> is <code>True</code> then <code>output</code> that solves
  <code>adjoint(matrix)</code> * <code>output</code> = <code>rhs</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matrix_solve_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matrix_solve_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matrix_solve_ls">
    <p>def <span class="ident">matrix_solve_ls</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matrix_solve_ls, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matrix_solve_ls</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matrix_solve_ls</strong></p>
<div class="codehilite"><pre><span></span>def matrix_solve_ls(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.matrix_solve_ls</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.matrix_solve_ls</code></strong></p>
<div class="codehilite"><pre><span></span>def matrix_solve_ls(matrix, rhs, l2_regularizer=0.0, fast=True, name=None)
</pre></div>


<p>Solves a linear least-squares problem.</p>
<p>Below we will use the following notation
<code>matrix</code>=\(A \in \Re^{m \times n}\),
<code>rhs</code>=\(B  \in \Re^{m \times k}\),
<code>output</code>=\(X  \in \Re^{n \times k}\),
<code>l2_regularizer</code>=\(\lambda\).</p>
<p>If <code>fast</code> is <code>True</code>, then the solution is computed by solving the normal
equations using Cholesky decomposition. Specifically, if \(m \ge n\) then
\(X = (A^T A + \lambda I)^{-1} A^T B\), which solves the regularized
least-squares problem \(X = \mathrm{argmin}<em>{Z \in \Re^{n \times k}}
||A Z - B||_F^2 + \lambda ||Z||_F^2\). If \(m \lt n\) then <code>output</code> is
computed as \(X = A^T (A A^T + \lambda I)^{-1} B\),
which (for \(\lambda = 0\)) is the minimum-norm solution to the
under-determined linear system, i.e.
\(X = \mathrm{argmin}</em>{Z \in \Re^{n \times k}} ||Z||<em>F^2 \),
subject to \(A Z = B\).
Notice that the fast path is only numerically stable when \(A\) is
numerically full rank and has a condition number
\(\mathrm{cond}(A) \lt \frac{1}{\sqrt{\epsilon</em>{mach}}}\)
or \(\lambda\) is sufficiently large.</p>
<p>If <code>fast</code> is <code>False</code> then the solution is computed using the rank revealing
QR decomposition with column pivoting. This will always compute a
least-squares solution that minimizes the residual norm
\(||A X - B||_F^2 \), even when \(A\) is rank deficient or
ill-conditioned. Notice: The current version does not compute a minimum norm
solution. If <code>fast</code> is <code>False</code> then <code>l2_regularizer</code> is ignored.</p>
<p>Args:
  matrix: 2-D <code>Tensor</code> of shape <code>[M, N]</code>.
  rhs: 2-D <code>Tensor</code> of shape is <code>[M, K]</code>.
  l2_regularizer: 0-D  <code>double</code> <code>Tensor</code>. Ignored if <code>fast=False</code>.
  fast: bool. Defaults to <code>True</code>.
  name: string, optional name of the operation.</p>
<p>Returns:
  output: Matrix of shape <code>[N, K]</code> containing the matrix that solves
    <code>matrix * output = rhs</code> in the least-squares sense.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matrix_solve_ls', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matrix_solve_ls" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matrix_solve_ls_layer">
    <p>def <span class="ident">matrix_solve_ls_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matrix_solve_ls_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matrix_solve_ls_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matrix_solve_ls_layer</strong></p>
<div class="codehilite"><pre><span></span>def matrix_solve_ls_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.matrix_solve_ls, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.matrix_solve_ls</strong></p>
<div class="codehilite"><pre><span></span>def matrix_solve_ls(matrix, rhs, l2_regularizer=0.0, fast=True, name=None):
</pre></div>


<p>Solves a linear least-squares problem.</p>
<p>Below we will use the following notation
<code>matrix</code>=\(A \in \Re^{m \times n}\),
<code>rhs</code>=\(B  \in \Re^{m \times k}\),
<code>output</code>=\(X  \in \Re^{n \times k}\),
<code>l2_regularizer</code>=\(\lambda\).</p>
<p>If <code>fast</code> is <code>True</code>, then the solution is computed by solving the normal
equations using Cholesky decomposition. Specifically, if \(m \ge n\) then
\(X = (A^T A + \lambda I)^{-1} A^T B\), which solves the regularized
least-squares problem \(X = \mathrm{argmin}<em>{Z \in \Re^{n \times k}}
||A Z - B||_F^2 + \lambda ||Z||_F^2\). If \(m \lt n\) then <code>output</code> is
computed as \(X = A^T (A A^T + \lambda I)^{-1} B\),
which (for \(\lambda = 0\)) is the minimum-norm solution to the
under-determined linear system, i.e.
\(X = \mathrm{argmin}</em>{Z \in \Re^{n \times k}} ||Z||<em>F^2 \),
subject to \(A Z = B\).
Notice that the fast path is only numerically stable when \(A\) is
numerically full rank and has a condition number
\(\mathrm{cond}(A) \lt \frac{1}{\sqrt{\epsilon</em>{mach}}}\)
or \(\lambda\) is sufficiently large.</p>
<p>If <code>fast</code> is <code>False</code> then the solution is computed using the rank revealing
QR decomposition with column pivoting. This will always compute a
least-squares solution that minimizes the residual norm
\(||A X - B||_F^2 \), even when \(A\) is rank deficient or
ill-conditioned. Notice: The current version does not compute a minimum norm
solution. If <code>fast</code> is <code>False</code> then <code>l2_regularizer</code> is ignored.</p>
<p>Args:
  matrix: 2-D <code>Tensor</code> of shape <code>[M, N]</code>.
  rhs: 2-D <code>Tensor</code> of shape is <code>[M, K]</code>.
  l2_regularizer: 0-D  <code>double</code> <code>Tensor</code>. Ignored if <code>fast=False</code>.
  fast: bool. Defaults to <code>True</code>.
  name: string, optional name of the operation.</p>
<p>Returns:
  output: Matrix of shape <code>[N, K]</code> containing the matrix that solves
    <code>matrix * output = rhs</code> in the least-squares sense.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matrix_solve_ls_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matrix_solve_ls_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matrix_triangular_solve">
    <p>def <span class="ident">matrix_triangular_solve</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matrix_triangular_solve, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matrix_triangular_solve</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matrix_triangular_solve</strong></p>
<div class="codehilite"><pre><span></span>def matrix_triangular_solve(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.matrix_triangular_solve</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.matrix_triangular_solve</code></strong></p>
<div class="codehilite"><pre><span></span>def matrix_triangular_solve(matrix, rhs, lower=None, adjoint=None, name=None)
</pre></div>


<p>Solves a system of linear equations with an upper or lower triangular matrix by</p>
<p>backsubstitution.</p>
<p><code>matrix</code> is a matrix of shape <code>[M, M]</code>. If <code>lower</code> is <code>True</code> then the strictly
upper triangular part of <code>matrix</code> is assumed to be zero and not accessed.
If <code>lower</code> is False then the strictly lower triangular part of <code>matrix</code> is
assumed to be zero and not accessed.
<code>rhs</code> is a matrix of shape [M, K]`.</p>
<p>The output is a matrix of shape <code>[M, K]</code>. If <code>adjoint</code> is <code>False</code> the output
satisfies the matrix equation <code>matrix</code> * <code>output</code> = <code>rhs</code>.
If <code>adjoint</code> is <code>False</code> then <code>output</code> satisfies the matrix equation
<code>matrix</code> * <code>output</code> = <code>rhs</code>.
If <code>adjoint</code> is <code>True</code> then <code>output</code> satisfies the matrix equation
<code>adjoint(matrix)</code> * <code>output</code> = <code>rhs</code>.</p>
<p>Args:
  matrix: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[M, M]</code>.
  rhs: A <code>Tensor</code>. Must have the same type as <code>matrix</code>. Shape is <code>[M, K]</code>.
  lower: An optional <code>bool</code>. Defaults to <code>True</code>.
    Boolean indicating whether <code>matrix</code> is lower or upper triangular
  adjoint: An optional <code>bool</code>. Defaults to <code>False</code>.
    Boolean indicating whether to solve with <code>matrix</code> or its adjoint.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>matrix</code>. Shape is <code>[M, K]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matrix_triangular_solve', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matrix_triangular_solve" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.matrix_triangular_solve_layer">
    <p>def <span class="ident">matrix_triangular_solve_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.matrix_triangular_solve_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.matrix_triangular_solve_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.matrix_triangular_solve_layer</strong></p>
<div class="codehilite"><pre><span></span>def matrix_triangular_solve_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.matrix_triangular_solve, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.matrix_triangular_solve</strong></p>
<div class="codehilite"><pre><span></span>def matrix_triangular_solve(matrix, rhs, lower=None, adjoint=None, name=None):
</pre></div>


<p>Solves a system of linear equations with an upper or lower triangular matrix by</p>
<p>backsubstitution.</p>
<p><code>matrix</code> is a matrix of shape <code>[M, M]</code>. If <code>lower</code> is <code>True</code> then the strictly
upper triangular part of <code>matrix</code> is assumed to be zero and not accessed.
If <code>lower</code> is False then the strictly lower triangular part of <code>matrix</code> is
assumed to be zero and not accessed.
<code>rhs</code> is a matrix of shape [M, K]`.</p>
<p>The output is a matrix of shape <code>[M, K]</code>. If <code>adjoint</code> is <code>False</code> the output
satisfies the matrix equation <code>matrix</code> * <code>output</code> = <code>rhs</code>.
If <code>adjoint</code> is <code>False</code> then <code>output</code> satisfies the matrix equation
<code>matrix</code> * <code>output</code> = <code>rhs</code>.
If <code>adjoint</code> is <code>True</code> then <code>output</code> satisfies the matrix equation
<code>adjoint(matrix)</code> * <code>output</code> = <code>rhs</code>.</p>
<p>Args:
  matrix: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[M, M]</code>.
  rhs: A <code>Tensor</code>. Must have the same type as <code>matrix</code>. Shape is <code>[M, K]</code>.
  lower: An optional <code>bool</code>. Defaults to <code>True</code>.
    Boolean indicating whether <code>matrix</code> is lower or upper triangular
  adjoint: An optional <code>bool</code>. Defaults to <code>False</code>.
    Boolean indicating whether to solve with <code>matrix</code> or its adjoint.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>matrix</code>. Shape is <code>[M, K]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.matrix_triangular_solve_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.matrix_triangular_solve_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.max_pool">
    <p>def <span class="ident">max_pool</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.max_pool, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.max_pool</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.max_pool</strong></p>
<div class="codehilite"><pre><span></span>def max_pool(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.max_pool</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.max_pool</code></strong></p>
<div class="codehilite"><pre><span></span>def max_pool(value, ksize, strides, padding, data_format=&quot;NHWC&quot;, name=None)
</pre></div>


<p>Performs the max pooling on the input.</p>
<p>Args:
  value: A 4-D <code>Tensor</code> with shape <code>[batch, height, width, channels]</code> and
    type <code>tf.float32</code>.
  ksize: A list of ints that has length &gt;= 4.  The size of the window for
    each dimension of the input tensor.
  strides: A list of ints that has length &gt;= 4.  The stride of the sliding
    window for each dimension of the input tensor.
  padding: A string, either <code>'VALID'</code> or <code>'SAME'</code>. The padding algorithm.
    See the <a href="https://www.tensorflow.org/api_docs/python/nn.html#convolution">comment here</a>
  data_format: A string. 'NHWC' and 'NCHW' are supported.
  name: Optional name for the operation.</p>
<p>Returns:
  A <code>Tensor</code> with type <code>tf.float32</code>.  The max pooled output tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.max_pool', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.max_pool" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.max_pool3d">
    <p>def <span class="ident">max_pool3d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.max_pool3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.max_pool3d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.max_pool3d</strong></p>
<div class="codehilite"><pre><span></span>def max_pool3d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.max_pool3d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.max_pool3d</code></strong></p>
<div class="codehilite"><pre><span></span>def max_pool3d(input, ksize, strides, padding, name=None)
</pre></div>


<p>Performs 3D max pooling on the input.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Shape <code>[batch, depth, rows, cols, channels]</code> tensor to pool over.
  ksize: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The size of the window for each dimension of
    the input tensor. Must have <code>ksize[0] = ksize[1] = 1</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. The max pooled output tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.max_pool3d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.max_pool3d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.max_pool3d_grad">
    <p>def <span class="ident">max_pool3d_grad</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.max_pool3d_grad, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.max_pool3d_grad</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.max_pool3d_grad</strong></p>
<div class="codehilite"><pre><span></span>def max_pool3d_grad(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.max_pool3d_grad</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.max_pool3d_grad</code></strong></p>
<div class="codehilite"><pre><span></span>def max_pool3d_grad(orig_input, orig_output, grad, ksize, strides, padding, name=None)
</pre></div>


<p>Computes gradients of max pooling function.</p>
<p>Args:
  orig_input: A <code>Tensor</code> of type <code>float32</code>. The original input tensor.
  orig_output: A <code>Tensor</code> of type <code>float32</code>. The original output tensor.
  grad: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Output backprop of shape <code>[batch, depth, rows, cols, channels]</code>.
  ksize: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The size of the window for each dimension of
    the input tensor. Must have <code>ksize[0] = ksize[1] = 1</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>grad</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.max_pool3d_grad', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.max_pool3d_grad" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.max_pool3d_grad_layer">
    <p>def <span class="ident">max_pool3d_grad_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.max_pool3d_grad_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.max_pool3d_grad_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.max_pool3d_grad_layer</strong></p>
<div class="codehilite"><pre><span></span>def max_pool3d_grad_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.max_pool3d_grad, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.max_pool3d_grad</strong></p>
<div class="codehilite"><pre><span></span>def max_pool3d_grad(orig_input, orig_output, grad, ksize, strides, padding, name=None):
</pre></div>


<p>Computes gradients of max pooling function.</p>
<p>Args:
  orig_input: A <code>Tensor</code> of type <code>float32</code>. The original input tensor.
  orig_output: A <code>Tensor</code> of type <code>float32</code>. The original output tensor.
  grad: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Output backprop of shape <code>[batch, depth, rows, cols, channels]</code>.
  ksize: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The size of the window for each dimension of
    the input tensor. Must have <code>ksize[0] = ksize[1] = 1</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>grad</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.max_pool3d_grad_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.max_pool3d_grad_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.max_pool3d_layer">
    <p>def <span class="ident">max_pool3d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.max_pool3d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.max_pool3d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.max_pool3d_layer</strong></p>
<div class="codehilite"><pre><span></span>def max_pool3d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.max_pool3d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.max_pool3d</strong></p>
<div class="codehilite"><pre><span></span>def max_pool3d(input, ksize, strides, padding, name=None):
</pre></div>


<p>Performs 3D max pooling on the input.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Shape <code>[batch, depth, rows, cols, channels]</code> tensor to pool over.
  ksize: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The size of the window for each dimension of
    the input tensor. Must have <code>ksize[0] = ksize[1] = 1</code>.
  strides: A list of <code>ints</code> that has length <code>&gt;= 5</code>.
    1-D tensor of length 5. The stride of the sliding window for each
    dimension of <code>input</code>. Must have <code>strides[0] = strides[4] = 1</code>.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. The max pooled output tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.max_pool3d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.max_pool3d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.max_pool_2d">
    <p>def <span class="ident">max_pool_2d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.max_pool_2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.max_pool_2d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.max_pool_2d</strong></p>
<div class="codehilite"><pre><span></span>def max_pool_2d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tflearn.layers.max_pool_2d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tflearn.layers.max_pool_2d</code></strong></p>
<div class="codehilite"><pre><span></span>def max_pool_2d(incoming, kernel_size, strides=None, padding=&quot;same&quot;, name=&quot;MaxPool2D&quot;)
</pre></div>


<p>Max Pooling 2D.</p>
<p>Input:
    4-D Tensor [batch, height, width, in_channels].</p>
<p>Output:
    4-D Tensor [batch, pooled height, pooled width, in_channels].</p>
<p>Arguments:
    incoming: <code>Tensor</code>. Incoming 4-D Layer.
    kernel_size: 'int<code>or list of</code>ints<code>. Pooling kernel size.
    strides: 'int</code> or list of <code>ints</code>. Strides of conv operation.
        Default: same as kernel_size.
    padding: <code>str</code> from <code>"same", "valid"</code>. Padding algo to use.
        Default: 'same'.
    name: A name for this layer (optional). Default: 'MaxPool2D'.</p>
<p>Attributes:
    scope: <code>Scope</code>. This layer scope.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.max_pool_2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.max_pool_2d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.max_pool_layer">
    <p>def <span class="ident">max_pool_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.max_pool_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.max_pool_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.max_pool_layer</strong></p>
<div class="codehilite"><pre><span></span>def max_pool_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.max_pool, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.max_pool</strong></p>
<div class="codehilite"><pre><span></span>def max_pool(value, ksize, strides, padding, data_format=&quot;NHWC&quot;, name=None):
</pre></div>


<p>Performs the max pooling on the input.</p>
<p>Args:
  value: A 4-D <code>Tensor</code> with shape <code>[batch, height, width, channels]</code> and
    type <code>tf.float32</code>.
  ksize: A list of ints that has length &gt;= 4.  The size of the window for
    each dimension of the input tensor.
  strides: A list of ints that has length &gt;= 4.  The stride of the sliding
    window for each dimension of the input tensor.
  padding: A string, either <code>'VALID'</code> or <code>'SAME'</code>. The padding algorithm.
    See the <a href="https://www.tensorflow.org/api_docs/python/nn.html#convolution">comment here</a>
  data_format: A string. 'NHWC' and 'NCHW' are supported.
  name: Optional name for the operation.</p>
<p>Returns:
  A <code>Tensor</code> with type <code>tf.float32</code>.  The max pooled output tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.max_pool_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.max_pool_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.max_pool_with_argmax">
    <p>def <span class="ident">max_pool_with_argmax</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.max_pool_with_argmax, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.max_pool_with_argmax</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.max_pool_with_argmax</strong></p>
<div class="codehilite"><pre><span></span>def max_pool_with_argmax(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.max_pool_with_argmax</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.max_pool_with_argmax</code></strong></p>
<div class="codehilite"><pre><span></span>def max_pool_with_argmax(input, ksize, strides, padding, Targmax=None, name=None)
</pre></div>


<p>Performs max pooling on the input and outputs both max values and indices.</p>
<p>The indices in <code>argmax</code> are flattened, so that a maximum value at position
<code>[b, y, x, c]</code> becomes flattened index
<code>((b * height + y) * width + x) * channels + c</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>float32</code>.
    4-D with shape <code>[batch, height, width, channels]</code>.  Input to pool over.
  ksize: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    The size of the window for each dimension of the input tensor.
  strides: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    The stride of the sliding window for each dimension of the
    input tensor.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  Targmax: An optional <code>tf.DType</code> from: <code>tf.int32, tf.int64</code>. Defaults to <code>tf.int64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tuple of <code>Tensor</code> objects (output, argmax).
  output: A <code>Tensor</code> of type <code>float32</code>. The max pooled output tensor.
  argmax: A <code>Tensor</code> of type <code>Targmax</code>. 4-D.  The flattened indices of the max values chosen for each output.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.max_pool_with_argmax', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.max_pool_with_argmax" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.max_pool_with_argmax_layer">
    <p>def <span class="ident">max_pool_with_argmax_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.max_pool_with_argmax_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.max_pool_with_argmax_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.max_pool_with_argmax_layer</strong></p>
<div class="codehilite"><pre><span></span>def max_pool_with_argmax_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.max_pool_with_argmax, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.max_pool_with_argmax</strong></p>
<div class="codehilite"><pre><span></span>def max_pool_with_argmax(input, ksize, strides, padding, Targmax=None, name=None):
</pre></div>


<p>Performs max pooling on the input and outputs both max values and indices.</p>
<p>The indices in <code>argmax</code> are flattened, so that a maximum value at position
<code>[b, y, x, c]</code> becomes flattened index
<code>((b * height + y) * width + x) * channels + c</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>float32</code>.
    4-D with shape <code>[batch, height, width, channels]</code>.  Input to pool over.
  ksize: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    The size of the window for each dimension of the input tensor.
  strides: A list of <code>ints</code> that has length <code>&gt;= 4</code>.
    The stride of the sliding window for each dimension of the
    input tensor.
  padding: A <code>string</code> from: <code>"SAME", "VALID"</code>.
    The type of padding algorithm to use.
  Targmax: An optional <code>tf.DType</code> from: <code>tf.int32, tf.int64</code>. Defaults to <code>tf.int64</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tuple of <code>Tensor</code> objects (output, argmax).
  output: A <code>Tensor</code> of type <code>float32</code>. The max pooled output tensor.
  argmax: A <code>Tensor</code> of type <code>Targmax</code>. 4-D.  The flattened indices of the max values chosen for each output.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.max_pool_with_argmax_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.max_pool_with_argmax_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.maximum">
    <p>def <span class="ident">maximum</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.maximum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.maximum</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.maximum</strong></p>
<div class="codehilite"><pre><span></span>def maximum(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.maximum</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.maximum</code></strong></p>
<div class="codehilite"><pre><span></span>def maximum(x, y, name=None)
</pre></div>


<p>Returns the max of x and y (i.e. x &gt; y ? x : y) element-wise, broadcasts.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.maximum', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.maximum" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.maximum_layer">
    <p>def <span class="ident">maximum_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.maximum_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.maximum_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.maximum_layer</strong></p>
<div class="codehilite"><pre><span></span>def maximum_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.maximum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.maximum</strong></p>
<div class="codehilite"><pre><span></span>def maximum(x, y, name=None):
</pre></div>


<p>Returns the max of x and y (i.e. x &gt; y ? x : y) element-wise, broadcasts.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.maximum_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.maximum_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.merge_all_summaries">
    <p>def <span class="ident">merge_all_summaries</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.merge_all_summaries, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.merge_all_summaries</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.merge_all_summaries</strong></p>
<div class="codehilite"><pre><span></span>def merge_all_summaries(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.merge_all_summaries</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.merge_all_summaries</code></strong></p>
<div class="codehilite"><pre><span></span>def merge_all_summaries(key=&quot;summaries&quot;)
</pre></div>


<p>Merges all summaries collected in the default graph.</p>
<p>Args:
  key: <code>GraphKey</code> used to collect the summaries.  Defaults to
    <code>GraphKeys.SUMMARIES</code>.</p>
<p>Returns:
  If no summaries were collected, returns None.  Otherwise returns a scalar
  <code>Tensor</code> of type <code>string</code> containing the serialized <code>Summary</code> protocol
  buffer resulting from the merging.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.merge_all_summaries', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.merge_all_summaries" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.merge_all_summaries_layer">
    <p>def <span class="ident">merge_all_summaries_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.merge_all_summaries_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.merge_all_summaries_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.merge_all_summaries_layer</strong></p>
<div class="codehilite"><pre><span></span>def merge_all_summaries_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.merge_all_summaries, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.merge_all_summaries</strong></p>
<div class="codehilite"><pre><span></span>def merge_all_summaries(key=&quot;summaries&quot;):
</pre></div>


<p>Merges all summaries collected in the default graph.</p>
<p>Args:
  key: <code>GraphKey</code> used to collect the summaries.  Defaults to
    <code>GraphKeys.SUMMARIES</code>.</p>
<p>Returns:
  If no summaries were collected, returns None.  Otherwise returns a scalar
  <code>Tensor</code> of type <code>string</code> containing the serialized <code>Summary</code> protocol
  buffer resulting from the merging.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.merge_all_summaries_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.merge_all_summaries_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.merge_summary">
    <p>def <span class="ident">merge_summary</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.merge_summary, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.merge_summary</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.merge_summary</strong></p>
<div class="codehilite"><pre><span></span>def merge_summary(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.merge_summary</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.merge_summary</code></strong></p>
<div class="codehilite"><pre><span></span>def merge_summary(inputs, collections=None, name=None)
</pre></div>


<p>Merges summaries.</p>
<p>This op creates a
<a href="https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto"><code>Summary</code></a>
protocol buffer that contains the union of all the values in the input
summaries.</p>
<p>When the Op is run, it reports an <code>InvalidArgument</code> error if multiple values
in the summaries to merge use the same tag.</p>
<p>Args:
  inputs: A list of <code>string</code> <code>Tensor</code> objects containing serialized <code>Summary</code>
    protocol buffers.
  collections: Optional list of graph collections keys. The new summary op is
    added to these collections. Defaults to <code>[GraphKeys.SUMMARIES]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A scalar <code>Tensor</code> of type <code>string</code>. The serialized <code>Summary</code> protocol
  buffer resulting from the merging.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.merge_summary', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.merge_summary" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.merge_summary_layer">
    <p>def <span class="ident">merge_summary_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.merge_summary_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.merge_summary_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.merge_summary_layer</strong></p>
<div class="codehilite"><pre><span></span>def merge_summary_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.merge_summary, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.merge_summary</strong></p>
<div class="codehilite"><pre><span></span>def merge_summary(inputs, collections=None, name=None):
</pre></div>


<p>Merges summaries.</p>
<p>This op creates a
<a href="https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto"><code>Summary</code></a>
protocol buffer that contains the union of all the values in the input
summaries.</p>
<p>When the Op is run, it reports an <code>InvalidArgument</code> error if multiple values
in the summaries to merge use the same tag.</p>
<p>Args:
  inputs: A list of <code>string</code> <code>Tensor</code> objects containing serialized <code>Summary</code>
    protocol buffers.
  collections: Optional list of graph collections keys. The new summary op is
    added to these collections. Defaults to <code>[GraphKeys.SUMMARIES]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A scalar <code>Tensor</code> of type <code>string</code>. The serialized <code>Summary</code> protocol
  buffer resulting from the merging.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.merge_summary_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.merge_summary_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.minimum">
    <p>def <span class="ident">minimum</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.minimum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.minimum</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.minimum</strong></p>
<div class="codehilite"><pre><span></span>def minimum(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.minimum</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.minimum</code></strong></p>
<div class="codehilite"><pre><span></span>def minimum(x, y, name=None)
</pre></div>


<p>Returns the min of x and y (i.e. x &lt; y ? x : y) element-wise, broadcasts.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.minimum', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.minimum" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.minimum_layer">
    <p>def <span class="ident">minimum_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.minimum_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.minimum_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.minimum_layer</strong></p>
<div class="codehilite"><pre><span></span>def minimum_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.minimum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.minimum</strong></p>
<div class="codehilite"><pre><span></span>def minimum(x, y, name=None):
</pre></div>


<p>Returns the min of x and y (i.e. x &lt; y ? x : y) element-wise, broadcasts.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.minimum_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.minimum_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.mod">
    <p>def <span class="ident">mod</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.mod, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.mod</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.mod</strong></p>
<div class="codehilite"><pre><span></span>def mod(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.mod</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.mod</code></strong></p>
<div class="codehilite"><pre><span></span>def mod(x, y, name=None)
</pre></div>


<p>Returns element-wise remainder of division.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>, <code>float32</code>, <code>float64</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.mod', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.mod" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.mod_layer">
    <p>def <span class="ident">mod_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.mod_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.mod_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.mod_layer</strong></p>
<div class="codehilite"><pre><span></span>def mod_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.mod, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.mod</strong></p>
<div class="codehilite"><pre><span></span>def mod(x, y, name=None):
</pre></div>


<p>Returns element-wise remainder of division.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>, <code>float32</code>, <code>float64</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.mod_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.mod_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.moments">
    <p>def <span class="ident">moments</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.moments, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.moments</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.moments</strong></p>
<div class="codehilite"><pre><span></span>def moments(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.moments</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.moments</code></strong></p>
<div class="codehilite"><pre><span></span>def moments(x, axes, shift=None, name=None, keep_dims=False)
</pre></div>


<p>Calculate the mean and variance of <code>x</code>.</p>
<p>The mean and variance are calculated by aggregating the contents of <code>x</code>
across <code>axes</code>.  If <code>x</code> is 1-D and <code>axes = [0]</code> this is just the mean
and variance of a vector.</p>
<p>When using these moments for batch normalization (see
<code>tf.nn.batch_normalization</code>):
  * for so-called "global normalization", used with convolutional filters with
    shape <code>[batch, height, width, depth]</code>, pass <code>axes=[0, 1, 2]</code>.
  * for simple batch normalization pass <code>axes=[0]</code> (batch only).</p>
<p>Args:
  x: A <code>Tensor</code>.
  axes: array of ints.  Axes along which to compute mean and
    variance.
  shift: A <code>Tensor</code> containing the value by which to shift the data for
    numerical stability, or <code>None</code> if no shift is to be performed. A shift
    close to the true mean provides the most numerically stable results.
  keep_dims: produce moments with the same dimensionality as the input.
  name: Name used to scope the operations that compute the moments.</p>
<p>Returns:
  Two <code>Tensor</code> objects: <code>mean</code> and <code>variance</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.moments', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.moments" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.moments_layer">
    <p>def <span class="ident">moments_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.moments_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.moments_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.moments_layer</strong></p>
<div class="codehilite"><pre><span></span>def moments_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.moments, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.moments</strong></p>
<div class="codehilite"><pre><span></span>def moments(x, axes, shift=None, name=None, keep_dims=False):
</pre></div>


<p>Calculate the mean and variance of <code>x</code>.</p>
<p>The mean and variance are calculated by aggregating the contents of <code>x</code>
across <code>axes</code>.  If <code>x</code> is 1-D and <code>axes = [0]</code> this is just the mean
and variance of a vector.</p>
<p>When using these moments for batch normalization (see
<code>tf.nn.batch_normalization</code>):
  * for so-called "global normalization", used with convolutional filters with
    shape <code>[batch, height, width, depth]</code>, pass <code>axes=[0, 1, 2]</code>.
  * for simple batch normalization pass <code>axes=[0]</code> (batch only).</p>
<p>Args:
  x: A <code>Tensor</code>.
  axes: array of ints.  Axes along which to compute mean and
    variance.
  shift: A <code>Tensor</code> containing the value by which to shift the data for
    numerical stability, or <code>None</code> if no shift is to be performed. A shift
    close to the true mean provides the most numerically stable results.
  keep_dims: produce moments with the same dimensionality as the input.
  name: Name used to scope the operations that compute the moments.</p>
<p>Returns:
  Two <code>Tensor</code> objects: <code>mean</code> and <code>variance</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.moments_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.moments_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.moving_average_variables">
    <p>def <span class="ident">moving_average_variables</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.moving_average_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.moving_average_variables</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.moving_average_variables</strong></p>
<div class="codehilite"><pre><span></span>def moving_average_variables(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.moving_average_variables</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.moving_average_variables</code></strong></p>
<div class="codehilite"><pre><span></span>def moving_average_variables()
</pre></div>


<p>Returns all variables that maintain their moving averages.</p>
<p>If an <code>ExponentialMovingAverage</code> object is created and the <code>apply()</code>
method is called on a list of variables, these variables will
be added to the <code>GraphKeys.MOVING_AVERAGE_VARIABLES</code> collection.
This convenience function returns the contents of that collection.</p>
<p>Returns:
  A list of Variable objects.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.moving_average_variables', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.moving_average_variables" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.moving_average_variables_layer">
    <p>def <span class="ident">moving_average_variables_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.moving_average_variables_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.moving_average_variables_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.moving_average_variables_layer</strong></p>
<div class="codehilite"><pre><span></span>def moving_average_variables_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.moving_average_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.moving_average_variables</strong></p>
<div class="codehilite"><pre><span></span>def moving_average_variables():
</pre></div>


<p>Returns all variables that maintain their moving averages.</p>
<p>If an <code>ExponentialMovingAverage</code> object is created and the <code>apply()</code>
method is called on a list of variables, these variables will
be added to the <code>GraphKeys.MOVING_AVERAGE_VARIABLES</code> collection.
This convenience function returns the contents of that collection.</p>
<p>Returns:
  A list of Variable objects.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.moving_average_variables_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.moving_average_variables_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.mul">
    <p>def <span class="ident">mul</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.mul, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.mul</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.mul</strong></p>
<div class="codehilite"><pre><span></span>def mul(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.mul</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.mul</code></strong></p>
<div class="codehilite"><pre><span></span>def mul(x, y, name=None)
</pre></div>


<p>Returns x * y element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.mul', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.mul" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.mul_layer">
    <p>def <span class="ident">mul_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.mul_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.mul_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.mul_layer</strong></p>
<div class="codehilite"><pre><span></span>def mul_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.mul, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.mul</strong></p>
<div class="codehilite"><pre><span></span>def mul(x, y, name=None):
</pre></div>


<p>Returns x * y element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.mul_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.mul_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.multinomial">
    <p>def <span class="ident">multinomial</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.multinomial, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.multinomial</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.multinomial</strong></p>
<div class="codehilite"><pre><span></span>def multinomial(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.multinomial</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.multinomial</code></strong></p>
<div class="codehilite"><pre><span></span>def multinomial(logits, num_samples, seed=None, name=None)
</pre></div>


<p>Draws samples from a multinomial distribution.</p>
<p>Example:</p>
<p>samples = tf.multinomial(tf.log([[0.5, 0.5]]), 10)
  # samples has shape [1, 10], where each value is either 0 or 1.</p>
<p>samples = tf.multinomial([[1, -1, -1]], 10)
  # samples is equivalent to tf.zeros([1, 10], dtype=tf.int64).</p>
<p>Args:
  logits: 2-D Tensor with shape <code>[batch_size, num_classes]</code>.  Each slice
    <code>[i, :]</code> represents the unnormalized log probabilities for all classes.
  num_samples: 0-D.  Number of independent samples to draw for each row slice.
  seed: A Python integer. Used to create a random seed for the distribution.
    See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: Optional name for the operation.</p>
<p>Returns:
  The drawn samples of shape <code>[batch_size, num_samples]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.multinomial', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.multinomial" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.multinomial_layer">
    <p>def <span class="ident">multinomial_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.multinomial_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.multinomial_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.multinomial_layer</strong></p>
<div class="codehilite"><pre><span></span>def multinomial_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.multinomial, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.multinomial</strong></p>
<div class="codehilite"><pre><span></span>def multinomial(logits, num_samples, seed=None, name=None):
</pre></div>


<p>Draws samples from a multinomial distribution.</p>
<p>Example:</p>
<p>samples = tf.multinomial(tf.log([[0.5, 0.5]]), 10)
  # samples has shape [1, 10], where each value is either 0 or 1.</p>
<p>samples = tf.multinomial([[1, -1, -1]], 10)
  # samples is equivalent to tf.zeros([1, 10], dtype=tf.int64).</p>
<p>Args:
  logits: 2-D Tensor with shape <code>[batch_size, num_classes]</code>.  Each slice
    <code>[i, :]</code> represents the unnormalized log probabilities for all classes.
  num_samples: 0-D.  Number of independent samples to draw for each row slice.
  seed: A Python integer. Used to create a random seed for the distribution.
    See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: Optional name for the operation.</p>
<p>Returns:
  The drawn samples of shape <code>[batch_size, num_samples]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.multinomial_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.multinomial_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.name_scope">
    <p>def <span class="ident">name_scope</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.name_scope, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.name_scope</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.name_scope</strong></p>
<div class="codehilite"><pre><span></span>def name_scope(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.name_scope</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.name_scope</code></strong></p>
<div class="codehilite"><pre><span></span>def name_scope(name)
</pre></div>


<p>Wrapper for <code>Graph.name_scope()</code> using the default graph.</p>
<p>See
<a href="../../api_docs/python/framework.md#Graph.name_scope"><code>Graph.name_scope()</code></a>
for more details.</p>
<p>Args:
  name: A name for the scope.</p>
<p>Returns:
  A context manager that installs <code>name</code> as a new name scope in the
  default graph.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.name_scope', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.name_scope" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.name_scope_layer">
    <p>def <span class="ident">name_scope_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.name_scope_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.name_scope_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.name_scope_layer</strong></p>
<div class="codehilite"><pre><span></span>def name_scope_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.name_scope, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.name_scope</strong></p>
<div class="codehilite"><pre><span></span>def name_scope(name):
</pre></div>


<p>Wrapper for <code>Graph.name_scope()</code> using the default graph.</p>
<p>See
<a href="../../api_docs/python/framework.md#Graph.name_scope"><code>Graph.name_scope()</code></a>
for more details.</p>
<p>Args:
  name: A name for the scope.</p>
<p>Returns:
  A context manager that installs <code>name</code> as a new name scope in the
  default graph.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.name_scope_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.name_scope_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.nce_loss">
    <p>def <span class="ident">nce_loss</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.nce_loss, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.nce_loss</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.nce_loss</strong></p>
<div class="codehilite"><pre><span></span>def nce_loss(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.nce_loss</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.nce_loss</code></strong></p>
<div class="codehilite"><pre><span></span>def nce_loss(weights, biases, inputs, labels, num_sampled, num_classes, num_true=1, sampled_values=None, remove_accidental_hits=False, partition_strategy=&quot;mod&quot;, name=&quot;nce_loss&quot;)
</pre></div>


<p>Computes and returns the noise-contrastive estimation training loss.</p>
<p>See [Noise-contrastive estimation: A new estimation principle for
unnormalized statistical models]
(http://www.jmlr.org/proceedings/papers/v9/gutmann10a/gutmann10a.pdf).
Also see our [Candidate Sampling Algorithms Reference]
(../../extras/candidate_sampling.pdf)</p>
<p>Note: In the case where <code>num_true</code> &gt; 1, we assign to each target class
the target probability 1 / <code>num_true</code> so that the target probabilities
sum to 1 per-example.</p>
<p>Note: It would be useful to allow a variable number of target classes per
example.  We hope to provide this functionality in a future release.
For now, if you have a variable number of target classes, you can pad them
out to a constant number by either repeating them or by padding
with an otherwise unused class.</p>
<p>Args:
  weights: A <code>Tensor</code> of shape <code>[num_classes, dim]</code>, or a list of <code>Tensor</code>
      objects whose concatenation along dimension 0 has shape
      [num_classes, dim].  The (possibly-partitioned) class embeddings.
  biases: A <code>Tensor</code> of shape <code>[num_classes]</code>.  The class biases.
  inputs: A <code>Tensor</code> of shape <code>[batch_size, dim]</code>.  The forward
      activations of the input network.
  labels: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
      num_true]</code>. The target classes.
  num_sampled: An <code>int</code>.  The number of classes to randomly sample per batch.
  num_classes: An <code>int</code>. The number of possible classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  sampled_values: a tuple of (<code>sampled_candidates</code>, <code>true_expected_count</code>,
      <code>sampled_expected_count</code>) returned by a <code>*_candidate_sampler</code> function.
      (if None, we default to <code>log_uniform_candidate_sampler</code>)
  remove_accidental_hits:  A <code>bool</code>.  Whether to remove "accidental hits"
      where a sampled class equals one of the target classes.  If set to
      <code>True</code>, this is a "Sampled Logistic" loss instead of NCE, and we are
      learning to generate log-odds instead of log probabilities.  See
      our [Candidate Sampling Algorithms Reference]
      (../../extras/candidate_sampling.pdf).
      Default is False.
  partition_strategy: A string specifying the partitioning strategy, relevant
      if <code>len(weights) &gt; 1</code>. Currently <code>"div"</code> and <code>"mod"</code> are supported.
      Default is <code>"mod"</code>. See <code>tf.nn.embedding_lookup</code> for more details.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>batch_size</code> 1-D tensor of per-example NCE losses.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.nce_loss', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.nce_loss" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.nce_loss_layer">
    <p>def <span class="ident">nce_loss_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.nce_loss_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.nce_loss_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.nce_loss_layer</strong></p>
<div class="codehilite"><pre><span></span>def nce_loss_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.nce_loss, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.nce_loss</strong></p>
<div class="codehilite"><pre><span></span>def nce_loss(weights, biases, inputs, labels, num_sampled, num_classes, num_true=1, sampled_values=None, remove_accidental_hits=False, partition_strategy=&quot;mod&quot;, name=&quot;nce_loss&quot;):
</pre></div>


<p>Computes and returns the noise-contrastive estimation training loss.</p>
<p>See [Noise-contrastive estimation: A new estimation principle for
unnormalized statistical models]
(http://www.jmlr.org/proceedings/papers/v9/gutmann10a/gutmann10a.pdf).
Also see our [Candidate Sampling Algorithms Reference]
(../../extras/candidate_sampling.pdf)</p>
<p>Note: In the case where <code>num_true</code> &gt; 1, we assign to each target class
the target probability 1 / <code>num_true</code> so that the target probabilities
sum to 1 per-example.</p>
<p>Note: It would be useful to allow a variable number of target classes per
example.  We hope to provide this functionality in a future release.
For now, if you have a variable number of target classes, you can pad them
out to a constant number by either repeating them or by padding
with an otherwise unused class.</p>
<p>Args:
  weights: A <code>Tensor</code> of shape <code>[num_classes, dim]</code>, or a list of <code>Tensor</code>
      objects whose concatenation along dimension 0 has shape
      [num_classes, dim].  The (possibly-partitioned) class embeddings.
  biases: A <code>Tensor</code> of shape <code>[num_classes]</code>.  The class biases.
  inputs: A <code>Tensor</code> of shape <code>[batch_size, dim]</code>.  The forward
      activations of the input network.
  labels: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
      num_true]</code>. The target classes.
  num_sampled: An <code>int</code>.  The number of classes to randomly sample per batch.
  num_classes: An <code>int</code>. The number of possible classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  sampled_values: a tuple of (<code>sampled_candidates</code>, <code>true_expected_count</code>,
      <code>sampled_expected_count</code>) returned by a <code>*_candidate_sampler</code> function.
      (if None, we default to <code>log_uniform_candidate_sampler</code>)
  remove_accidental_hits:  A <code>bool</code>.  Whether to remove "accidental hits"
      where a sampled class equals one of the target classes.  If set to
      <code>True</code>, this is a "Sampled Logistic" loss instead of NCE, and we are
      learning to generate log-odds instead of log probabilities.  See
      our [Candidate Sampling Algorithms Reference]
      (../../extras/candidate_sampling.pdf).
      Default is False.
  partition_strategy: A string specifying the partitioning strategy, relevant
      if <code>len(weights) &gt; 1</code>. Currently <code>"div"</code> and <code>"mod"</code> are supported.
      Default is <code>"mod"</code>. See <code>tf.nn.embedding_lookup</code> for more details.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>batch_size</code> 1-D tensor of per-example NCE losses.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.nce_loss_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.nce_loss_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.neg">
    <p>def <span class="ident">neg</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.neg, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.neg</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.neg</strong></p>
<div class="codehilite"><pre><span></span>def neg(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.neg</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.neg</code></strong></p>
<div class="codehilite"><pre><span></span>def neg(x, name=None)
</pre></div>


<p>Computes numerical negative value element-wise.</p>
<p>I.e., \(y = -x\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.neg', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.neg" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.neg_layer">
    <p>def <span class="ident">neg_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.neg_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.neg_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.neg_layer</strong></p>
<div class="codehilite"><pre><span></span>def neg_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.neg, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.neg</strong></p>
<div class="codehilite"><pre><span></span>def neg(x, name=None):
</pre></div>


<p>Computes numerical negative value element-wise.</p>
<p>I.e., \(y = -x\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.neg_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.neg_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.no_op">
    <p>def <span class="ident">no_op</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.no_op, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.no_op</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.no_op</strong></p>
<div class="codehilite"><pre><span></span>def no_op(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.no_op</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.no_op</code></strong></p>
<div class="codehilite"><pre><span></span>def no_op(name=None)
</pre></div>


<p>Does nothing. Only useful as a placeholder for control edges.</p>
<p>Args:
  name: A name for the operation (optional).</p>
<p>Returns:
  The created Operation.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.no_op', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.no_op" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.no_op_layer">
    <p>def <span class="ident">no_op_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.no_op_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.no_op_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.no_op_layer</strong></p>
<div class="codehilite"><pre><span></span>def no_op_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.no_op, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.no_op</strong></p>
<div class="codehilite"><pre><span></span>def no_op(name=None):
</pre></div>


<p>Does nothing. Only useful as a placeholder for control edges.</p>
<p>Args:
  name: A name for the operation (optional).</p>
<p>Returns:
  The created Operation.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.no_op_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.no_op_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.no_regularizer">
    <p>def <span class="ident">no_regularizer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.no_regularizer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.no_regularizer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.no_regularizer</strong></p>
<div class="codehilite"><pre><span></span>def no_regularizer(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.no_regularizer</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.no_regularizer</code></strong></p>
<div class="codehilite"><pre><span></span>def no_regularizer(_)
</pre></div>


<p>Use this function to prevent regularization of variables.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.no_regularizer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.no_regularizer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.no_regularizer_layer">
    <p>def <span class="ident">no_regularizer_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.no_regularizer_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.no_regularizer_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.no_regularizer_layer</strong></p>
<div class="codehilite"><pre><span></span>def no_regularizer_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.no_regularizer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.no_regularizer</strong></p>
<div class="codehilite"><pre><span></span>def no_regularizer(_):
</pre></div>


<p>Use this function to prevent regularization of variables.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.no_regularizer_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.no_regularizer_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.normalize_moments">
    <p>def <span class="ident">normalize_moments</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.normalize_moments, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.normalize_moments</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.normalize_moments</strong></p>
<div class="codehilite"><pre><span></span>def normalize_moments(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.normalize_moments</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.normalize_moments</code></strong></p>
<div class="codehilite"><pre><span></span>def normalize_moments(counts, mean_ss, variance_ss, shift, name=None)
</pre></div>


<p>Calculate the mean and variance of based on the sufficient statistics.</p>
<p>Args:
  counts: A <code>Tensor</code> containing a the total count of the data (one value).
  mean_ss: A <code>Tensor</code> containing the mean sufficient statistics: the (possibly
    shifted) sum of the elements to average over.
  variance_ss: A <code>Tensor</code> containing the variance sufficient statistics: the
    (possibly shifted) squared sum of the data to compute the variance over.
  shift: A <code>Tensor</code> containing the value by which the data is shifted for
    numerical stability, or <code>None</code> if no shift was performed.
  name: Name used to scope the operations that compute the moments.</p>
<p>Returns:
  Two <code>Tensor</code> objects: <code>mean</code> and <code>variance</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.normalize_moments', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.normalize_moments" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.normalize_moments_layer">
    <p>def <span class="ident">normalize_moments_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.normalize_moments_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.normalize_moments_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.normalize_moments_layer</strong></p>
<div class="codehilite"><pre><span></span>def normalize_moments_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.normalize_moments, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.normalize_moments</strong></p>
<div class="codehilite"><pre><span></span>def normalize_moments(counts, mean_ss, variance_ss, shift, name=None):
</pre></div>


<p>Calculate the mean and variance of based on the sufficient statistics.</p>
<p>Args:
  counts: A <code>Tensor</code> containing a the total count of the data (one value).
  mean_ss: A <code>Tensor</code> containing the mean sufficient statistics: the (possibly
    shifted) sum of the elements to average over.
  variance_ss: A <code>Tensor</code> containing the variance sufficient statistics: the
    (possibly shifted) squared sum of the data to compute the variance over.
  shift: A <code>Tensor</code> containing the value by which the data is shifted for
    numerical stability, or <code>None</code> if no shift was performed.
  name: Name used to scope the operations that compute the moments.</p>
<p>Returns:
  Two <code>Tensor</code> objects: <code>mean</code> and <code>variance</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.normalize_moments_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.normalize_moments_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.not_equal">
    <p>def <span class="ident">not_equal</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.not_equal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.not_equal</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.not_equal</strong></p>
<div class="codehilite"><pre><span></span>def not_equal(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.not_equal</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.not_equal</code></strong></p>
<div class="codehilite"><pre><span></span>def not_equal(x, y, name=None)
</pre></div>


<p>Returns the truth value of (x != y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>quint8</code>, <code>qint8</code>, <code>qint32</code>, <code>string</code>, <code>bool</code>, <code>complex128</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.not_equal', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.not_equal" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.not_equal_layer">
    <p>def <span class="ident">not_equal_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.not_equal_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.not_equal_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.not_equal_layer</strong></p>
<div class="codehilite"><pre><span></span>def not_equal_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.not_equal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.not_equal</strong></p>
<div class="codehilite"><pre><span></span>def not_equal(x, y, name=None):
</pre></div>


<p>Returns the truth value of (x != y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>uint8</code>, <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>quint8</code>, <code>qint8</code>, <code>qint32</code>, <code>string</code>, <code>bool</code>, <code>complex128</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>bool</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.not_equal_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.not_equal_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.one_hot">
    <p>def <span class="ident">one_hot</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.one_hot, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.one_hot</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.one_hot</strong></p>
<div class="codehilite"><pre><span></span>def one_hot(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.one_hot</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.one_hot</code></strong></p>
<div class="codehilite"><pre><span></span>def one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None)
</pre></div>


<p>Returns a one-hot tensor.</p>
<p>The locations represented by indices in <code>indices</code> take value <code>on_value</code>,
while all other locations take value <code>off_value</code>. </p>
<p><code>on_value</code> and <code>off_value</code> must have matching data types. If <code>dtype</code> is also
provided, they must be the same data type as specified by <code>dtype</code>.</p>
<p>If <code>on_value</code> is not provided, it will default to the value <code>1</code> with type 
<code>dtype</code></p>
<p>If <code>off_value</code> is not provided, it will default to the value <code>0</code> with type 
<code>dtype</code></p>
<p>If the input <code>indices</code> is rank <code>N</code>, the output will have rank <code>N+1</code>. The
new axis is created at dimension <code>axis</code> (default: the new axis is appended
at the end).</p>
<p>If <code>indices</code> is a scalar the output shape will be a vector of length <code>depth</code></p>
<p>If <code>indices</code> is a vector of length <code>features</code>, the output shape will be:
<code>features x depth if axis == -1
  depth x features if axis == 0</code></p>
<p>If <code>indices</code> is a matrix (batch) with shape <code>[batch, features]</code>, the output
shape will be:
<code>batch x features x depth if axis == -1
  batch x depth x features if axis == 1
  depth x batch x features if axis == 0</code></p>
<p>If <code>dtype</code> is not provided, it will attempt to assume the data type of 
<code>on_value</code> or <code>off_value</code>, if one or both are passed in. If none of 
<code>on_value</code>, <code>off_value</code>, or <code>dtype</code> are provided, <code>dtype</code> will default to the 
value <code>tf.float32</code></p>
<p>Note: If a non-numeric data type output is desired (tf.string, tf.bool, etc.),
both <code>on_value</code> and <code>off_value</code> <em>must</em> be provided to <code>one_hot</code></p>
<h1>Examples</h1>
<p>Suppose that</p>
<p><code>indices = [0, 2, -1, 1]
  depth = 3
  on_value = 5.0
  off_value = 0.0
  axis = -1</code></p>
<p>Then output is <code>[4 x 3]</code>:</p>
<p><code>output =
  [5.0 0.0 0.0]  // one_hot(0)
  [0.0 0.0 5.0]  // one_hot(2)
  [0.0 0.0 0.0]  // one_hot(-1)
  [0.0 5.0 0.0]  // one_hot(1)</code></p>
<p>Suppose that</p>
<p><code>indices = [[0, 2], [1, -1]]
  depth = 3
  on_value = 1.0
  off_value = 0.0
  axis = -1</code></p>
<p>Then output is <code>[2 x 2 x 3]</code>:</p>
<p><code>output =
  [
    [1.0, 0.0, 0.0]  // one_hot(0)
    [0.0, 0.0, 1.0]  // one_hot(2)
  ][
    [0.0, 1.0, 0.0]  // one_hot(1)
    [0.0, 0.0, 0.0]  // one_hot(-1)
  ]</code></p>
<p>Using default values for <code>on_value</code> and <code>off_value</code>:</p>
<p><code>indices = [0, 1, 2]
  depth = 3</code></p>
<p>The output will be</p>
<p><code>output = 
  [[1., 0., 0.],
   [0., 1., 0.],
   [0., 0., 1.]]</code></p>
<p>Args:
  indices: A <code>Tensor</code> of indices.
  depth: A scalar defining the depth of the one hot dimension.
  on_value: A scalar defining the value to fill in output when <code>indices[j]
    = i</code>. (default: 1)
  off_value: A scalar defining the value to fill in output when <code>indices[j]
    != i</code>. (default: 0)
  axis: The axis to fill (default: -1, a new inner-most axis).
  dtype: The data type of the output tensor.</p>
<p>Returns:
  output: The one-hot tensor.</p>
<p>Raises:
  TypeError: If dtype of either <code>on_value</code> or <code>off_value</code> don't match <code>dtype</code>
  TypeError: If dtype of <code>on_value</code> and <code>off_value</code> don't match one another</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.one_hot', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.one_hot" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.one_hot_layer">
    <p>def <span class="ident">one_hot_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.one_hot_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.one_hot_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.one_hot_layer</strong></p>
<div class="codehilite"><pre><span></span>def one_hot_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.one_hot, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.one_hot</strong></p>
<div class="codehilite"><pre><span></span>def one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None):
</pre></div>


<p>Returns a one-hot tensor.</p>
<p>The locations represented by indices in <code>indices</code> take value <code>on_value</code>,
while all other locations take value <code>off_value</code>. </p>
<p><code>on_value</code> and <code>off_value</code> must have matching data types. If <code>dtype</code> is also
provided, they must be the same data type as specified by <code>dtype</code>.</p>
<p>If <code>on_value</code> is not provided, it will default to the value <code>1</code> with type 
<code>dtype</code></p>
<p>If <code>off_value</code> is not provided, it will default to the value <code>0</code> with type 
<code>dtype</code></p>
<p>If the input <code>indices</code> is rank <code>N</code>, the output will have rank <code>N+1</code>. The
new axis is created at dimension <code>axis</code> (default: the new axis is appended
at the end).</p>
<p>If <code>indices</code> is a scalar the output shape will be a vector of length <code>depth</code></p>
<p>If <code>indices</code> is a vector of length <code>features</code>, the output shape will be:
<code>features x depth if axis == -1
  depth x features if axis == 0</code></p>
<p>If <code>indices</code> is a matrix (batch) with shape <code>[batch, features]</code>, the output
shape will be:
<code>batch x features x depth if axis == -1
  batch x depth x features if axis == 1
  depth x batch x features if axis == 0</code></p>
<p>If <code>dtype</code> is not provided, it will attempt to assume the data type of 
<code>on_value</code> or <code>off_value</code>, if one or both are passed in. If none of 
<code>on_value</code>, <code>off_value</code>, or <code>dtype</code> are provided, <code>dtype</code> will default to the 
value <code>tf.float32</code></p>
<p>Note: If a non-numeric data type output is desired (tf.string, tf.bool, etc.),
both <code>on_value</code> and <code>off_value</code> <em>must</em> be provided to <code>one_hot</code></p>
<h1>Examples</h1>
<p>Suppose that</p>
<p><code>indices = [0, 2, -1, 1]
  depth = 3
  on_value = 5.0
  off_value = 0.0
  axis = -1</code></p>
<p>Then output is <code>[4 x 3]</code>:</p>
<p><code>output =
  [5.0 0.0 0.0]  // one_hot(0)
  [0.0 0.0 5.0]  // one_hot(2)
  [0.0 0.0 0.0]  // one_hot(-1)
  [0.0 5.0 0.0]  // one_hot(1)</code></p>
<p>Suppose that</p>
<p><code>indices = [[0, 2], [1, -1]]
  depth = 3
  on_value = 1.0
  off_value = 0.0
  axis = -1</code></p>
<p>Then output is <code>[2 x 2 x 3]</code>:</p>
<p><code>output =
  [
    [1.0, 0.0, 0.0]  // one_hot(0)
    [0.0, 0.0, 1.0]  // one_hot(2)
  ][
    [0.0, 1.0, 0.0]  // one_hot(1)
    [0.0, 0.0, 0.0]  // one_hot(-1)
  ]</code></p>
<p>Using default values for <code>on_value</code> and <code>off_value</code>:</p>
<p><code>indices = [0, 1, 2]
  depth = 3</code></p>
<p>The output will be</p>
<p><code>output = 
  [[1., 0., 0.],
   [0., 1., 0.],
   [0., 0., 1.]]</code></p>
<p>Args:
  indices: A <code>Tensor</code> of indices.
  depth: A scalar defining the depth of the one hot dimension.
  on_value: A scalar defining the value to fill in output when <code>indices[j]
    = i</code>. (default: 1)
  off_value: A scalar defining the value to fill in output when <code>indices[j]
    != i</code>. (default: 0)
  axis: The axis to fill (default: -1, a new inner-most axis).
  dtype: The data type of the output tensor.</p>
<p>Returns:
  output: The one-hot tensor.</p>
<p>Raises:
  TypeError: If dtype of either <code>on_value</code> or <code>off_value</code> don't match <code>dtype</code>
  TypeError: If dtype of <code>on_value</code> and <code>off_value</code> don't match one another</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.one_hot_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.one_hot_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ones">
    <p>def <span class="ident">ones</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ones, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ones</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ones</strong></p>
<div class="codehilite"><pre><span></span>def ones(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.ones</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.ones</code></strong></p>
<div class="codehilite"><pre><span></span>def ones(shape, dtype=&lt;dtype: &#39;float32&#39;&gt;, name=None)
</pre></div>


<p>Creates a tensor with all elements set to 1.</p>
<p>This operation returns a tensor of type <code>dtype</code> with shape <code>shape</code> and all
elements set to 1.</p>
<p>For example:</p>
<p><code>python
tf.ones([2, 3], int32) ==&gt; [[1, 1, 1], [1, 1, 1]]</code></p>
<p>Args:
  shape: Either a list of integers, or a 1-D <code>Tensor</code> of type <code>int32</code>.
  dtype: The type of an element in the resulting <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with all elements set to 1.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ones', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ones" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ones_initializer">
    <p>def <span class="ident">ones_initializer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ones_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ones_initializer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ones_initializer</strong></p>
<div class="codehilite"><pre><span></span>def ones_initializer(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.ones_initializer</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.ones_initializer</code></strong></p>
<div class="codehilite"><pre><span></span>def ones_initializer(shape, dtype=&lt;dtype: &#39;float32&#39;&gt;)
</pre></div>


<p>An adaptor for ones() to match the Initializer spec.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ones_initializer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ones_initializer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ones_initializer_layer">
    <p>def <span class="ident">ones_initializer_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ones_initializer_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ones_initializer_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ones_initializer_layer</strong></p>
<div class="codehilite"><pre><span></span>def ones_initializer_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.ones_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.ones_initializer</strong></p>
<div class="codehilite"><pre><span></span>def ones_initializer(shape, dtype=&lt;dtype: &#39;float32&#39;&gt;):
</pre></div>


<p>An adaptor for ones() to match the Initializer spec.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ones_initializer_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ones_initializer_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ones_layer">
    <p>def <span class="ident">ones_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ones_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ones_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ones_layer</strong></p>
<div class="codehilite"><pre><span></span>def ones_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.ones, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.ones</strong></p>
<div class="codehilite"><pre><span></span>def ones(shape, dtype=&lt;dtype: &#39;float32&#39;&gt;, name=None):
</pre></div>


<p>Creates a tensor with all elements set to 1.</p>
<p>This operation returns a tensor of type <code>dtype</code> with shape <code>shape</code> and all
elements set to 1.</p>
<p>For example:</p>
<p><code>python
tf.ones([2, 3], int32) ==&gt; [[1, 1, 1], [1, 1, 1]]</code></p>
<p>Args:
  shape: Either a list of integers, or a 1-D <code>Tensor</code> of type <code>int32</code>.
  dtype: The type of an element in the resulting <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with all elements set to 1.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ones_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ones_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ones_like">
    <p>def <span class="ident">ones_like</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ones_like, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ones_like</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ones_like</strong></p>
<div class="codehilite"><pre><span></span>def ones_like(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.ones_like</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.ones_like</code></strong></p>
<div class="codehilite"><pre><span></span>def ones_like(tensor, dtype=None, name=None)
</pre></div>


<p>Creates a tensor with all elements set to 1.</p>
<p>Given a single tensor (<code>tensor</code>), this operation returns a tensor of the same
type and shape as <code>tensor</code> with all elements set to 1. Optionally, you can
specify a new type (<code>dtype</code>) for the returned tensor.</p>
<p>For example:</p>
<p>```python</p>
<h1>'tensor' is [[1, 2, 3], [4, 5, 6]]</h1>
<p>tf.ones_like(tensor) ==&gt; [[1, 1, 1], [1, 1, 1]]
```</p>
<p>Args:
  tensor: A <code>Tensor</code>.
  dtype: A type for the returned <code>Tensor</code>. Must be <code>float32</code>, <code>float64</code>,
  <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>complex64</code>, or <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with all elements set to 1.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ones_like', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ones_like" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.ones_like_layer">
    <p>def <span class="ident">ones_like_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.ones_like_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.ones_like_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.ones_like_layer</strong></p>
<div class="codehilite"><pre><span></span>def ones_like_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.ones_like, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.ones_like</strong></p>
<div class="codehilite"><pre><span></span>def ones_like(tensor, dtype=None, name=None):
</pre></div>


<p>Creates a tensor with all elements set to 1.</p>
<p>Given a single tensor (<code>tensor</code>), this operation returns a tensor of the same
type and shape as <code>tensor</code> with all elements set to 1. Optionally, you can
specify a new type (<code>dtype</code>) for the returned tensor.</p>
<p>For example:</p>
<p>```python</p>
<h1>'tensor' is [[1, 2, 3], [4, 5, 6]]</h1>
<p>tf.ones_like(tensor) ==&gt; [[1, 1, 1], [1, 1, 1]]
```</p>
<p>Args:
  tensor: A <code>Tensor</code>.
  dtype: A type for the returned <code>Tensor</code>. Must be <code>float32</code>, <code>float64</code>,
  <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>complex64</code>, or <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with all elements set to 1.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.ones_like_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.ones_like_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.op_scope">
    <p>def <span class="ident">op_scope</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.op_scope, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.op_scope</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.op_scope</strong></p>
<div class="codehilite"><pre><span></span>def op_scope(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.op_scope</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.op_scope</code></strong></p>
<div class="codehilite"><pre><span></span>def op_scope()
</pre></div>


<p>Returns a context manager for use when defining a Python op.</p>
<p>This context manager validates that the given <code>values</code> are from the
same graph, ensures that graph is the default graph, and pushes a
name scope.</p>
<p>For example, to define a new Python op called <code>my_op</code>:</p>
<p><code>python
def my_op(a, b, c, name=None):
  with tf.op_scope([a, b, c], name, "MyOp") as scope:
    a = tf.convert_to_tensor(a, name="a")
    b = tf.convert_to_tensor(b, name="b")
    c = tf.convert_to_tensor(c, name="c")
    # Define some computation that uses `a`, `b`, and `c`.
    return foo_op(..., name=scope)</code></p>
<p>Args:
  values: The list of <code>Tensor</code> arguments that are passed to the op function.
  name: The name argument that is passed to the op function.
  default_name: The default name to use if the <code>name</code> argument is <code>None</code>.</p>
<p>Returns:
  A context manager for use in defining Python ops. Yields the name scope.</p>
<p>Raises:
  ValueError: if neither <code>name</code> nor <code>default_name</code> is provided.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.op_scope', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.op_scope" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.op_scope_layer">
    <p>def <span class="ident">op_scope_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.op_scope_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.op_scope_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.op_scope_layer</strong></p>
<div class="codehilite"><pre><span></span>def op_scope_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.op_scope, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.op_scope</strong></p>
<div class="codehilite"><pre><span></span>def op_scope():
</pre></div>


<p>Returns a context manager for use when defining a Python op.</p>
<p>This context manager validates that the given <code>values</code> are from the
same graph, ensures that graph is the default graph, and pushes a
name scope.</p>
<p>For example, to define a new Python op called <code>my_op</code>:</p>
<p><code>python
def my_op(a, b, c, name=None):
  with tf.op_scope([a, b, c], name, "MyOp") as scope:
    a = tf.convert_to_tensor(a, name="a")
    b = tf.convert_to_tensor(b, name="b")
    c = tf.convert_to_tensor(c, name="c")
    # Define some computation that uses `a`, `b`, and `c`.
    return foo_op(..., name=scope)</code></p>
<p>Args:
  values: The list of <code>Tensor</code> arguments that are passed to the op function.
  name: The name argument that is passed to the op function.
  default_name: The default name to use if the <code>name</code> argument is <code>None</code>.</p>
<p>Returns:
  A context manager for use in defining Python ops. Yields the name scope.</p>
<p>Raises:
  ValueError: if neither <code>name</code> nor <code>default_name</code> is provided.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.op_scope_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.op_scope_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.pack">
    <p>def <span class="ident">pack</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.pack, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.pack</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.pack</strong></p>
<div class="codehilite"><pre><span></span>def pack(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.pack</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.pack</code></strong></p>
<div class="codehilite"><pre><span></span>def pack(values, name=&quot;pack&quot;)
</pre></div>


<p>Packs a list of rank-<code>R</code> tensors into one rank-<code>(R+1)</code> tensor.</p>
<p>Packs tensors in <code>values</code> into a tensor with rank one higher than each tensor
in <code>values</code> and shape <code>[len(values)] + values[0].shape</code>. The output satisfies
<code>output[i, ...] = values[i][...]</code>.</p>
<p>This is the opposite of unpack.  The numpy equivalent is</p>
<div class="codehilite"><pre><span></span>tf.pack([x, y, z]) = np.asarray([x, y, z])
</pre></div>


<p>Args:
  values: A list of <code>Tensor</code> objects with the same shape and type.
  name: A name for this operation (optional).</p>
<p>Returns:
  output: A packed <code>Tensor</code> with the same type as <code>values</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.pack', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.pack" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.pack_layer">
    <p>def <span class="ident">pack_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.pack_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.pack_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.pack_layer</strong></p>
<div class="codehilite"><pre><span></span>def pack_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.pack, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.pack</strong></p>
<div class="codehilite"><pre><span></span>def pack(values, name=&quot;pack&quot;):
</pre></div>


<p>Packs a list of rank-<code>R</code> tensors into one rank-<code>(R+1)</code> tensor.</p>
<p>Packs tensors in <code>values</code> into a tensor with rank one higher than each tensor
in <code>values</code> and shape <code>[len(values)] + values[0].shape</code>. The output satisfies
<code>output[i, ...] = values[i][...]</code>.</p>
<p>This is the opposite of unpack.  The numpy equivalent is</p>
<div class="codehilite"><pre><span></span>tf.pack([x, y, z]) = np.asarray([x, y, z])
</pre></div>


<p>Args:
  values: A list of <code>Tensor</code> objects with the same shape and type.
  name: A name for this operation (optional).</p>
<p>Returns:
  output: A packed <code>Tensor</code> with the same type as <code>values</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.pack_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.pack_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.pad">
    <p>def <span class="ident">pad</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.pad, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.pad</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.pad</strong></p>
<div class="codehilite"><pre><span></span>def pad(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.pad</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.pad</code></strong></p>
<div class="codehilite"><pre><span></span>def pad(tensor, paddings, mode=&quot;CONSTANT&quot;, name=None)
</pre></div>


<p>Pads a tensor.</p>
<p>This operation pads a <code>tensor</code> according to the <code>paddings</code> you specify.
<code>paddings</code> is an integer tensor with shape <code>[n, 2]</code>, where n is the rank of
<code>tensor</code>. For each dimension D of <code>input</code>, <code>paddings[D, 0]</code> indicates how
many values to add before the contents of <code>tensor</code> in that dimension, and
<code>paddings[D, 1]</code> indicates how many values to add after the contents of
<code>tensor</code> in that dimension. If <code>mode</code> is "REFLECT" then both <code>paddings[D, 0]</code>
and <code>paddings[D, 1]</code> must be no greater than <code>tensor.dim_size(D) - 1</code>. If
<code>mode</code> is "SYMMETRIC" then both <code>paddings[D, 0]</code> and <code>paddings[D, 1]</code> must be
no greater than <code>tensor.dim_size(D)</code>.</p>
<p>The padded size of each dimension D of the output is:</p>
<p><code>paddings[D, 0] + tensor.dim_size(D) + paddings[D, 1]</code></p>
<p>For example:</p>
<p>```python</p>
<h1>'t' is [[1, 2, 3], [4, 5, 6]].</h1>
<h1>'paddings' is [[1, 1,], [2, 2]].</h1>
<h1>rank of 't' is 2.</h1>
<p>pad(t, paddings, "CONSTANT") ==&gt; [[0, 0, 0, 0, 0, 0, 0],
                                  [0, 0, 1, 2, 3, 0, 0],
                                  [0, 0, 4, 5, 6, 0, 0],
                                  [0, 0, 0, 0, 0, 0, 0]]</p>
<p>pad(t, paddings, "REFLECT") ==&gt; [[6, 5, 4, 5, 6, 5, 4],
                                 [3, 2, 1, 2, 3, 2, 1],
                                 [6, 5, 4, 5, 6, 5, 4],
                                 [3, 2, 1, 2, 3, 2, 1]]</p>
<p>pad(t, paddings, "SYMMETRIC") ==&gt; [[2, 1, 1, 2, 3, 3, 2],
                                   [2, 1, 1, 2, 3, 3, 2],
                                   [5, 4, 4, 5, 6, 6, 5],
                                   [5, 4, 4, 5, 6, 6, 5]]
```</p>
<p>Args:
  tensor: A <code>Tensor</code>.
  paddings: A <code>Tensor</code> of type <code>int32</code>.
  mode: One of "CONSTANT", "REFLECT", or "SYMMETRIC".
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>tensor</code>.</p>
<p>Raises:
  ValueError: When mode is not one of "CONSTANT", "REFLECT", or "SYMMETRIC".</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.pad', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.pad" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.pad_layer">
    <p>def <span class="ident">pad_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.pad_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.pad_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.pad_layer</strong></p>
<div class="codehilite"><pre><span></span>def pad_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.pad, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.pad</strong></p>
<div class="codehilite"><pre><span></span>def pad(tensor, paddings, mode=&quot;CONSTANT&quot;, name=None):
</pre></div>


<p>Pads a tensor.</p>
<p>This operation pads a <code>tensor</code> according to the <code>paddings</code> you specify.
<code>paddings</code> is an integer tensor with shape <code>[n, 2]</code>, where n is the rank of
<code>tensor</code>. For each dimension D of <code>input</code>, <code>paddings[D, 0]</code> indicates how
many values to add before the contents of <code>tensor</code> in that dimension, and
<code>paddings[D, 1]</code> indicates how many values to add after the contents of
<code>tensor</code> in that dimension. If <code>mode</code> is "REFLECT" then both <code>paddings[D, 0]</code>
and <code>paddings[D, 1]</code> must be no greater than <code>tensor.dim_size(D) - 1</code>. If
<code>mode</code> is "SYMMETRIC" then both <code>paddings[D, 0]</code> and <code>paddings[D, 1]</code> must be
no greater than <code>tensor.dim_size(D)</code>.</p>
<p>The padded size of each dimension D of the output is:</p>
<p><code>paddings[D, 0] + tensor.dim_size(D) + paddings[D, 1]</code></p>
<p>For example:</p>
<p>```python</p>
<h1>'t' is [[1, 2, 3], [4, 5, 6]].</h1>
<h1>'paddings' is [[1, 1,], [2, 2]].</h1>
<h1>rank of 't' is 2.</h1>
<p>pad(t, paddings, "CONSTANT") ==&gt; [[0, 0, 0, 0, 0, 0, 0],
                                  [0, 0, 1, 2, 3, 0, 0],
                                  [0, 0, 4, 5, 6, 0, 0],
                                  [0, 0, 0, 0, 0, 0, 0]]</p>
<p>pad(t, paddings, "REFLECT") ==&gt; [[6, 5, 4, 5, 6, 5, 4],
                                 [3, 2, 1, 2, 3, 2, 1],
                                 [6, 5, 4, 5, 6, 5, 4],
                                 [3, 2, 1, 2, 3, 2, 1]]</p>
<p>pad(t, paddings, "SYMMETRIC") ==&gt; [[2, 1, 1, 2, 3, 3, 2],
                                   [2, 1, 1, 2, 3, 3, 2],
                                   [5, 4, 4, 5, 6, 6, 5],
                                   [5, 4, 4, 5, 6, 6, 5]]
```</p>
<p>Args:
  tensor: A <code>Tensor</code>.
  paddings: A <code>Tensor</code> of type <code>int32</code>.
  mode: One of "CONSTANT", "REFLECT", or "SYMMETRIC".
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>tensor</code>.</p>
<p>Raises:
  ValueError: When mode is not one of "CONSTANT", "REFLECT", or "SYMMETRIC".</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.pad_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.pad_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.parse_example">
    <p>def <span class="ident">parse_example</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.parse_example, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.parse_example</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.parse_example</strong></p>
<div class="codehilite"><pre><span></span>def parse_example(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.parse_example</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.parse_example</code></strong></p>
<div class="codehilite"><pre><span></span>def parse_example(serialized, features, name=None, example_names=None)
</pre></div>


<p>Parses <code>Example</code> protos into a <code>dict</code> of tensors.</p>
<p>Parses a number of serialized [<code>Example</code>]
(https://www.tensorflow.org/code/tensorflow/core/example/example.proto)
protos given in <code>serialized</code>.</p>
<p><code>example_names</code> may contain descriptive names for the corresponding serialized
protos. These may be useful for debugging purposes, but they have no effect on
the output. If not <code>None</code>, <code>example_names</code> must be the same length as <code>serialized</code>.</p>
<p>This op parses serialized examples into a dictionary mapping keys to <code>Tensor</code>
and <code>SparseTensor</code> objects. <code>features</code> is a dict from keys to <code>VarLenFeature</code>
and <code>FixedLenFeature</code> objects. Each <code>VarLenFeature</code> is mapped to a
<code>SparseTensor</code>, and each <code>FixedLenFeature</code> is mapped to a <code>Tensor</code>.</p>
<p>Each <code>VarLenFeature</code> maps to a <code>SparseTensor</code> of the specified type
representing a ragged matrix. Its indices are <code>[batch, index]</code> where <code>batch</code>
is the batch entry the value is from in <code>serialized</code>, and <code>index</code> is the
value's index in the list of values associated with that feature and example.</p>
<p>Each <code>FixedLenFeature</code> <code>df</code> maps to a <code>Tensor</code> of the specified type (or
<code>tf.float32</code> if not specified) and shape <code>(serialized.size(),) + df.shape</code>.</p>
<p><code>FixedLenFeature</code> entries with a <code>default_value</code> are optional. With no default
value, we will fail if that <code>Feature</code> is missing from any example in
<code>serialized</code>.</p>
<p>Examples:</p>
<p>For example, if one expects a <code>tf.float32</code> sparse feature <code>ft</code> and three
serialized <code>Example</code>s are provided:</p>
<p><code>serialized = [
  features
    { feature { key: "ft" value { float_list { value: [1.0, 2.0] } } } },
  features
    { feature []},
  features
    { feature { key: "ft" value { float_list { value: [3.0] } } }
]</code></p>
<p>then the output will look like:</p>
<p><code>{"ft": SparseTensor(indices=[[0, 0], [0, 1], [2, 0]],
                    values=[1.0, 2.0, 3.0],
                    shape=(3, 2)) }</code></p>
<p>Given two <code>Example</code> input protos in <code>serialized</code>:</p>
<p><code>[
  features {
    feature { key: "kw" value { bytes_list { value: [ "knit", "big" ] } } }
    feature { key: "gps" value { float_list { value: [] } } }
  },
  features {
    feature { key: "kw" value { bytes_list { value: [ "emmy" ] } } }
    feature { key: "dank" value { int64_list { value: [ 42 ] } } }
    feature { key: "gps" value { } }
  }
]</code></p>
<p>And arguments</p>
<p><code>example_names: ["input0", "input1"],
features: {
    "kw": VarLenFeature(tf.string),
    "dank": VarLenFeature(tf.int64),
    "gps": VarLenFeature(tf.float32),
}</code></p>
<p>Then the output is a dictionary:</p>
<p><code>python
{
  "kw": SparseTensor(
      indices=[[0, 0], [0, 1], [1, 0]],
      values=["knit", "big", "emmy"]
      shape=[2, 2]),
  "dank": SparseTensor(
      indices=[[1, 0]],
      values=[42],
      shape=[2, 1]),
  "gps": SparseTensor(
      indices=[],
      values=[],
      shape=[2, 0]),
}</code></p>
<p>For dense results in two serialized <code>Example</code>s:</p>
<p><code>[
  features {
    feature { key: "age" value { int64_list { value: [ 0 ] } } }
    feature { key: "gender" value { bytes_list { value: [ "f" ] } } }
   },
   features {
    feature { key: "age" value { int64_list { value: [] } } }
    feature { key: "gender" value { bytes_list { value: [ "f" ] } } }
  }
]</code></p>
<p>We can use arguments:</p>
<p><code>example_names: ["input0", "input1"],
features: {
    "age": FixedLenFeature([], dtype=tf.int64, default_value=-1),
    "gender": FixedLenFeature([], dtype=tf.string),
}</code></p>
<p>And the expected output is:</p>
<p><code>python
{
  "age": [[0], [-1]],
  "gender": [["f"], ["f"]],
}</code></p>
<p>Args:
  serialized: A vector (1-D Tensor) of strings, a batch of binary
    serialized <code>Example</code> protos.
  features: A <code>dict</code> mapping feature keys to <code>FixedLenFeature</code> or
    <code>VarLenFeature</code> values.
  name: A name for this operation (optional).
  example_names: A vector (1-D Tensor) of strings (optional), the names of
    the serialized protos in the batch.</p>
<p>Returns:
  A <code>dict</code> mapping feature keys to <code>Tensor</code> and <code>SparseTensor</code> values.</p>
<p>Raises:
  ValueError: if any feature is invalid.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.parse_example', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.parse_example" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.parse_example_layer">
    <p>def <span class="ident">parse_example_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.parse_example_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.parse_example_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.parse_example_layer</strong></p>
<div class="codehilite"><pre><span></span>def parse_example_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.parse_example, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.parse_example</strong></p>
<div class="codehilite"><pre><span></span>def parse_example(serialized, features, name=None, example_names=None):
</pre></div>


<p>Parses <code>Example</code> protos into a <code>dict</code> of tensors.</p>
<p>Parses a number of serialized [<code>Example</code>]
(https://www.tensorflow.org/code/tensorflow/core/example/example.proto)
protos given in <code>serialized</code>.</p>
<p><code>example_names</code> may contain descriptive names for the corresponding serialized
protos. These may be useful for debugging purposes, but they have no effect on
the output. If not <code>None</code>, <code>example_names</code> must be the same length as <code>serialized</code>.</p>
<p>This op parses serialized examples into a dictionary mapping keys to <code>Tensor</code>
and <code>SparseTensor</code> objects. <code>features</code> is a dict from keys to <code>VarLenFeature</code>
and <code>FixedLenFeature</code> objects. Each <code>VarLenFeature</code> is mapped to a
<code>SparseTensor</code>, and each <code>FixedLenFeature</code> is mapped to a <code>Tensor</code>.</p>
<p>Each <code>VarLenFeature</code> maps to a <code>SparseTensor</code> of the specified type
representing a ragged matrix. Its indices are <code>[batch, index]</code> where <code>batch</code>
is the batch entry the value is from in <code>serialized</code>, and <code>index</code> is the
value's index in the list of values associated with that feature and example.</p>
<p>Each <code>FixedLenFeature</code> <code>df</code> maps to a <code>Tensor</code> of the specified type (or
<code>tf.float32</code> if not specified) and shape <code>(serialized.size(),) + df.shape</code>.</p>
<p><code>FixedLenFeature</code> entries with a <code>default_value</code> are optional. With no default
value, we will fail if that <code>Feature</code> is missing from any example in
<code>serialized</code>.</p>
<p>Examples:</p>
<p>For example, if one expects a <code>tf.float32</code> sparse feature <code>ft</code> and three
serialized <code>Example</code>s are provided:</p>
<p><code>serialized = [
  features
    { feature { key: "ft" value { float_list { value: [1.0, 2.0] } } } },
  features
    { feature []},
  features
    { feature { key: "ft" value { float_list { value: [3.0] } } }
]</code></p>
<p>then the output will look like:</p>
<p><code>{"ft": SparseTensor(indices=[[0, 0], [0, 1], [2, 0]],
                    values=[1.0, 2.0, 3.0],
                    shape=(3, 2)) }</code></p>
<p>Given two <code>Example</code> input protos in <code>serialized</code>:</p>
<p><code>[
  features {
    feature { key: "kw" value { bytes_list { value: [ "knit", "big" ] } } }
    feature { key: "gps" value { float_list { value: [] } } }
  },
  features {
    feature { key: "kw" value { bytes_list { value: [ "emmy" ] } } }
    feature { key: "dank" value { int64_list { value: [ 42 ] } } }
    feature { key: "gps" value { } }
  }
]</code></p>
<p>And arguments</p>
<p><code>example_names: ["input0", "input1"],
features: {
    "kw": VarLenFeature(tf.string),
    "dank": VarLenFeature(tf.int64),
    "gps": VarLenFeature(tf.float32),
}</code></p>
<p>Then the output is a dictionary:</p>
<p><code>python
{
  "kw": SparseTensor(
      indices=[[0, 0], [0, 1], [1, 0]],
      values=["knit", "big", "emmy"]
      shape=[2, 2]),
  "dank": SparseTensor(
      indices=[[1, 0]],
      values=[42],
      shape=[2, 1]),
  "gps": SparseTensor(
      indices=[],
      values=[],
      shape=[2, 0]),
}</code></p>
<p>For dense results in two serialized <code>Example</code>s:</p>
<p><code>[
  features {
    feature { key: "age" value { int64_list { value: [ 0 ] } } }
    feature { key: "gender" value { bytes_list { value: [ "f" ] } } }
   },
   features {
    feature { key: "age" value { int64_list { value: [] } } }
    feature { key: "gender" value { bytes_list { value: [ "f" ] } } }
  }
]</code></p>
<p>We can use arguments:</p>
<p><code>example_names: ["input0", "input1"],
features: {
    "age": FixedLenFeature([], dtype=tf.int64, default_value=-1),
    "gender": FixedLenFeature([], dtype=tf.string),
}</code></p>
<p>And the expected output is:</p>
<p><code>python
{
  "age": [[0], [-1]],
  "gender": [["f"], ["f"]],
}</code></p>
<p>Args:
  serialized: A vector (1-D Tensor) of strings, a batch of binary
    serialized <code>Example</code> protos.
  features: A <code>dict</code> mapping feature keys to <code>FixedLenFeature</code> or
    <code>VarLenFeature</code> values.
  name: A name for this operation (optional).
  example_names: A vector (1-D Tensor) of strings (optional), the names of
    the serialized protos in the batch.</p>
<p>Returns:
  A <code>dict</code> mapping feature keys to <code>Tensor</code> and <code>SparseTensor</code> values.</p>
<p>Raises:
  ValueError: if any feature is invalid.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.parse_example_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.parse_example_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.parse_single_example">
    <p>def <span class="ident">parse_single_example</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.parse_single_example, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.parse_single_example</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.parse_single_example</strong></p>
<div class="codehilite"><pre><span></span>def parse_single_example(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.parse_single_example</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.parse_single_example</code></strong></p>
<div class="codehilite"><pre><span></span>def parse_single_example(serialized, features, name=None, example_names=None)
</pre></div>


<p>Parses a single <code>Example</code> proto.</p>
<p>Similar to <code>parse_example</code>, except:</p>
<p>For dense tensors, the returned <code>Tensor</code> is identical to the output of
<code>parse_example</code>, except there is no batch dimension, the output shape is the
same as the shape given in <code>dense_shape</code>.</p>
<p>For <code>SparseTensor</code>s, the first (batch) column of the indices matrix is removed
(the indices matrix is a column vector), the values vector is unchanged, and
the first (<code>batch_size</code>) entry of the shape vector is removed (it is now a
single element vector).</p>
<p>Args:
  serialized: A scalar string Tensor, a single serialized Example.
    See <code>_parse_single_example_raw</code> documentation for more details.
  features: A <code>dict</code> mapping feature keys to <code>FixedLenFeature</code> or
    <code>VarLenFeature</code> values.
  name: A name for this operation (optional).
  example_names: (Optional) A scalar string Tensor, the associated name.
    See <code>_parse_single_example_raw</code> documentation for more details.</p>
<p>Returns:
  A <code>dict</code> mapping feature keys to <code>Tensor</code> and <code>SparseTensor</code> values.</p>
<p>Raises:
  ValueError: if any feature is invalid.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.parse_single_example', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.parse_single_example" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.parse_single_example_layer">
    <p>def <span class="ident">parse_single_example_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.parse_single_example_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.parse_single_example_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.parse_single_example_layer</strong></p>
<div class="codehilite"><pre><span></span>def parse_single_example_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.parse_single_example, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.parse_single_example</strong></p>
<div class="codehilite"><pre><span></span>def parse_single_example(serialized, features, name=None, example_names=None):
</pre></div>


<p>Parses a single <code>Example</code> proto.</p>
<p>Similar to <code>parse_example</code>, except:</p>
<p>For dense tensors, the returned <code>Tensor</code> is identical to the output of
<code>parse_example</code>, except there is no batch dimension, the output shape is the
same as the shape given in <code>dense_shape</code>.</p>
<p>For <code>SparseTensor</code>s, the first (batch) column of the indices matrix is removed
(the indices matrix is a column vector), the values vector is unchanged, and
the first (<code>batch_size</code>) entry of the shape vector is removed (it is now a
single element vector).</p>
<p>Args:
  serialized: A scalar string Tensor, a single serialized Example.
    See <code>_parse_single_example_raw</code> documentation for more details.
  features: A <code>dict</code> mapping feature keys to <code>FixedLenFeature</code> or
    <code>VarLenFeature</code> values.
  name: A name for this operation (optional).
  example_names: (Optional) A scalar string Tensor, the associated name.
    See <code>_parse_single_example_raw</code> documentation for more details.</p>
<p>Returns:
  A <code>dict</code> mapping feature keys to <code>Tensor</code> and <code>SparseTensor</code> values.</p>
<p>Raises:
  ValueError: if any feature is invalid.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.parse_single_example_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.parse_single_example_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.parse_single_sequence_example">
    <p>def <span class="ident">parse_single_sequence_example</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.parse_single_sequence_example, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.parse_single_sequence_example</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.parse_single_sequence_example</strong></p>
<div class="codehilite"><pre><span></span>def parse_single_sequence_example(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.parse_single_sequence_example</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.parse_single_sequence_example</code></strong></p>
<div class="codehilite"><pre><span></span>def parse_single_sequence_example(serialized, context_features=None, sequence_features=None, example_name=None, name=None)
</pre></div>


<p>Parses a single <code>SequenceExample</code> proto.</p>
<p>Parses a single serialized [<code>SequenceExample</code>]
(https://www.tensorflow.org/code/tensorflow/core/example/example.proto)
proto given in <code>serialized</code>.</p>
<p>This op parses a serialize sequence example into a tuple of dictionaries
mapping keys to <code>Tensor</code> and <code>SparseTensor</code> objects respectively.
The first dictionary contains mappings for keys appearing in
<code>context_features</code>, and the second dictionary contains mappings for keys
appearing in <code>sequence_features</code>.</p>
<p>At least one of <code>context_features</code> and <code>sequence_features</code> must be provided
and non-empty.</p>
<p>The <code>context_features</code> keys are associated with a <code>SequenceExample</code> as a
whole, independent of time / frame.  In contrast, the <code>sequence_features</code> keys
provide a way to access variable-length data within the <code>FeatureList</code> section
of the <code>SequenceExample</code> proto.  While the shapes of <code>context_features</code> values
are fixed with respect to frame, the frame dimension (the first dimension)
of <code>sequence_features</code> values may vary between <code>SequenceExample</code> protos,
and even between <code>feature_list</code> keys within the same <code>SequenceExample</code>.</p>
<p><code>context_features</code> contains <code>VarLenFeature</code> and <code>FixedLenFeature</code> objects.
Each <code>VarLenFeature</code> is mapped to a <code>SparseTensor</code>, and each <code>FixedLenFeature</code>
is mapped to a <code>Tensor</code>, of the specified type, shape, and default value.</p>
<p><code>sequence_features</code> contains <code>VarLenFeature</code> and <code>FixedLenSequenceFeature</code>
objects. Each <code>VarLenFeature</code> is mapped to a <code>SparseTensor</code>, and each
<code>FixedLenSequenceFeature</code> is mapped to a <code>Tensor</code>, each of the specified type.
The shape will be <code>(T,) + df.shape</code> for <code>FixedLenSequenceFeature</code> <code>df</code>, where
<code>T</code> is the length of the associated <code>FeatureList</code> in the <code>SequenceExample</code>.</p>
<p>Each <code>SparseTensor</code> corresponding to <code>sequence_features</code> represents a ragged
vector.  Its indices are <code>[time, index]</code>, where <code>time</code> is the <code>FeatureList</code>
entry and <code>index</code> is the value's index in the list of values associated with
that time.</p>
<p><code>FixedLenFeature</code> entries with a <code>default_value</code> and <code>FixedLenSequenceFeature</code>
entries with <code>allow_missing=True</code> are optional; otherwise, we will fail if
that <code>Feature</code> or <code>FeatureList</code> is missing from any example in <code>serialized</code>.</p>
<p><code>example_name</code> may contain a descriptive name for the corresponding serialized
proto. This may be useful for debugging purposes, but it has no effect on the
output. If not <code>None</code>, <code>example_name</code> must be a scalar.</p>
<p>Args:
  serialized: A scalar (0-D Tensor) of type string, a single binary
    serialized <code>SequenceExample</code> proto.
  context_features: A <code>dict</code> mapping feature keys to <code>FixedLenFeature</code> or
    <code>VarLenFeature</code> values. These features are associated with a
    <code>SequenceExample</code> as a whole.
  sequence_features: A <code>dict</code> mapping feature keys to
    <code>FixedLenSequenceFeature</code> or <code>VarLenFeature</code> values. These features are
    associated with data within the <code>FeatureList</code> section of the
    <code>SequenceExample</code> proto.
  example_name: A scalar (0-D Tensor) of strings (optional), the name of
    the serialized proto.
  name: A name for this operation (optional).</p>
<p>Returns:
  A tuple of two <code>dict</code>s, each mapping keys to <code>Tensor</code>s and <code>SparseTensor</code>s.
  The first dict contains the context key/values.
  The second dict contains the feature_list key/values.</p>
<p>Raises:
  ValueError: if any feature is invalid.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.parse_single_sequence_example', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.parse_single_sequence_example" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.parse_single_sequence_example_layer">
    <p>def <span class="ident">parse_single_sequence_example_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.parse_single_sequence_example_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.parse_single_sequence_example_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.parse_single_sequence_example_layer</strong></p>
<div class="codehilite"><pre><span></span>def parse_single_sequence_example_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.parse_single_sequence_example, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.parse_single_sequence_example</strong></p>
<div class="codehilite"><pre><span></span>def parse_single_sequence_example(serialized, context_features=None, sequence_features=None, example_name=None, name=None):
</pre></div>


<p>Parses a single <code>SequenceExample</code> proto.</p>
<p>Parses a single serialized [<code>SequenceExample</code>]
(https://www.tensorflow.org/code/tensorflow/core/example/example.proto)
proto given in <code>serialized</code>.</p>
<p>This op parses a serialize sequence example into a tuple of dictionaries
mapping keys to <code>Tensor</code> and <code>SparseTensor</code> objects respectively.
The first dictionary contains mappings for keys appearing in
<code>context_features</code>, and the second dictionary contains mappings for keys
appearing in <code>sequence_features</code>.</p>
<p>At least one of <code>context_features</code> and <code>sequence_features</code> must be provided
and non-empty.</p>
<p>The <code>context_features</code> keys are associated with a <code>SequenceExample</code> as a
whole, independent of time / frame.  In contrast, the <code>sequence_features</code> keys
provide a way to access variable-length data within the <code>FeatureList</code> section
of the <code>SequenceExample</code> proto.  While the shapes of <code>context_features</code> values
are fixed with respect to frame, the frame dimension (the first dimension)
of <code>sequence_features</code> values may vary between <code>SequenceExample</code> protos,
and even between <code>feature_list</code> keys within the same <code>SequenceExample</code>.</p>
<p><code>context_features</code> contains <code>VarLenFeature</code> and <code>FixedLenFeature</code> objects.
Each <code>VarLenFeature</code> is mapped to a <code>SparseTensor</code>, and each <code>FixedLenFeature</code>
is mapped to a <code>Tensor</code>, of the specified type, shape, and default value.</p>
<p><code>sequence_features</code> contains <code>VarLenFeature</code> and <code>FixedLenSequenceFeature</code>
objects. Each <code>VarLenFeature</code> is mapped to a <code>SparseTensor</code>, and each
<code>FixedLenSequenceFeature</code> is mapped to a <code>Tensor</code>, each of the specified type.
The shape will be <code>(T,) + df.shape</code> for <code>FixedLenSequenceFeature</code> <code>df</code>, where
<code>T</code> is the length of the associated <code>FeatureList</code> in the <code>SequenceExample</code>.</p>
<p>Each <code>SparseTensor</code> corresponding to <code>sequence_features</code> represents a ragged
vector.  Its indices are <code>[time, index]</code>, where <code>time</code> is the <code>FeatureList</code>
entry and <code>index</code> is the value's index in the list of values associated with
that time.</p>
<p><code>FixedLenFeature</code> entries with a <code>default_value</code> and <code>FixedLenSequenceFeature</code>
entries with <code>allow_missing=True</code> are optional; otherwise, we will fail if
that <code>Feature</code> or <code>FeatureList</code> is missing from any example in <code>serialized</code>.</p>
<p><code>example_name</code> may contain a descriptive name for the corresponding serialized
proto. This may be useful for debugging purposes, but it has no effect on the
output. If not <code>None</code>, <code>example_name</code> must be a scalar.</p>
<p>Args:
  serialized: A scalar (0-D Tensor) of type string, a single binary
    serialized <code>SequenceExample</code> proto.
  context_features: A <code>dict</code> mapping feature keys to <code>FixedLenFeature</code> or
    <code>VarLenFeature</code> values. These features are associated with a
    <code>SequenceExample</code> as a whole.
  sequence_features: A <code>dict</code> mapping feature keys to
    <code>FixedLenSequenceFeature</code> or <code>VarLenFeature</code> values. These features are
    associated with data within the <code>FeatureList</code> section of the
    <code>SequenceExample</code> proto.
  example_name: A scalar (0-D Tensor) of strings (optional), the name of
    the serialized proto.
  name: A name for this operation (optional).</p>
<p>Returns:
  A tuple of two <code>dict</code>s, each mapping keys to <code>Tensor</code>s and <code>SparseTensor</code>s.
  The first dict contains the context key/values.
  The second dict contains the feature_list key/values.</p>
<p>Raises:
  ValueError: if any feature is invalid.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.parse_single_sequence_example_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.parse_single_sequence_example_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.pipe">
    <p>def <span class="ident">pipe</span>(</p><p>self, builder, *ast)</p>
    </div>
    

    
  
    <div class="desc"><p><code>pipe</code> takes in a <code>builder</code> of type <code>Builder</code>, <code>BuilderTree</code> or <code>Tensor</code> preferably and an object <code>ast</code> which must be part of the domain of the DSL, and compiles <code>ast</code> to a function of type <code>Builder -&gt; Builder</code> and applies it to the input <code>builder</code>. All *args after <code>builder</code> are taken as a tuple, therefore, it makes it easier to define an initial tuple <code>()</code> element to define a sequential operation.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>builder</code>: a <code>Builder</code>, <code>BuilderTree</code> or <code>Tensor</code> preferably.</li>
<li><code>*ast</code>: a sequence of elements of the DSL.</li>
</ul>
<p><strong>Return</strong></p>
<p>An object with the result of the computation, probable types: <code>Tensor | Builder | BuilderTree | list(Tensor) |</code></p>
<p><strong>Examples</strong></p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">h</span> <span class="o">=</span> <span class="n">tb</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="p">[</span>
        <span class="p">{</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/gpu:0&quot;</span><span class="p">):</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">,</span>
        <span class="p">{</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/gpu:1&quot;</span><span class="p">):</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">,</span>
        <span class="p">{</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/cpu:0&quot;</span><span class="p">):</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">tanh_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">],</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.pipe', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.pipe" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">pipe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">builder</span><span class="p">,</span> <span class="o">*</span><span class="n">ast</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    `pipe` takes in a `builder` of type `Builder`, `BuilderTree` or `Tensor` preferably and an object `ast` which must be part of the domain of the DSL, and compiles `ast` to a function of type `Builder -&gt; Builder` and applies it to the input `builder`. All \*args after `builder` are taken as a tuple, therefore, it makes it easier to define an initial tuple `()` element to define a sequential operation.</span>
<span class="sd">    **Arguments**</span>
<span class="sd">    * `builder`: a `Builder`, `BuilderTree` or `Tensor` preferably.</span>
<span class="sd">    * `*ast`: a sequence of elements of the DSL.</span>
<span class="sd">    **Return**</span>
<span class="sd">    An object with the result of the computation, probable types: `Tensor | Builder | BuilderTree | list(Tensor) |  `</span>
<span class="sd">    **Examples**</span>
<span class="sd">        import tensorflow as tf</span>
<span class="sd">        from tensorbuilder import tb</span>
<span class="sd">        x = placeholder(tf.float32, shape=[None, 10])</span>
<span class="sd">        h = tb.pipe(</span>
<span class="sd">            x,</span>
<span class="sd">            [</span>
<span class="sd">                { tf.device(&quot;/gpu:0&quot;):</span>
<span class="sd">                    tb.relu_layer(20)</span>
<span class="sd">                }</span>
<span class="sd">            ,</span>
<span class="sd">                { tf.device(&quot;/gpu:1&quot;):</span>
<span class="sd">                    tb.sigmoid_layer(20)</span>
<span class="sd">                }</span>
<span class="sd">            ,</span>
<span class="sd">                { tf.device(&quot;/cpu:0&quot;):</span>
<span class="sd">                    tb.tanh_layer(20)</span>
<span class="sd">                }</span>
<span class="sd">            ],</span>
<span class="sd">            tb.relu_layer(10)</span>
<span class="sd">            .tensor()</span>
<span class="sd">        )</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">_compile</span><span class="p">(</span><span class="n">ast</span><span class="p">)</span>
    <span class="c1">#if the input is a Tensor, create a Builder</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">builder</span><span class="p">)</span> <span class="ow">is</span> <span class="n">tf</span><span class="o">.</span><span class="n">python</span><span class="o">.</span><span class="n">framework</span><span class="o">.</span><span class="n">ops</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">builder</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">Builder</span><span class="p">(</span><span class="n">builder</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">f</span><span class="p">(</span><span class="n">builder</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.placeholder">
    <p>def <span class="ident">placeholder</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.placeholder, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.placeholder</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.placeholder</strong></p>
<div class="codehilite"><pre><span></span>def placeholder(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.placeholder</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.placeholder</code></strong></p>
<div class="codehilite"><pre><span></span>def placeholder(dtype, shape=None, name=None)
</pre></div>


<p>Inserts a placeholder for a tensor that will be always fed.</p>
<p><strong>Important</strong>: This tensor will produce an error if evaluated. Its value must
be fed using the <code>feed_dict</code> optional argument to <code>Session.run()</code>,
<code>Tensor.eval()</code>, or <code>Operation.run()</code>.</p>
<p>For example:</p>
<p>```python
x = tf.placeholder(tf.float32, shape=(1024, 1024))
y = tf.matmul(x, x)</p>
<p>with tf.Session() as sess:
  print(sess.run(y))  # ERROR: will fail because x was not fed.</p>
<p>rand_array = np.random.rand(1024, 1024)
  print(sess.run(y, feed_dict={x: rand_array}))  # Will succeed.
```</p>
<p>Args:
  dtype: The type of elements in the tensor to be fed.
  shape: The shape of the tensor to be fed (optional). If the shape is not
    specified, you can feed a tensor of any shape.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> that may be used as a handle for feeding a value, but not
  evaluated directly.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.placeholder', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.placeholder" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.placeholder_layer">
    <p>def <span class="ident">placeholder_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.placeholder_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.placeholder_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.placeholder_layer</strong></p>
<div class="codehilite"><pre><span></span>def placeholder_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.placeholder, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.placeholder</strong></p>
<div class="codehilite"><pre><span></span>def placeholder(dtype, shape=None, name=None):
</pre></div>


<p>Inserts a placeholder for a tensor that will be always fed.</p>
<p><strong>Important</strong>: This tensor will produce an error if evaluated. Its value must
be fed using the <code>feed_dict</code> optional argument to <code>Session.run()</code>,
<code>Tensor.eval()</code>, or <code>Operation.run()</code>.</p>
<p>For example:</p>
<p>```python
x = tf.placeholder(tf.float32, shape=(1024, 1024))
y = tf.matmul(x, x)</p>
<p>with tf.Session() as sess:
  print(sess.run(y))  # ERROR: will fail because x was not fed.</p>
<p>rand_array = np.random.rand(1024, 1024)
  print(sess.run(y, feed_dict={x: rand_array}))  # Will succeed.
```</p>
<p>Args:
  dtype: The type of elements in the tensor to be fed.
  shape: The shape of the tensor to be fed (optional). If the shape is not
    specified, you can feed a tensor of any shape.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> that may be used as a handle for feeding a value, but not
  evaluated directly.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.placeholder_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.placeholder_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.placeholder_with_default">
    <p>def <span class="ident">placeholder_with_default</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.placeholder_with_default, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.placeholder_with_default</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.placeholder_with_default</strong></p>
<div class="codehilite"><pre><span></span>def placeholder_with_default(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.placeholder_with_default</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.placeholder_with_default</code></strong></p>
<div class="codehilite"><pre><span></span>def placeholder_with_default(input, shape, name=None)
</pre></div>


<p>A placeholder op that passes though <code>input</code> when its output is not fed.</p>
<p>Args:
  input: A <code>Tensor</code>. The default value to produce when <code>output</code> is not fed.
  shape: A <code>tf.TensorShape</code> or list of <code>ints</code>.
    The (possibly partial) shape of the tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  A placeholder tensor that defaults to <code>input</code> if it is not fed.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.placeholder_with_default', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.placeholder_with_default" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.placeholder_with_default_layer">
    <p>def <span class="ident">placeholder_with_default_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.placeholder_with_default_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.placeholder_with_default_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.placeholder_with_default_layer</strong></p>
<div class="codehilite"><pre><span></span>def placeholder_with_default_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.placeholder_with_default, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.placeholder_with_default</strong></p>
<div class="codehilite"><pre><span></span>def placeholder_with_default(input, shape, name=None):
</pre></div>


<p>A placeholder op that passes though <code>input</code> when its output is not fed.</p>
<p>Args:
  input: A <code>Tensor</code>. The default value to produce when <code>output</code> is not fed.
  shape: A <code>tf.TensorShape</code> or list of <code>ints</code>.
    The (possibly partial) shape of the tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  A placeholder tensor that defaults to <code>input</code> if it is not fed.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.placeholder_with_default_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.placeholder_with_default_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.polygamma">
    <p>def <span class="ident">polygamma</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.polygamma, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.polygamma</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.polygamma</strong></p>
<div class="codehilite"><pre><span></span>def polygamma(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.polygamma</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.polygamma</code></strong></p>
<div class="codehilite"><pre><span></span>def polygamma(a, x, name=None)
</pre></div>


<p>Compute the polygamma function \(\psi^{(n)}(x)\).</p>
<p>The polygamma function is defined as:</p>
<p><code>\psi^{(n)}(x) = \frac{d^n}{dx^n} \psi(x)</code>
where \(\psi(x)\) is the digamma function.</p>
<p>Args:
  a: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  x: A <code>Tensor</code>. Must have the same type as <code>a</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>a</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.polygamma', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.polygamma" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.polygamma_layer">
    <p>def <span class="ident">polygamma_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.polygamma_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.polygamma_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.polygamma_layer</strong></p>
<div class="codehilite"><pre><span></span>def polygamma_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.polygamma, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.polygamma</strong></p>
<div class="codehilite"><pre><span></span>def polygamma(a, x, name=None):
</pre></div>


<p>Compute the polygamma function \(\psi^{(n)}(x)\).</p>
<p>The polygamma function is defined as:</p>
<p><code>\psi^{(n)}(x) = \frac{d^n}{dx^n} \psi(x)</code>
where \(\psi(x)\) is the digamma function.</p>
<p>Args:
  a: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  x: A <code>Tensor</code>. Must have the same type as <code>a</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>a</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.polygamma_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.polygamma_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.pow">
    <p>def <span class="ident">pow</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.pow, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.pow</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.pow</strong></p>
<div class="codehilite"><pre><span></span>def pow(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.pow</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.pow</code></strong></p>
<div class="codehilite"><pre><span></span>def pow(x, y, name=None)
</pre></div>


<p>Computes the power of one value to another.</p>
<p>Given a tensor <code>x</code> and a tensor <code>y</code>, this operation computes \(x^y\) for
corresponding elements in <code>x</code> and <code>y</code>. For example:</p>
<p>```</p>
<h1>tensor 'x' is [[2, 2], [3, 3]]</h1>
<h1>tensor 'y' is [[8, 16], [2, 3]]</h1>
<p>tf.pow(x, y) ==&gt; [[256, 65536], [9, 27]]
```</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>float</code>, <code>double</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, or
   <code>complex128</code>.
  y: A <code>Tensor</code> of type <code>float</code>, <code>double</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, or
   <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.pow', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.pow" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.pow_layer">
    <p>def <span class="ident">pow_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.pow_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.pow_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.pow_layer</strong></p>
<div class="codehilite"><pre><span></span>def pow_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.pow, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.pow</strong></p>
<div class="codehilite"><pre><span></span>def pow(x, y, name=None):
</pre></div>


<p>Computes the power of one value to another.</p>
<p>Given a tensor <code>x</code> and a tensor <code>y</code>, this operation computes \(x^y\) for
corresponding elements in <code>x</code> and <code>y</code>. For example:</p>
<p>```</p>
<h1>tensor 'x' is [[2, 2], [3, 3]]</h1>
<h1>tensor 'y' is [[8, 16], [2, 3]]</h1>
<p>tf.pow(x, y) ==&gt; [[256, 65536], [9, 27]]
```</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>float</code>, <code>double</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, or
   <code>complex128</code>.
  y: A <code>Tensor</code> of type <code>float</code>, <code>double</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, or
   <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.pow_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.pow_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.py_func">
    <p>def <span class="ident">py_func</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.py_func, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.py_func</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.py_func</strong></p>
<div class="codehilite"><pre><span></span>def py_func(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.py_func</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.py_func</code></strong></p>
<div class="codehilite"><pre><span></span>def py_func(func, inp, Tout, name=None)
</pre></div>


<p>Wraps a python function and uses it as a tensorflow op.</p>
<p>Given a python function <code>func</code>, which takes numpy arrays as its
inputs and returns numpy arrays as its outputs. E.g.,</p>
<p><code>python
def my_func(x):
  # x will be a numpy array with the contents of the placeholder below
  return np.sinh(x)
inp = tf.placeholder(tf.float32, [...])
y = py_func(my_func, [inp], [tf.float32])</code></p>
<p>The above snippet constructs a tf graph which invokes a numpy
sinh(x) as an op in the graph.</p>
<p>Args:
  func: A python function.
  inp: A list of <code>Tensor</code>.
  Tout: A list of tensorflow data types indicating what <code>func</code>
        returns.
  name: A name for the operation (optional).</p>
<p>Returns:
  A list of <code>Tensor</code> which <code>func</code> computes.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.py_func', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.py_func" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.py_func_layer">
    <p>def <span class="ident">py_func_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.py_func_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.py_func_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.py_func_layer</strong></p>
<div class="codehilite"><pre><span></span>def py_func_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.py_func, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.py_func</strong></p>
<div class="codehilite"><pre><span></span>def py_func(func, inp, Tout, name=None):
</pre></div>


<p>Wraps a python function and uses it as a tensorflow op.</p>
<p>Given a python function <code>func</code>, which takes numpy arrays as its
inputs and returns numpy arrays as its outputs. E.g.,</p>
<p><code>python
def my_func(x):
  # x will be a numpy array with the contents of the placeholder below
  return np.sinh(x)
inp = tf.placeholder(tf.float32, [...])
y = py_func(my_func, [inp], [tf.float32])</code></p>
<p>The above snippet constructs a tf graph which invokes a numpy
sinh(x) as an op in the graph.</p>
<p>Args:
  func: A python function.
  inp: A list of <code>Tensor</code>.
  Tout: A list of tensorflow data types indicating what <code>func</code>
        returns.
  name: A name for the operation (optional).</p>
<p>Returns:
  A list of <code>Tensor</code> which <code>func</code> computes.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.py_func_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.py_func_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.random_crop">
    <p>def <span class="ident">random_crop</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.random_crop, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.random_crop</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.random_crop</strong></p>
<div class="codehilite"><pre><span></span>def random_crop(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.random_crop</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.random_crop</code></strong></p>
<div class="codehilite"><pre><span></span>def random_crop(value, size, seed=None, name=None)
</pre></div>


<p>Randomly crops a tensor to a given size.</p>
<p>Slices a shape <code>size</code> portion out of <code>value</code> at a uniformly chosen offset.
Requires <code>value.shape &gt;= size</code>.</p>
<p>If a dimension should not be cropped, pass the full size of that dimension.
For example, RGB images can be cropped with
<code>size = [crop_height, crop_width, 3]</code>.</p>
<p>Args:
  value: Input tensor to crop.
  size: 1-D tensor with size the rank of <code>value</code>.
  seed: Python integer. Used to create a random seed. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: A name for this operation (optional).</p>
<p>Returns:
  A cropped tensor of the same rank as <code>value</code> and shape <code>size</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.random_crop', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.random_crop" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.random_crop_layer">
    <p>def <span class="ident">random_crop_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.random_crop_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.random_crop_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.random_crop_layer</strong></p>
<div class="codehilite"><pre><span></span>def random_crop_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.random_crop, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.random_crop</strong></p>
<div class="codehilite"><pre><span></span>def random_crop(value, size, seed=None, name=None):
</pre></div>


<p>Randomly crops a tensor to a given size.</p>
<p>Slices a shape <code>size</code> portion out of <code>value</code> at a uniformly chosen offset.
Requires <code>value.shape &gt;= size</code>.</p>
<p>If a dimension should not be cropped, pass the full size of that dimension.
For example, RGB images can be cropped with
<code>size = [crop_height, crop_width, 3]</code>.</p>
<p>Args:
  value: Input tensor to crop.
  size: 1-D tensor with size the rank of <code>value</code>.
  seed: Python integer. Used to create a random seed. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: A name for this operation (optional).</p>
<p>Returns:
  A cropped tensor of the same rank as <code>value</code> and shape <code>size</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.random_crop_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.random_crop_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.random_normal">
    <p>def <span class="ident">random_normal</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.random_normal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.random_normal</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.random_normal</strong></p>
<div class="codehilite"><pre><span></span>def random_normal(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.random_normal</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.random_normal</code></strong></p>
<div class="codehilite"><pre><span></span>def random_normal(shape, mean=0.0, stddev=1.0, dtype=&lt;dtype: &#39;float32&#39;&gt;, seed=None, name=None)
</pre></div>


<p>Outputs random values from a normal distribution.</p>
<p>Args:
  shape: A 1-D integer Tensor or Python array. The shape of the output tensor.
  mean: A 0-D Tensor or Python value of type <code>dtype</code>. The mean of the normal
    distribution.
  stddev: A 0-D Tensor or Python value of type <code>dtype</code>. The standard deviation
    of the normal distribution.
  dtype: The type of the output.
  seed: A Python integer. Used to create a random seed for the distribution.
    See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tensor of the specified shape filled with random normal values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.random_normal', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.random_normal" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.random_normal_initializer">
    <p>def <span class="ident">random_normal_initializer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.random_normal_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.random_normal_initializer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.random_normal_initializer</strong></p>
<div class="codehilite"><pre><span></span>def random_normal_initializer(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.random_normal_initializer</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.random_normal_initializer</code></strong></p>
<div class="codehilite"><pre><span></span>def random_normal_initializer(mean=0.0, stddev=1.0, seed=None, dtype=&lt;dtype: &#39;float32&#39;&gt;)
</pre></div>


<p>Returns an initializer that generates tensors with a normal distribution.</p>
<p>Args:
  mean: a python scalar or a scalar tensor. Mean of the random values
    to generate.
  stddev: a python scalar or a scalar tensor. Standard deviation of the
    random values to generate.
  seed: A Python integer. Used to create random seeds. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  dtype: The data type. Only floating point types are supported.</p>
<p>Returns:
  An initializer that generates tensors with a normal distribution.</p>
<p>Raises:
  ValueError: if <code>dtype</code> is not a floating point type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.random_normal_initializer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.random_normal_initializer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.random_normal_initializer_layer">
    <p>def <span class="ident">random_normal_initializer_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.random_normal_initializer_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.random_normal_initializer_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.random_normal_initializer_layer</strong></p>
<div class="codehilite"><pre><span></span>def random_normal_initializer_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.random_normal_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.random_normal_initializer</strong></p>
<div class="codehilite"><pre><span></span>def random_normal_initializer(mean=0.0, stddev=1.0, seed=None, dtype=&lt;dtype: &#39;float32&#39;&gt;):
</pre></div>


<p>Returns an initializer that generates tensors with a normal distribution.</p>
<p>Args:
  mean: a python scalar or a scalar tensor. Mean of the random values
    to generate.
  stddev: a python scalar or a scalar tensor. Standard deviation of the
    random values to generate.
  seed: A Python integer. Used to create random seeds. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  dtype: The data type. Only floating point types are supported.</p>
<p>Returns:
  An initializer that generates tensors with a normal distribution.</p>
<p>Raises:
  ValueError: if <code>dtype</code> is not a floating point type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.random_normal_initializer_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.random_normal_initializer_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.random_normal_layer">
    <p>def <span class="ident">random_normal_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.random_normal_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.random_normal_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.random_normal_layer</strong></p>
<div class="codehilite"><pre><span></span>def random_normal_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.random_normal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.random_normal</strong></p>
<div class="codehilite"><pre><span></span>def random_normal(shape, mean=0.0, stddev=1.0, dtype=&lt;dtype: &#39;float32&#39;&gt;, seed=None, name=None):
</pre></div>


<p>Outputs random values from a normal distribution.</p>
<p>Args:
  shape: A 1-D integer Tensor or Python array. The shape of the output tensor.
  mean: A 0-D Tensor or Python value of type <code>dtype</code>. The mean of the normal
    distribution.
  stddev: A 0-D Tensor or Python value of type <code>dtype</code>. The standard deviation
    of the normal distribution.
  dtype: The type of the output.
  seed: A Python integer. Used to create a random seed for the distribution.
    See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tensor of the specified shape filled with random normal values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.random_normal_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.random_normal_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.random_shuffle">
    <p>def <span class="ident">random_shuffle</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.random_shuffle, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.random_shuffle</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.random_shuffle</strong></p>
<div class="codehilite"><pre><span></span>def random_shuffle(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.random_shuffle</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.random_shuffle</code></strong></p>
<div class="codehilite"><pre><span></span>def random_shuffle(value, seed=None, name=None)
</pre></div>


<p>Randomly shuffles a tensor along its first dimension.</p>
<p>The tensor is shuffled along dimension 0, such that each <code>value[j]</code> is mapped
to one and only one <code>output[i]</code>. For example, a mapping that might occur for a
3x2 tensor is:</p>
<p><code>python
[[1, 2],       [[5, 6],
 [3, 4],  ==&gt;   [1, 2],
 [5, 6]]        [3, 4]]</code></p>
<p>Args:
  value: A Tensor to be shuffled.
  seed: A Python integer. Used to create a random seed for the distribution.
    See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tensor of same shape and type as <code>value</code>, shuffled along its first
  dimension.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.random_shuffle', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.random_shuffle" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.random_shuffle_layer">
    <p>def <span class="ident">random_shuffle_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.random_shuffle_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.random_shuffle_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.random_shuffle_layer</strong></p>
<div class="codehilite"><pre><span></span>def random_shuffle_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.random_shuffle, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.random_shuffle</strong></p>
<div class="codehilite"><pre><span></span>def random_shuffle(value, seed=None, name=None):
</pre></div>


<p>Randomly shuffles a tensor along its first dimension.</p>
<p>The tensor is shuffled along dimension 0, such that each <code>value[j]</code> is mapped
to one and only one <code>output[i]</code>. For example, a mapping that might occur for a
3x2 tensor is:</p>
<p><code>python
[[1, 2],       [[5, 6],
 [3, 4],  ==&gt;   [1, 2],
 [5, 6]]        [3, 4]]</code></p>
<p>Args:
  value: A Tensor to be shuffled.
  seed: A Python integer. Used to create a random seed for the distribution.
    See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tensor of same shape and type as <code>value</code>, shuffled along its first
  dimension.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.random_shuffle_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.random_shuffle_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.random_uniform">
    <p>def <span class="ident">random_uniform</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.random_uniform, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.random_uniform</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.random_uniform</strong></p>
<div class="codehilite"><pre><span></span>def random_uniform(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.random_uniform</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.random_uniform</code></strong></p>
<div class="codehilite"><pre><span></span>def random_uniform(shape, minval=0, maxval=None, dtype=&lt;dtype: &#39;float32&#39;&gt;, seed=None, name=None)
</pre></div>


<p>Outputs random values from a uniform distribution.</p>
<p>The generated values follow a uniform distribution in the range
<code>[minval, maxval)</code>. The lower bound <code>minval</code> is included in the range, while
the upper bound <code>maxval</code> is excluded.</p>
<p>For floats, the default range is <code>[0, 1)</code>.  For ints, at least <code>maxval</code> must
be specified explicitly.</p>
<p>In the integer case, the random integers are slightly biased unless
<code>maxval - minval</code> is an exact power of two.  The bias is small for values of
<code>maxval - minval</code> significantly smaller than the range of the output (either
<code>2**32</code> or <code>2**64</code>).</p>
<p>Args:
  shape: A 1-D integer Tensor or Python array. The shape of the output tensor.
  minval: A 0-D Tensor or Python value of type <code>dtype</code>. The lower bound on the
    range of random values to generate.  Defaults to 0.
  maxval: A 0-D Tensor or Python value of type <code>dtype</code>. The upper bound on
    the range of random values to generate.  Defaults to 1 if <code>dtype</code> is
    floating point.
  dtype: The type of the output: <code>float32</code>, <code>float64</code>, <code>int32</code>, or <code>int64</code>.
  seed: A Python integer. Used to create a random seed for the distribution.
    See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tensor of the specified shape filled with random uniform values.</p>
<p>Raises:
  ValueError: If <code>dtype</code> is integral and <code>maxval</code> is not specified.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.random_uniform', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.random_uniform" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.random_uniform_initializer">
    <p>def <span class="ident">random_uniform_initializer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.random_uniform_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.random_uniform_initializer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.random_uniform_initializer</strong></p>
<div class="codehilite"><pre><span></span>def random_uniform_initializer(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.random_uniform_initializer</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.random_uniform_initializer</code></strong></p>
<div class="codehilite"><pre><span></span>def random_uniform_initializer(minval=0.0, maxval=1.0, seed=None, dtype=&lt;dtype: &#39;float32&#39;&gt;)
</pre></div>


<p>Returns an initializer that generates tensors with a uniform distribution.</p>
<p>Args:
  minval: a python scalar or a scalar tensor. lower bound of the range
    of random values to generate.
  maxval: a python scalar or a scalar tensor. upper bound of the range
    of random values to generate.
  seed: A Python integer. Used to create random seeds. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  dtype: The data type. Only floating point types are supported.</p>
<p>Returns:
  An initializer that generates tensors with a uniform distribution.</p>
<p>Raises:
  ValueError: if <code>dtype</code> is not a floating point type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.random_uniform_initializer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.random_uniform_initializer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.random_uniform_initializer_layer">
    <p>def <span class="ident">random_uniform_initializer_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.random_uniform_initializer_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.random_uniform_initializer_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.random_uniform_initializer_layer</strong></p>
<div class="codehilite"><pre><span></span>def random_uniform_initializer_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.random_uniform_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.random_uniform_initializer</strong></p>
<div class="codehilite"><pre><span></span>def random_uniform_initializer(minval=0.0, maxval=1.0, seed=None, dtype=&lt;dtype: &#39;float32&#39;&gt;):
</pre></div>


<p>Returns an initializer that generates tensors with a uniform distribution.</p>
<p>Args:
  minval: a python scalar or a scalar tensor. lower bound of the range
    of random values to generate.
  maxval: a python scalar or a scalar tensor. upper bound of the range
    of random values to generate.
  seed: A Python integer. Used to create random seeds. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  dtype: The data type. Only floating point types are supported.</p>
<p>Returns:
  An initializer that generates tensors with a uniform distribution.</p>
<p>Raises:
  ValueError: if <code>dtype</code> is not a floating point type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.random_uniform_initializer_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.random_uniform_initializer_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.random_uniform_layer">
    <p>def <span class="ident">random_uniform_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.random_uniform_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.random_uniform_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.random_uniform_layer</strong></p>
<div class="codehilite"><pre><span></span>def random_uniform_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.random_uniform, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.random_uniform</strong></p>
<div class="codehilite"><pre><span></span>def random_uniform(shape, minval=0, maxval=None, dtype=&lt;dtype: &#39;float32&#39;&gt;, seed=None, name=None):
</pre></div>


<p>Outputs random values from a uniform distribution.</p>
<p>The generated values follow a uniform distribution in the range
<code>[minval, maxval)</code>. The lower bound <code>minval</code> is included in the range, while
the upper bound <code>maxval</code> is excluded.</p>
<p>For floats, the default range is <code>[0, 1)</code>.  For ints, at least <code>maxval</code> must
be specified explicitly.</p>
<p>In the integer case, the random integers are slightly biased unless
<code>maxval - minval</code> is an exact power of two.  The bias is small for values of
<code>maxval - minval</code> significantly smaller than the range of the output (either
<code>2**32</code> or <code>2**64</code>).</p>
<p>Args:
  shape: A 1-D integer Tensor or Python array. The shape of the output tensor.
  minval: A 0-D Tensor or Python value of type <code>dtype</code>. The lower bound on the
    range of random values to generate.  Defaults to 0.
  maxval: A 0-D Tensor or Python value of type <code>dtype</code>. The upper bound on
    the range of random values to generate.  Defaults to 1 if <code>dtype</code> is
    floating point.
  dtype: The type of the output: <code>float32</code>, <code>float64</code>, <code>int32</code>, or <code>int64</code>.
  seed: A Python integer. Used to create a random seed for the distribution.
    See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tensor of the specified shape filled with random uniform values.</p>
<p>Raises:
  ValueError: If <code>dtype</code> is integral and <code>maxval</code> is not specified.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.random_uniform_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.random_uniform_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.range">
    <p>def <span class="ident">range</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.range, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.range</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.range</strong></p>
<div class="codehilite"><pre><span></span>def range(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.range</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.range</code></strong></p>
<div class="codehilite"><pre><span></span>def range(start, limit=None, delta=1, name=&quot;range&quot;)
</pre></div>


<p>Creates a sequence of integers.</p>
<p>Creates a sequence of integers that begins at <code>start</code> and extends by
increments of <code>delta</code> up to but not including <code>limit</code>.</p>
<p>Like the Python builtin <code>range</code>, <code>start</code> defaults to 0, so that
<code>range(n) = range(0, n)</code>.</p>
<p>For example:</p>
<p>```</p>
<h1>'start' is 3</h1>
<h1>'limit' is 18</h1>
<h1>'delta' is 3</h1>
<p>tf.range(start, limit, delta) ==&gt; [3, 6, 9, 12, 15]</p>
<h1>'limit' is 5</h1>
<p>tf.range(limit) ==&gt; [0, 1, 2, 3, 4]
```</p>
<p>Args:
  start: A 0-D (scalar) of type <code>int32</code>. First entry in sequence.
    Defaults to 0.
  limit: A 0-D (scalar) of type <code>int32</code>. Upper limit of sequence,
    exclusive.
  delta: A 0-D <code>Tensor</code> (scalar) of type <code>int32</code>. Optional. Default is 1.
    Number that increments <code>start</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  An 1-D <code>int32</code> <code>Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.range', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.range" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.range_layer">
    <p>def <span class="ident">range_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.range_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.range_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.range_layer</strong></p>
<div class="codehilite"><pre><span></span>def range_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.range, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.range</strong></p>
<div class="codehilite"><pre><span></span>def range(start, limit=None, delta=1, name=&quot;range&quot;):
</pre></div>


<p>Creates a sequence of integers.</p>
<p>Creates a sequence of integers that begins at <code>start</code> and extends by
increments of <code>delta</code> up to but not including <code>limit</code>.</p>
<p>Like the Python builtin <code>range</code>, <code>start</code> defaults to 0, so that
<code>range(n) = range(0, n)</code>.</p>
<p>For example:</p>
<p>```</p>
<h1>'start' is 3</h1>
<h1>'limit' is 18</h1>
<h1>'delta' is 3</h1>
<p>tf.range(start, limit, delta) ==&gt; [3, 6, 9, 12, 15]</p>
<h1>'limit' is 5</h1>
<p>tf.range(limit) ==&gt; [0, 1, 2, 3, 4]
```</p>
<p>Args:
  start: A 0-D (scalar) of type <code>int32</code>. First entry in sequence.
    Defaults to 0.
  limit: A 0-D (scalar) of type <code>int32</code>. Upper limit of sequence,
    exclusive.
  delta: A 0-D <code>Tensor</code> (scalar) of type <code>int32</code>. Optional. Default is 1.
    Number that increments <code>start</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  An 1-D <code>int32</code> <code>Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.range_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.range_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.rank">
    <p>def <span class="ident">rank</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.rank, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.rank</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.rank</strong></p>
<div class="codehilite"><pre><span></span>def rank(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.rank</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.rank</code></strong></p>
<div class="codehilite"><pre><span></span>def rank(input, name=None)
</pre></div>


<p>Returns the rank of a tensor.</p>
<p>This operation returns an integer representing the rank of <code>input</code>.</p>
<p>For example:</p>
<p>```python</p>
<h1>'t' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]</h1>
<h1>shape of tensor 't' is [2, 2, 3]</h1>
<p>rank(t) ==&gt; 3
```</p>
<p><strong>Note</strong>: The rank of a tensor is not the same as the rank of a matrix. The
rank of a tensor is the number of indices required to uniquely select each
element of the tensor. Rank is also known as "order", "degree", or "ndims."</p>
<p>Args:
  input: A <code>Tensor</code> or <code>SparseTensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.rank', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.rank" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.rank_layer">
    <p>def <span class="ident">rank_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.rank_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.rank_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.rank_layer</strong></p>
<div class="codehilite"><pre><span></span>def rank_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.rank, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.rank</strong></p>
<div class="codehilite"><pre><span></span>def rank(input, name=None):
</pre></div>


<p>Returns the rank of a tensor.</p>
<p>This operation returns an integer representing the rank of <code>input</code>.</p>
<p>For example:</p>
<p>```python</p>
<h1>'t' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]</h1>
<h1>shape of tensor 't' is [2, 2, 3]</h1>
<p>rank(t) ==&gt; 3
```</p>
<p><strong>Note</strong>: The rank of a tensor is not the same as the rank of a matrix. The
rank of a tensor is the number of indices required to uniquely select each
element of the tensor. Rank is also known as "order", "degree", or "ndims."</p>
<p>Args:
  input: A <code>Tensor</code> or <code>SparseTensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.rank_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.rank_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.read_file">
    <p>def <span class="ident">read_file</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.read_file, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.read_file</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.read_file</strong></p>
<div class="codehilite"><pre><span></span>def read_file(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.read_file</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.read_file</code></strong></p>
<div class="codehilite"><pre><span></span>def read_file(filename, name=None)
</pre></div>


<p>Reads and outputs the entire contents of the input filename.</p>
<p>Args:
  filename: A <code>Tensor</code> of type <code>string</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>string</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.read_file', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.read_file" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.read_file_layer">
    <p>def <span class="ident">read_file_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.read_file_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.read_file_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.read_file_layer</strong></p>
<div class="codehilite"><pre><span></span>def read_file_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.read_file, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.read_file</strong></p>
<div class="codehilite"><pre><span></span>def read_file(filename, name=None):
</pre></div>


<p>Reads and outputs the entire contents of the input filename.</p>
<p>Args:
  filename: A <code>Tensor</code> of type <code>string</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>string</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.read_file_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.read_file_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.real">
    <p>def <span class="ident">real</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.real, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.real</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.real</strong></p>
<div class="codehilite"><pre><span></span>def real(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.real</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.real</code></strong></p>
<div class="codehilite"><pre><span></span>def real(input, name=None)
</pre></div>


<p>Returns the real part of a complex number.</p>
<p>Given a tensor <code>input</code> of complex numbers, this operation returns a tensor of
type <code>float</code> or <code>double</code> that is the real part of each element in <code>input</code>.
All elements in <code>input</code> must be complex numbers of the form (a + bj),
where <em>a</em> is the real part returned by this operation and <em>b</em> is the
imaginary part.</p>
<p>For example:</p>
<p>```</p>
<h1>tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]</h1>
<p>tf.real(input) ==&gt; [-2.25, 3.25]
```</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>complex64</code>,
       <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>float</code> or <code>double</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.real', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.real" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.real_layer">
    <p>def <span class="ident">real_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.real_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.real_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.real_layer</strong></p>
<div class="codehilite"><pre><span></span>def real_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.real, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.real</strong></p>
<div class="codehilite"><pre><span></span>def real(input, name=None):
</pre></div>


<p>Returns the real part of a complex number.</p>
<p>Given a tensor <code>input</code> of complex numbers, this operation returns a tensor of
type <code>float</code> or <code>double</code> that is the real part of each element in <code>input</code>.
All elements in <code>input</code> must be complex numbers of the form (a + bj),
where <em>a</em> is the real part returned by this operation and <em>b</em> is the
imaginary part.</p>
<p>For example:</p>
<p>```</p>
<h1>tensor 'input' is [-2.25 + 4.75j, 3.25 + 5.75j]</h1>
<p>tf.real(input) ==&gt; [-2.25, 3.25]
```</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>complex64</code>,
       <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>float</code> or <code>double</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.real_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.real_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce">
    <p>def <span class="ident">reduce</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(BuilderTree.reduce, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>BuilderTree.reduce</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for BuilderTree.reduce</strong></p>
<div class="codehilite"><pre><span></span>def reduce(tree, fn, initializer=None):
</pre></div>


<p><code>@immutable</code></p>
<p>Expects a function <strong>fn</strong> with type <code>(Tensor, Tensor) -&gt; Tensor</code> and optionally an <code>initializer</code> and applies python <a href="https://docs.python.org/2/library/functions.html#reduce">reduce</a> function to <code>tensorbuilder.core.builders.BuilderTree.tensors</code> using these arguments; the resulting Tensor is the wrapped inside a Builder.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>fn</code>: a function of type <code>(Tensor, Tensor) -&gt; Tensor</code>.</li>
<li><code>initializer</code>: an optional Tensor as initial element of the folding operation (default: <code>None</code>)s</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><code>tensorbuilder.core.builders.Builder</code></li>
</ul>
<p><strong> Example </strong></p>
<p>Lets reduce the example on <code>tensorbuilder.core.builders.Builder.branch</code> this time doing the reduction ourselves instead of relying on the <code>*_layer</code> of <code>tensorbuilder.core.builders.BuilderTree</code> that do this for us</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">h</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span>
        <span class="n">x</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
        <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">x</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
        <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">x</span><span class="o">.</span><span class="n">tanh_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
        <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="p">])</span>
    <span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">)</span>
    <span class="o">.</span><span class="n">softmax</span><span class="p">()</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>


<p>Same example using the DSL</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">h</span> <span class="o">=</span> <span class="n">tb</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="p">[</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
        <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
        <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="p">,</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">tanh_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
        <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="p">],</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">)</span>
    <span class="o">.</span><span class="n">softmax</span><span class="p">()</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_all">
    <p>def <span class="ident">reduce_all</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_all, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_all</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_all</strong></p>
<div class="codehilite"><pre><span></span>def reduce_all(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.reduce_all</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.reduce_all</code></strong></p>
<div class="codehilite"><pre><span></span>def reduce_all(input_tensor, reduction_indices=None, keep_dims=False, name=None)
</pre></div>


<p>Computes the "logical and" of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' is [[True,  True]</h1>
<h1>[False, False]]</h1>
<p>tf.reduce_all(x) ==&gt; False
tf.reduce_all(x, 0) ==&gt; [False, False]
tf.reduce_all(x, 1) ==&gt; [True, False]
```</p>
<p>Args:
  input_tensor: The boolean tensor to reduce.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_all', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_all" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_all_layer">
    <p>def <span class="ident">reduce_all_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_all_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_all_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_all_layer</strong></p>
<div class="codehilite"><pre><span></span>def reduce_all_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.reduce_all, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.reduce_all</strong></p>
<div class="codehilite"><pre><span></span>def reduce_all(input_tensor, reduction_indices=None, keep_dims=False, name=None):
</pre></div>


<p>Computes the "logical and" of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' is [[True,  True]</h1>
<h1>[False, False]]</h1>
<p>tf.reduce_all(x) ==&gt; False
tf.reduce_all(x, 0) ==&gt; [False, False]
tf.reduce_all(x, 1) ==&gt; [True, False]
```</p>
<p>Args:
  input_tensor: The boolean tensor to reduce.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_all_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_all_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_any">
    <p>def <span class="ident">reduce_any</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_any, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_any</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_any</strong></p>
<div class="codehilite"><pre><span></span>def reduce_any(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.reduce_any</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.reduce_any</code></strong></p>
<div class="codehilite"><pre><span></span>def reduce_any(input_tensor, reduction_indices=None, keep_dims=False, name=None)
</pre></div>


<p>Computes the "logical or" of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' is [[True,  True]</h1>
<h1>[False, False]]</h1>
<p>tf.reduce_any(x) ==&gt; True
tf.reduce_any(x, 0) ==&gt; [True, True]
tf.reduce_any(x, 1) ==&gt; [True, False]
```</p>
<p>Args:
  input_tensor: The boolean tensor to reduce.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_any', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_any" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_any_layer">
    <p>def <span class="ident">reduce_any_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_any_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_any_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_any_layer</strong></p>
<div class="codehilite"><pre><span></span>def reduce_any_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.reduce_any, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.reduce_any</strong></p>
<div class="codehilite"><pre><span></span>def reduce_any(input_tensor, reduction_indices=None, keep_dims=False, name=None):
</pre></div>


<p>Computes the "logical or" of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' is [[True,  True]</h1>
<h1>[False, False]]</h1>
<p>tf.reduce_any(x) ==&gt; True
tf.reduce_any(x, 0) ==&gt; [True, True]
tf.reduce_any(x, 1) ==&gt; [True, False]
```</p>
<p>Args:
  input_tensor: The boolean tensor to reduce.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_any_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_any_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_join">
    <p>def <span class="ident">reduce_join</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_join, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_join</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_join</strong></p>
<div class="codehilite"><pre><span></span>def reduce_join(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.reduce_join</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.reduce_join</code></strong></p>
<div class="codehilite"><pre><span></span>def reduce_join(inputs, reduction_indices, keep_dims=None, separator=None, name=None)
</pre></div>


<p>Joins a string Tensor across the given dimensions.</p>
<p>Computes the string join across dimensions in the given string Tensor of shape
<code>[d_0, d_1, ..., d_n-1]</code>.  Returns a new Tensor created by joining the input
strings with the given separator (default: empty string).  Negative indices are
counted backwards from the end, with <code>-1</code> being equivalent to <code>n - 1</code>.  Passing
an empty <code>reduction_indices</code> joins all strings in linear index order and outputs
a scalar string.</p>
<p>For example:
```</p>
<h1>tensor <code>a</code> is [["a", "b"], ["c", "d"]]</h1>
<p>tf.reduce_join(a, 0) ==&gt; ["ac", "bd"]
tf.reduce_join(a, 1) ==&gt; ["ab", "cd"]
tf.reduce_join(a, -2) = tf.reduce_join(a, 0) ==&gt; ["ac", "bd"]
tf.reduce_join(a, -1) = tf.reduce_join(a, 1) ==&gt; ["ab", "cd"]
tf.reduce_join(a, 0, keep_dims=True) ==&gt; [["ac", "bd"]]
tf.reduce_join(a, 1, keep_dims=True) ==&gt; [["ab"], ["cd"]]
tf.reduce_join(a, 0, separator=".") ==&gt; ["a.c", "b.d"]
tf.reduce_join(a, [0, 1]) ==&gt; ["acbd"]
tf.reduce_join(a, [1, 0]) ==&gt; ["abcd"]
tf.reduce_join(a, []) ==&gt; ["abcd"]
```</p>
<p>Args:
  inputs: A <code>Tensor</code> of type <code>string</code>.
    The input to be joined.  All reduced indices must have non-zero size.
  reduction_indices: A <code>Tensor</code> of type <code>int32</code>.
    The dimensions to reduce over.  Dimensions are reduced in the
    order specified.  If <code>reduction_indices</code> has higher rank than <code>1</code>, it is
    flattened.  Omitting <code>reduction_indices</code> is equivalent to passing
    <code>[n-1, n-2, ..., 0]</code>.  Negative indices from <code>-n</code> to <code>-1</code> are supported.
  keep_dims: An optional <code>bool</code>. Defaults to <code>False</code>.
    If <code>True</code>, retain reduced dimensions with length <code>1</code>.
  separator: An optional <code>string</code>. Defaults to <code>""</code>.
    The separator to use when joining.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>string</code>.
  Has shape equal to that of the input with reduced dimensions removed or
  set to <code>1</code> depending on <code>keep_dims</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_join', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_join" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_join_layer">
    <p>def <span class="ident">reduce_join_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_join_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_join_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_join_layer</strong></p>
<div class="codehilite"><pre><span></span>def reduce_join_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.reduce_join, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.reduce_join</strong></p>
<div class="codehilite"><pre><span></span>def reduce_join(inputs, reduction_indices, keep_dims=None, separator=None, name=None):
</pre></div>


<p>Joins a string Tensor across the given dimensions.</p>
<p>Computes the string join across dimensions in the given string Tensor of shape
<code>[d_0, d_1, ..., d_n-1]</code>.  Returns a new Tensor created by joining the input
strings with the given separator (default: empty string).  Negative indices are
counted backwards from the end, with <code>-1</code> being equivalent to <code>n - 1</code>.  Passing
an empty <code>reduction_indices</code> joins all strings in linear index order and outputs
a scalar string.</p>
<p>For example:
```</p>
<h1>tensor <code>a</code> is [["a", "b"], ["c", "d"]]</h1>
<p>tf.reduce_join(a, 0) ==&gt; ["ac", "bd"]
tf.reduce_join(a, 1) ==&gt; ["ab", "cd"]
tf.reduce_join(a, -2) = tf.reduce_join(a, 0) ==&gt; ["ac", "bd"]
tf.reduce_join(a, -1) = tf.reduce_join(a, 1) ==&gt; ["ab", "cd"]
tf.reduce_join(a, 0, keep_dims=True) ==&gt; [["ac", "bd"]]
tf.reduce_join(a, 1, keep_dims=True) ==&gt; [["ab"], ["cd"]]
tf.reduce_join(a, 0, separator=".") ==&gt; ["a.c", "b.d"]
tf.reduce_join(a, [0, 1]) ==&gt; ["acbd"]
tf.reduce_join(a, [1, 0]) ==&gt; ["abcd"]
tf.reduce_join(a, []) ==&gt; ["abcd"]
```</p>
<p>Args:
  inputs: A <code>Tensor</code> of type <code>string</code>.
    The input to be joined.  All reduced indices must have non-zero size.
  reduction_indices: A <code>Tensor</code> of type <code>int32</code>.
    The dimensions to reduce over.  Dimensions are reduced in the
    order specified.  If <code>reduction_indices</code> has higher rank than <code>1</code>, it is
    flattened.  Omitting <code>reduction_indices</code> is equivalent to passing
    <code>[n-1, n-2, ..., 0]</code>.  Negative indices from <code>-n</code> to <code>-1</code> are supported.
  keep_dims: An optional <code>bool</code>. Defaults to <code>False</code>.
    If <code>True</code>, retain reduced dimensions with length <code>1</code>.
  separator: An optional <code>string</code>. Defaults to <code>""</code>.
    The separator to use when joining.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>string</code>.
  Has shape equal to that of the input with reduced dimensions removed or
  set to <code>1</code> depending on <code>keep_dims</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_join_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_join_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_max">
    <p>def <span class="ident">reduce_max</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_max, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_max</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_max</strong></p>
<div class="codehilite"><pre><span></span>def reduce_max(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.reduce_max</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.reduce_max</code></strong></p>
<div class="codehilite"><pre><span></span>def reduce_max(input_tensor, reduction_indices=None, keep_dims=False, name=None)
</pre></div>


<p>Computes the maximum of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>Args:
  input_tensor: The tensor to reduce. Should have numeric type.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_max', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_max" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_max_layer">
    <p>def <span class="ident">reduce_max_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_max_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_max_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_max_layer</strong></p>
<div class="codehilite"><pre><span></span>def reduce_max_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.reduce_max, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.reduce_max</strong></p>
<div class="codehilite"><pre><span></span>def reduce_max(input_tensor, reduction_indices=None, keep_dims=False, name=None):
</pre></div>


<p>Computes the maximum of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>Args:
  input_tensor: The tensor to reduce. Should have numeric type.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_max_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_max_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_mean">
    <p>def <span class="ident">reduce_mean</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_mean, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_mean</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_mean</strong></p>
<div class="codehilite"><pre><span></span>def reduce_mean(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.reduce_mean</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.reduce_mean</code></strong></p>
<div class="codehilite"><pre><span></span>def reduce_mean(input_tensor, reduction_indices=None, keep_dims=False, name=None)
</pre></div>


<p>Computes the mean of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' is [[1., 1.]</h1>
<h1>[2., 2.]]</h1>
<p>tf.reduce_mean(x) ==&gt; 1.5
tf.reduce_mean(x, 0) ==&gt; [1.5, 1.5]
tf.reduce_mean(x, 1) ==&gt; [1.,  2.]
```</p>
<p>Args:
  input_tensor: The tensor to reduce. Should have numeric type.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_mean', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_mean" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_mean_layer">
    <p>def <span class="ident">reduce_mean_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_mean_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_mean_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_mean_layer</strong></p>
<div class="codehilite"><pre><span></span>def reduce_mean_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.reduce_mean, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.reduce_mean</strong></p>
<div class="codehilite"><pre><span></span>def reduce_mean(input_tensor, reduction_indices=None, keep_dims=False, name=None):
</pre></div>


<p>Computes the mean of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' is [[1., 1.]</h1>
<h1>[2., 2.]]</h1>
<p>tf.reduce_mean(x) ==&gt; 1.5
tf.reduce_mean(x, 0) ==&gt; [1.5, 1.5]
tf.reduce_mean(x, 1) ==&gt; [1.,  2.]
```</p>
<p>Args:
  input_tensor: The tensor to reduce. Should have numeric type.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_mean_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_mean_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_min">
    <p>def <span class="ident">reduce_min</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_min, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_min</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_min</strong></p>
<div class="codehilite"><pre><span></span>def reduce_min(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.reduce_min</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.reduce_min</code></strong></p>
<div class="codehilite"><pre><span></span>def reduce_min(input_tensor, reduction_indices=None, keep_dims=False, name=None)
</pre></div>


<p>Computes the minimum of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>Args:
  input_tensor: The tensor to reduce. Should have numeric type.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_min', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_min" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_min_layer">
    <p>def <span class="ident">reduce_min_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_min_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_min_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_min_layer</strong></p>
<div class="codehilite"><pre><span></span>def reduce_min_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.reduce_min, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.reduce_min</strong></p>
<div class="codehilite"><pre><span></span>def reduce_min(input_tensor, reduction_indices=None, keep_dims=False, name=None):
</pre></div>


<p>Computes the minimum of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>Args:
  input_tensor: The tensor to reduce. Should have numeric type.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_min_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_min_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_prod">
    <p>def <span class="ident">reduce_prod</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_prod, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_prod</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_prod</strong></p>
<div class="codehilite"><pre><span></span>def reduce_prod(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.reduce_prod</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.reduce_prod</code></strong></p>
<div class="codehilite"><pre><span></span>def reduce_prod(input_tensor, reduction_indices=None, keep_dims=False, name=None)
</pre></div>


<p>Computes the product of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>Args:
  input_tensor: The tensor to reduce. Should have numeric type.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_prod', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_prod" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_prod_layer">
    <p>def <span class="ident">reduce_prod_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_prod_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_prod_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_prod_layer</strong></p>
<div class="codehilite"><pre><span></span>def reduce_prod_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.reduce_prod, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.reduce_prod</strong></p>
<div class="codehilite"><pre><span></span>def reduce_prod(input_tensor, reduction_indices=None, keep_dims=False, name=None):
</pre></div>


<p>Computes the product of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>Args:
  input_tensor: The tensor to reduce. Should have numeric type.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_prod_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_prod_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_sum">
    <p>def <span class="ident">reduce_sum</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_sum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_sum</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_sum</strong></p>
<div class="codehilite"><pre><span></span>def reduce_sum(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.reduce_sum</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.reduce_sum</code></strong></p>
<div class="codehilite"><pre><span></span>def reduce_sum(input_tensor, reduction_indices=None, keep_dims=False, name=None)
</pre></div>


<p>Computes the sum of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' is [[1, 1, 1]</h1>
<h1>[1, 1, 1]]</h1>
<p>tf.reduce_sum(x) ==&gt; 6
tf.reduce_sum(x, 0) ==&gt; [2, 2, 2]
tf.reduce_sum(x, 1) ==&gt; [3, 3]
tf.reduce_sum(x, 1, keep_dims=True) ==&gt; [[3], [3]]
tf.reduce_sum(x, [0, 1]) ==&gt; 6
```</p>
<p>Args:
  input_tensor: The tensor to reduce. Should have numeric type.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_sum', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_sum" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reduce_sum_layer">
    <p>def <span class="ident">reduce_sum_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reduce_sum_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reduce_sum_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reduce_sum_layer</strong></p>
<div class="codehilite"><pre><span></span>def reduce_sum_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.reduce_sum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.reduce_sum</strong></p>
<div class="codehilite"><pre><span></span>def reduce_sum(input_tensor, reduction_indices=None, keep_dims=False, name=None):
</pre></div>


<p>Computes the sum of elements across dimensions of a tensor.</p>
<p>Reduces <code>input_tensor</code> along the dimensions given in <code>reduction_indices</code>.
Unless <code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each
entry in <code>reduction_indices</code>. If <code>keep_dims</code> is true, the reduced dimensions
are retained with length 1.</p>
<p>If <code>reduction_indices</code> has no entries, all dimensions are reduced, and a
tensor with a single element is returned.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' is [[1, 1, 1]</h1>
<h1>[1, 1, 1]]</h1>
<p>tf.reduce_sum(x) ==&gt; 6
tf.reduce_sum(x, 0) ==&gt; [2, 2, 2]
tf.reduce_sum(x, 1) ==&gt; [3, 3]
tf.reduce_sum(x, 1, keep_dims=True) ==&gt; [[3], [3]]
tf.reduce_sum(x, [0, 1]) ==&gt; 6
```</p>
<p>Args:
  input_tensor: The tensor to reduce. Should have numeric type.
  reduction_indices: The dimensions to reduce. If <code>None</code> (the default),
    reduces all dimensions.
  keep_dims: If true, retains reduced dimensions with length 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  The reduced tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reduce_sum_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reduce_sum_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.register_map_method">
    <p>def <span class="ident">register_map_method</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.register_map_method, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.register_map_method</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.register_map_method</strong></p>
<div class="codehilite"><pre><span></span>def register_map_method(cls, fn, library_path, alias=None, doc=None):
</pre></div>


<p>This method enables you to register any function <code>fn</code> that takes a Tensor as its first argument and returns a Tensor as a method of the Builder class. The resulting method is created by <em>lifting</em> the function to work with a Builder.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>fn</code>: a function of type <code>Tensor -&gt; Tensor</code>.</li>
<li><code>library_path</code>: the route of the librar from which this function was taken, used for documentation purposes.</li>
<li><code>alias</code>: allows you to specify the name of the method, it will take the name of the function if its <code>None</code>.</li>
<li><code>doc</code>: the documentation for the method, if <code>None</code> a predefied documentation will be generated based on the documentation of <code>fn</code>.</li>
</ul>
<p><strong>Return</strong></p>
<p><code>None</code></p>
<p><strong>Examples</strong></p>
<p>In this example we will register <code>tf.reshape</code> as a method of the Builder class</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">tb</span><span class="o">.</span><span class="n">Builder</span><span class="o">.</span><span class="n">register_map_method</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">,</span> <span class="s2">&quot;tf&quot;</span><span class="p">)</span>
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.register_map_method', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.register_map_method" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.register_method">
    <p>def <span class="ident">register_method</span>(</p><p>cls, fn, library_path, alias=None, doc=None)</p>
    </div>
    

    
  
    <div class="desc"><p>This method enables you to register any function <code>fn</code> that takes an Applicative as its first argument as a method of the Builder class.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>fn</code>: a function that atleast takes an Applicative as its first argument.</li>
<li><code>library_path</code>: the route of the librar from which this function was taken, used for documentation purposes.</li>
<li><code>alias</code>: allows you to specify the name of the method, it will take the name of the function if its <code>None</code>.</li>
<li><code>doc</code>: the documentation for the method, if <code>None</code> a predefied documentation will be generated based on the documentation of <code>fn</code>.</li>
</ul>
<p><strong>Return</strong></p>
<p><code>None</code></p>
<p><strong>Examples</strong></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.register_method', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.register_method" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">register_method</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method enables you to register any function `fn` that takes an Applicative as its first argument as a method of the Builder class.</span>
<span class="sd">    **Arguments**</span>
<span class="sd">    * `fn`: a function that atleast takes an Applicative as its first argument.</span>
<span class="sd">    * `library_path`: the route of the librar from which this function was taken, used for documentation purposes.</span>
<span class="sd">    * `alias`: allows you to specify the name of the method, it will take the name of the function if its `None`.</span>
<span class="sd">    * `doc`: the documentation for the method, if `None` a predefied documentation will be generated based on the documentation of `fn`.</span>
<span class="sd">    **Return**</span>
<span class="sd">    `None`</span>
<span class="sd">    **Examples**</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">fn_signature</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">get_method_sig</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
 	<span class="n">fn_docs</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getdoc</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="n">original_name</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">__name__</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">alias</span> <span class="k">if</span> <span class="n">alias</span> <span class="k">else</span> <span class="n">original_name</span>
    <span class="n">fn</span><span class="o">.</span><span class="n">__name__</span> <span class="o">=</span> <span class="n">name</span>
    <span class="n">fn</span><span class="o">.</span><span class="n">__doc__</span> <span class="o">=</span> <span class="n">doc</span> <span class="k">if</span> <span class="n">doc</span> <span class="k">else</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    THIS METHOD IS AUTOMATICALLY GENERATED</span>
<span class="s2">    This method accepts the same arguments as `{3}.{0}`</span>
<span class="s2">    ** Documentation from `{3}.{0}`**</span>
<span class="s2">        def {1}</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">fn_signature</span><span class="p">,</span> <span class="n">fn</span><span class="o">.</span><span class="n">__doc__</span><span class="p">,</span> <span class="n">library_path</span><span class="p">)</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.register_reduce_method">
    <p>def <span class="ident">register_reduce_method</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(BuilderTree.register_reduce_method, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>BuilderTree.register_reduce_method</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for BuilderTree.register_reduce_method</strong></p>
<div class="codehilite"><pre><span></span>def register_reduce_method(cls, fn, library_path, alias=None, doc=None):
</pre></div>


<p>This method enables you to register a function <code>fn</code> of type <code>(Tensor, Tensor) -&gt; Tensor</code> as a method of the Builder class.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>fn</code>: a function of type <code>(Tensor, Tensor) -&gt; Tensor</code></li>
<li><code>library_path</code>: the route of the librar from which this function was taken, used for documentation purposes.</li>
<li><code>alias</code>: allows you to specify the name of the method, it will take the name of the function if its <code>None</code>.</li>
<li><code>doc</code>: the documentation for the method, if <code>None</code> a predefied documentation will be generated based on the documentation of <code>fn</code>.</li>
</ul>
<p><strong>Return</strong></p>
<p><code>None</code></p>
<p><strong>Examples</strong></p>
<p>In this example we will create the method <code>reduce_add</code> for the BuilderTree class</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">tb</span><span class="o">.</span><span class="n">BuilderTree</span><span class="o">.</span><span class="n">register_reduce_method</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="s2">&quot;tf&quot;</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="s2">&quot;reduce_add&quot;</span><span class="p">)</span>
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.register_reduce_method', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.register_reduce_method" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.register_tensor_conversion_function">
    <p>def <span class="ident">register_tensor_conversion_function</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.register_tensor_conversion_function, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.register_tensor_conversion_function</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.register_tensor_conversion_function</strong></p>
<div class="codehilite"><pre><span></span>def register_tensor_conversion_function(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.register_tensor_conversion_function</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.register_tensor_conversion_function</code></strong></p>
<div class="codehilite"><pre><span></span>def register_tensor_conversion_function(base_type, conversion_func, priority=100)
</pre></div>


<p>Registers a function for converting objects of <code>base_type</code> to <code>Tensor</code>.</p>
<p>The conversion function must have the following signature:</p>
<div class="codehilite"><pre><span></span>def conversion_func(value, dtype=None, name=None, as_ref=False):
  # ...
</pre></div>


<p>It must return a <code>Tensor</code> with the given <code>dtype</code> if specified. If the
conversion function creates a new <code>Tensor</code>, it should use the given
<code>name</code> if specified. All exceptions will be propagated to the caller.</p>
<p>The conversion function may return <code>NotImplemented</code> for some
inputs. In this case, the conversion process will continue to try
subsequent conversion functions.</p>
<p>If <code>as_ref</code> is true, the function must return a <code>Tensor</code> reference,
such as a <code>Variable</code>.</p>
<p>NOTE: The conversion functions will execute in order of priority,
followed by order of registration. To ensure that a conversion function
<code>F</code> runs before another conversion function <code>G</code>, ensure that <code>F</code> is
registered with a smaller priority than <code>G</code>.</p>
<p>Args:
  base_type: The base type or tuple of base types for all objects that
    <code>conversion_func</code> accepts.
  conversion_func: A function that converts instances of <code>base_type</code> to
    <code>Tensor</code>.
  priority: Optional integer that indicates the priority for applying this
    conversion function. Conversion functions with smaller priority values
    run earlier than conversion functions with larger priority values.
    Defaults to 100.</p>
<p>Raises:
  TypeError: If the arguments do not have the appropriate type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.register_tensor_conversion_function', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.register_tensor_conversion_function" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.register_tensor_conversion_function_layer">
    <p>def <span class="ident">register_tensor_conversion_function_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.register_tensor_conversion_function_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.register_tensor_conversion_function_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.register_tensor_conversion_function_layer</strong></p>
<div class="codehilite"><pre><span></span>def register_tensor_conversion_function_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.register_tensor_conversion_function, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.register_tensor_conversion_function</strong></p>
<div class="codehilite"><pre><span></span>def register_tensor_conversion_function(base_type, conversion_func, priority=100):
</pre></div>


<p>Registers a function for converting objects of <code>base_type</code> to <code>Tensor</code>.</p>
<p>The conversion function must have the following signature:</p>
<div class="codehilite"><pre><span></span>def conversion_func(value, dtype=None, name=None, as_ref=False):
  # ...
</pre></div>


<p>It must return a <code>Tensor</code> with the given <code>dtype</code> if specified. If the
conversion function creates a new <code>Tensor</code>, it should use the given
<code>name</code> if specified. All exceptions will be propagated to the caller.</p>
<p>The conversion function may return <code>NotImplemented</code> for some
inputs. In this case, the conversion process will continue to try
subsequent conversion functions.</p>
<p>If <code>as_ref</code> is true, the function must return a <code>Tensor</code> reference,
such as a <code>Variable</code>.</p>
<p>NOTE: The conversion functions will execute in order of priority,
followed by order of registration. To ensure that a conversion function
<code>F</code> runs before another conversion function <code>G</code>, ensure that <code>F</code> is
registered with a smaller priority than <code>G</code>.</p>
<p>Args:
  base_type: The base type or tuple of base types for all objects that
    <code>conversion_func</code> accepts.
  conversion_func: A function that converts instances of <code>base_type</code> to
    <code>Tensor</code>.
  priority: Optional integer that indicates the priority for applying this
    conversion function. Conversion functions with smaller priority values
    run earlier than conversion functions with larger priority values.
    Defaults to 100.</p>
<p>Raises:
  TypeError: If the arguments do not have the appropriate type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.register_tensor_conversion_function_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.register_tensor_conversion_function_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.relu">
    <p>def <span class="ident">relu</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.relu, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.relu</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.relu</strong></p>
<div class="codehilite"><pre><span></span>def relu(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.relu</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.relu</code></strong></p>
<div class="codehilite"><pre><span></span>def relu(features, name=None)
</pre></div>


<p>Computes rectified linear: <code>max(features, 0)</code>.</p>
<p>Args:
  features: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>features</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.relu', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.relu" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.relu6">
    <p>def <span class="ident">relu6</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.relu6, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.relu6</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.relu6</strong></p>
<div class="codehilite"><pre><span></span>def relu6(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.relu6</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.relu6</code></strong></p>
<div class="codehilite"><pre><span></span>def relu6(features, name=None)
</pre></div>


<p>Computes Rectified Linear 6: <code>min(max(features, 0), 6)</code>.</p>
<p>Args:
  features: A <code>Tensor</code> with type <code>float</code>, <code>double</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>,
    <code>int16</code>, or <code>int8</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with the same type as <code>features</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.relu6', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.relu6" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.relu6_layer">
    <p>def <span class="ident">relu6_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.relu6_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.relu6_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.relu6_layer</strong></p>
<div class="codehilite"><pre><span></span>def relu6_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.relu6, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.relu6</strong></p>
<div class="codehilite"><pre><span></span>def relu6(features, name=None):
</pre></div>


<p>Computes Rectified Linear 6: <code>min(max(features, 0), 6)</code>.</p>
<p>Args:
  features: A <code>Tensor</code> with type <code>float</code>, <code>double</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>,
    <code>int16</code>, or <code>int8</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with the same type as <code>features</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.relu6_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.relu6_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.relu_layer">
    <p>def <span class="ident">relu_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.relu_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.relu_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.relu_layer</strong></p>
<div class="codehilite"><pre><span></span>def relu_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.relu, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.relu</strong></p>
<div class="codehilite"><pre><span></span>def relu(features, name=None):
</pre></div>


<p>Computes rectified linear: <code>max(features, 0)</code>.</p>
<p>Args:
  features: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>features</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.relu_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.relu_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.report_uninitialized_variables">
    <p>def <span class="ident">report_uninitialized_variables</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.report_uninitialized_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.report_uninitialized_variables</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.report_uninitialized_variables</strong></p>
<div class="codehilite"><pre><span></span>def report_uninitialized_variables(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.report_uninitialized_variables</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.report_uninitialized_variables</code></strong></p>
<div class="codehilite"><pre><span></span>def report_uninitialized_variables(var_list=None, name=&quot;report_uninitialized_variables&quot;)
</pre></div>


<p>Adds ops to list the names of uninitialized variables.</p>
<p>When run, it returns a 1-D tensor containing the names of uninitialized
variables if there are any, or an empty array if there are none.</p>
<p>Args:
  var_list: List of <code>Variable</code> objects to check. Defaults to the
    value of <code>all_variables() + local_variables()</code>
  name: Optional name of the <code>Operation</code>.</p>
<p>Returns:
  A 1-D tensor containing names of the unintialized variables, or an empty 1-D
  tensor if there are no variables or no uninitialized variables.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.report_uninitialized_variables', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.report_uninitialized_variables" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.report_uninitialized_variables_layer">
    <p>def <span class="ident">report_uninitialized_variables_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.report_uninitialized_variables_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.report_uninitialized_variables_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.report_uninitialized_variables_layer</strong></p>
<div class="codehilite"><pre><span></span>def report_uninitialized_variables_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.report_uninitialized_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.report_uninitialized_variables</strong></p>
<div class="codehilite"><pre><span></span>def report_uninitialized_variables(var_list=None, name=&quot;report_uninitialized_variables&quot;):
</pre></div>


<p>Adds ops to list the names of uninitialized variables.</p>
<p>When run, it returns a 1-D tensor containing the names of uninitialized
variables if there are any, or an empty array if there are none.</p>
<p>Args:
  var_list: List of <code>Variable</code> objects to check. Defaults to the
    value of <code>all_variables() + local_variables()</code>
  name: Optional name of the <code>Operation</code>.</p>
<p>Returns:
  A 1-D tensor containing names of the unintialized variables, or an empty 1-D
  tensor if there are no variables or no uninitialized variables.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.report_uninitialized_variables_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.report_uninitialized_variables_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reset_default_graph">
    <p>def <span class="ident">reset_default_graph</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reset_default_graph, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reset_default_graph</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reset_default_graph</strong></p>
<div class="codehilite"><pre><span></span>def reset_default_graph(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.reset_default_graph</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.reset_default_graph</code></strong></p>
<div class="codehilite"><pre><span></span>def reset_default_graph()
</pre></div>


<p>Clears the default graph stack and resets the global default graph.</p>
<p>NOTE: The default graph is a property of the current thread. This
function applies only to the current thread.  Calling this function while
a <code>tf.Session</code> or <code>tf.InteractiveSession</code> is active will result in undefined
behavior. Using any previously created <code>tf.Operation</code> or <code>tf.Tensor</code> objects
after calling this function will result in undefined behavior.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reset_default_graph', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reset_default_graph" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reset_default_graph_layer">
    <p>def <span class="ident">reset_default_graph_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reset_default_graph_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reset_default_graph_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reset_default_graph_layer</strong></p>
<div class="codehilite"><pre><span></span>def reset_default_graph_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.reset_default_graph, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.reset_default_graph</strong></p>
<div class="codehilite"><pre><span></span>def reset_default_graph():
</pre></div>


<p>Clears the default graph stack and resets the global default graph.</p>
<p>NOTE: The default graph is a property of the current thread. This
function applies only to the current thread.  Calling this function while
a <code>tf.Session</code> or <code>tf.InteractiveSession</code> is active will result in undefined
behavior. Using any previously created <code>tf.Operation</code> or <code>tf.Tensor</code> objects
after calling this function will result in undefined behavior.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reset_default_graph_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reset_default_graph_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reshape">
    <p>def <span class="ident">reshape</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reshape, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reshape</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reshape</strong></p>
<div class="codehilite"><pre><span></span>def reshape(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.reshape</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.reshape</code></strong></p>
<div class="codehilite"><pre><span></span>def reshape(tensor, shape, name=None)
</pre></div>


<p>Reshapes a tensor.</p>
<p>Given <code>tensor</code>, this operation returns a tensor that has the same values
as <code>tensor</code> with shape <code>shape</code>.</p>
<p>If one component of <code>shape</code> is the special value -1, the size of that dimension
is computed so that the total size remains constant.  In particular, a <code>shape</code>
of <code>[-1]</code> flattens into 1-D.  At most one component of <code>shape</code> can be -1.</p>
<p>If <code>shape</code> is 1-D or higher, then the operation returns a tensor with shape
<code>shape</code> filled with the values of <code>tensor</code>. In this case, the number of elements
implied by <code>shape</code> must be the same as the number of elements in <code>tensor</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>tensor 't' is [1, 2, 3, 4, 5, 6, 7, 8, 9]</h1>
<h1>tensor 't' has shape [9]</h1>
<p>reshape(t, [3, 3]) ==&gt; [[1, 2, 3],
                        [4, 5, 6],
                        [7, 8, 9]]</p>
<h1>tensor 't' is [[[1, 1], [2, 2]],</h1>
<h1>[[3, 3], [4, 4]]]</h1>
<h1>tensor 't' has shape [2, 2, 2]</h1>
<p>reshape(t, [2, 4]) ==&gt; [[1, 1, 2, 2],
                        [3, 3, 4, 4]]</p>
<h1>tensor 't' is [[[1, 1, 1],</h1>
<h1>[2, 2, 2]],</h1>
<h1>[[3, 3, 3],</h1>
<h1>[4, 4, 4]],</h1>
<h1>[[5, 5, 5],</h1>
<h1>[6, 6, 6]]]</h1>
<h1>tensor 't' has shape [3, 2, 3]</h1>
<h1>pass '[-1]' to flatten 't'</h1>
<p>reshape(t, [-1]) ==&gt; [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]</p>
<h1>-1 can also be used to infer the shape</h1>
<h1>-1 is inferred to be 9:</h1>
<p>reshape(t, [2, -1]) ==&gt; [[1, 1, 1, 2, 2, 2, 3, 3, 3],
                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]</p>
<h1>-1 is inferred to be 2:</h1>
<p>reshape(t, [-1, 9]) ==&gt; [[1, 1, 1, 2, 2, 2, 3, 3, 3],
                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]</p>
<h1>-1 is inferred to be 3:</h1>
<p>reshape(t, [ 2, -1, 3]) ==&gt; [[[1, 1, 1],
                              [2, 2, 2],
                              [3, 3, 3]],
                             [[4, 4, 4],
                              [5, 5, 5],
                              [6, 6, 6]]]</p>
<h1>tensor 't' is [7]</h1>
<h1>shape <code>[]</code> reshapes to a scalar</h1>
<p>reshape(t, []) ==&gt; 7
```</p>
<p>Args:
  tensor: A <code>Tensor</code>.
  shape: A <code>Tensor</code> of type <code>int32</code>. Defines the shape of the output tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reshape', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reshape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reshape_layer">
    <p>def <span class="ident">reshape_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reshape_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reshape_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reshape_layer</strong></p>
<div class="codehilite"><pre><span></span>def reshape_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.reshape, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.reshape</strong></p>
<div class="codehilite"><pre><span></span>def reshape(tensor, shape, name=None):
</pre></div>


<p>Reshapes a tensor.</p>
<p>Given <code>tensor</code>, this operation returns a tensor that has the same values
as <code>tensor</code> with shape <code>shape</code>.</p>
<p>If one component of <code>shape</code> is the special value -1, the size of that dimension
is computed so that the total size remains constant.  In particular, a <code>shape</code>
of <code>[-1]</code> flattens into 1-D.  At most one component of <code>shape</code> can be -1.</p>
<p>If <code>shape</code> is 1-D or higher, then the operation returns a tensor with shape
<code>shape</code> filled with the values of <code>tensor</code>. In this case, the number of elements
implied by <code>shape</code> must be the same as the number of elements in <code>tensor</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>tensor 't' is [1, 2, 3, 4, 5, 6, 7, 8, 9]</h1>
<h1>tensor 't' has shape [9]</h1>
<p>reshape(t, [3, 3]) ==&gt; [[1, 2, 3],
                        [4, 5, 6],
                        [7, 8, 9]]</p>
<h1>tensor 't' is [[[1, 1], [2, 2]],</h1>
<h1>[[3, 3], [4, 4]]]</h1>
<h1>tensor 't' has shape [2, 2, 2]</h1>
<p>reshape(t, [2, 4]) ==&gt; [[1, 1, 2, 2],
                        [3, 3, 4, 4]]</p>
<h1>tensor 't' is [[[1, 1, 1],</h1>
<h1>[2, 2, 2]],</h1>
<h1>[[3, 3, 3],</h1>
<h1>[4, 4, 4]],</h1>
<h1>[[5, 5, 5],</h1>
<h1>[6, 6, 6]]]</h1>
<h1>tensor 't' has shape [3, 2, 3]</h1>
<h1>pass '[-1]' to flatten 't'</h1>
<p>reshape(t, [-1]) ==&gt; [1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6]</p>
<h1>-1 can also be used to infer the shape</h1>
<h1>-1 is inferred to be 9:</h1>
<p>reshape(t, [2, -1]) ==&gt; [[1, 1, 1, 2, 2, 2, 3, 3, 3],
                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]</p>
<h1>-1 is inferred to be 2:</h1>
<p>reshape(t, [-1, 9]) ==&gt; [[1, 1, 1, 2, 2, 2, 3, 3, 3],
                         [4, 4, 4, 5, 5, 5, 6, 6, 6]]</p>
<h1>-1 is inferred to be 3:</h1>
<p>reshape(t, [ 2, -1, 3]) ==&gt; [[[1, 1, 1],
                              [2, 2, 2],
                              [3, 3, 3]],
                             [[4, 4, 4],
                              [5, 5, 5],
                              [6, 6, 6]]]</p>
<h1>tensor 't' is [7]</h1>
<h1>shape <code>[]</code> reshapes to a scalar</h1>
<p>reshape(t, []) ==&gt; 7
```</p>
<p>Args:
  tensor: A <code>Tensor</code>.
  shape: A <code>Tensor</code> of type <code>int32</code>. Defines the shape of the output tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reshape_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reshape_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reverse">
    <p>def <span class="ident">reverse</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reverse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reverse</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reverse</strong></p>
<div class="codehilite"><pre><span></span>def reverse(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.reverse</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.reverse</code></strong></p>
<div class="codehilite"><pre><span></span>def reverse(tensor, dims, name=None)
</pre></div>


<p>Reverses specific dimensions of a tensor.</p>
<p>Given a <code>tensor</code>, and a <code>bool</code> tensor <code>dims</code> representing the dimensions
of <code>tensor</code>, this operation reverses each dimension i of <code>tensor</code> where
<code>dims[i]</code> is <code>True</code>.</p>
<p><code>tensor</code> can have up to 8 dimensions. The number of dimensions
of <code>tensor</code> must equal the number of elements in <code>dims</code>. In other words:</p>
<p><code>rank(tensor) = size(dims)</code></p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>tensor 't' is [[[[ 0,  1,  2,  3],</h1>
<h1>[ 4,  5,  6,  7],</h1>
<h1>[ 8,  9, 10, 11]],</h1>
<h1>[[12, 13, 14, 15],</h1>
<h1>[16, 17, 18, 19],</h1>
<h1>[20, 21, 22, 23]]]]</h1>
<h1>tensor 't' shape is [1, 2, 3, 4]</h1>
<h1>'dims' is [False, False, False, True]</h1>
<p>reverse(t, dims) ==&gt; [[[[ 3,  2,  1,  0],
                        [ 7,  6,  5,  4],
                        [ 11, 10, 9, 8]],
                       [[15, 14, 13, 12],
                        [19, 18, 17, 16],
                        [23, 22, 21, 20]]]]</p>
<h1>'dims' is [False, True, False, False]</h1>
<p>reverse(t, dims) ==&gt; [[[[12, 13, 14, 15],
                        [16, 17, 18, 19],
                        [20, 21, 22, 23]
                       [[ 0,  1,  2,  3],
                        [ 4,  5,  6,  7],
                        [ 8,  9, 10, 11]]]]</p>
<h1>'dims' is [False, False, True, False]</h1>
<p>reverse(t, dims) ==&gt; [[[[8, 9, 10, 11],
                        [4, 5, 6, 7],
                        [0, 1, 2, 3]]
                       [[20, 21, 22, 23],
                        [16, 17, 18, 19],
                        [12, 13, 14, 15]]]]
```</p>
<p>Args:
  tensor: A <code>Tensor</code>. Must be one of the following types: <code>uint8</code>, <code>int8</code>, <code>int32</code>, <code>bool</code>, <code>half</code>, <code>float32</code>, <code>float64</code>.
    Up to 8-D.
  dims: A <code>Tensor</code> of type <code>bool</code>. 1-D. The dimensions to reverse.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>tensor</code>. The same shape as <code>tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reverse', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reverse" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reverse_layer">
    <p>def <span class="ident">reverse_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reverse_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reverse_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reverse_layer</strong></p>
<div class="codehilite"><pre><span></span>def reverse_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.reverse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.reverse</strong></p>
<div class="codehilite"><pre><span></span>def reverse(tensor, dims, name=None):
</pre></div>


<p>Reverses specific dimensions of a tensor.</p>
<p>Given a <code>tensor</code>, and a <code>bool</code> tensor <code>dims</code> representing the dimensions
of <code>tensor</code>, this operation reverses each dimension i of <code>tensor</code> where
<code>dims[i]</code> is <code>True</code>.</p>
<p><code>tensor</code> can have up to 8 dimensions. The number of dimensions
of <code>tensor</code> must equal the number of elements in <code>dims</code>. In other words:</p>
<p><code>rank(tensor) = size(dims)</code></p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>tensor 't' is [[[[ 0,  1,  2,  3],</h1>
<h1>[ 4,  5,  6,  7],</h1>
<h1>[ 8,  9, 10, 11]],</h1>
<h1>[[12, 13, 14, 15],</h1>
<h1>[16, 17, 18, 19],</h1>
<h1>[20, 21, 22, 23]]]]</h1>
<h1>tensor 't' shape is [1, 2, 3, 4]</h1>
<h1>'dims' is [False, False, False, True]</h1>
<p>reverse(t, dims) ==&gt; [[[[ 3,  2,  1,  0],
                        [ 7,  6,  5,  4],
                        [ 11, 10, 9, 8]],
                       [[15, 14, 13, 12],
                        [19, 18, 17, 16],
                        [23, 22, 21, 20]]]]</p>
<h1>'dims' is [False, True, False, False]</h1>
<p>reverse(t, dims) ==&gt; [[[[12, 13, 14, 15],
                        [16, 17, 18, 19],
                        [20, 21, 22, 23]
                       [[ 0,  1,  2,  3],
                        [ 4,  5,  6,  7],
                        [ 8,  9, 10, 11]]]]</p>
<h1>'dims' is [False, False, True, False]</h1>
<p>reverse(t, dims) ==&gt; [[[[8, 9, 10, 11],
                        [4, 5, 6, 7],
                        [0, 1, 2, 3]]
                       [[20, 21, 22, 23],
                        [16, 17, 18, 19],
                        [12, 13, 14, 15]]]]
```</p>
<p>Args:
  tensor: A <code>Tensor</code>. Must be one of the following types: <code>uint8</code>, <code>int8</code>, <code>int32</code>, <code>bool</code>, <code>half</code>, <code>float32</code>, <code>float64</code>.
    Up to 8-D.
  dims: A <code>Tensor</code> of type <code>bool</code>. 1-D. The dimensions to reverse.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>tensor</code>. The same shape as <code>tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reverse_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reverse_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reverse_sequence">
    <p>def <span class="ident">reverse_sequence</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reverse_sequence, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reverse_sequence</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reverse_sequence</strong></p>
<div class="codehilite"><pre><span></span>def reverse_sequence(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.reverse_sequence</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.reverse_sequence</code></strong></p>
<div class="codehilite"><pre><span></span>def reverse_sequence(input, seq_lengths, seq_dim, batch_dim=None, name=None)
</pre></div>


<p>Reverses variable length slices.</p>
<p>This op first slices <code>input</code> along the dimension <code>batch_dim</code>, and for each
slice <code>i</code>, reverses the first <code>seq_lengths[i]</code> elements along
the dimension <code>seq_dim</code>.</p>
<p>The elements of <code>seq_lengths</code> must obey <code>seq_lengths[i] &lt; input.dims[seq_dim]</code>,
and <code>seq_lengths</code> must be a vector of length <code>input.dims[batch_dim]</code>.</p>
<p>The output slice <code>i</code> along dimension <code>batch_dim</code> is then given by input
slice <code>i</code>, with the first <code>seq_lengths[i]</code> slices along dimension
<code>seq_dim</code> reversed.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>Given this:</h1>
<p>batch_dim = 0
seq_dim = 1
input.dims = (4, 8, ...)
seq_lengths = [7, 2, 3, 5]</p>
<h1>then slices of input are reversed on seq_dim, but only up to seq_lengths:</h1>
<p>output[0, 0:7, :, ...] = input[0, 7:0:-1, :, ...]
output[1, 0:2, :, ...] = input[1, 2:0:-1, :, ...]
output[2, 0:3, :, ...] = input[2, 3:0:-1, :, ...]
output[3, 0:5, :, ...] = input[3, 5:0:-1, :, ...]</p>
<h1>while entries past seq_lens are copied through:</h1>
<p>output[0, 7:, :, ...] = input[0, 7:, :, ...]
output[1, 2:, :, ...] = input[1, 2:, :, ...]
output[2, 3:, :, ...] = input[2, 3:, :, ...]
output[3, 2:, :, ...] = input[3, 2:, :, ...]
```</p>
<p>In contrast, if:</p>
<p>```prettyprint</p>
<h1>Given this:</h1>
<p>batch_dim = 2
seq_dim = 0
input.dims = (8, ?, 4, ...)
seq_lengths = [7, 2, 3, 5]</p>
<h1>then slices of input are reversed on seq_dim, but only up to seq_lengths:</h1>
<p>output[0:7, :, 0, :, ...] = input[7:0:-1, :, 0, :, ...]
output[0:2, :, 1, :, ...] = input[2:0:-1, :, 1, :, ...]
output[0:3, :, 2, :, ...] = input[3:0:-1, :, 2, :, ...]
output[0:5, :, 3, :, ...] = input[5:0:-1, :, 3, :, ...]</p>
<h1>while entries past seq_lens are copied through:</h1>
<p>output[7:, :, 0, :, ...] = input[7:, :, 0, :, ...]
output[2:, :, 1, :, ...] = input[2:, :, 1, :, ...]
output[3:, :, 2, :, ...] = input[3:, :, 2, :, ...]
output[2:, :, 3, :, ...] = input[2:, :, 3, :, ...]
```</p>
<p>Args:
  input: A <code>Tensor</code>. The input to reverse.
  seq_lengths: A <code>Tensor</code> of type <code>int64</code>.
    1-D with length <code>input.dims(batch_dim)</code> and
    <code>max(seq_lengths) &lt; input.dims(seq_dim)</code>
  seq_dim: An <code>int</code>. The dimension which is partially reversed.
  batch_dim: An optional <code>int</code>. Defaults to <code>0</code>.
    The dimension along which reversal is performed.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  The partially reversed input. It has the same shape as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reverse_sequence', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reverse_sequence" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.reverse_sequence_layer">
    <p>def <span class="ident">reverse_sequence_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.reverse_sequence_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.reverse_sequence_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.reverse_sequence_layer</strong></p>
<div class="codehilite"><pre><span></span>def reverse_sequence_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.reverse_sequence, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.reverse_sequence</strong></p>
<div class="codehilite"><pre><span></span>def reverse_sequence(input, seq_lengths, seq_dim, batch_dim=None, name=None):
</pre></div>


<p>Reverses variable length slices.</p>
<p>This op first slices <code>input</code> along the dimension <code>batch_dim</code>, and for each
slice <code>i</code>, reverses the first <code>seq_lengths[i]</code> elements along
the dimension <code>seq_dim</code>.</p>
<p>The elements of <code>seq_lengths</code> must obey <code>seq_lengths[i] &lt; input.dims[seq_dim]</code>,
and <code>seq_lengths</code> must be a vector of length <code>input.dims[batch_dim]</code>.</p>
<p>The output slice <code>i</code> along dimension <code>batch_dim</code> is then given by input
slice <code>i</code>, with the first <code>seq_lengths[i]</code> slices along dimension
<code>seq_dim</code> reversed.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>Given this:</h1>
<p>batch_dim = 0
seq_dim = 1
input.dims = (4, 8, ...)
seq_lengths = [7, 2, 3, 5]</p>
<h1>then slices of input are reversed on seq_dim, but only up to seq_lengths:</h1>
<p>output[0, 0:7, :, ...] = input[0, 7:0:-1, :, ...]
output[1, 0:2, :, ...] = input[1, 2:0:-1, :, ...]
output[2, 0:3, :, ...] = input[2, 3:0:-1, :, ...]
output[3, 0:5, :, ...] = input[3, 5:0:-1, :, ...]</p>
<h1>while entries past seq_lens are copied through:</h1>
<p>output[0, 7:, :, ...] = input[0, 7:, :, ...]
output[1, 2:, :, ...] = input[1, 2:, :, ...]
output[2, 3:, :, ...] = input[2, 3:, :, ...]
output[3, 2:, :, ...] = input[3, 2:, :, ...]
```</p>
<p>In contrast, if:</p>
<p>```prettyprint</p>
<h1>Given this:</h1>
<p>batch_dim = 2
seq_dim = 0
input.dims = (8, ?, 4, ...)
seq_lengths = [7, 2, 3, 5]</p>
<h1>then slices of input are reversed on seq_dim, but only up to seq_lengths:</h1>
<p>output[0:7, :, 0, :, ...] = input[7:0:-1, :, 0, :, ...]
output[0:2, :, 1, :, ...] = input[2:0:-1, :, 1, :, ...]
output[0:3, :, 2, :, ...] = input[3:0:-1, :, 2, :, ...]
output[0:5, :, 3, :, ...] = input[5:0:-1, :, 3, :, ...]</p>
<h1>while entries past seq_lens are copied through:</h1>
<p>output[7:, :, 0, :, ...] = input[7:, :, 0, :, ...]
output[2:, :, 1, :, ...] = input[2:, :, 1, :, ...]
output[3:, :, 2, :, ...] = input[3:, :, 2, :, ...]
output[2:, :, 3, :, ...] = input[2:, :, 3, :, ...]
```</p>
<p>Args:
  input: A <code>Tensor</code>. The input to reverse.
  seq_lengths: A <code>Tensor</code> of type <code>int64</code>.
    1-D with length <code>input.dims(batch_dim)</code> and
    <code>max(seq_lengths) &lt; input.dims(seq_dim)</code>
  seq_dim: An <code>int</code>. The dimension which is partially reversed.
  batch_dim: An optional <code>int</code>. Defaults to <code>0</code>.
    The dimension along which reversal is performed.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  The partially reversed input. It has the same shape as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.reverse_sequence_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.reverse_sequence_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.rnn">
    <p>def <span class="ident">rnn</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.rnn, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.rnn</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.rnn</strong></p>
<div class="codehilite"><pre><span></span>def rnn(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.rnn</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.rnn</code></strong></p>
<div class="codehilite"><pre><span></span>def rnn(cell, inputs, initial_state=None, dtype=None, sequence_length=None, scope=None)
</pre></div>


<p>Creates a recurrent neural network specified by RNNCell <code>cell</code>.</p>
<p>The simplest form of RNN network generated is:
  state = cell.zero_state(...)
  outputs = []
  for input_ in inputs:
    output, state = cell(input_, state)
    outputs.append(output)
  return (outputs, state)</p>
<p>However, a few other options are available:</p>
<p>An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output.</p>
<p>The dynamic calculation performed is, at time t for batch row b,
  (output, state)(b, t) =
    (t &gt;= sequence_length(b))
      ? (zeros(cell.output_size), states(b, sequence_length(b) - 1))
      : cell(input(b, t), state(b, t - 1))</p>
<p>Args:
  cell: An instance of RNNCell.
  inputs: A length T list of inputs, each a tensor of shape
    [batch_size, input_size].
  initial_state: (optional) An initial state for the RNN.
    If <code>cell.state_size</code> is an integer, this must be
    a tensor of appropriate type and shape <code>[batch_size x cell.state_size]</code>.
    If <code>cell.state_size</code> is a tuple, this should be a tuple of
    tensors having shapes <code>[batch_size, s] for s in cell.state_size</code>.
  dtype: (optional) The data type for the initial state.  Required if
    initial_state is not provided.
  sequence_length: Specifies the length of each sequence in inputs.
    An int32 or int64 vector (tensor) size <code>[batch_size]</code>, values in <code>[0, T)</code>.
  scope: VariableScope for the created subgraph; defaults to "RNN".</p>
<p>Returns:
  A pair (outputs, state) where:
    - outputs is a length T list of outputs (one for each input)
    - state is the final state</p>
<p>Raises:
  TypeError: If <code>cell</code> is not an instance of RNNCell.
  ValueError: If <code>inputs</code> is <code>None</code> or an empty list, or if the input depth
    (column size) cannot be inferred from inputs via shape inference.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.rnn', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.rnn" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.rnn_layer">
    <p>def <span class="ident">rnn_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.rnn_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.rnn_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.rnn_layer</strong></p>
<div class="codehilite"><pre><span></span>def rnn_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.rnn, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.rnn</strong></p>
<div class="codehilite"><pre><span></span>def rnn(cell, inputs, initial_state=None, dtype=None, sequence_length=None, scope=None):
</pre></div>


<p>Creates a recurrent neural network specified by RNNCell <code>cell</code>.</p>
<p>The simplest form of RNN network generated is:
  state = cell.zero_state(...)
  outputs = []
  for input_ in inputs:
    output, state = cell(input_, state)
    outputs.append(output)
  return (outputs, state)</p>
<p>However, a few other options are available:</p>
<p>An initial state can be provided.
If the sequence_length vector is provided, dynamic calculation is performed.
This method of calculation does not compute the RNN steps past the maximum
sequence length of the minibatch (thus saving computational time),
and properly propagates the state at an example's sequence length
to the final state output.</p>
<p>The dynamic calculation performed is, at time t for batch row b,
  (output, state)(b, t) =
    (t &gt;= sequence_length(b))
      ? (zeros(cell.output_size), states(b, sequence_length(b) - 1))
      : cell(input(b, t), state(b, t - 1))</p>
<p>Args:
  cell: An instance of RNNCell.
  inputs: A length T list of inputs, each a tensor of shape
    [batch_size, input_size].
  initial_state: (optional) An initial state for the RNN.
    If <code>cell.state_size</code> is an integer, this must be
    a tensor of appropriate type and shape <code>[batch_size x cell.state_size]</code>.
    If <code>cell.state_size</code> is a tuple, this should be a tuple of
    tensors having shapes <code>[batch_size, s] for s in cell.state_size</code>.
  dtype: (optional) The data type for the initial state.  Required if
    initial_state is not provided.
  sequence_length: Specifies the length of each sequence in inputs.
    An int32 or int64 vector (tensor) size <code>[batch_size]</code>, values in <code>[0, T)</code>.
  scope: VariableScope for the created subgraph; defaults to "RNN".</p>
<p>Returns:
  A pair (outputs, state) where:
    - outputs is a length T list of outputs (one for each input)
    - state is the final state</p>
<p>Raises:
  TypeError: If <code>cell</code> is not an instance of RNNCell.
  ValueError: If <code>inputs</code> is <code>None</code> or an empty list, or if the input depth
    (column size) cannot be inferred from inputs via shape inference.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.rnn_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.rnn_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.round">
    <p>def <span class="ident">round</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.round, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.round</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.round</strong></p>
<div class="codehilite"><pre><span></span>def round(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.round</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.round</code></strong></p>
<div class="codehilite"><pre><span></span>def round(x, name=None)
</pre></div>


<p>Rounds the values of a tensor to the nearest integer, element-wise.</p>
<p>For example:</p>
<p>```python</p>
<h1>'a' is [0.9, 2.5, 2.3, -4.4]</h1>
<p>tf.round(a) ==&gt; [ 1.0, 3.0, 2.0, -4.0 ]
```</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>float</code> or <code>double</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of same shape and type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.round', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.round" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.round_layer">
    <p>def <span class="ident">round_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.round_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.round_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.round_layer</strong></p>
<div class="codehilite"><pre><span></span>def round_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.round, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.round</strong></p>
<div class="codehilite"><pre><span></span>def round(x, name=None):
</pre></div>


<p>Rounds the values of a tensor to the nearest integer, element-wise.</p>
<p>For example:</p>
<p>```python</p>
<h1>'a' is [0.9, 2.5, 2.3, -4.4]</h1>
<p>tf.round(a) ==&gt; [ 1.0, 3.0, 2.0, -4.0 ]
```</p>
<p>Args:
  x: A <code>Tensor</code> of type <code>float</code> or <code>double</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of same shape and type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.round_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.round_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.rsqrt">
    <p>def <span class="ident">rsqrt</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.rsqrt, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.rsqrt</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.rsqrt</strong></p>
<div class="codehilite"><pre><span></span>def rsqrt(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.rsqrt</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.rsqrt</code></strong></p>
<div class="codehilite"><pre><span></span>def rsqrt(x, name=None)
</pre></div>


<p>Computes reciprocal of square root of x element-wise.</p>
<p>I.e., \(y = 1 / \sqrt{x}\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.rsqrt', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.rsqrt" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.rsqrt_layer">
    <p>def <span class="ident">rsqrt_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.rsqrt_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.rsqrt_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.rsqrt_layer</strong></p>
<div class="codehilite"><pre><span></span>def rsqrt_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.rsqrt, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.rsqrt</strong></p>
<div class="codehilite"><pre><span></span>def rsqrt(x, name=None):
</pre></div>


<p>Computes reciprocal of square root of x element-wise.</p>
<p>I.e., \(y = 1 / \sqrt{x}\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.rsqrt_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.rsqrt_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sampled_softmax_loss">
    <p>def <span class="ident">sampled_softmax_loss</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sampled_softmax_loss, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sampled_softmax_loss</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sampled_softmax_loss</strong></p>
<div class="codehilite"><pre><span></span>def sampled_softmax_loss(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.sampled_softmax_loss</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.sampled_softmax_loss</code></strong></p>
<div class="codehilite"><pre><span></span>def sampled_softmax_loss(weights, biases, inputs, labels, num_sampled, num_classes, num_true=1, sampled_values=None, remove_accidental_hits=True, partition_strategy=&quot;mod&quot;, name=&quot;sampled_softmax_loss&quot;)
</pre></div>


<p>Computes and returns the sampled softmax training loss.</p>
<p>This is a faster way to train a softmax classifier over a huge number of
classes.</p>
<p>This operation is for training only.  It is generally an underestimate of
the full softmax loss.</p>
<p>At inference time, you can compute full softmax probabilities with the
expression <code>tf.nn.softmax(tf.matmul(inputs, tf.transpose(weights)) + biases)</code>.</p>
<p>See our [Candidate Sampling Algorithms Reference]
(../../extras/candidate_sampling.pdf)</p>
<p>Also see Section 3 of <a href="http://arxiv.org/abs/1412.2007">Jean et al., 2014</a>
(<a href="http://arxiv.org/pdf/1412.2007.pdf">pdf</a>) for the math.</p>
<p>Args:
  weights: A <code>Tensor</code> of shape <code>[num_classes, dim]</code>, or a list of <code>Tensor</code>
      objects whose concatenation along dimension 0 has shape
      [num_classes, dim].  The (possibly-sharded) class embeddings.
  biases: A <code>Tensor</code> of shape <code>[num_classes]</code>.  The class biases.
  inputs: A <code>Tensor</code> of shape <code>[batch_size, dim]</code>.  The forward
      activations of the input network.
  labels: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
      num_true]</code>. The target classes.  Note that this format differs from
      the <code>labels</code> argument of <code>nn.softmax_cross_entropy_with_logits</code>.
  num_sampled: An <code>int</code>.  The number of classes to randomly sample per batch.
  num_classes: An <code>int</code>. The number of possible classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  sampled_values: a tuple of (<code>sampled_candidates</code>, <code>true_expected_count</code>,
      <code>sampled_expected_count</code>) returned by a <code>*_candidate_sampler</code> function.
      (if None, we default to <code>log_uniform_candidate_sampler</code>)
  remove_accidental_hits:  A <code>bool</code>.  whether to remove "accidental hits"
      where a sampled class equals one of the target classes.  Default is
      True.
  partition_strategy: A string specifying the partitioning strategy, relevant
      if <code>len(weights) &gt; 1</code>. Currently <code>"div"</code> and <code>"mod"</code> are supported.
      Default is <code>"mod"</code>. See <code>tf.nn.embedding_lookup</code> for more details.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>batch_size</code> 1-D tensor of per-example sampled softmax losses.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sampled_softmax_loss', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sampled_softmax_loss" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sampled_softmax_loss_layer">
    <p>def <span class="ident">sampled_softmax_loss_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sampled_softmax_loss_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sampled_softmax_loss_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sampled_softmax_loss_layer</strong></p>
<div class="codehilite"><pre><span></span>def sampled_softmax_loss_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.sampled_softmax_loss, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.sampled_softmax_loss</strong></p>
<div class="codehilite"><pre><span></span>def sampled_softmax_loss(weights, biases, inputs, labels, num_sampled, num_classes, num_true=1, sampled_values=None, remove_accidental_hits=True, partition_strategy=&quot;mod&quot;, name=&quot;sampled_softmax_loss&quot;):
</pre></div>


<p>Computes and returns the sampled softmax training loss.</p>
<p>This is a faster way to train a softmax classifier over a huge number of
classes.</p>
<p>This operation is for training only.  It is generally an underestimate of
the full softmax loss.</p>
<p>At inference time, you can compute full softmax probabilities with the
expression <code>tf.nn.softmax(tf.matmul(inputs, tf.transpose(weights)) + biases)</code>.</p>
<p>See our [Candidate Sampling Algorithms Reference]
(../../extras/candidate_sampling.pdf)</p>
<p>Also see Section 3 of <a href="http://arxiv.org/abs/1412.2007">Jean et al., 2014</a>
(<a href="http://arxiv.org/pdf/1412.2007.pdf">pdf</a>) for the math.</p>
<p>Args:
  weights: A <code>Tensor</code> of shape <code>[num_classes, dim]</code>, or a list of <code>Tensor</code>
      objects whose concatenation along dimension 0 has shape
      [num_classes, dim].  The (possibly-sharded) class embeddings.
  biases: A <code>Tensor</code> of shape <code>[num_classes]</code>.  The class biases.
  inputs: A <code>Tensor</code> of shape <code>[batch_size, dim]</code>.  The forward
      activations of the input network.
  labels: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
      num_true]</code>. The target classes.  Note that this format differs from
      the <code>labels</code> argument of <code>nn.softmax_cross_entropy_with_logits</code>.
  num_sampled: An <code>int</code>.  The number of classes to randomly sample per batch.
  num_classes: An <code>int</code>. The number of possible classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  sampled_values: a tuple of (<code>sampled_candidates</code>, <code>true_expected_count</code>,
      <code>sampled_expected_count</code>) returned by a <code>*_candidate_sampler</code> function.
      (if None, we default to <code>log_uniform_candidate_sampler</code>)
  remove_accidental_hits:  A <code>bool</code>.  whether to remove "accidental hits"
      where a sampled class equals one of the target classes.  Default is
      True.
  partition_strategy: A string specifying the partitioning strategy, relevant
      if <code>len(weights) &gt; 1</code>. Currently <code>"div"</code> and <code>"mod"</code> are supported.
      Default is <code>"mod"</code>. See <code>tf.nn.embedding_lookup</code> for more details.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>batch_size</code> 1-D tensor of per-example sampled softmax losses.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sampled_softmax_loss_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sampled_softmax_loss_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.saturate_cast">
    <p>def <span class="ident">saturate_cast</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.saturate_cast, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.saturate_cast</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.saturate_cast</strong></p>
<div class="codehilite"><pre><span></span>def saturate_cast(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.saturate_cast</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.saturate_cast</code></strong></p>
<div class="codehilite"><pre><span></span>def saturate_cast(value, dtype, name=None)
</pre></div>


<p>Performs a safe saturating cast of <code>value</code> to <code>dtype</code>.</p>
<p>This function casts the input to <code>dtype</code> without applying any scaling.  If
there is a danger that values would over or underflow in the cast, this op
applies the appropriate clamping before the cast.</p>
<p>Args:
  value: A <code>Tensor</code>.
  dtype: The desired output <code>DType</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  <code>value</code> safely cast to <code>dtype</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.saturate_cast', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.saturate_cast" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.saturate_cast_layer">
    <p>def <span class="ident">saturate_cast_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.saturate_cast_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.saturate_cast_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.saturate_cast_layer</strong></p>
<div class="codehilite"><pre><span></span>def saturate_cast_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.saturate_cast, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.saturate_cast</strong></p>
<div class="codehilite"><pre><span></span>def saturate_cast(value, dtype, name=None):
</pre></div>


<p>Performs a safe saturating cast of <code>value</code> to <code>dtype</code>.</p>
<p>This function casts the input to <code>dtype</code> without applying any scaling.  If
there is a danger that values would over or underflow in the cast, this op
applies the appropriate clamping before the cast.</p>
<p>Args:
  value: A <code>Tensor</code>.
  dtype: The desired output <code>DType</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  <code>value</code> safely cast to <code>dtype</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.saturate_cast_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.saturate_cast_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.scalar_mul">
    <p>def <span class="ident">scalar_mul</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.scalar_mul, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.scalar_mul</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.scalar_mul</strong></p>
<div class="codehilite"><pre><span></span>def scalar_mul(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.scalar_mul</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.scalar_mul</code></strong></p>
<div class="codehilite"><pre><span></span>def scalar_mul(scalar, x)
</pre></div>


<p>Multiplies a scalar times a <code>Tensor</code> or <code>IndexedSlices</code> object.</p>
<p>Intended for use in gradient code which might deal with <code>IndexedSlices</code>
objects, which are easy to multiply by a scalar but more expensive to
multiply with arbitrary tensors.</p>
<p>Args:
  scalar: A 0-D scalar <code>Tensor</code>. Must have known shape.
  x: A <code>Tensor</code> or <code>IndexedSlices</code> to be scaled.</p>
<p>Returns:
  <code>scalar * x</code> of the same type (<code>Tensor</code> or <code>IndexedSlices</code>) as <code>x</code>.</p>
<p>Raises:
  ValueError: if scalar is not a 0-D <code>scalar</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.scalar_mul', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.scalar_mul" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.scalar_mul_layer">
    <p>def <span class="ident">scalar_mul_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.scalar_mul_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.scalar_mul_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.scalar_mul_layer</strong></p>
<div class="codehilite"><pre><span></span>def scalar_mul_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.scalar_mul, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.scalar_mul</strong></p>
<div class="codehilite"><pre><span></span>def scalar_mul(scalar, x):
</pre></div>


<p>Multiplies a scalar times a <code>Tensor</code> or <code>IndexedSlices</code> object.</p>
<p>Intended for use in gradient code which might deal with <code>IndexedSlices</code>
objects, which are easy to multiply by a scalar but more expensive to
multiply with arbitrary tensors.</p>
<p>Args:
  scalar: A 0-D scalar <code>Tensor</code>. Must have known shape.
  x: A <code>Tensor</code> or <code>IndexedSlices</code> to be scaled.</p>
<p>Returns:
  <code>scalar * x</code> of the same type (<code>Tensor</code> or <code>IndexedSlices</code>) as <code>x</code>.</p>
<p>Raises:
  ValueError: if scalar is not a 0-D <code>scalar</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.scalar_mul_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.scalar_mul_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.scalar_summary">
    <p>def <span class="ident">scalar_summary</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.scalar_summary, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.scalar_summary</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.scalar_summary</strong></p>
<div class="codehilite"><pre><span></span>def scalar_summary(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.scalar_summary</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.scalar_summary</code></strong></p>
<div class="codehilite"><pre><span></span>def scalar_summary(tags, values, collections=None, name=None)
</pre></div>


<p>Outputs a <code>Summary</code> protocol buffer with scalar values.</p>
<p>The input <code>tags</code> and <code>values</code> must have the same shape.  The generated
summary has a summary value for each tag-value pair in <code>tags</code> and <code>values</code>.</p>
<p>Args:
  tags: A <code>string</code> <code>Tensor</code>.  Tags for the summaries.
  values: A real numeric Tensor.  Values for the summaries.
  collections: Optional list of graph collections keys. The new summary op is
    added to these collections. Defaults to <code>[GraphKeys.SUMMARIES]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A scalar <code>Tensor</code> of type <code>string</code>. The serialized <code>Summary</code> protocol
  buffer.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.scalar_summary', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.scalar_summary" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.scalar_summary_layer">
    <p>def <span class="ident">scalar_summary_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.scalar_summary_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.scalar_summary_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.scalar_summary_layer</strong></p>
<div class="codehilite"><pre><span></span>def scalar_summary_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.scalar_summary, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.scalar_summary</strong></p>
<div class="codehilite"><pre><span></span>def scalar_summary(tags, values, collections=None, name=None):
</pre></div>


<p>Outputs a <code>Summary</code> protocol buffer with scalar values.</p>
<p>The input <code>tags</code> and <code>values</code> must have the same shape.  The generated
summary has a summary value for each tag-value pair in <code>tags</code> and <code>values</code>.</p>
<p>Args:
  tags: A <code>string</code> <code>Tensor</code>.  Tags for the summaries.
  values: A real numeric Tensor.  Values for the summaries.
  collections: Optional list of graph collections keys. The new summary op is
    added to these collections. Defaults to <code>[GraphKeys.SUMMARIES]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A scalar <code>Tensor</code> of type <code>string</code>. The serialized <code>Summary</code> protocol
  buffer.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.scalar_summary_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.scalar_summary_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.scan">
    <p>def <span class="ident">scan</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.scan, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.scan</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.scan</strong></p>
<div class="codehilite"><pre><span></span>def scan(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.scan</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.scan</code></strong></p>
<div class="codehilite"><pre><span></span>def scan(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)
</pre></div>


<p>scan on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p>This scan operator repeatedly applies the callable <code>fn</code> to a sequence
of elements from first to last. The elements are made of the tensors
unpacked from <code>elems</code> on dimension 0. The callable fn takes two tensors as
arguments. The first argument is the accumulated value computed from the
preceding invocation of fn. If <code>initializer</code> is None, <code>elems</code> must contain
at least one element, and its first element is used as the initializer.</p>
<p>Suppose that <code>elems</code> is unpacked into <code>values</code>, a list of tensors. The shape
of the result tensor is <code>[len(values)] + fn(initializer, values[0]).shape</code>.</p>
<p>Args:
  fn: The callable to be performed.
  elems: A tensor to be unpacked on dimension 0.
  initializer: (optional) The initial value for the accumulator.
  parallel_iterations: (optional) The number of iterations allowed to run
                       in parallel.
  back_prop: (optional) True enables back propagation.
  swap_memory: (optional) True enables GPU-CPU memory swapping.
  name: (optional) Name prefix for the returned tensors.</p>
<p>Returns:
  A tensor that packs the results of applying <code>fn</code> to the list of tensors
  unpacked from <code>elems</code>, from first to last.</p>
<p>Raises:
  TypeError: if <code>fn</code> is not callable.</p>
<p>Example:
  <code>python
  elems = [1, 2, 3, 4, 5, 6]
  sum = scan(lambda a, x: a + x, elems)
  # sum == [1, 3, 6, 10, 15, 21]</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.scan', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.scan" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.scan_layer">
    <p>def <span class="ident">scan_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.scan_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.scan_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.scan_layer</strong></p>
<div class="codehilite"><pre><span></span>def scan_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.scan, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.scan</strong></p>
<div class="codehilite"><pre><span></span>def scan(fn, elems, initializer=None, parallel_iterations=10, back_prop=True, swap_memory=False, name=None):
</pre></div>


<p>scan on the list of tensors unpacked from <code>elems</code> on dimension 0.</p>
<p>This scan operator repeatedly applies the callable <code>fn</code> to a sequence
of elements from first to last. The elements are made of the tensors
unpacked from <code>elems</code> on dimension 0. The callable fn takes two tensors as
arguments. The first argument is the accumulated value computed from the
preceding invocation of fn. If <code>initializer</code> is None, <code>elems</code> must contain
at least one element, and its first element is used as the initializer.</p>
<p>Suppose that <code>elems</code> is unpacked into <code>values</code>, a list of tensors. The shape
of the result tensor is <code>[len(values)] + fn(initializer, values[0]).shape</code>.</p>
<p>Args:
  fn: The callable to be performed.
  elems: A tensor to be unpacked on dimension 0.
  initializer: (optional) The initial value for the accumulator.
  parallel_iterations: (optional) The number of iterations allowed to run
                       in parallel.
  back_prop: (optional) True enables back propagation.
  swap_memory: (optional) True enables GPU-CPU memory swapping.
  name: (optional) Name prefix for the returned tensors.</p>
<p>Returns:
  A tensor that packs the results of applying <code>fn</code> to the list of tensors
  unpacked from <code>elems</code>, from first to last.</p>
<p>Raises:
  TypeError: if <code>fn</code> is not callable.</p>
<p>Example:
  <code>python
  elems = [1, 2, 3, 4, 5, 6]
  sum = scan(lambda a, x: a + x, elems)
  # sum == [1, 3, 6, 10, 15, 21]</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.scan_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.scan_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.scatter_add">
    <p>def <span class="ident">scatter_add</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.scatter_add, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.scatter_add</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.scatter_add</strong></p>
<div class="codehilite"><pre><span></span>def scatter_add(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.scatter_add</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.scatter_add</code></strong></p>
<div class="codehilite"><pre><span></span>def scatter_add(ref, indices, updates, use_locking=None, name=None)
</pre></div>


<p>Adds sparse updates to a variable reference.</p>
<p>This operation computes</p>
<div class="codehilite"><pre><span></span># Scalar indices
ref[indices, ...] += updates[...]

# Vector indices (for each i)
ref[indices[i], ...] += updates[i, ...]

# High rank indices (for each i, ..., j)
ref[indices[i, ..., j], ...] += updates[i, ..., j, ...]
</pre></div>


<p>This operation outputs <code>ref</code> after the update is done.
This makes it easier to chain operations that need to use the reset value.</p>
<p>Duplicate entries are handled correctly: if multiple <code>indices</code> reference
the same location, their contributions add.</p>
<p>Requires <code>updates.shape = indices.shape + ref.shape[1:]</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/ScatterAdd.png" alt>
</div>

<p>Args:
  ref: A mutable <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Should be from a <code>Variable</code> node.
  indices: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A tensor of indices into the first dimension of <code>ref</code>.
  updates: A <code>Tensor</code>. Must have the same type as <code>ref</code>.
    A tensor of updated values to add to <code>ref</code>.
  use_locking: An optional <code>bool</code>. Defaults to <code>False</code>.
    If True, the addition will be protected by a lock;
    otherwise the behavior is undefined, but may exhibit less contention.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same as <code>ref</code>.  Returned as a convenience for operations that want
  to use the updated values after the update is done.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.scatter_add', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.scatter_add" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.scatter_add_layer">
    <p>def <span class="ident">scatter_add_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.scatter_add_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.scatter_add_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.scatter_add_layer</strong></p>
<div class="codehilite"><pre><span></span>def scatter_add_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.scatter_add, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.scatter_add</strong></p>
<div class="codehilite"><pre><span></span>def scatter_add(ref, indices, updates, use_locking=None, name=None):
</pre></div>


<p>Adds sparse updates to a variable reference.</p>
<p>This operation computes</p>
<div class="codehilite"><pre><span></span># Scalar indices
ref[indices, ...] += updates[...]

# Vector indices (for each i)
ref[indices[i], ...] += updates[i, ...]

# High rank indices (for each i, ..., j)
ref[indices[i, ..., j], ...] += updates[i, ..., j, ...]
</pre></div>


<p>This operation outputs <code>ref</code> after the update is done.
This makes it easier to chain operations that need to use the reset value.</p>
<p>Duplicate entries are handled correctly: if multiple <code>indices</code> reference
the same location, their contributions add.</p>
<p>Requires <code>updates.shape = indices.shape + ref.shape[1:]</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/ScatterAdd.png" alt>
</div>

<p>Args:
  ref: A mutable <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Should be from a <code>Variable</code> node.
  indices: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A tensor of indices into the first dimension of <code>ref</code>.
  updates: A <code>Tensor</code>. Must have the same type as <code>ref</code>.
    A tensor of updated values to add to <code>ref</code>.
  use_locking: An optional <code>bool</code>. Defaults to <code>False</code>.
    If True, the addition will be protected by a lock;
    otherwise the behavior is undefined, but may exhibit less contention.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same as <code>ref</code>.  Returned as a convenience for operations that want
  to use the updated values after the update is done.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.scatter_add_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.scatter_add_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.scatter_sub">
    <p>def <span class="ident">scatter_sub</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.scatter_sub, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.scatter_sub</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.scatter_sub</strong></p>
<div class="codehilite"><pre><span></span>def scatter_sub(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.scatter_sub</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.scatter_sub</code></strong></p>
<div class="codehilite"><pre><span></span>def scatter_sub(ref, indices, updates, use_locking=None, name=None)
</pre></div>


<p>Subtracts sparse updates to a variable reference.</p>
<div class="codehilite"><pre><span></span># Scalar indices
ref[indices, ...] -= updates[...]

# Vector indices (for each i)
ref[indices[i], ...] -= updates[i, ...]

# High rank indices (for each i, ..., j)
ref[indices[i, ..., j], ...] -= updates[i, ..., j, ...]
</pre></div>


<p>This operation outputs <code>ref</code> after the update is done.
This makes it easier to chain operations that need to use the reset value.</p>
<p>Duplicate entries are handled correctly: if multiple <code>indices</code> reference
the same location, their (negated) contributions add.</p>
<p>Requires <code>updates.shape = indices.shape + ref.shape[1:]</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/ScatterSub.png" alt>
</div>

<p>Args:
  ref: A mutable <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Should be from a <code>Variable</code> node.
  indices: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A tensor of indices into the first dimension of <code>ref</code>.
  updates: A <code>Tensor</code>. Must have the same type as <code>ref</code>.
    A tensor of updated values to subtract from <code>ref</code>.
  use_locking: An optional <code>bool</code>. Defaults to <code>False</code>.
    If True, the subtraction will be protected by a lock;
    otherwise the behavior is undefined, but may exhibit less contention.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same as <code>ref</code>.  Returned as a convenience for operations that want
  to use the updated values after the update is done.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.scatter_sub', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.scatter_sub" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.scatter_sub_layer">
    <p>def <span class="ident">scatter_sub_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.scatter_sub_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.scatter_sub_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.scatter_sub_layer</strong></p>
<div class="codehilite"><pre><span></span>def scatter_sub_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.scatter_sub, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.scatter_sub</strong></p>
<div class="codehilite"><pre><span></span>def scatter_sub(ref, indices, updates, use_locking=None, name=None):
</pre></div>


<p>Subtracts sparse updates to a variable reference.</p>
<div class="codehilite"><pre><span></span># Scalar indices
ref[indices, ...] -= updates[...]

# Vector indices (for each i)
ref[indices[i], ...] -= updates[i, ...]

# High rank indices (for each i, ..., j)
ref[indices[i, ..., j], ...] -= updates[i, ..., j, ...]
</pre></div>


<p>This operation outputs <code>ref</code> after the update is done.
This makes it easier to chain operations that need to use the reset value.</p>
<p>Duplicate entries are handled correctly: if multiple <code>indices</code> reference
the same location, their (negated) contributions add.</p>
<p>Requires <code>updates.shape = indices.shape + ref.shape[1:]</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/ScatterSub.png" alt>
</div>

<p>Args:
  ref: A mutable <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
    Should be from a <code>Variable</code> node.
  indices: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A tensor of indices into the first dimension of <code>ref</code>.
  updates: A <code>Tensor</code>. Must have the same type as <code>ref</code>.
    A tensor of updated values to subtract from <code>ref</code>.
  use_locking: An optional <code>bool</code>. Defaults to <code>False</code>.
    If True, the subtraction will be protected by a lock;
    otherwise the behavior is undefined, but may exhibit less contention.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same as <code>ref</code>.  Returned as a convenience for operations that want
  to use the updated values after the update is done.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.scatter_sub_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.scatter_sub_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.scatter_update">
    <p>def <span class="ident">scatter_update</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.scatter_update, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.scatter_update</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.scatter_update</strong></p>
<div class="codehilite"><pre><span></span>def scatter_update(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.scatter_update</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.scatter_update</code></strong></p>
<div class="codehilite"><pre><span></span>def scatter_update(ref, indices, updates, use_locking=None, name=None)
</pre></div>


<p>Applies sparse updates to a variable reference.</p>
<p>This operation computes</p>
<div class="codehilite"><pre><span></span># Scalar indices
ref[indices, ...] = updates[...]

# Vector indices (for each i)
ref[indices[i], ...] = updates[i, ...]

# High rank indices (for each i, ..., j)
ref[indices[i, ..., j], ...] = updates[i, ..., j, ...]
</pre></div>


<p>This operation outputs <code>ref</code> after the update is done.
This makes it easier to chain operations that need to use the reset value.</p>
<p>If values in <code>ref</code> is to be updated more than once, because there are
duplicate entires in <code>indices</code>, the order at which the updates happen
for each value is undefined.</p>
<p>Requires <code>updates.shape = indices.shape + ref.shape[1:]</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/ScatterUpdate.png" alt>
</div>

<p>Args:
  ref: A mutable <code>Tensor</code>. Should be from a <code>Variable</code> node.
  indices: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A tensor of indices into the first dimension of <code>ref</code>.
  updates: A <code>Tensor</code>. Must have the same type as <code>ref</code>.
    A tensor of updated values to store in <code>ref</code>.
  use_locking: An optional <code>bool</code>. Defaults to <code>True</code>.
    If True, the assignment will be protected by a lock;
    otherwise the behavior is undefined, but may exhibit less contention.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same as <code>ref</code>.  Returned as a convenience for operations that want
  to use the updated values after the update is done.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.scatter_update', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.scatter_update" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.scatter_update_layer">
    <p>def <span class="ident">scatter_update_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.scatter_update_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.scatter_update_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.scatter_update_layer</strong></p>
<div class="codehilite"><pre><span></span>def scatter_update_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.scatter_update, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.scatter_update</strong></p>
<div class="codehilite"><pre><span></span>def scatter_update(ref, indices, updates, use_locking=None, name=None):
</pre></div>


<p>Applies sparse updates to a variable reference.</p>
<p>This operation computes</p>
<div class="codehilite"><pre><span></span># Scalar indices
ref[indices, ...] = updates[...]

# Vector indices (for each i)
ref[indices[i], ...] = updates[i, ...]

# High rank indices (for each i, ..., j)
ref[indices[i, ..., j], ...] = updates[i, ..., j, ...]
</pre></div>


<p>This operation outputs <code>ref</code> after the update is done.
This makes it easier to chain operations that need to use the reset value.</p>
<p>If values in <code>ref</code> is to be updated more than once, because there are
duplicate entires in <code>indices</code>, the order at which the updates happen
for each value is undefined.</p>
<p>Requires <code>updates.shape = indices.shape + ref.shape[1:]</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/ScatterUpdate.png" alt>
</div>

<p>Args:
  ref: A mutable <code>Tensor</code>. Should be from a <code>Variable</code> node.
  indices: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A tensor of indices into the first dimension of <code>ref</code>.
  updates: A <code>Tensor</code>. Must have the same type as <code>ref</code>.
    A tensor of updated values to store in <code>ref</code>.
  use_locking: An optional <code>bool</code>. Defaults to <code>True</code>.
    If True, the assignment will be protected by a lock;
    otherwise the behavior is undefined, but may exhibit less contention.
  name: A name for the operation (optional).</p>
<p>Returns:
  Same as <code>ref</code>.  Returned as a convenience for operations that want
  to use the updated values after the update is done.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.scatter_update_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.scatter_update_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.segment_max">
    <p>def <span class="ident">segment_max</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.segment_max, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.segment_max</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.segment_max</strong></p>
<div class="codehilite"><pre><span></span>def segment_max(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.segment_max</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.segment_max</code></strong></p>
<div class="codehilite"><pre><span></span>def segment_max(data, segment_ids, name=None)
</pre></div>


<p>Computes the maximum along segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on Segmentation</a>
for an explanation of segments.</p>
<p>Computes a tensor such that
\(output_i = \max_j(data_j)\) where <code>max</code> is over <code>j</code> such
that <code>segment_ids[j] == i</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/SegmentMax.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  segment_ids: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A 1-D tensor whose rank is equal to the rank of <code>data</code>'s
    first dimension.  Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.segment_max', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.segment_max" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.segment_max_layer">
    <p>def <span class="ident">segment_max_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.segment_max_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.segment_max_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.segment_max_layer</strong></p>
<div class="codehilite"><pre><span></span>def segment_max_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.segment_max, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.segment_max</strong></p>
<div class="codehilite"><pre><span></span>def segment_max(data, segment_ids, name=None):
</pre></div>


<p>Computes the maximum along segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on Segmentation</a>
for an explanation of segments.</p>
<p>Computes a tensor such that
\(output_i = \max_j(data_j)\) where <code>max</code> is over <code>j</code> such
that <code>segment_ids[j] == i</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/SegmentMax.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  segment_ids: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A 1-D tensor whose rank is equal to the rank of <code>data</code>'s
    first dimension.  Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.segment_max_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.segment_max_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.segment_mean">
    <p>def <span class="ident">segment_mean</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.segment_mean, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.segment_mean</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.segment_mean</strong></p>
<div class="codehilite"><pre><span></span>def segment_mean(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.segment_mean</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.segment_mean</code></strong></p>
<div class="codehilite"><pre><span></span>def segment_mean(data, segment_ids, name=None)
</pre></div>


<p>Computes the mean along segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Computes a tensor such that
\(output_i = \frac{\sum_j data_j}{N}\) where <code>mean</code> is
over <code>j</code> such that <code>segment_ids[j] == i</code> and <code>N</code> is the total number of
values summed.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/SegmentMean.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  segment_ids: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A 1-D tensor whose rank is equal to the rank of <code>data</code>'s
    first dimension.  Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.segment_mean', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.segment_mean" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.segment_mean_layer">
    <p>def <span class="ident">segment_mean_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.segment_mean_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.segment_mean_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.segment_mean_layer</strong></p>
<div class="codehilite"><pre><span></span>def segment_mean_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.segment_mean, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.segment_mean</strong></p>
<div class="codehilite"><pre><span></span>def segment_mean(data, segment_ids, name=None):
</pre></div>


<p>Computes the mean along segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Computes a tensor such that
\(output_i = \frac{\sum_j data_j}{N}\) where <code>mean</code> is
over <code>j</code> such that <code>segment_ids[j] == i</code> and <code>N</code> is the total number of
values summed.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/SegmentMean.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  segment_ids: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A 1-D tensor whose rank is equal to the rank of <code>data</code>'s
    first dimension.  Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.segment_mean_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.segment_mean_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.segment_min">
    <p>def <span class="ident">segment_min</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.segment_min, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.segment_min</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.segment_min</strong></p>
<div class="codehilite"><pre><span></span>def segment_min(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.segment_min</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.segment_min</code></strong></p>
<div class="codehilite"><pre><span></span>def segment_min(data, segment_ids, name=None)
</pre></div>


<p>Computes the minimum along segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Computes a tensor such that
\(output_i = \min_j(data_j)\) where <code>min</code> is over <code>j</code> such
that <code>segment_ids[j] == i</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/SegmentMin.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  segment_ids: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A 1-D tensor whose rank is equal to the rank of <code>data</code>'s
    first dimension.  Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.segment_min', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.segment_min" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.segment_min_layer">
    <p>def <span class="ident">segment_min_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.segment_min_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.segment_min_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.segment_min_layer</strong></p>
<div class="codehilite"><pre><span></span>def segment_min_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.segment_min, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.segment_min</strong></p>
<div class="codehilite"><pre><span></span>def segment_min(data, segment_ids, name=None):
</pre></div>


<p>Computes the minimum along segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Computes a tensor such that
\(output_i = \min_j(data_j)\) where <code>min</code> is over <code>j</code> such
that <code>segment_ids[j] == i</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/SegmentMin.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  segment_ids: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A 1-D tensor whose rank is equal to the rank of <code>data</code>'s
    first dimension.  Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.segment_min_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.segment_min_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.segment_prod">
    <p>def <span class="ident">segment_prod</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.segment_prod, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.segment_prod</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.segment_prod</strong></p>
<div class="codehilite"><pre><span></span>def segment_prod(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.segment_prod</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.segment_prod</code></strong></p>
<div class="codehilite"><pre><span></span>def segment_prod(data, segment_ids, name=None)
</pre></div>


<p>Computes the product along segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Computes a tensor such that
\(output_i = \prod_j data_j\) where the product is over <code>j</code> such
that <code>segment_ids[j] == i</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/SegmentProd.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  segment_ids: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A 1-D tensor whose rank is equal to the rank of <code>data</code>'s
    first dimension.  Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.segment_prod', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.segment_prod" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.segment_prod_layer">
    <p>def <span class="ident">segment_prod_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.segment_prod_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.segment_prod_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.segment_prod_layer</strong></p>
<div class="codehilite"><pre><span></span>def segment_prod_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.segment_prod, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.segment_prod</strong></p>
<div class="codehilite"><pre><span></span>def segment_prod(data, segment_ids, name=None):
</pre></div>


<p>Computes the product along segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Computes a tensor such that
\(output_i = \prod_j data_j\) where the product is over <code>j</code> such
that <code>segment_ids[j] == i</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/SegmentProd.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  segment_ids: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A 1-D tensor whose rank is equal to the rank of <code>data</code>'s
    first dimension.  Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.segment_prod_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.segment_prod_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.segment_sum">
    <p>def <span class="ident">segment_sum</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.segment_sum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.segment_sum</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.segment_sum</strong></p>
<div class="codehilite"><pre><span></span>def segment_sum(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.segment_sum</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.segment_sum</code></strong></p>
<div class="codehilite"><pre><span></span>def segment_sum(data, segment_ids, name=None)
</pre></div>


<p>Computes the sum along segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on Segmentation</a>
for an explanation of segments.</p>
<p>Computes a tensor such that
\(output_i = \sum_j data_j\) where sum is over <code>j</code> such
that <code>segment_ids[j] == i</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/SegmentSum.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  segment_ids: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A 1-D tensor whose rank is equal to the rank of <code>data</code>'s
    first dimension.  Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.segment_sum', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.segment_sum" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.segment_sum_layer">
    <p>def <span class="ident">segment_sum_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.segment_sum_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.segment_sum_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.segment_sum_layer</strong></p>
<div class="codehilite"><pre><span></span>def segment_sum_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.segment_sum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.segment_sum</strong></p>
<div class="codehilite"><pre><span></span>def segment_sum(data, segment_ids, name=None):
</pre></div>


<p>Computes the sum along segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on Segmentation</a>
for an explanation of segments.</p>
<p>Computes a tensor such that
\(output_i = \sum_j data_j\) where sum is over <code>j</code> such
that <code>segment_ids[j] == i</code>.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/SegmentSum.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  segment_ids: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A 1-D tensor whose rank is equal to the rank of <code>data</code>'s
    first dimension.  Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.segment_sum_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.segment_sum_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.select">
    <p>def <span class="ident">select</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.select, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.select</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.select</strong></p>
<div class="codehilite"><pre><span></span>def select(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.select</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.select</code></strong></p>
<div class="codehilite"><pre><span></span>def select(condition, t, e, name=None)
</pre></div>


<p>Selects elements from <code>t</code> or <code>e</code>, depending on <code>condition</code>.</p>
<p>The <code>t</code>, and <code>e</code> tensors must all have the same shape,
and the output will also have that shape.  The <code>condition</code> tensor
must be a scalar if <code>t</code> and <code>e</code> are scalars.  If <code>t</code> and <code>e</code> are vectors
or higher rank, then <code>condition</code> must be either a vector with size
matching the first dimension of <code>t</code>, or must have the same shape as <code>t</code>.</p>
<p>The <code>condition</code> tensor acts as a mask that chooses, based on the value at each
element, whether the corresponding element / row in the output should be
taken from <code>t</code> (if true) or <code>e</code> (if false).</p>
<p>If <code>condition</code> is a vector and <code>t</code> and <code>e</code> are higher rank matrices, then
it chooses which row (outer dimension) to copy from <code>t</code> and <code>e</code>.
If <code>condition</code> has the same shape as <code>t</code> and <code>e</code>, then it chooses which
element to copy from <code>t</code> and <code>e</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'condition' tensor is [[True,  False]</h1>
<h1>[False, True]]</h1>
<h1>'t' is [[1, 2],</h1>
<h1>[3, 4]]</h1>
<h1>'e' is [[5, 6],</h1>
<h1>[7, 8]]</h1>
<p>select(condition, t, e) ==&gt; [[1, 6],
                             [7, 4]]</p>
<h1>'condition' tensor is [True, False]</h1>
<h1>'t' is [[1, 2],</h1>
<h1>[3, 4]]</h1>
<h1>'e' is [[5, 6],</h1>
<h1>[7, 8]]</h1>
<p>select(condition, t, e) ==&gt; [[1, 2],
                             [7, 8]]</p>
<p>```</p>
<p>Args:
  condition: A <code>Tensor</code> of type <code>bool</code>.
  t:  A <code>Tensor</code> which may have the same shape as <code>condition</code>.
    If <code>condition</code> is rank 1, <code>t</code> may have higher rank,
    but its first dimension must match the size of <code>condition</code>.
  e:  A <code>Tensor</code> with the same type and shape as <code>t</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with the same type and shape as <code>t</code> and <code>e</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.select', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.select" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.select_layer">
    <p>def <span class="ident">select_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.select_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.select_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.select_layer</strong></p>
<div class="codehilite"><pre><span></span>def select_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.select, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.select</strong></p>
<div class="codehilite"><pre><span></span>def select(condition, t, e, name=None):
</pre></div>


<p>Selects elements from <code>t</code> or <code>e</code>, depending on <code>condition</code>.</p>
<p>The <code>t</code>, and <code>e</code> tensors must all have the same shape,
and the output will also have that shape.  The <code>condition</code> tensor
must be a scalar if <code>t</code> and <code>e</code> are scalars.  If <code>t</code> and <code>e</code> are vectors
or higher rank, then <code>condition</code> must be either a vector with size
matching the first dimension of <code>t</code>, or must have the same shape as <code>t</code>.</p>
<p>The <code>condition</code> tensor acts as a mask that chooses, based on the value at each
element, whether the corresponding element / row in the output should be
taken from <code>t</code> (if true) or <code>e</code> (if false).</p>
<p>If <code>condition</code> is a vector and <code>t</code> and <code>e</code> are higher rank matrices, then
it chooses which row (outer dimension) to copy from <code>t</code> and <code>e</code>.
If <code>condition</code> has the same shape as <code>t</code> and <code>e</code>, then it chooses which
element to copy from <code>t</code> and <code>e</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'condition' tensor is [[True,  False]</h1>
<h1>[False, True]]</h1>
<h1>'t' is [[1, 2],</h1>
<h1>[3, 4]]</h1>
<h1>'e' is [[5, 6],</h1>
<h1>[7, 8]]</h1>
<p>select(condition, t, e) ==&gt; [[1, 6],
                             [7, 4]]</p>
<h1>'condition' tensor is [True, False]</h1>
<h1>'t' is [[1, 2],</h1>
<h1>[3, 4]]</h1>
<h1>'e' is [[5, 6],</h1>
<h1>[7, 8]]</h1>
<p>select(condition, t, e) ==&gt; [[1, 2],
                             [7, 8]]</p>
<p>```</p>
<p>Args:
  condition: A <code>Tensor</code> of type <code>bool</code>.
  t:  A <code>Tensor</code> which may have the same shape as <code>condition</code>.
    If <code>condition</code> is rank 1, <code>t</code> may have higher rank,
    but its first dimension must match the size of <code>condition</code>.
  e:  A <code>Tensor</code> with the same type and shape as <code>t</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with the same type and shape as <code>t</code> and <code>e</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.select_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.select_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.self_adjoint_eig">
    <p>def <span class="ident">self_adjoint_eig</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.self_adjoint_eig, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.self_adjoint_eig</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.self_adjoint_eig</strong></p>
<div class="codehilite"><pre><span></span>def self_adjoint_eig(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.self_adjoint_eig</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.self_adjoint_eig</code></strong></p>
<div class="codehilite"><pre><span></span>def self_adjoint_eig(input, name=None)
</pre></div>


<p>Calculates the Eigen Decomposition of a square Self-Adjoint matrix.</p>
<p>Only the lower-triangular part of the input will be used in this case. The
upper-triangular part will not be read.</p>
<p>The result is a M+1 x M matrix whose first row is the eigenvalues, and
subsequent rows are eigenvectors.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[M, M]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. Shape is <code>[M+1, M]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.self_adjoint_eig', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.self_adjoint_eig" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.self_adjoint_eig_layer">
    <p>def <span class="ident">self_adjoint_eig_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.self_adjoint_eig_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.self_adjoint_eig_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.self_adjoint_eig_layer</strong></p>
<div class="codehilite"><pre><span></span>def self_adjoint_eig_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.self_adjoint_eig, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.self_adjoint_eig</strong></p>
<div class="codehilite"><pre><span></span>def self_adjoint_eig(input, name=None):
</pre></div>


<p>Calculates the Eigen Decomposition of a square Self-Adjoint matrix.</p>
<p>Only the lower-triangular part of the input will be used in this case. The
upper-triangular part will not be read.</p>
<p>The result is a M+1 x M matrix whose first row is the eigenvalues, and
subsequent rows are eigenvectors.</p>
<p>Args:
  input: A <code>Tensor</code>. Must be one of the following types: <code>float64</code>, <code>float32</code>.
    Shape is <code>[M, M]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>. Shape is <code>[M+1, M]</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.self_adjoint_eig_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.self_adjoint_eig_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.separable_conv2d">
    <p>def <span class="ident">separable_conv2d</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.separable_conv2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.separable_conv2d</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.separable_conv2d</strong></p>
<div class="codehilite"><pre><span></span>def separable_conv2d(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.separable_conv2d</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.separable_conv2d</code></strong></p>
<div class="codehilite"><pre><span></span>def separable_conv2d(input, depthwise_filter, pointwise_filter, strides, padding, name=None)
</pre></div>


<p>2-D convolution with separable filters.</p>
<p>Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions <code>[1, 2]</code> and <code>3</code>, not spatial separability between
dimensions <code>1</code> and <code>2</code>.</p>
<p>In detail,</p>
<div class="codehilite"><pre><span></span>output[b, i, j, k] = sum_{di, dj, q, r]
    input[b, strides[1] * i + di, strides[2] * j + dj, q] *
    depthwise_filter[di, dj, q, r] *
    pointwise_filter[0, 0, q * channel_multiplier + r, k]
</pre></div>


<p><code>strides</code> controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of <code>[1, 1, 1, 1]</code>.  Must have
<code>strides[0] = strides[3] = 1</code>.  For the most common case of the same
horizontal and vertical strides, <code>strides = [1, stride, stride, 1]</code>.</p>
<p>Args:
  input: 4-D <code>Tensor</code> with shape <code>[batch, in_height, in_width, in_channels]</code>.
  depthwise_filter: 4-D <code>Tensor</code> with shape
    <code>[filter_height, filter_width, in_channels, channel_multiplier]</code>.
    Contains <code>in_channels</code> convolutional filters of depth 1.
  pointwise_filter: 4-D <code>Tensor</code> with shape
    <code>[1, 1, channel_multiplier * in_channels, out_channels]</code>.  Pointwise
    filter to mix channels after <code>depthwise_filter</code> has convolved spatially.
  strides: 1-D of size 4.  The strides for the depthwise convolution for
    each dimension of <code>input</code>.
  padding: A string, either <code>'VALID'</code> or <code>'SAME'</code>.  The padding algorithm.
    See the <a href="https://www.tensorflow.org/api_docs/python/nn.html#convolution">comment here</a>
  name: A name for this operation (optional).</p>
<p>Returns:
  A 4-D <code>Tensor</code> of shape <code>[batch, out_height, out_width, out_channels]</code>.</p>
<p>Raises:
  ValueError: If channel_multiplier * in_channels &gt; out_channels,
    which means that the separable convolution is overparameterized.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.separable_conv2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.separable_conv2d" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.separable_conv2d_layer">
    <p>def <span class="ident">separable_conv2d_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.separable_conv2d_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.separable_conv2d_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.separable_conv2d_layer</strong></p>
<div class="codehilite"><pre><span></span>def separable_conv2d_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.separable_conv2d, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.separable_conv2d</strong></p>
<div class="codehilite"><pre><span></span>def separable_conv2d(input, depthwise_filter, pointwise_filter, strides, padding, name=None):
</pre></div>


<p>2-D convolution with separable filters.</p>
<p>Performs a depthwise convolution that acts separately on channels followed by
a pointwise convolution that mixes channels.  Note that this is separability
between dimensions <code>[1, 2]</code> and <code>3</code>, not spatial separability between
dimensions <code>1</code> and <code>2</code>.</p>
<p>In detail,</p>
<div class="codehilite"><pre><span></span>output[b, i, j, k] = sum_{di, dj, q, r]
    input[b, strides[1] * i + di, strides[2] * j + dj, q] *
    depthwise_filter[di, dj, q, r] *
    pointwise_filter[0, 0, q * channel_multiplier + r, k]
</pre></div>


<p><code>strides</code> controls the strides for the depthwise convolution only, since
the pointwise convolution has implicit strides of <code>[1, 1, 1, 1]</code>.  Must have
<code>strides[0] = strides[3] = 1</code>.  For the most common case of the same
horizontal and vertical strides, <code>strides = [1, stride, stride, 1]</code>.</p>
<p>Args:
  input: 4-D <code>Tensor</code> with shape <code>[batch, in_height, in_width, in_channels]</code>.
  depthwise_filter: 4-D <code>Tensor</code> with shape
    <code>[filter_height, filter_width, in_channels, channel_multiplier]</code>.
    Contains <code>in_channels</code> convolutional filters of depth 1.
  pointwise_filter: 4-D <code>Tensor</code> with shape
    <code>[1, 1, channel_multiplier * in_channels, out_channels]</code>.  Pointwise
    filter to mix channels after <code>depthwise_filter</code> has convolved spatially.
  strides: 1-D of size 4.  The strides for the depthwise convolution for
    each dimension of <code>input</code>.
  padding: A string, either <code>'VALID'</code> or <code>'SAME'</code>.  The padding algorithm.
    See the <a href="https://www.tensorflow.org/api_docs/python/nn.html#convolution">comment here</a>
  name: A name for this operation (optional).</p>
<p>Returns:
  A 4-D <code>Tensor</code> of shape <code>[batch, out_height, out_width, out_channels]</code>.</p>
<p>Raises:
  ValueError: If channel_multiplier * in_channels &gt; out_channels,
    which means that the separable convolution is overparameterized.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.separable_conv2d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.separable_conv2d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.serialize_many_sparse">
    <p>def <span class="ident">serialize_many_sparse</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.serialize_many_sparse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.serialize_many_sparse</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.serialize_many_sparse</strong></p>
<div class="codehilite"><pre><span></span>def serialize_many_sparse(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.serialize_many_sparse</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.serialize_many_sparse</code></strong></p>
<div class="codehilite"><pre><span></span>def serialize_many_sparse(sp_input, name=None)
</pre></div>


<p>Serialize an <code>N</code>-minibatch <code>SparseTensor</code> into an <code>[N, 3]</code> string <code>Tensor</code>.</p>
<p>The <code>SparseTensor</code> must have rank <code>R</code> greater than 1, and the first dimension
is treated as the minibatch dimension.  Elements of the <code>SparseTensor</code>
must be sorted in increasing order of this first dimension.  The serialized
<code>SparseTensor</code> objects going into each row of the output <code>Tensor</code> will have
rank <code>R-1</code>.</p>
<p>The minibatch size <code>N</code> is extracted from <code>sparse_shape[0]</code>.</p>
<p>Args:
  sp_input: The input rank <code>R</code> <code>SparseTensor</code>.
  name: A name prefix for the returned tensors (optional).</p>
<p>Returns:
  A string matrix (2-D <code>Tensor</code>) with <code>N</code> rows and <code>3</code> columns.
  Each column represents serialized <code>SparseTensor</code>'s indices, values, and
  shape (respectively).</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.serialize_many_sparse', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.serialize_many_sparse" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.serialize_many_sparse_layer">
    <p>def <span class="ident">serialize_many_sparse_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.serialize_many_sparse_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.serialize_many_sparse_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.serialize_many_sparse_layer</strong></p>
<div class="codehilite"><pre><span></span>def serialize_many_sparse_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.serialize_many_sparse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.serialize_many_sparse</strong></p>
<div class="codehilite"><pre><span></span>def serialize_many_sparse(sp_input, name=None):
</pre></div>


<p>Serialize an <code>N</code>-minibatch <code>SparseTensor</code> into an <code>[N, 3]</code> string <code>Tensor</code>.</p>
<p>The <code>SparseTensor</code> must have rank <code>R</code> greater than 1, and the first dimension
is treated as the minibatch dimension.  Elements of the <code>SparseTensor</code>
must be sorted in increasing order of this first dimension.  The serialized
<code>SparseTensor</code> objects going into each row of the output <code>Tensor</code> will have
rank <code>R-1</code>.</p>
<p>The minibatch size <code>N</code> is extracted from <code>sparse_shape[0]</code>.</p>
<p>Args:
  sp_input: The input rank <code>R</code> <code>SparseTensor</code>.
  name: A name prefix for the returned tensors (optional).</p>
<p>Returns:
  A string matrix (2-D <code>Tensor</code>) with <code>N</code> rows and <code>3</code> columns.
  Each column represents serialized <code>SparseTensor</code>'s indices, values, and
  shape (respectively).</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.serialize_many_sparse_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.serialize_many_sparse_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.serialize_sparse">
    <p>def <span class="ident">serialize_sparse</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.serialize_sparse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.serialize_sparse</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.serialize_sparse</strong></p>
<div class="codehilite"><pre><span></span>def serialize_sparse(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.serialize_sparse</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.serialize_sparse</code></strong></p>
<div class="codehilite"><pre><span></span>def serialize_sparse(sp_input, name=None)
</pre></div>


<p>Serialize a <code>SparseTensor</code> into a string 3-vector (1-D <code>Tensor</code>) object.</p>
<p>Args:
  sp_input: The input <code>SparseTensor</code>.
  name: A name prefix for the returned tensors (optional).</p>
<p>Returns:
  A string 3-vector (1D <code>Tensor</code>), with each column representing the
  serialized <code>SparseTensor</code>'s indices, values, and shape (respectively).</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.serialize_sparse', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.serialize_sparse" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.serialize_sparse_layer">
    <p>def <span class="ident">serialize_sparse_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.serialize_sparse_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.serialize_sparse_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.serialize_sparse_layer</strong></p>
<div class="codehilite"><pre><span></span>def serialize_sparse_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.serialize_sparse, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.serialize_sparse</strong></p>
<div class="codehilite"><pre><span></span>def serialize_sparse(sp_input, name=None):
</pre></div>


<p>Serialize a <code>SparseTensor</code> into a string 3-vector (1-D <code>Tensor</code>) object.</p>
<p>Args:
  sp_input: The input <code>SparseTensor</code>.
  name: A name prefix for the returned tensors (optional).</p>
<p>Returns:
  A string 3-vector (1D <code>Tensor</code>), with each column representing the
  serialized <code>SparseTensor</code>'s indices, values, and shape (respectively).</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.serialize_sparse_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.serialize_sparse_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.set_random_seed">
    <p>def <span class="ident">set_random_seed</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.set_random_seed, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.set_random_seed</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.set_random_seed</strong></p>
<div class="codehilite"><pre><span></span>def set_random_seed(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.set_random_seed</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.set_random_seed</code></strong></p>
<div class="codehilite"><pre><span></span>def set_random_seed(seed)
</pre></div>


<p>Sets the graph-level random seed.</p>
<p>Operations that rely on a random seed actually derive it from two seeds:
the graph-level and operation-level seeds. This sets the graph-level seed.</p>
<p>Its interactions with operation-level seeds is as follows:</p>
<ol>
<li>If neither the graph-level nor the operation seed is set:
    A random seed is used for this op.</li>
<li>If the graph-level seed is set, but the operation seed is not:
    The system deterministically picks an operation seed in conjunction
    with the graph-level seed so that it gets a unique random sequence.</li>
<li>If the graph-level seed is not set, but the operation seed is set:
    A default graph-level seed and the specified operation seed are used to
    determine the random sequence.</li>
<li>If both the graph-level and the operation seed are set:
    Both seeds are used in conjunction to determine the random sequence.</li>
</ol>
<p>To illustrate the user-visible effects, consider these examples:</p>
<p>To generate different sequences across sessions, set neither
graph-level nor op-level seeds:</p>
<p>```python
a = tf.random_uniform([1])
b = tf.random_normal([1])</p>
<p>print("Session 1")
with tf.Session() as sess1:
  print(sess1.run(a))  # generates 'A1'
  print(sess1.run(a))  # generates 'A2'
  print(sess1.run(b))  # generates 'B1'
  print(sess1.run(b))  # generates 'B2'</p>
<p>print("Session 2")
with tf.Session() as sess2:
  print(sess2.run(a))  # generates 'A3'
  print(sess2.run(a))  # generates 'A4'
  print(sess2.run(b))  # generates 'B3'
  print(sess2.run(b))  # generates 'B4'
```</p>
<p>To generate the same repeatable sequence for an op across sessions, set the
seed for the op:</p>
<p>```python
a = tf.random_uniform([1], seed=1)
b = tf.random_normal([1])</p>
<h1>Repeatedly running this block with the same graph will generate the same</h1>
<h1>sequence of values for 'a', but different sequences of values for 'b'.</h1>
<p>print("Session 1")
with tf.Session() as sess1:
  print(sess1.run(a))  # generates 'A1'
  print(sess1.run(a))  # generates 'A2'
  print(sess1.run(b))  # generates 'B1'
  print(sess1.run(b))  # generates 'B2'</p>
<p>print("Session 2")
with tf.Session() as sess2:
  print(sess2.run(a))  # generates 'A1'
  print(sess2.run(a))  # generates 'A2'
  print(sess2.run(b))  # generates 'B3'
  print(sess2.run(b))  # generates 'B4'
```</p>
<p>To make the random sequences generated by all ops be repeatable across
sessions, set a graph-level seed:</p>
<p>```python
tf.set_random_seed(1234)
a = tf.random_uniform([1])
b = tf.random_normal([1])</p>
<h1>Repeatedly running this block with the same graph will generate different</h1>
<h1>sequences of 'a' and 'b'.</h1>
<p>print("Session 1")
with tf.Session() as sess1:
  print(sess1.run(a))  # generates 'A1'
  print(sess1.run(a))  # generates 'A2'
  print(sess1.run(b))  # generates 'B1'
  print(sess1.run(b))  # generates 'B2'</p>
<p>print("Session 2")
with tf.Session() as sess2:
  print(sess2.run(a))  # generates 'A1'
  print(sess2.run(a))  # generates 'A2'
  print(sess2.run(b))  # generates 'B1'
  print(sess2.run(b))  # generates 'B2'
```</p>
<p>Args:
  seed: integer.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.set_random_seed', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.set_random_seed" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.set_random_seed_layer">
    <p>def <span class="ident">set_random_seed_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.set_random_seed_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.set_random_seed_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.set_random_seed_layer</strong></p>
<div class="codehilite"><pre><span></span>def set_random_seed_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.set_random_seed, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.set_random_seed</strong></p>
<div class="codehilite"><pre><span></span>def set_random_seed(seed):
</pre></div>


<p>Sets the graph-level random seed.</p>
<p>Operations that rely on a random seed actually derive it from two seeds:
the graph-level and operation-level seeds. This sets the graph-level seed.</p>
<p>Its interactions with operation-level seeds is as follows:</p>
<ol>
<li>If neither the graph-level nor the operation seed is set:
    A random seed is used for this op.</li>
<li>If the graph-level seed is set, but the operation seed is not:
    The system deterministically picks an operation seed in conjunction
    with the graph-level seed so that it gets a unique random sequence.</li>
<li>If the graph-level seed is not set, but the operation seed is set:
    A default graph-level seed and the specified operation seed are used to
    determine the random sequence.</li>
<li>If both the graph-level and the operation seed are set:
    Both seeds are used in conjunction to determine the random sequence.</li>
</ol>
<p>To illustrate the user-visible effects, consider these examples:</p>
<p>To generate different sequences across sessions, set neither
graph-level nor op-level seeds:</p>
<p>```python
a = tf.random_uniform([1])
b = tf.random_normal([1])</p>
<p>print("Session 1")
with tf.Session() as sess1:
  print(sess1.run(a))  # generates 'A1'
  print(sess1.run(a))  # generates 'A2'
  print(sess1.run(b))  # generates 'B1'
  print(sess1.run(b))  # generates 'B2'</p>
<p>print("Session 2")
with tf.Session() as sess2:
  print(sess2.run(a))  # generates 'A3'
  print(sess2.run(a))  # generates 'A4'
  print(sess2.run(b))  # generates 'B3'
  print(sess2.run(b))  # generates 'B4'
```</p>
<p>To generate the same repeatable sequence for an op across sessions, set the
seed for the op:</p>
<p>```python
a = tf.random_uniform([1], seed=1)
b = tf.random_normal([1])</p>
<h1>Repeatedly running this block with the same graph will generate the same</h1>
<h1>sequence of values for 'a', but different sequences of values for 'b'.</h1>
<p>print("Session 1")
with tf.Session() as sess1:
  print(sess1.run(a))  # generates 'A1'
  print(sess1.run(a))  # generates 'A2'
  print(sess1.run(b))  # generates 'B1'
  print(sess1.run(b))  # generates 'B2'</p>
<p>print("Session 2")
with tf.Session() as sess2:
  print(sess2.run(a))  # generates 'A1'
  print(sess2.run(a))  # generates 'A2'
  print(sess2.run(b))  # generates 'B3'
  print(sess2.run(b))  # generates 'B4'
```</p>
<p>To make the random sequences generated by all ops be repeatable across
sessions, set a graph-level seed:</p>
<p>```python
tf.set_random_seed(1234)
a = tf.random_uniform([1])
b = tf.random_normal([1])</p>
<h1>Repeatedly running this block with the same graph will generate different</h1>
<h1>sequences of 'a' and 'b'.</h1>
<p>print("Session 1")
with tf.Session() as sess1:
  print(sess1.run(a))  # generates 'A1'
  print(sess1.run(a))  # generates 'A2'
  print(sess1.run(b))  # generates 'B1'
  print(sess1.run(b))  # generates 'B2'</p>
<p>print("Session 2")
with tf.Session() as sess2:
  print(sess2.run(a))  # generates 'A1'
  print(sess2.run(a))  # generates 'A2'
  print(sess2.run(b))  # generates 'B1'
  print(sess2.run(b))  # generates 'B2'
```</p>
<p>Args:
  seed: integer.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.set_random_seed_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.set_random_seed_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.shape">
    <p>def <span class="ident">shape</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.shape, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.shape</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.shape</strong></p>
<div class="codehilite"><pre><span></span>def shape(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.shape</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.shape</code></strong></p>
<div class="codehilite"><pre><span></span>def shape(input, name=None)
</pre></div>


<p>Returns the shape of a tensor.</p>
<p>This operation returns a 1-D integer tensor representing the shape of <code>input</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'t' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]</h1>
<p>shape(t) ==&gt; [2, 2, 3]
```</p>
<p>Args:
  input: A <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.shape', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.shape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.shape_layer">
    <p>def <span class="ident">shape_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.shape_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.shape_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.shape_layer</strong></p>
<div class="codehilite"><pre><span></span>def shape_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.shape, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.shape</strong></p>
<div class="codehilite"><pre><span></span>def shape(input, name=None):
</pre></div>


<p>Returns the shape of a tensor.</p>
<p>This operation returns a 1-D integer tensor representing the shape of <code>input</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'t' is [[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]</h1>
<p>shape(t) ==&gt; [2, 2, 3]
```</p>
<p>Args:
  input: A <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.shape_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.shape_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.shape_n">
    <p>def <span class="ident">shape_n</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.shape_n, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.shape_n</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.shape_n</strong></p>
<div class="codehilite"><pre><span></span>def shape_n(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.shape_n</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.shape_n</code></strong></p>
<div class="codehilite"><pre><span></span>def shape_n(input, name=None)
</pre></div>


<p>Returns shape of tensors.</p>
<p>This operation returns N 1-D integer tensors representing shape of <code>input[i]s</code>.</p>
<p>Args:
  input: A list of at least 1 <code>Tensor</code> objects of the same type.
  name: A name for the operation (optional).</p>
<p>Returns:
  A list with the same number of <code>Tensor</code> objects as <code>input</code> of <code>Tensor</code> objects of type <code>int32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.shape_n', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.shape_n" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.shape_n_layer">
    <p>def <span class="ident">shape_n_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.shape_n_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.shape_n_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.shape_n_layer</strong></p>
<div class="codehilite"><pre><span></span>def shape_n_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.shape_n, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.shape_n</strong></p>
<div class="codehilite"><pre><span></span>def shape_n(input, name=None):
</pre></div>


<p>Returns shape of tensors.</p>
<p>This operation returns N 1-D integer tensors representing shape of <code>input[i]s</code>.</p>
<p>Args:
  input: A list of at least 1 <code>Tensor</code> objects of the same type.
  name: A name for the operation (optional).</p>
<p>Returns:
  A list with the same number of <code>Tensor</code> objects as <code>input</code> of <code>Tensor</code> objects of type <code>int32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.shape_n_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.shape_n_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sigmoid">
    <p>def <span class="ident">sigmoid</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sigmoid, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sigmoid</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sigmoid</strong></p>
<div class="codehilite"><pre><span></span>def sigmoid(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sigmoid</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sigmoid</code></strong></p>
<div class="codehilite"><pre><span></span>def sigmoid(x, name=None)
</pre></div>


<p>Computes sigmoid of <code>x</code> element-wise.</p>
<p>Specifically, <code>y = 1 / (1 + exp(-x))</code>.</p>
<p>Args:
  x: A Tensor with type <code>float</code>, <code>double</code>, <code>int32</code>, <code>complex64</code>, <code>int64</code>,
    or <code>qint32</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A Tensor with the same type as <code>x</code> if <code>x.dtype != qint32</code>
    otherwise the return type is <code>quint8</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sigmoid', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sigmoid" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sigmoid_cross_entropy_with_logits">
    <p>def <span class="ident">sigmoid_cross_entropy_with_logits</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sigmoid_cross_entropy_with_logits, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sigmoid_cross_entropy_with_logits</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sigmoid_cross_entropy_with_logits</strong></p>
<div class="codehilite"><pre><span></span>def sigmoid_cross_entropy_with_logits(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.sigmoid_cross_entropy_with_logits</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.sigmoid_cross_entropy_with_logits</code></strong></p>
<div class="codehilite"><pre><span></span>def sigmoid_cross_entropy_with_logits(logits, targets, name=None)
</pre></div>


<p>Computes sigmoid cross entropy given <code>logits</code>.</p>
<p>Measures the probability error in discrete classification tasks in which each
class is independent and not mutually exclusive.  For instance, one could
perform multilabel classification where a picture can contain both an elephant
and a dog at the same time.</p>
<p>For brevity, let <code>x = logits</code>, <code>z = targets</code>.  The logistic loss is</p>
<div class="codehilite"><pre><span></span>  z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
= z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))
= z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))
= z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))
= (1 - z) * x + log(1 + exp(-x))
= x - x * z + log(1 + exp(-x))
</pre></div>


<p>For x &lt; 0, to avoid overflow in exp(-x), we reformulate the above</p>
<div class="codehilite"><pre><span></span>  x - x * z + log(1 + exp(-x))
= log(exp(x)) - x * z + log(1 + exp(-x))
= - x * z + log(1 + exp(x))
</pre></div>


<p>Hence, to ensure stability and avoid overflow, the implementation uses this
equivalent formulation</p>
<div class="codehilite"><pre><span></span>max(x, 0) - x * z + log(1 + exp(-abs(x)))
</pre></div>


<p><code>logits</code> and <code>targets</code> must have the same type and shape.</p>
<p>Args:
  logits: A <code>Tensor</code> of type <code>float32</code> or <code>float64</code>.
  targets: A <code>Tensor</code> of the same type and shape as <code>logits</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of the same shape as <code>logits</code> with the componentwise
  logistic losses.</p>
<p>Raises:
  ValueError: If <code>logits</code> and <code>targets</code> do not have the same shape.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sigmoid_cross_entropy_with_logits', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sigmoid_cross_entropy_with_logits" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sigmoid_cross_entropy_with_logits_layer">
    <p>def <span class="ident">sigmoid_cross_entropy_with_logits_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sigmoid_cross_entropy_with_logits_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sigmoid_cross_entropy_with_logits_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sigmoid_cross_entropy_with_logits_layer</strong></p>
<div class="codehilite"><pre><span></span>def sigmoid_cross_entropy_with_logits_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.sigmoid_cross_entropy_with_logits, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.sigmoid_cross_entropy_with_logits</strong></p>
<div class="codehilite"><pre><span></span>def sigmoid_cross_entropy_with_logits(logits, targets, name=None):
</pre></div>


<p>Computes sigmoid cross entropy given <code>logits</code>.</p>
<p>Measures the probability error in discrete classification tasks in which each
class is independent and not mutually exclusive.  For instance, one could
perform multilabel classification where a picture can contain both an elephant
and a dog at the same time.</p>
<p>For brevity, let <code>x = logits</code>, <code>z = targets</code>.  The logistic loss is</p>
<div class="codehilite"><pre><span></span>  z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
= z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))
= z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))
= z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))
= (1 - z) * x + log(1 + exp(-x))
= x - x * z + log(1 + exp(-x))
</pre></div>


<p>For x &lt; 0, to avoid overflow in exp(-x), we reformulate the above</p>
<div class="codehilite"><pre><span></span>  x - x * z + log(1 + exp(-x))
= log(exp(x)) - x * z + log(1 + exp(-x))
= - x * z + log(1 + exp(x))
</pre></div>


<p>Hence, to ensure stability and avoid overflow, the implementation uses this
equivalent formulation</p>
<div class="codehilite"><pre><span></span>max(x, 0) - x * z + log(1 + exp(-abs(x)))
</pre></div>


<p><code>logits</code> and <code>targets</code> must have the same type and shape.</p>
<p>Args:
  logits: A <code>Tensor</code> of type <code>float32</code> or <code>float64</code>.
  targets: A <code>Tensor</code> of the same type and shape as <code>logits</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of the same shape as <code>logits</code> with the componentwise
  logistic losses.</p>
<p>Raises:
  ValueError: If <code>logits</code> and <code>targets</code> do not have the same shape.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sigmoid_cross_entropy_with_logits_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sigmoid_cross_entropy_with_logits_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sigmoid_layer">
    <p>def <span class="ident">sigmoid_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sigmoid_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sigmoid_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sigmoid_layer</strong></p>
<div class="codehilite"><pre><span></span>def sigmoid_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sigmoid, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sigmoid</strong></p>
<div class="codehilite"><pre><span></span>def sigmoid(x, name=None):
</pre></div>


<p>Computes sigmoid of <code>x</code> element-wise.</p>
<p>Specifically, <code>y = 1 / (1 + exp(-x))</code>.</p>
<p>Args:
  x: A Tensor with type <code>float</code>, <code>double</code>, <code>int32</code>, <code>complex64</code>, <code>int64</code>,
    or <code>qint32</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A Tensor with the same type as <code>x</code> if <code>x.dtype != qint32</code>
    otherwise the return type is <code>quint8</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sigmoid_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sigmoid_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sign">
    <p>def <span class="ident">sign</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sign, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sign</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sign</strong></p>
<div class="codehilite"><pre><span></span>def sign(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sign</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sign</code></strong></p>
<div class="codehilite"><pre><span></span>def sign(x, name=None)
</pre></div>


<p>Returns an element-wise indication of the sign of a number.</p>
<p><code>y = sign(x) = -1</code> if <code>x &lt; 0</code>; 0 if <code>x == 0</code>; 1 if <code>x &gt; 0</code>.</p>
<p>For complex numbers, <code>y = sign(x) = x / |x|</code> if <code>x != 0</code>, otherwise <code>y = 0</code>.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sign', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sign" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sign_layer">
    <p>def <span class="ident">sign_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sign_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sign_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sign_layer</strong></p>
<div class="codehilite"><pre><span></span>def sign_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sign, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sign</strong></p>
<div class="codehilite"><pre><span></span>def sign(x, name=None):
</pre></div>


<p>Returns an element-wise indication of the sign of a number.</p>
<p><code>y = sign(x) = -1</code> if <code>x &lt; 0</code>; 0 if <code>x == 0</code>; 1 if <code>x &gt; 0</code>.</p>
<p>For complex numbers, <code>y = sign(x) = x / |x|</code> if <code>x != 0</code>, otherwise <code>y = 0</code>.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sign_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sign_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sin">
    <p>def <span class="ident">sin</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sin, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sin</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sin</strong></p>
<div class="codehilite"><pre><span></span>def sin(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sin</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sin</code></strong></p>
<div class="codehilite"><pre><span></span>def sin(x, name=None)
</pre></div>


<p>Computes sin of x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sin', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sin" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sin_layer">
    <p>def <span class="ident">sin_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sin_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sin_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sin_layer</strong></p>
<div class="codehilite"><pre><span></span>def sin_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sin, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sin</strong></p>
<div class="codehilite"><pre><span></span>def sin(x, name=None):
</pre></div>


<p>Computes sin of x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sin_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sin_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.size">
    <p>def <span class="ident">size</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.size, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.size</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.size</strong></p>
<div class="codehilite"><pre><span></span>def size(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.size</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.size</code></strong></p>
<div class="codehilite"><pre><span></span>def size(input, name=None)
</pre></div>


<p>Returns the size of a tensor.</p>
<p>This operation returns an integer representing the number of elements in
<code>input</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'t' is [[[1, 1,, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]]</h1>
<p>size(t) ==&gt; 12
```</p>
<p>Args:
  input: A <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.size', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.size" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.size_layer">
    <p>def <span class="ident">size_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.size_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.size_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.size_layer</strong></p>
<div class="codehilite"><pre><span></span>def size_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.size, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.size</strong></p>
<div class="codehilite"><pre><span></span>def size(input, name=None):
</pre></div>


<p>Returns the size of a tensor.</p>
<p>This operation returns an integer representing the number of elements in
<code>input</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'t' is [[[1, 1,, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]]]</h1>
<p>size(t) ==&gt; 12
```</p>
<p>Args:
  input: A <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.size_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.size_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.slice">
    <p>def <span class="ident">slice</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.slice, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.slice</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.slice</strong></p>
<div class="codehilite"><pre><span></span>def slice(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.slice</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.slice</code></strong></p>
<div class="codehilite"><pre><span></span>def slice(input_, begin, size, name=None)
</pre></div>


<p>Extracts a slice from a tensor.</p>
<p>This operation extracts a slice of size <code>size</code> from a tensor <code>input</code> starting
at the location specified by <code>begin</code>. The slice <code>size</code> is represented as a
tensor shape, where <code>size[i]</code> is the number of elements of the 'i'th dimension
of <code>input</code> that you want to slice. The starting location (<code>begin</code>) for the
slice is represented as an offset in each dimension of <code>input</code>. In other
words, <code>begin[i]</code> is the offset into the 'i'th dimension of <code>input</code> that you
want to slice from.</p>
<p><code>begin</code> is zero-based; <code>size</code> is one-based. If <code>size[i]</code> is -1,
all remaining elements in dimension i are included in the
slice. In other words, this is equivalent to setting:</p>
<p><code>size[i] = input.dim_size(i) - begin[i]</code></p>
<p>This operation requires that:</p>
<p><code>0 &lt;= begin[i] &lt;= begin[i] + size[i] &lt;= Di  for i in [0, n]</code></p>
<p>For example:</p>
<p>```</p>
<h1>'input' is [[[1, 1, 1], [2, 2, 2]],</h1>
<h1>[[3, 3, 3], [4, 4, 4]],</h1>
<h1>[[5, 5, 5], [6, 6, 6]]]</h1>
<p>tf.slice(input, [1, 0, 0], [1, 1, 3]) ==&gt; [[[3, 3, 3]]]
tf.slice(input, [1, 0, 0], [1, 2, 3]) ==&gt; [[[3, 3, 3],
                                            [4, 4, 4]]]
tf.slice(input, [1, 0, 0], [2, 1, 3]) ==&gt; [[[3, 3, 3]],
                                           [[5, 5, 5]]]
```</p>
<p>Args:
  input_: A <code>Tensor</code>.
  begin: An <code>int32</code> or <code>int64</code> <code>Tensor</code>.
  size: An <code>int32</code> or <code>int64</code> <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.slice', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.slice" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.slice_layer">
    <p>def <span class="ident">slice_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.slice_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.slice_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.slice_layer</strong></p>
<div class="codehilite"><pre><span></span>def slice_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.slice, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.slice</strong></p>
<div class="codehilite"><pre><span></span>def slice(input_, begin, size, name=None):
</pre></div>


<p>Extracts a slice from a tensor.</p>
<p>This operation extracts a slice of size <code>size</code> from a tensor <code>input</code> starting
at the location specified by <code>begin</code>. The slice <code>size</code> is represented as a
tensor shape, where <code>size[i]</code> is the number of elements of the 'i'th dimension
of <code>input</code> that you want to slice. The starting location (<code>begin</code>) for the
slice is represented as an offset in each dimension of <code>input</code>. In other
words, <code>begin[i]</code> is the offset into the 'i'th dimension of <code>input</code> that you
want to slice from.</p>
<p><code>begin</code> is zero-based; <code>size</code> is one-based. If <code>size[i]</code> is -1,
all remaining elements in dimension i are included in the
slice. In other words, this is equivalent to setting:</p>
<p><code>size[i] = input.dim_size(i) - begin[i]</code></p>
<p>This operation requires that:</p>
<p><code>0 &lt;= begin[i] &lt;= begin[i] + size[i] &lt;= Di  for i in [0, n]</code></p>
<p>For example:</p>
<p>```</p>
<h1>'input' is [[[1, 1, 1], [2, 2, 2]],</h1>
<h1>[[3, 3, 3], [4, 4, 4]],</h1>
<h1>[[5, 5, 5], [6, 6, 6]]]</h1>
<p>tf.slice(input, [1, 0, 0], [1, 1, 3]) ==&gt; [[[3, 3, 3]]]
tf.slice(input, [1, 0, 0], [1, 2, 3]) ==&gt; [[[3, 3, 3],
                                            [4, 4, 4]]]
tf.slice(input, [1, 0, 0], [2, 1, 3]) ==&gt; [[[3, 3, 3]],
                                           [[5, 5, 5]]]
```</p>
<p>Args:
  input_: A <code>Tensor</code>.
  begin: An <code>int32</code> or <code>int64</code> <code>Tensor</code>.
  size: An <code>int32</code> or <code>int64</code> <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.slice_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.slice_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.softmax">
    <p>def <span class="ident">softmax</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.softmax, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.softmax</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.softmax</strong></p>
<div class="codehilite"><pre><span></span>def softmax(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.softmax</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.softmax</code></strong></p>
<div class="codehilite"><pre><span></span>def softmax(logits, name=None)
</pre></div>


<p>Computes softmax activations.</p>
<p>For each batch <code>i</code> and class <code>j</code> we have</p>
<div class="codehilite"><pre><span></span>softmax[i, j] = exp(logits[i, j]) / sum(exp(logits[i]))
</pre></div>


<p>Args:
  logits: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
    2-D with shape <code>[batch_size, num_classes]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>logits</code>. Same shape as <code>logits</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.softmax', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.softmax" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.softmax_cross_entropy_with_logits">
    <p>def <span class="ident">softmax_cross_entropy_with_logits</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.softmax_cross_entropy_with_logits, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.softmax_cross_entropy_with_logits</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.softmax_cross_entropy_with_logits</strong></p>
<div class="codehilite"><pre><span></span>def softmax_cross_entropy_with_logits(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.softmax_cross_entropy_with_logits</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.softmax_cross_entropy_with_logits</code></strong></p>
<div class="codehilite"><pre><span></span>def softmax_cross_entropy_with_logits(logits, labels, name=None)
</pre></div>


<p>Computes softmax cross entropy between <code>logits</code> and <code>labels</code>.</p>
<p>Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both.</p>
<p><strong>NOTE:</strong>  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of <code>labels</code> is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect.</p>
<p>If using exclusive <code>labels</code> (wherein one and only
one class is true at a time), see <code>sparse_softmax_cross_entropy_with_logits</code>.</p>
<p><strong>WARNING:</strong> This op expects unscaled logits, since it performs a <code>softmax</code>
on <code>logits</code> internally for efficiency.  Do not call this op with the
output of <code>softmax</code>, as it will produce incorrect results.</p>
<p><code>logits</code> and <code>labels</code> must have the same shape <code>[batch_size, num_classes]</code>
and the same dtype (either <code>float32</code> or <code>float64</code>).</p>
<p>Args:
  logits: Unscaled log probabilities.
  labels: Each row <code>labels[i]</code> must be a valid probability distribution.
  name: A name for the operation (optional).</p>
<p>Returns:
  A 1-D <code>Tensor</code> of length <code>batch_size</code> of the same type as <code>logits</code> with the
  softmax cross entropy loss.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.softmax_cross_entropy_with_logits', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.softmax_cross_entropy_with_logits" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.softmax_cross_entropy_with_logits_layer">
    <p>def <span class="ident">softmax_cross_entropy_with_logits_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.softmax_cross_entropy_with_logits_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.softmax_cross_entropy_with_logits_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.softmax_cross_entropy_with_logits_layer</strong></p>
<div class="codehilite"><pre><span></span>def softmax_cross_entropy_with_logits_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.softmax_cross_entropy_with_logits, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.softmax_cross_entropy_with_logits</strong></p>
<div class="codehilite"><pre><span></span>def softmax_cross_entropy_with_logits(logits, labels, name=None):
</pre></div>


<p>Computes softmax cross entropy between <code>logits</code> and <code>labels</code>.</p>
<p>Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both.</p>
<p><strong>NOTE:</strong>  While the classes are mutually exclusive, their probabilities
need not be.  All that is required is that each row of <code>labels</code> is
a valid probability distribution.  If they are not, the computation of the
gradient will be incorrect.</p>
<p>If using exclusive <code>labels</code> (wherein one and only
one class is true at a time), see <code>sparse_softmax_cross_entropy_with_logits</code>.</p>
<p><strong>WARNING:</strong> This op expects unscaled logits, since it performs a <code>softmax</code>
on <code>logits</code> internally for efficiency.  Do not call this op with the
output of <code>softmax</code>, as it will produce incorrect results.</p>
<p><code>logits</code> and <code>labels</code> must have the same shape <code>[batch_size, num_classes]</code>
and the same dtype (either <code>float32</code> or <code>float64</code>).</p>
<p>Args:
  logits: Unscaled log probabilities.
  labels: Each row <code>labels[i]</code> must be a valid probability distribution.
  name: A name for the operation (optional).</p>
<p>Returns:
  A 1-D <code>Tensor</code> of length <code>batch_size</code> of the same type as <code>logits</code> with the
  softmax cross entropy loss.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.softmax_cross_entropy_with_logits_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.softmax_cross_entropy_with_logits_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.softmax_layer">
    <p>def <span class="ident">softmax_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.softmax_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.softmax_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.softmax_layer</strong></p>
<div class="codehilite"><pre><span></span>def softmax_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.softmax, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.softmax</strong></p>
<div class="codehilite"><pre><span></span>def softmax(logits, name=None):
</pre></div>


<p>Computes softmax activations.</p>
<p>For each batch <code>i</code> and class <code>j</code> we have</p>
<div class="codehilite"><pre><span></span>softmax[i, j] = exp(logits[i, j]) / sum(exp(logits[i]))
</pre></div>


<p>Args:
  logits: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>.
    2-D with shape <code>[batch_size, num_classes]</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>logits</code>. Same shape as <code>logits</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.softmax_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.softmax_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.softplus">
    <p>def <span class="ident">softplus</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.softplus, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.softplus</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.softplus</strong></p>
<div class="codehilite"><pre><span></span>def softplus(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.softplus</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.softplus</code></strong></p>
<div class="codehilite"><pre><span></span>def softplus(features, name=None)
</pre></div>


<p>Computes softplus: <code>log(exp(features) + 1)</code>.</p>
<p>Args:
  features: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>features</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.softplus', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.softplus" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.softplus_layer">
    <p>def <span class="ident">softplus_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.softplus_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.softplus_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.softplus_layer</strong></p>
<div class="codehilite"><pre><span></span>def softplus_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.softplus, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.softplus</strong></p>
<div class="codehilite"><pre><span></span>def softplus(features, name=None):
</pre></div>


<p>Computes softplus: <code>log(exp(features) + 1)</code>.</p>
<p>Args:
  features: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>features</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.softplus_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.softplus_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.softsign">
    <p>def <span class="ident">softsign</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.softsign, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.softsign</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.softsign</strong></p>
<div class="codehilite"><pre><span></span>def softsign(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.softsign</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.softsign</code></strong></p>
<div class="codehilite"><pre><span></span>def softsign(features, name=None)
</pre></div>


<p>Computes softsign: <code>features / (abs(features) + 1)</code>.</p>
<p>Args:
  features: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>features</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.softsign', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.softsign" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.softsign_layer">
    <p>def <span class="ident">softsign_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.softsign_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.softsign_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.softsign_layer</strong></p>
<div class="codehilite"><pre><span></span>def softsign_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.softsign, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.softsign</strong></p>
<div class="codehilite"><pre><span></span>def softsign(features, name=None):
</pre></div>


<p>Computes softsign: <code>features / (abs(features) + 1)</code>.</p>
<p>Args:
  features: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>features</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.softsign_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.softsign_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.space_to_batch">
    <p>def <span class="ident">space_to_batch</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.space_to_batch, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.space_to_batch</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.space_to_batch</strong></p>
<div class="codehilite"><pre><span></span>def space_to_batch(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.space_to_batch</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.space_to_batch</code></strong></p>
<div class="codehilite"><pre><span></span>def space_to_batch(input, paddings, block_size, name=None)
</pre></div>


<p>SpaceToBatch for 4-D tensors of type T.</p>
<p>Zero-pads and then rearranges (permutes) blocks of spatial data into batch.
More specifically, this op outputs a copy of the input tensor where values from
the <code>height</code> and <code>width</code> dimensions are moved to the <code>batch</code> dimension. After
the zero-padding, both <code>height</code> and <code>width</code> of the input must be divisible by the
block size.</p>
<p>Args:
  input: A <code>Tensor</code>. 4-D with shape <code>[batch, height, width, depth]</code>.
  paddings: A <code>Tensor</code> of type <code>int32</code>.
    2-D tensor of non-negative integers with shape <code>[2, 2]</code>. It specifies
      the padding of the input with zeros across the spatial dimensions as follows:</p>
<div class="codehilite"><pre><span></span>      paddings = [[pad_top, pad_bottom], [pad_left, pad_right]]

  The effective spatial dimensions of the zero-padded input tensor will be:

      height_pad = pad_top + height + pad_bottom
      width_pad = pad_left + width + pad_right

The attr `block_size` must be greater than one. It indicates the block size.

  * Non-overlapping blocks of size `block_size x block size` in the height and
    width dimensions are rearranged into the batch dimension at each location.
  * The batch of the output tensor is `batch * block_size * block_size`.
  * Both height_pad and width_pad must be divisible by block_size.

The shape of the output will be:

    [batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
     depth]
</pre></div>


<p>block_size: An <code>int</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.space_to_batch', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.space_to_batch" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.space_to_batch_layer">
    <p>def <span class="ident">space_to_batch_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.space_to_batch_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.space_to_batch_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.space_to_batch_layer</strong></p>
<div class="codehilite"><pre><span></span>def space_to_batch_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.space_to_batch, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.space_to_batch</strong></p>
<div class="codehilite"><pre><span></span>def space_to_batch(input, paddings, block_size, name=None):
</pre></div>


<p>SpaceToBatch for 4-D tensors of type T.</p>
<p>Zero-pads and then rearranges (permutes) blocks of spatial data into batch.
More specifically, this op outputs a copy of the input tensor where values from
the <code>height</code> and <code>width</code> dimensions are moved to the <code>batch</code> dimension. After
the zero-padding, both <code>height</code> and <code>width</code> of the input must be divisible by the
block size.</p>
<p>Args:
  input: A <code>Tensor</code>. 4-D with shape <code>[batch, height, width, depth]</code>.
  paddings: A <code>Tensor</code> of type <code>int32</code>.
    2-D tensor of non-negative integers with shape <code>[2, 2]</code>. It specifies
      the padding of the input with zeros across the spatial dimensions as follows:</p>
<div class="codehilite"><pre><span></span>      paddings = [[pad_top, pad_bottom], [pad_left, pad_right]]

  The effective spatial dimensions of the zero-padded input tensor will be:

      height_pad = pad_top + height + pad_bottom
      width_pad = pad_left + width + pad_right

The attr `block_size` must be greater than one. It indicates the block size.

  * Non-overlapping blocks of size `block_size x block size` in the height and
    width dimensions are rearranged into the batch dimension at each location.
  * The batch of the output tensor is `batch * block_size * block_size`.
  * Both height_pad and width_pad must be divisible by block_size.

The shape of the output will be:

    [batch*block_size*block_size, height_pad/block_size, width_pad/block_size,
     depth]
</pre></div>


<p>block_size: An <code>int</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.space_to_batch_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.space_to_batch_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.space_to_depth">
    <p>def <span class="ident">space_to_depth</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.space_to_depth, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.space_to_depth</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.space_to_depth</strong></p>
<div class="codehilite"><pre><span></span>def space_to_depth(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.space_to_depth</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.space_to_depth</code></strong></p>
<div class="codehilite"><pre><span></span>def space_to_depth(input, block_size, name=None)
</pre></div>


<p>SpaceToDepth for tensors of type T.</p>
<p>Rearranges blocks of spatial data, into depth. More specifically,
this op outputs a copy of the input tensor where values from the <code>height</code>
and <code>width</code> dimensions are moved to the <code>depth</code> dimension.
The attr <code>block_size</code> indicates the input block size and how the data is moved.</p>
<ul>
<li>Non-overlapping blocks of size <code>block_size x block size</code> are rearranged
    into depth at each location.</li>
<li>The depth of the output tensor is <code>input_depth * block_size * block_size</code>.</li>
<li>The input tensor's height and width must be divisible by block_size.</li>
</ul>
<p>That is, assuming the input is in the shape:
<code>[batch, height, width, depth]</code>,
the shape of the output will be:
<code>[batch, height/block_size, width/block_size, depth*block_size*block_size]</code></p>
<p>This operation requires that the input tensor be of rank 4, and that
<code>block_size</code> be &gt;=1 and a divisor of both the input <code>height</code> and <code>width</code>.</p>
<p>This operation is useful for resizing the activations between convolutions
(but keeping all data), e.g. instead of pooling. It is also useful for training
purely convolutional models.</p>
<p>For example, given this input of shape <code>[1, 2, 2, 1]</code>, and block_size of 2:</p>
<p><code>prettyprint
x = [[[[1], [2]],
      [[3], [4]]]]</code></p>
<p>This operation will output a tensor of shape <code>[1, 1, 1, 4]</code>:</p>
<p><code>prettyprint
[[[[1, 2, 3, 4]]]]</code></p>
<p>Here, the input has a batch of 1 and each batch element has shape <code>[2, 2, 1]</code>,
the corresponding output will have a single element (i.e. width and height are
both 1) and will have a depth of 4 channels (1 * block_size * block_size).
The output element shape is <code>[1, 1, 4]</code>.</p>
<p>For an input tensor with larger depth, here of shape <code>[1, 2, 2, 3]</code>, e.g.</p>
<p><code>prettyprint
x = [[[[1, 2, 3], [4, 5, 6]],
      [[7, 8, 9], [10, 11, 12]]]]</code></p>
<p>This operation, for block_size of 2, will return the following tensor of shape
<code>[1, 1, 1, 12]</code></p>
<p><code>prettyprint
[[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]</code></p>
<p>Similarly, for the following input of shape <code>[1 4 4 1]</code>, and a block size of 2:</p>
<p><code>prettyprint
x = [[[[1],   [2],  [5],  [6]],
      [[3],   [4],  [7],  [8]],
      [[9],  [10], [13],  [14]],
      [[11], [12], [15],  [16]]]]</code></p>
<p>the operator will return the following tensor of shape <code>[1 2 2 4]</code>:</p>
<p><code>prettyprint
x = [[[[1, 2, 3, 4],
       [5, 6, 7, 8]],
      [[9, 10, 11, 12],
       [13, 14, 15, 16]]]]</code></p>
<p>Args:
  input: A <code>Tensor</code>.
  block_size: An <code>int</code>. The size of the spatial block.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.space_to_depth', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.space_to_depth" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.space_to_depth_layer">
    <p>def <span class="ident">space_to_depth_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.space_to_depth_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.space_to_depth_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.space_to_depth_layer</strong></p>
<div class="codehilite"><pre><span></span>def space_to_depth_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.space_to_depth, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.space_to_depth</strong></p>
<div class="codehilite"><pre><span></span>def space_to_depth(input, block_size, name=None):
</pre></div>


<p>SpaceToDepth for tensors of type T.</p>
<p>Rearranges blocks of spatial data, into depth. More specifically,
this op outputs a copy of the input tensor where values from the <code>height</code>
and <code>width</code> dimensions are moved to the <code>depth</code> dimension.
The attr <code>block_size</code> indicates the input block size and how the data is moved.</p>
<ul>
<li>Non-overlapping blocks of size <code>block_size x block size</code> are rearranged
    into depth at each location.</li>
<li>The depth of the output tensor is <code>input_depth * block_size * block_size</code>.</li>
<li>The input tensor's height and width must be divisible by block_size.</li>
</ul>
<p>That is, assuming the input is in the shape:
<code>[batch, height, width, depth]</code>,
the shape of the output will be:
<code>[batch, height/block_size, width/block_size, depth*block_size*block_size]</code></p>
<p>This operation requires that the input tensor be of rank 4, and that
<code>block_size</code> be &gt;=1 and a divisor of both the input <code>height</code> and <code>width</code>.</p>
<p>This operation is useful for resizing the activations between convolutions
(but keeping all data), e.g. instead of pooling. It is also useful for training
purely convolutional models.</p>
<p>For example, given this input of shape <code>[1, 2, 2, 1]</code>, and block_size of 2:</p>
<p><code>prettyprint
x = [[[[1], [2]],
      [[3], [4]]]]</code></p>
<p>This operation will output a tensor of shape <code>[1, 1, 1, 4]</code>:</p>
<p><code>prettyprint
[[[[1, 2, 3, 4]]]]</code></p>
<p>Here, the input has a batch of 1 and each batch element has shape <code>[2, 2, 1]</code>,
the corresponding output will have a single element (i.e. width and height are
both 1) and will have a depth of 4 channels (1 * block_size * block_size).
The output element shape is <code>[1, 1, 4]</code>.</p>
<p>For an input tensor with larger depth, here of shape <code>[1, 2, 2, 3]</code>, e.g.</p>
<p><code>prettyprint
x = [[[[1, 2, 3], [4, 5, 6]],
      [[7, 8, 9], [10, 11, 12]]]]</code></p>
<p>This operation, for block_size of 2, will return the following tensor of shape
<code>[1, 1, 1, 12]</code></p>
<p><code>prettyprint
[[[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]]]]</code></p>
<p>Similarly, for the following input of shape <code>[1 4 4 1]</code>, and a block size of 2:</p>
<p><code>prettyprint
x = [[[[1],   [2],  [5],  [6]],
      [[3],   [4],  [7],  [8]],
      [[9],  [10], [13],  [14]],
      [[11], [12], [15],  [16]]]]</code></p>
<p>the operator will return the following tensor of shape <code>[1 2 2 4]</code>:</p>
<p><code>prettyprint
x = [[[[1, 2, 3, 4],
       [5, 6, 7, 8]],
      [[9, 10, 11, 12],
       [13, 14, 15, 16]]]]</code></p>
<p>Args:
  input: A <code>Tensor</code>.
  block_size: An <code>int</code>. The size of the spatial block.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.space_to_depth_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.space_to_depth_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_add">
    <p>def <span class="ident">sparse_add</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_add, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_add</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_add</strong></p>
<div class="codehilite"><pre><span></span>def sparse_add(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_add</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_add</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_add(a, b, thresh=0)
</pre></div>


<p>Adds two tensors, at least one of each is a <code>SparseTensor</code>.</p>
<p>If one <code>SparseTensor</code> and one <code>Tensor</code> are passed in, returns a <code>Tensor</code>.  If
both arguments are <code>SparseTensor</code>s, this returns a <code>SparseTensor</code>.  The order
of arguments does not matter.  Use vanilla <code>tf.add()</code> for adding two dense
<code>Tensor</code>s.</p>
<p>The indices of any input <code>SparseTensor</code> are assumed ordered in standard
lexicographic order.  If this is not the case, before this step run
<code>SparseReorder</code> to restore index ordering.</p>
<p>If both arguments are sparse, we perform "clipping" as follows.  By default,
if two values sum to zero at some index, the output <code>SparseTensor</code> would still
include that particular location in its index, storing a zero in the
corresponding value slot.  To override this, callers can specify <code>thresh</code>,
indicating that if the sum has a magnitude strictly smaller than <code>thresh</code>, its
corresponding value and index would then not be included.  In particular,
<code>thresh == 0.0</code> (default) means everything is kept and actual thresholding
happens only for a positive value.</p>
<p>For example, suppose the logical sum of two sparse operands is (densified):</p>
<div class="codehilite"><pre><span></span><span class="k">[       2]</span>
<span class="k">[.1     0]</span>
<span class="k">[ 6   -.2]</span>
</pre></div>


<p>Then,</p>
<div class="codehilite"><pre><span></span>- thresh == 0 (the default): all 5 index/value pairs will be returned.
- thresh == 0.11: only .1 and 0  will vanish, and the remaining three
    index/value pairs will be returned.
- thresh == 0.21: .1, 0, and -.2 will vanish.
</pre></div>


<p>Args:
  a: The first operand; <code>SparseTensor</code> or <code>Tensor</code>.
  b: The second operand; <code>SparseTensor</code> or <code>Tensor</code>.  At least one operand
    must be sparse.
  thresh: A 0-D <code>Tensor</code>.  The magnitude threshold that determines if an
  output value/index pair takes space.  Its dtype should match that of the
  values if they are real; if the latter are complex64/complex128, then the
  dtype should be float32/float64, correspondingly.</p>
<p>Returns:
  A <code>SparseTensor</code> or a <code>Tensor</code>, representing the sum.</p>
<p>Raises:
  TypeError: If both <code>a</code> and <code>b</code> are <code>Tensor</code>s.  Use <code>tf.add()</code> instead.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_add', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_add" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_add_layer">
    <p>def <span class="ident">sparse_add_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_add_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_add_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_add_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_add_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_add, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_add</strong></p>
<div class="codehilite"><pre><span></span>def sparse_add(a, b, thresh=0):
</pre></div>


<p>Adds two tensors, at least one of each is a <code>SparseTensor</code>.</p>
<p>If one <code>SparseTensor</code> and one <code>Tensor</code> are passed in, returns a <code>Tensor</code>.  If
both arguments are <code>SparseTensor</code>s, this returns a <code>SparseTensor</code>.  The order
of arguments does not matter.  Use vanilla <code>tf.add()</code> for adding two dense
<code>Tensor</code>s.</p>
<p>The indices of any input <code>SparseTensor</code> are assumed ordered in standard
lexicographic order.  If this is not the case, before this step run
<code>SparseReorder</code> to restore index ordering.</p>
<p>If both arguments are sparse, we perform "clipping" as follows.  By default,
if two values sum to zero at some index, the output <code>SparseTensor</code> would still
include that particular location in its index, storing a zero in the
corresponding value slot.  To override this, callers can specify <code>thresh</code>,
indicating that if the sum has a magnitude strictly smaller than <code>thresh</code>, its
corresponding value and index would then not be included.  In particular,
<code>thresh == 0.0</code> (default) means everything is kept and actual thresholding
happens only for a positive value.</p>
<p>For example, suppose the logical sum of two sparse operands is (densified):</p>
<div class="codehilite"><pre><span></span><span class="k">[       2]</span>
<span class="k">[.1     0]</span>
<span class="k">[ 6   -.2]</span>
</pre></div>


<p>Then,</p>
<div class="codehilite"><pre><span></span>- thresh == 0 (the default): all 5 index/value pairs will be returned.
- thresh == 0.11: only .1 and 0  will vanish, and the remaining three
    index/value pairs will be returned.
- thresh == 0.21: .1, 0, and -.2 will vanish.
</pre></div>


<p>Args:
  a: The first operand; <code>SparseTensor</code> or <code>Tensor</code>.
  b: The second operand; <code>SparseTensor</code> or <code>Tensor</code>.  At least one operand
    must be sparse.
  thresh: A 0-D <code>Tensor</code>.  The magnitude threshold that determines if an
  output value/index pair takes space.  Its dtype should match that of the
  values if they are real; if the latter are complex64/complex128, then the
  dtype should be float32/float64, correspondingly.</p>
<p>Returns:
  A <code>SparseTensor</code> or a <code>Tensor</code>, representing the sum.</p>
<p>Raises:
  TypeError: If both <code>a</code> and <code>b</code> are <code>Tensor</code>s.  Use <code>tf.add()</code> instead.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_add_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_add_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_concat">
    <p>def <span class="ident">sparse_concat</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_concat, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_concat</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_concat</strong></p>
<div class="codehilite"><pre><span></span>def sparse_concat(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_concat</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_concat</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_concat(concat_dim, sp_inputs, name=None, expand_nonconcat_dim=False)
</pre></div>


<p>Concatenates a list of <code>SparseTensor</code> along the specified dimension.</p>
<p>Concatenation is with respect to the dense versions of each sparse input.
It is assumed that each inputs is a <code>SparseTensor</code> whose elements are ordered
along increasing dimension number.</p>
<p>If expand_nonconcat_dim is False, all inputs' shapes must match, except for
the concat dimension. If expand_nonconcat_dim is True, then inputs' shapes are
allowd to vary among all inputs.</p>
<p>The <code>indices</code>, <code>values</code>, and <code>shapes</code> lists must have the same length.</p>
<p>If expand_nonconcat_dim is False, then the output shape is identical to the
inputs', except along the concat dimension, where it is the sum of the inputs'
sizes along that dimension.</p>
<p>If expand_nonconcat_dim is True, then the output shape along the non-concat
dimensions will be expand to be the largest among all inputs, and it is the
sum of the inputs sizes along the concat dimension.</p>
<p>The output elements will be resorted to preserve the sort order along
increasing dimension number.</p>
<p>This op runs in <code>O(M log M)</code> time, where <code>M</code> is the total number of non-empty
values across all inputs. This is due to the need for an internal sort in
order to concatenate efficiently across an arbitrary dimension.</p>
<p>For example, if <code>concat_dim = 1</code> and the inputs are</p>
<div class="codehilite"><pre><span></span>sp_inputs[0]: shape = [2, 3]
[0, 2]: &quot;a&quot;
[1, 0]: &quot;b&quot;
[1, 1]: &quot;c&quot;

sp_inputs[1]: shape = [2, 4]
[0, 1]: &quot;d&quot;
[0, 2]: &quot;e&quot;
</pre></div>


<p>then the output will be</p>
<div class="codehilite"><pre><span></span>shape = [2, 7]
[0, 2]: &quot;a&quot;
[0, 4]: &quot;d&quot;
[0, 5]: &quot;e&quot;
[1, 0]: &quot;b&quot;
[1, 1]: &quot;c&quot;
</pre></div>


<p>Graphically this is equivalent to doing</p>
<div class="codehilite"><pre><span></span><span class="k">[    a] concat [  d e  ] = [    a   d e  ]</span>
<span class="k">[b c  ]        [       ]   [b c          ]</span>
</pre></div>


<p>Another example, if 'concat_dim = 1' and the inputs are</p>
<div class="codehilite"><pre><span></span>sp_inputs[0]: shape = [3, 3]
[0, 2]: &quot;a&quot;
[1, 0]: &quot;b&quot;
[2, 1]: &quot;c&quot;

sp_inputs[1]: shape = [2, 4]
[0, 1]: &quot;d&quot;
[0, 2]: &quot;e&quot;
</pre></div>


<p>if expand_nonconcat_dim = False, this will result in an error. But if
expand_nonconcat_dim = True, this will result in:</p>
<div class="codehilite"><pre><span></span>shape = [3, 7]
[0, 2]: &quot;a&quot;
[0, 4]: &quot;d&quot;
[0, 5]: &quot;e&quot;
[1, 0]: &quot;b&quot;
[2, 1]: &quot;c&quot;
</pre></div>


<p>Graphically this is equivalent to doing</p>
<div class="codehilite"><pre><span></span><span class="k">[    a] concat [  d e  ] = [    a   d e  ]</span>
<span class="k">[b    ]        [       ]   [b            ]</span>
<span class="k">[  c  ]                    [  c          ]</span>
</pre></div>


<p>Args:
  concat_dim: Dimension to concatenate along.
  sp_inputs: List of <code>SparseTensor</code> to concatenate.
  name: A name prefix for the returned tensors (optional).
  expand_nonconcat_dim: Whether to allow the expansion in the non-concat
    dimensions. Defaulted to False.</p>
<p>Returns:
  A <code>SparseTensor</code> with the concatenated output.</p>
<p>Raises:
  TypeError: If <code>sp_inputs</code> is not a list of <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_concat', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_concat" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_concat_layer">
    <p>def <span class="ident">sparse_concat_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_concat_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_concat_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_concat_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_concat_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_concat, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_concat</strong></p>
<div class="codehilite"><pre><span></span>def sparse_concat(concat_dim, sp_inputs, name=None, expand_nonconcat_dim=False):
</pre></div>


<p>Concatenates a list of <code>SparseTensor</code> along the specified dimension.</p>
<p>Concatenation is with respect to the dense versions of each sparse input.
It is assumed that each inputs is a <code>SparseTensor</code> whose elements are ordered
along increasing dimension number.</p>
<p>If expand_nonconcat_dim is False, all inputs' shapes must match, except for
the concat dimension. If expand_nonconcat_dim is True, then inputs' shapes are
allowd to vary among all inputs.</p>
<p>The <code>indices</code>, <code>values</code>, and <code>shapes</code> lists must have the same length.</p>
<p>If expand_nonconcat_dim is False, then the output shape is identical to the
inputs', except along the concat dimension, where it is the sum of the inputs'
sizes along that dimension.</p>
<p>If expand_nonconcat_dim is True, then the output shape along the non-concat
dimensions will be expand to be the largest among all inputs, and it is the
sum of the inputs sizes along the concat dimension.</p>
<p>The output elements will be resorted to preserve the sort order along
increasing dimension number.</p>
<p>This op runs in <code>O(M log M)</code> time, where <code>M</code> is the total number of non-empty
values across all inputs. This is due to the need for an internal sort in
order to concatenate efficiently across an arbitrary dimension.</p>
<p>For example, if <code>concat_dim = 1</code> and the inputs are</p>
<div class="codehilite"><pre><span></span>sp_inputs[0]: shape = [2, 3]
[0, 2]: &quot;a&quot;
[1, 0]: &quot;b&quot;
[1, 1]: &quot;c&quot;

sp_inputs[1]: shape = [2, 4]
[0, 1]: &quot;d&quot;
[0, 2]: &quot;e&quot;
</pre></div>


<p>then the output will be</p>
<div class="codehilite"><pre><span></span>shape = [2, 7]
[0, 2]: &quot;a&quot;
[0, 4]: &quot;d&quot;
[0, 5]: &quot;e&quot;
[1, 0]: &quot;b&quot;
[1, 1]: &quot;c&quot;
</pre></div>


<p>Graphically this is equivalent to doing</p>
<div class="codehilite"><pre><span></span><span class="k">[    a] concat [  d e  ] = [    a   d e  ]</span>
<span class="k">[b c  ]        [       ]   [b c          ]</span>
</pre></div>


<p>Another example, if 'concat_dim = 1' and the inputs are</p>
<div class="codehilite"><pre><span></span>sp_inputs[0]: shape = [3, 3]
[0, 2]: &quot;a&quot;
[1, 0]: &quot;b&quot;
[2, 1]: &quot;c&quot;

sp_inputs[1]: shape = [2, 4]
[0, 1]: &quot;d&quot;
[0, 2]: &quot;e&quot;
</pre></div>


<p>if expand_nonconcat_dim = False, this will result in an error. But if
expand_nonconcat_dim = True, this will result in:</p>
<div class="codehilite"><pre><span></span>shape = [3, 7]
[0, 2]: &quot;a&quot;
[0, 4]: &quot;d&quot;
[0, 5]: &quot;e&quot;
[1, 0]: &quot;b&quot;
[2, 1]: &quot;c&quot;
</pre></div>


<p>Graphically this is equivalent to doing</p>
<div class="codehilite"><pre><span></span><span class="k">[    a] concat [  d e  ] = [    a   d e  ]</span>
<span class="k">[b    ]        [       ]   [b            ]</span>
<span class="k">[  c  ]                    [  c          ]</span>
</pre></div>


<p>Args:
  concat_dim: Dimension to concatenate along.
  sp_inputs: List of <code>SparseTensor</code> to concatenate.
  name: A name prefix for the returned tensors (optional).
  expand_nonconcat_dim: Whether to allow the expansion in the non-concat
    dimensions. Defaulted to False.</p>
<p>Returns:
  A <code>SparseTensor</code> with the concatenated output.</p>
<p>Raises:
  TypeError: If <code>sp_inputs</code> is not a list of <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_concat_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_concat_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_fill_empty_rows">
    <p>def <span class="ident">sparse_fill_empty_rows</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_fill_empty_rows, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_fill_empty_rows</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_fill_empty_rows</strong></p>
<div class="codehilite"><pre><span></span>def sparse_fill_empty_rows(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_fill_empty_rows</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_fill_empty_rows</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_fill_empty_rows(sp_input, default_value, name=None)
</pre></div>


<p>Fills empty rows in the input 2-D <code>SparseTensor</code> with a default value.</p>
<p>This op adds entries with the specified <code>default_value</code> at index
<code>[row, 0]</code> for any row in the input that does not already have a value.</p>
<p>For example, suppose <code>sp_input</code> has shape <code>[5, 6]</code> and non-empty values:</p>
<div class="codehilite"><pre><span></span>[0, 1]: a
[0, 3]: b
[2, 0]: c
[3, 1]: d
</pre></div>


<p>Rows 1 and 4 are empty, so the output will be of shape <code>[5, 6]</code> with values:</p>
<div class="codehilite"><pre><span></span>[0, 1]: a
[0, 3]: b
[1, 0]: default_value
[2, 0]: c
[3, 1]: d
[4, 0]: default_value
</pre></div>


<p>Note that the input may have empty columns at the end, with no effect on
this op.</p>
<p>The output <code>SparseTensor</code> will be in row-major order and will have the
same shape as the input.</p>
<p>This op also returns an indicator vector such that</p>
<div class="codehilite"><pre><span></span>empty_row_indicator[i] = True iff row i was an empty row.
</pre></div>


<p>Args:
  sp_input: A <code>SparseTensor</code> with shape <code>[N, M]</code>.
  default_value: The value to fill for empty rows, with the same type as
    <code>sp_input.</code>
  name: A name prefix for the returned tensors (optional)</p>
<p>Returns:
  sp_ordered_output: A <code>SparseTensor</code> with shape <code>[N, M]</code>, and with all empty
    rows filled in with <code>default_value</code>.
  empty_row_indicator: A bool vector of length <code>N</code> indicating whether each
    input row was empty.</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_fill_empty_rows', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_fill_empty_rows" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_fill_empty_rows_layer">
    <p>def <span class="ident">sparse_fill_empty_rows_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_fill_empty_rows_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_fill_empty_rows_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_fill_empty_rows_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_fill_empty_rows_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_fill_empty_rows, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_fill_empty_rows</strong></p>
<div class="codehilite"><pre><span></span>def sparse_fill_empty_rows(sp_input, default_value, name=None):
</pre></div>


<p>Fills empty rows in the input 2-D <code>SparseTensor</code> with a default value.</p>
<p>This op adds entries with the specified <code>default_value</code> at index
<code>[row, 0]</code> for any row in the input that does not already have a value.</p>
<p>For example, suppose <code>sp_input</code> has shape <code>[5, 6]</code> and non-empty values:</p>
<div class="codehilite"><pre><span></span>[0, 1]: a
[0, 3]: b
[2, 0]: c
[3, 1]: d
</pre></div>


<p>Rows 1 and 4 are empty, so the output will be of shape <code>[5, 6]</code> with values:</p>
<div class="codehilite"><pre><span></span>[0, 1]: a
[0, 3]: b
[1, 0]: default_value
[2, 0]: c
[3, 1]: d
[4, 0]: default_value
</pre></div>


<p>Note that the input may have empty columns at the end, with no effect on
this op.</p>
<p>The output <code>SparseTensor</code> will be in row-major order and will have the
same shape as the input.</p>
<p>This op also returns an indicator vector such that</p>
<div class="codehilite"><pre><span></span>empty_row_indicator[i] = True iff row i was an empty row.
</pre></div>


<p>Args:
  sp_input: A <code>SparseTensor</code> with shape <code>[N, M]</code>.
  default_value: The value to fill for empty rows, with the same type as
    <code>sp_input.</code>
  name: A name prefix for the returned tensors (optional)</p>
<p>Returns:
  sp_ordered_output: A <code>SparseTensor</code> with shape <code>[N, M]</code>, and with all empty
    rows filled in with <code>default_value</code>.
  empty_row_indicator: A bool vector of length <code>N</code> indicating whether each
    input row was empty.</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_fill_empty_rows_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_fill_empty_rows_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_mask">
    <p>def <span class="ident">sparse_mask</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_mask, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_mask</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_mask</strong></p>
<div class="codehilite"><pre><span></span>def sparse_mask(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_mask</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_mask</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_mask(a, mask_indices, name=None)
</pre></div>


<p>Masks elements of <code>IndexedSlices</code>.</p>
<p>Given an <code>IndexedSlices</code> instance <code>a</code>, returns another <code>IndexedSlices</code> that
contains a subset of the slices of <code>a</code>. Only the slices at indices specified
in <code>mask_indices</code> are returned.</p>
<p>This is useful when you need to extract a subset of slices in an
<code>IndexedSlices</code> object.</p>
<p>For example:</p>
<p>```python</p>
<h1><code>a</code> contains slices at indices [12, 26, 37, 45] from a large tensor</h1>
<h1>with shape [1000, 10]</h1>
<p>a.indices =&gt; [12, 26, 37, 45]
tf.shape(a.values) =&gt; [4, 10]</p>
<h1><code>b</code> will be the subset of <code>a</code> slices at its second and third indices, so</h1>
<h1>we want to mask of its first and last indices (which are at absolute</h1>
<h1>indices 12, 45)</h1>
<p>b = tf.sparse_mask(a, [12, 45])</p>
<p>b.indices =&gt; [26, 37]
tf.shape(b.values) =&gt; [2, 10]</p>
<p>```</p>
<p>Args:
  * <code>a</code>: An <code>IndexedSlices</code> instance.
  * <code>mask_indices</code>: Indices of elements to mask.
  * <code>name</code>: A name for the operation (optional).</p>
<p>Returns:
  The masked <code>IndexedSlices</code> instance.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_mask', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_mask" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_mask_layer">
    <p>def <span class="ident">sparse_mask_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_mask_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_mask_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_mask_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_mask_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_mask, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_mask</strong></p>
<div class="codehilite"><pre><span></span>def sparse_mask(a, mask_indices, name=None):
</pre></div>


<p>Masks elements of <code>IndexedSlices</code>.</p>
<p>Given an <code>IndexedSlices</code> instance <code>a</code>, returns another <code>IndexedSlices</code> that
contains a subset of the slices of <code>a</code>. Only the slices at indices specified
in <code>mask_indices</code> are returned.</p>
<p>This is useful when you need to extract a subset of slices in an
<code>IndexedSlices</code> object.</p>
<p>For example:</p>
<p>```python</p>
<h1><code>a</code> contains slices at indices [12, 26, 37, 45] from a large tensor</h1>
<h1>with shape [1000, 10]</h1>
<p>a.indices =&gt; [12, 26, 37, 45]
tf.shape(a.values) =&gt; [4, 10]</p>
<h1><code>b</code> will be the subset of <code>a</code> slices at its second and third indices, so</h1>
<h1>we want to mask of its first and last indices (which are at absolute</h1>
<h1>indices 12, 45)</h1>
<p>b = tf.sparse_mask(a, [12, 45])</p>
<p>b.indices =&gt; [26, 37]
tf.shape(b.values) =&gt; [2, 10]</p>
<p>```</p>
<p>Args:
  * <code>a</code>: An <code>IndexedSlices</code> instance.
  * <code>mask_indices</code>: Indices of elements to mask.
  * <code>name</code>: A name for the operation (optional).</p>
<p>Returns:
  The masked <code>IndexedSlices</code> instance.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_mask_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_mask_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_matmul_layer">
    <p>def <span class="ident">sparse_matmul_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_matmul_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_matmul_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_matmul_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_matmul_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_matmul, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_matmul</strong></p>
<div class="codehilite"><pre><span></span>def _sparse_mat_mul(a, b, transpose_a=None, transpose_b=None, a_is_sparse=None, b_is_sparse=None, name=None):
</pre></div>


<p>Multiply matrix "a" by matrix "b".</p>
<p>The inputs must be two-dimensional matrices and the inner dimension of "a" must
match the outer dimension of "b". This op is optimized for the case where at
least one of "a" or "b" is sparse. The breakeven for using this versus a dense
matrix multiply on one platform was 30% zero values in the sparse matrix.</p>
<p>Args:
  a: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>bfloat16</code>.
  b: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>bfloat16</code>.
  transpose_a: An optional <code>bool</code>. Defaults to <code>False</code>.
  transpose_b: An optional <code>bool</code>. Defaults to <code>False</code>.
  a_is_sparse: An optional <code>bool</code>. Defaults to <code>False</code>.
  b_is_sparse: An optional <code>bool</code>. Defaults to <code>False</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>float32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_matmul_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_matmul_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_merge">
    <p>def <span class="ident">sparse_merge</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_merge, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_merge</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_merge</strong></p>
<div class="codehilite"><pre><span></span>def sparse_merge(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_merge</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_merge</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_merge(sp_ids, sp_values, vocab_size, name=None)
</pre></div>


<p>Combines a batch of feature ids and values into a single <code>SparseTensor</code>.</p>
<p>The most common use case for this function occurs when feature ids and
their corresponding values are stored in <code>Example</code> protos on disk.
<code>parse_example</code> will return a batch of ids and a batch of values, and this
function joins them into a single logical <code>SparseTensor</code> for use in
functions such as <code>sparse_tensor_dense_matmul</code>, <code>sparse_to_dense</code>, etc.</p>
<p>The <code>SparseTensor</code> returned by this function has the following properties:</p>
<ul>
<li><code>indices</code> is equivalent to <code>sp_ids.indices</code> with the last
    dimension discarded and replaced with <code>sp_ids.values</code>.</li>
<li><code>values</code> is simply <code>sp_values.values</code>.</li>
<li>If <code>sp_ids.shape = [D0, D1, ..., Dn, K]</code>, then
    <code>output.shape = [D0, D1, ..., Dn, vocab_size]</code>.</li>
</ul>
<p>For example, consider the following feature vectors:</p>
<p>vector1 = [-3, 0, 0, 0, 0, 0]
  vector2 = [ 0, 1, 0, 4, 1, 0]
  vector3 = [ 5, 0, 0, 9, 0, 0]</p>
<p>These might be stored sparsely in the following Example protos by storing
only the feature ids (column number if the vectors are treated as a matrix)
of the non-zero elements and the corresponding values:</p>
<p>examples = [Example(features={
                  "ids": Feature(int64_list=Int64List(value=[0])),
                  "values": Feature(float_list=FloatList(value=[-3]))}),
              Example(features={
                  "ids": Feature(int64_list=Int64List(value=[1, 4, 3])),
                  "values": Feature(float_list=FloatList(value=[1, 1, 4]))}),
              Example(features={
                  "ids": Feature(int64_list=Int64List(value=[0, 3])),
                  "values": Feature(float_list=FloatList(value=[5, 9]))})]</p>
<p>The result of calling parse_example on these examples will produce a
dictionary with entries for "ids" and "values". Passing those two objects
to this function along with vocab_size=6, will produce a <code>SparseTensor</code> that
sparsely represents all three instances. Namely, the <code>indices</code> property will
contain the coordinates of the non-zero entries in the feature matrix (the
first dimension is the row number in the matrix, i.e., the index within the
batch, and the second dimension is the column number, i.e., the feature id);
<code>values</code> will contain the actual values. <code>shape</code> will be the shape of the
original matrix, i.e., (3, 6). For our example above, the output will be
equal to:</p>
<p>SparseTensor(indices=[[0, 0], [1, 1], [1, 3], [1, 4], [2, 0], [2, 3]],
               values=[-3, 1, 4, 1, 5, 9],
               shape=[3, 6])</p>
<p>Args:
  sp_ids: A <code>SparseTensor</code> with <code>values</code> property of type <code>int32</code>
    or <code>int64</code>.
  sp_values: A<code>SparseTensor</code> of any type.
  vocab_size: A scalar <code>int64</code> Tensor (or Python int) containing the new size
    of the last dimension, <code>all(0 &lt;= sp_ids.values &lt; vocab_size)</code>.
  name: A name prefix for the returned tensors (optional)</p>
<p>Returns:
  A <code>SparseTensor</code> compactly representing a batch of feature ids and values,
  useful for passing to functions that expect such a <code>SparseTensor</code>.</p>
<p>Raises:
  TypeError: If <code>sp_ids</code> or <code>sp_values</code> are not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_merge', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_merge" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_merge_layer">
    <p>def <span class="ident">sparse_merge_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_merge_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_merge_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_merge_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_merge_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_merge, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_merge</strong></p>
<div class="codehilite"><pre><span></span>def sparse_merge(sp_ids, sp_values, vocab_size, name=None):
</pre></div>


<p>Combines a batch of feature ids and values into a single <code>SparseTensor</code>.</p>
<p>The most common use case for this function occurs when feature ids and
their corresponding values are stored in <code>Example</code> protos on disk.
<code>parse_example</code> will return a batch of ids and a batch of values, and this
function joins them into a single logical <code>SparseTensor</code> for use in
functions such as <code>sparse_tensor_dense_matmul</code>, <code>sparse_to_dense</code>, etc.</p>
<p>The <code>SparseTensor</code> returned by this function has the following properties:</p>
<ul>
<li><code>indices</code> is equivalent to <code>sp_ids.indices</code> with the last
    dimension discarded and replaced with <code>sp_ids.values</code>.</li>
<li><code>values</code> is simply <code>sp_values.values</code>.</li>
<li>If <code>sp_ids.shape = [D0, D1, ..., Dn, K]</code>, then
    <code>output.shape = [D0, D1, ..., Dn, vocab_size]</code>.</li>
</ul>
<p>For example, consider the following feature vectors:</p>
<p>vector1 = [-3, 0, 0, 0, 0, 0]
  vector2 = [ 0, 1, 0, 4, 1, 0]
  vector3 = [ 5, 0, 0, 9, 0, 0]</p>
<p>These might be stored sparsely in the following Example protos by storing
only the feature ids (column number if the vectors are treated as a matrix)
of the non-zero elements and the corresponding values:</p>
<p>examples = [Example(features={
                  "ids": Feature(int64_list=Int64List(value=[0])),
                  "values": Feature(float_list=FloatList(value=[-3]))}),
              Example(features={
                  "ids": Feature(int64_list=Int64List(value=[1, 4, 3])),
                  "values": Feature(float_list=FloatList(value=[1, 1, 4]))}),
              Example(features={
                  "ids": Feature(int64_list=Int64List(value=[0, 3])),
                  "values": Feature(float_list=FloatList(value=[5, 9]))})]</p>
<p>The result of calling parse_example on these examples will produce a
dictionary with entries for "ids" and "values". Passing those two objects
to this function along with vocab_size=6, will produce a <code>SparseTensor</code> that
sparsely represents all three instances. Namely, the <code>indices</code> property will
contain the coordinates of the non-zero entries in the feature matrix (the
first dimension is the row number in the matrix, i.e., the index within the
batch, and the second dimension is the column number, i.e., the feature id);
<code>values</code> will contain the actual values. <code>shape</code> will be the shape of the
original matrix, i.e., (3, 6). For our example above, the output will be
equal to:</p>
<p>SparseTensor(indices=[[0, 0], [1, 1], [1, 3], [1, 4], [2, 0], [2, 3]],
               values=[-3, 1, 4, 1, 5, 9],
               shape=[3, 6])</p>
<p>Args:
  sp_ids: A <code>SparseTensor</code> with <code>values</code> property of type <code>int32</code>
    or <code>int64</code>.
  sp_values: A<code>SparseTensor</code> of any type.
  vocab_size: A scalar <code>int64</code> Tensor (or Python int) containing the new size
    of the last dimension, <code>all(0 &lt;= sp_ids.values &lt; vocab_size)</code>.
  name: A name prefix for the returned tensors (optional)</p>
<p>Returns:
  A <code>SparseTensor</code> compactly representing a batch of feature ids and values,
  useful for passing to functions that expect such a <code>SparseTensor</code>.</p>
<p>Raises:
  TypeError: If <code>sp_ids</code> or <code>sp_values</code> are not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_merge_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_merge_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_placeholder">
    <p>def <span class="ident">sparse_placeholder</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_placeholder, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_placeholder</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_placeholder</strong></p>
<div class="codehilite"><pre><span></span>def sparse_placeholder(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_placeholder</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_placeholder</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_placeholder(dtype, shape=None, name=None)
</pre></div>


<p>Inserts a placeholder for a sparse tensor that will be always fed.</p>
<p><strong>Important</strong>: This sparse tensor will produce an error if evaluated.
Its value must be fed using the <code>feed_dict</code> optional argument to
<code>Session.run()</code>, <code>Tensor.eval()</code>, or <code>Operation.run()</code>.</p>
<p>For example:</p>
<p>```python
x = tf.sparse_placeholder(tf.float32)
y = tf.sparse_reduce_sum(x)</p>
<p>with tf.Session() as sess:
  print(sess.run(y))  # ERROR: will fail because x was not fed.</p>
<p>indices = np.array([[3, 2, 0], [4, 5, 1]], dtype=np.int64)
  values = np.array([1.0, 2.0], dtype=np.float32)
  shape = np.array([7, 9, 2], dtype=np.int64)
  print(sess.run(y, feed_dict={
    x: tf.SparseTensorValue(indices, values, shape)}))  # Will succeed.
  print(sess.run(y, feed_dict={
    x: (indices, values, shape)}))  # Will succeed.</p>
<p>sp = tf.SparseTensor(indices=indices, values=values, shape=shape)
  sp_value = sp.eval(session)
  print(sess.run(y, feed_dict={x: sp_value}))  # Will succeed.
```</p>
<p>Args:
  dtype: The type of <code>values</code> elements in the tensor to be fed.
  shape: The shape of the tensor to be fed (optional). If the shape is not
    specified, you can feed a sparse tensor of any shape.
  name: A name for prefixing the operations (optional).</p>
<p>Returns:
  A <code>SparseTensor</code> that may be used as a handle for feeding a value, but not
  evaluated directly.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_placeholder', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_placeholder" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_placeholder_layer">
    <p>def <span class="ident">sparse_placeholder_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_placeholder_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_placeholder_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_placeholder_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_placeholder_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_placeholder, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_placeholder</strong></p>
<div class="codehilite"><pre><span></span>def sparse_placeholder(dtype, shape=None, name=None):
</pre></div>


<p>Inserts a placeholder for a sparse tensor that will be always fed.</p>
<p><strong>Important</strong>: This sparse tensor will produce an error if evaluated.
Its value must be fed using the <code>feed_dict</code> optional argument to
<code>Session.run()</code>, <code>Tensor.eval()</code>, or <code>Operation.run()</code>.</p>
<p>For example:</p>
<p>```python
x = tf.sparse_placeholder(tf.float32)
y = tf.sparse_reduce_sum(x)</p>
<p>with tf.Session() as sess:
  print(sess.run(y))  # ERROR: will fail because x was not fed.</p>
<p>indices = np.array([[3, 2, 0], [4, 5, 1]], dtype=np.int64)
  values = np.array([1.0, 2.0], dtype=np.float32)
  shape = np.array([7, 9, 2], dtype=np.int64)
  print(sess.run(y, feed_dict={
    x: tf.SparseTensorValue(indices, values, shape)}))  # Will succeed.
  print(sess.run(y, feed_dict={
    x: (indices, values, shape)}))  # Will succeed.</p>
<p>sp = tf.SparseTensor(indices=indices, values=values, shape=shape)
  sp_value = sp.eval(session)
  print(sess.run(y, feed_dict={x: sp_value}))  # Will succeed.
```</p>
<p>Args:
  dtype: The type of <code>values</code> elements in the tensor to be fed.
  shape: The shape of the tensor to be fed (optional). If the shape is not
    specified, you can feed a sparse tensor of any shape.
  name: A name for prefixing the operations (optional).</p>
<p>Returns:
  A <code>SparseTensor</code> that may be used as a handle for feeding a value, but not
  evaluated directly.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_placeholder_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_placeholder_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_reduce_sum">
    <p>def <span class="ident">sparse_reduce_sum</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_reduce_sum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_reduce_sum</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_reduce_sum</strong></p>
<div class="codehilite"><pre><span></span>def sparse_reduce_sum(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_reduce_sum</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_reduce_sum</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_reduce_sum(sp_input, reduction_axes=None, keep_dims=False)
</pre></div>


<p>Computes the sum of elements across dimensions of a SparseTensor.</p>
<p>This Op takes a SparseTensor and is the sparse counterpart to
<code>tf.reduce_sum()</code>.  In particular, this Op also returns a dense <code>Tensor</code>
instead of a sparse one.</p>
<p>Reduces <code>sp_input</code> along the dimensions given in <code>reduction_axes</code>.  Unless
<code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each entry in
<code>reduction_axes</code>. If <code>keep_dims</code> is true, the reduced dimensions are retained
with length 1.</p>
<p>If <code>reduction_axes</code> has no entries, all dimensions are reduced, and a tensor
with a single element is returned.  Additionally, the axes can be negative,
similar to the indexing rules in Python.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' represents [[1, ?, 1]</h1>
<h1>[?, 1, ?]]</h1>
<h1>where ? is implictly-zero.</h1>
<p>tf.sparse_reduce_sum(x) ==&gt; 3
tf.sparse_reduce_sum(x, 0) ==&gt; [1, 1, 1]
tf.sparse_reduce_sum(x, 1) ==&gt; [2, 1]  # Can also use -1 as the axis.
tf.sparse_reduce_sum(x, 1, keep_dims=True) ==&gt; [[2], [1]]
tf.sparse_reduce_sum(x, [0, 1]) ==&gt; 3
```</p>
<p>Args:
  sp_input: The SparseTensor to reduce. Should have numeric type.
  reduction_axes: The dimensions to reduce; list or scalar. If <code>None</code> (the
    default), reduces all dimensions.
  keep_dims: If true, retain reduced dimensions with length 1.</p>
<p>Returns:
  The reduced Tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_reduce_sum', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_reduce_sum" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_reduce_sum_layer">
    <p>def <span class="ident">sparse_reduce_sum_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_reduce_sum_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_reduce_sum_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_reduce_sum_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_reduce_sum_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_reduce_sum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_reduce_sum</strong></p>
<div class="codehilite"><pre><span></span>def sparse_reduce_sum(sp_input, reduction_axes=None, keep_dims=False):
</pre></div>


<p>Computes the sum of elements across dimensions of a SparseTensor.</p>
<p>This Op takes a SparseTensor and is the sparse counterpart to
<code>tf.reduce_sum()</code>.  In particular, this Op also returns a dense <code>Tensor</code>
instead of a sparse one.</p>
<p>Reduces <code>sp_input</code> along the dimensions given in <code>reduction_axes</code>.  Unless
<code>keep_dims</code> is true, the rank of the tensor is reduced by 1 for each entry in
<code>reduction_axes</code>. If <code>keep_dims</code> is true, the reduced dimensions are retained
with length 1.</p>
<p>If <code>reduction_axes</code> has no entries, all dimensions are reduced, and a tensor
with a single element is returned.  Additionally, the axes can be negative,
similar to the indexing rules in Python.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' represents [[1, ?, 1]</h1>
<h1>[?, 1, ?]]</h1>
<h1>where ? is implictly-zero.</h1>
<p>tf.sparse_reduce_sum(x) ==&gt; 3
tf.sparse_reduce_sum(x, 0) ==&gt; [1, 1, 1]
tf.sparse_reduce_sum(x, 1) ==&gt; [2, 1]  # Can also use -1 as the axis.
tf.sparse_reduce_sum(x, 1, keep_dims=True) ==&gt; [[2], [1]]
tf.sparse_reduce_sum(x, [0, 1]) ==&gt; 3
```</p>
<p>Args:
  sp_input: The SparseTensor to reduce. Should have numeric type.
  reduction_axes: The dimensions to reduce; list or scalar. If <code>None</code> (the
    default), reduces all dimensions.
  keep_dims: If true, retain reduced dimensions with length 1.</p>
<p>Returns:
  The reduced Tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_reduce_sum_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_reduce_sum_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_reorder">
    <p>def <span class="ident">sparse_reorder</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_reorder, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_reorder</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_reorder</strong></p>
<div class="codehilite"><pre><span></span>def sparse_reorder(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_reorder</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_reorder</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_reorder(sp_input, name=None)
</pre></div>


<p>Reorders a <code>SparseTensor</code> into the canonical, row-major ordering.</p>
<p>Note that by convention, all sparse ops preserve the canonical ordering
along increasing dimension number. The only time ordering can be violated
is during manual manipulation of the indices and values to add entries.</p>
<p>Reordering does not affect the shape of the <code>SparseTensor</code>.</p>
<p>For example, if <code>sp_input</code> has shape <code>[4, 5]</code> and <code>indices</code> / <code>values</code>:</p>
<div class="codehilite"><pre><span></span>[0, 3]: b
[0, 1]: a
[3, 1]: d
[2, 0]: c
</pre></div>


<p>then the output will be a <code>SparseTensor</code> of shape <code>[4, 5]</code> and
<code>indices</code> / <code>values</code>:</p>
<div class="codehilite"><pre><span></span>[0, 1]: a
[0, 3]: b
[2, 0]: c
[3, 1]: d
</pre></div>


<p>Args:
  sp_input: The input <code>SparseTensor</code>.
  name: A name prefix for the returned tensors (optional)</p>
<p>Returns:
  A <code>SparseTensor</code> with the same shape and non-empty values, but in
  canonical ordering.</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_reorder', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_reorder" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_reorder_layer">
    <p>def <span class="ident">sparse_reorder_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_reorder_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_reorder_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_reorder_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_reorder_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_reorder, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_reorder</strong></p>
<div class="codehilite"><pre><span></span>def sparse_reorder(sp_input, name=None):
</pre></div>


<p>Reorders a <code>SparseTensor</code> into the canonical, row-major ordering.</p>
<p>Note that by convention, all sparse ops preserve the canonical ordering
along increasing dimension number. The only time ordering can be violated
is during manual manipulation of the indices and values to add entries.</p>
<p>Reordering does not affect the shape of the <code>SparseTensor</code>.</p>
<p>For example, if <code>sp_input</code> has shape <code>[4, 5]</code> and <code>indices</code> / <code>values</code>:</p>
<div class="codehilite"><pre><span></span>[0, 3]: b
[0, 1]: a
[3, 1]: d
[2, 0]: c
</pre></div>


<p>then the output will be a <code>SparseTensor</code> of shape <code>[4, 5]</code> and
<code>indices</code> / <code>values</code>:</p>
<div class="codehilite"><pre><span></span>[0, 1]: a
[0, 3]: b
[2, 0]: c
[3, 1]: d
</pre></div>


<p>Args:
  sp_input: The input <code>SparseTensor</code>.
  name: A name prefix for the returned tensors (optional)</p>
<p>Returns:
  A <code>SparseTensor</code> with the same shape and non-empty values, but in
  canonical ordering.</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_reorder_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_reorder_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_reset_shape">
    <p>def <span class="ident">sparse_reset_shape</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_reset_shape, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_reset_shape</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_reset_shape</strong></p>
<div class="codehilite"><pre><span></span>def sparse_reset_shape(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_reset_shape</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_reset_shape</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_reset_shape(sp_input, new_shape=None)
</pre></div>


<p>Resets the shape of a <code>SparseTensor</code> with indices and values unchanged.</p>
<p>If <code>new_shape</code> is None, returns a copy of <code>sp_input</code> with its shape reset
to the tight bounding box of <code>sp_input</code>.</p>
<p>If <code>new_shape</code> is provided, then it must be larger or equal in all dimensions
compared to the shape of <code>sp_input</code>. When this condition is met, the returned
SparseTensor will have its shape reset to <code>new_shape</code> and its indices and
values unchanged from that of <code>sp_input.</code></p>
<p>For example:</p>
<p>Consider a <code>sp_input</code> with shape [2, 3, 5]:</p>
<div class="codehilite"><pre><span></span>[0, 0, 1]: a
[0, 1, 0]: b
[0, 2, 2]: c
[1, 0, 3]: d
</pre></div>


<ul>
<li>
<p>It is an error to set <code>new_shape</code> as [3, 7] since this represents a
    rank-2 tensor while <code>sp_input</code> is rank-3. This is either a ValueError
    during graph construction (if both shapes are known) or an OpError during
    run time.</p>
</li>
<li>
<p>Setting <code>new_shape</code> as [2, 3, 6] will be fine as this shape is larger or
    eqaul in every dimension compared to the original shape [2, 3, 5].</p>
</li>
<li>
<p>On the other hand, setting new_shape as [2, 3, 4] is also an error: The
    third dimension is smaller than the original shape [2, 3, 5] (and an
    <code>InvalidArgumentError</code> will be raised).</p>
</li>
<li>
<p>If <code>new_shape</code> is None, the returned SparseTensor will have a shape
    [2, 3, 4], which is the tight bounding box of <code>sp_input</code>.</p>
</li>
</ul>
<p>Args:
  sp_input: The input <code>SparseTensor</code>.
  new_shape: None or a vector representing the new shape for the returned
    <code>SpraseTensor</code>.</p>
<p>Returns:
  A <code>SparseTensor</code> indices and values unchanged from <code>input_sp</code>. Its shape is
    <code>new_shape</code> if that is set. Otherwise it is  the tight bounding box of
     <code>input_sp</code></p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.
  ValueError: If <code>new_shape</code> represents a tensor with a different rank from
    that of <code>sp_input</code> (if shapes are known when graph is constructed).
  OpError:
    - If <code>new_shape</code> has dimension sizes that are too small.
    - If shapes are not known during graph construction time, and during run
      time it is found out that the ranks do not match.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_reset_shape', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_reset_shape" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_reset_shape_layer">
    <p>def <span class="ident">sparse_reset_shape_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_reset_shape_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_reset_shape_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_reset_shape_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_reset_shape_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_reset_shape, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_reset_shape</strong></p>
<div class="codehilite"><pre><span></span>def sparse_reset_shape(sp_input, new_shape=None):
</pre></div>


<p>Resets the shape of a <code>SparseTensor</code> with indices and values unchanged.</p>
<p>If <code>new_shape</code> is None, returns a copy of <code>sp_input</code> with its shape reset
to the tight bounding box of <code>sp_input</code>.</p>
<p>If <code>new_shape</code> is provided, then it must be larger or equal in all dimensions
compared to the shape of <code>sp_input</code>. When this condition is met, the returned
SparseTensor will have its shape reset to <code>new_shape</code> and its indices and
values unchanged from that of <code>sp_input.</code></p>
<p>For example:</p>
<p>Consider a <code>sp_input</code> with shape [2, 3, 5]:</p>
<div class="codehilite"><pre><span></span>[0, 0, 1]: a
[0, 1, 0]: b
[0, 2, 2]: c
[1, 0, 3]: d
</pre></div>


<ul>
<li>
<p>It is an error to set <code>new_shape</code> as [3, 7] since this represents a
    rank-2 tensor while <code>sp_input</code> is rank-3. This is either a ValueError
    during graph construction (if both shapes are known) or an OpError during
    run time.</p>
</li>
<li>
<p>Setting <code>new_shape</code> as [2, 3, 6] will be fine as this shape is larger or
    eqaul in every dimension compared to the original shape [2, 3, 5].</p>
</li>
<li>
<p>On the other hand, setting new_shape as [2, 3, 4] is also an error: The
    third dimension is smaller than the original shape [2, 3, 5] (and an
    <code>InvalidArgumentError</code> will be raised).</p>
</li>
<li>
<p>If <code>new_shape</code> is None, the returned SparseTensor will have a shape
    [2, 3, 4], which is the tight bounding box of <code>sp_input</code>.</p>
</li>
</ul>
<p>Args:
  sp_input: The input <code>SparseTensor</code>.
  new_shape: None or a vector representing the new shape for the returned
    <code>SpraseTensor</code>.</p>
<p>Returns:
  A <code>SparseTensor</code> indices and values unchanged from <code>input_sp</code>. Its shape is
    <code>new_shape</code> if that is set. Otherwise it is  the tight bounding box of
     <code>input_sp</code></p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.
  ValueError: If <code>new_shape</code> represents a tensor with a different rank from
    that of <code>sp_input</code> (if shapes are known when graph is constructed).
  OpError:
    - If <code>new_shape</code> has dimension sizes that are too small.
    - If shapes are not known during graph construction time, and during run
      time it is found out that the ranks do not match.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_reset_shape_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_reset_shape_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_retain">
    <p>def <span class="ident">sparse_retain</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_retain, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_retain</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_retain</strong></p>
<div class="codehilite"><pre><span></span>def sparse_retain(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_retain</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_retain</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_retain(sp_input, to_retain)
</pre></div>


<p>Retains specified non-empty values within a <code>SparseTensor</code>.</p>
<p>For example, if <code>sp_input</code> has shape <code>[4, 5]</code> and 4 non-empty string values:</p>
<div class="codehilite"><pre><span></span>[0, 1]: a
[0, 3]: b
[2, 0]: c
[3, 1]: d
</pre></div>


<p>and <code>to_retain = [True, False, False, True]</code>, then the output will
be a <code>SparseTensor</code> of shape <code>[4, 5]</code> with 2 non-empty values:</p>
<div class="codehilite"><pre><span></span>[0, 1]: a
[3, 1]: d
</pre></div>


<p>Args:
  sp_input: The input <code>SparseTensor</code> with <code>N</code> non-empty elements.
  to_retain: A bool vector of length <code>N</code> with <code>M</code> true values.</p>
<p>Returns:
  A <code>SparseTensor</code> with the same shape as the input and <code>M</code> non-empty
  elements corresponding to the true positions in <code>to_retain</code>.</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_retain', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_retain" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_retain_layer">
    <p>def <span class="ident">sparse_retain_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_retain_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_retain_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_retain_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_retain_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_retain, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_retain</strong></p>
<div class="codehilite"><pre><span></span>def sparse_retain(sp_input, to_retain):
</pre></div>


<p>Retains specified non-empty values within a <code>SparseTensor</code>.</p>
<p>For example, if <code>sp_input</code> has shape <code>[4, 5]</code> and 4 non-empty string values:</p>
<div class="codehilite"><pre><span></span>[0, 1]: a
[0, 3]: b
[2, 0]: c
[3, 1]: d
</pre></div>


<p>and <code>to_retain = [True, False, False, True]</code>, then the output will
be a <code>SparseTensor</code> of shape <code>[4, 5]</code> with 2 non-empty values:</p>
<div class="codehilite"><pre><span></span>[0, 1]: a
[3, 1]: d
</pre></div>


<p>Args:
  sp_input: The input <code>SparseTensor</code> with <code>N</code> non-empty elements.
  to_retain: A bool vector of length <code>N</code> with <code>M</code> true values.</p>
<p>Returns:
  A <code>SparseTensor</code> with the same shape as the input and <code>M</code> non-empty
  elements corresponding to the true positions in <code>to_retain</code>.</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_retain_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_retain_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_segment_mean">
    <p>def <span class="ident">sparse_segment_mean</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_segment_mean, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_segment_mean</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_segment_mean</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_mean(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_segment_mean</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_segment_mean</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_mean(data, indices, segment_ids, name=None)
</pre></div>


<p>Computes the mean along sparse segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Like <code>SegmentMean</code>, but <code>segment_ids</code> can have rank less than <code>data</code>'s first
dimension, selecting a subset of dimension 0, specified by <code>indices</code>.</p>
<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  indices: A <code>Tensor</code> of type <code>int32</code>.
    A 1-D tensor. Has same rank as <code>segment_ids</code>.
  segment_ids: A <code>Tensor</code> of type <code>int32</code>.
    A 1-D tensor. Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_segment_mean', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_segment_mean" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_segment_mean_grad">
    <p>def <span class="ident">sparse_segment_mean_grad</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_segment_mean_grad, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_segment_mean_grad</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_segment_mean_grad</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_mean_grad(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_segment_mean_grad</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_segment_mean_grad</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_mean_grad(grad, indices, segment_ids, output_dim0, name=None)
</pre></div>


<p>Computes gradients for SparseSegmentMean.</p>
<p>Returns tensor "output" with same shape as grad, except for dimension 0 whose
value is output_dim0.</p>
<p>Args:
  grad: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    gradient propagated to the SparseSegmentMean op.
  indices: A <code>Tensor</code> of type <code>int32</code>.
    indices passed to the corresponding SparseSegmentMean op.
  segment_ids: A <code>Tensor</code> of type <code>int32</code>.
    segment_ids passed to the corresponding SparseSegmentMean op.
  output_dim0: A <code>Tensor</code> of type <code>int32</code>.
    dimension 0 of "data" passed to SparseSegmentMean op.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>grad</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_segment_mean_grad', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_segment_mean_grad" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_segment_mean_grad_layer">
    <p>def <span class="ident">sparse_segment_mean_grad_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_segment_mean_grad_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_segment_mean_grad_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_segment_mean_grad_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_mean_grad_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_segment_mean_grad, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_segment_mean_grad</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_mean_grad(grad, indices, segment_ids, output_dim0, name=None):
</pre></div>


<p>Computes gradients for SparseSegmentMean.</p>
<p>Returns tensor "output" with same shape as grad, except for dimension 0 whose
value is output_dim0.</p>
<p>Args:
  grad: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    gradient propagated to the SparseSegmentMean op.
  indices: A <code>Tensor</code> of type <code>int32</code>.
    indices passed to the corresponding SparseSegmentMean op.
  segment_ids: A <code>Tensor</code> of type <code>int32</code>.
    segment_ids passed to the corresponding SparseSegmentMean op.
  output_dim0: A <code>Tensor</code> of type <code>int32</code>.
    dimension 0 of "data" passed to SparseSegmentMean op.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>grad</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_segment_mean_grad_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_segment_mean_grad_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_segment_mean_layer">
    <p>def <span class="ident">sparse_segment_mean_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_segment_mean_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_segment_mean_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_segment_mean_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_mean_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_segment_mean, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_segment_mean</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_mean(data, indices, segment_ids, name=None):
</pre></div>


<p>Computes the mean along sparse segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Like <code>SegmentMean</code>, but <code>segment_ids</code> can have rank less than <code>data</code>'s first
dimension, selecting a subset of dimension 0, specified by <code>indices</code>.</p>
<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  indices: A <code>Tensor</code> of type <code>int32</code>.
    A 1-D tensor. Has same rank as <code>segment_ids</code>.
  segment_ids: A <code>Tensor</code> of type <code>int32</code>.
    A 1-D tensor. Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_segment_mean_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_segment_mean_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n">
    <p>def <span class="ident">sparse_segment_sqrt_n</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_segment_sqrt_n, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_segment_sqrt_n</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_segment_sqrt_n</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_sqrt_n(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_segment_sqrt_n</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_segment_sqrt_n</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_sqrt_n(data, indices, segment_ids, name=None)
</pre></div>


<p>Computes the sum along sparse segments of a tensor divided by the sqrt of N.</p>
<p>N is the size of the segment being reduced.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  indices: A <code>Tensor</code> of type <code>int32</code>.
    A 1-D tensor. Has same rank as <code>segment_ids</code>.
  segment_ids: A <code>Tensor</code> of type <code>int32</code>.
    A 1-D tensor. Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n_grad">
    <p>def <span class="ident">sparse_segment_sqrt_n_grad</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_segment_sqrt_n_grad, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_segment_sqrt_n_grad</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_segment_sqrt_n_grad</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_sqrt_n_grad(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_segment_sqrt_n_grad</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_segment_sqrt_n_grad</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_sqrt_n_grad(grad, indices, segment_ids, output_dim0, name=None)
</pre></div>


<p>Computes gradients for SparseSegmentSqrtN.</p>
<p>Returns tensor "output" with same shape as grad, except for dimension 0 whose
value is output_dim0.</p>
<p>Args:
  grad: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    gradient propagated to the SparseSegmentSqrtN op.
  indices: A <code>Tensor</code> of type <code>int32</code>.
    indices passed to the corresponding SparseSegmentSqrtN op.
  segment_ids: A <code>Tensor</code> of type <code>int32</code>.
    segment_ids passed to the corresponding SparseSegmentSqrtN op.
  output_dim0: A <code>Tensor</code> of type <code>int32</code>.
    dimension 0 of "data" passed to SparseSegmentSqrtN op.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>grad</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n_grad', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n_grad" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n_grad_layer">
    <p>def <span class="ident">sparse_segment_sqrt_n_grad_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_segment_sqrt_n_grad_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_segment_sqrt_n_grad_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_segment_sqrt_n_grad_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_sqrt_n_grad_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_segment_sqrt_n_grad, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_segment_sqrt_n_grad</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_sqrt_n_grad(grad, indices, segment_ids, output_dim0, name=None):
</pre></div>


<p>Computes gradients for SparseSegmentSqrtN.</p>
<p>Returns tensor "output" with same shape as grad, except for dimension 0 whose
value is output_dim0.</p>
<p>Args:
  grad: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
    gradient propagated to the SparseSegmentSqrtN op.
  indices: A <code>Tensor</code> of type <code>int32</code>.
    indices passed to the corresponding SparseSegmentSqrtN op.
  segment_ids: A <code>Tensor</code> of type <code>int32</code>.
    segment_ids passed to the corresponding SparseSegmentSqrtN op.
  output_dim0: A <code>Tensor</code> of type <code>int32</code>.
    dimension 0 of "data" passed to SparseSegmentSqrtN op.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>grad</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n_grad_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n_grad_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n_layer">
    <p>def <span class="ident">sparse_segment_sqrt_n_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_segment_sqrt_n_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_segment_sqrt_n_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_segment_sqrt_n_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_sqrt_n_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_segment_sqrt_n, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_segment_sqrt_n</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_sqrt_n(data, indices, segment_ids, name=None):
</pre></div>


<p>Computes the sum along sparse segments of a tensor divided by the sqrt of N.</p>
<p>N is the size of the segment being reduced.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  indices: A <code>Tensor</code> of type <code>int32</code>.
    A 1-D tensor. Has same rank as <code>segment_ids</code>.
  segment_ids: A <code>Tensor</code> of type <code>int32</code>.
    A 1-D tensor. Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_segment_sqrt_n_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_segment_sum">
    <p>def <span class="ident">sparse_segment_sum</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_segment_sum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_segment_sum</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_segment_sum</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_sum(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_segment_sum</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_segment_sum</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_sum(data, indices, segment_ids, name=None)
</pre></div>


<p>Computes the sum along sparse segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Like <code>SegmentSum</code>, but <code>segment_ids</code> can have rank less than <code>data</code>'s first
dimension, selecting a subset of dimension 0, specified by <code>indices</code>.</p>
<p>For example:</p>
<p>```prettyprint
c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])</p>
<h1>Select two rows, one segment.</h1>
<p>tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0]))
  ==&gt; [[0 0 0 0]]</p>
<h1>Select two rows, two segment.</h1>
<p>tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 1]))
  ==&gt; [[ 1  2  3  4]
       [-1 -2 -3 -4]]</p>
<h1>Select all rows, two segments.</h1>
<p>tf.sparse_segment_sum(c, tf.constant([0, 1, 2]), tf.constant([0, 0, 1]))
  ==&gt; [[0 0 0 0]
       [5 6 7 8]]</p>
<h1>Which is equivalent to:</h1>
<p>tf.segment_sum(c, tf.constant([0, 0, 1]))
```</p>
<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  indices: A <code>Tensor</code> of type <code>int32</code>.
    A 1-D tensor. Has same rank as <code>segment_ids</code>.
  segment_ids: A <code>Tensor</code> of type <code>int32</code>.
    A 1-D tensor. Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_segment_sum', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_segment_sum" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_segment_sum_layer">
    <p>def <span class="ident">sparse_segment_sum_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_segment_sum_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_segment_sum_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_segment_sum_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_sum_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_segment_sum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_segment_sum</strong></p>
<div class="codehilite"><pre><span></span>def sparse_segment_sum(data, indices, segment_ids, name=None):
</pre></div>


<p>Computes the sum along sparse segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Like <code>SegmentSum</code>, but <code>segment_ids</code> can have rank less than <code>data</code>'s first
dimension, selecting a subset of dimension 0, specified by <code>indices</code>.</p>
<p>For example:</p>
<p>```prettyprint
c = tf.constant([[1,2,3,4], [-1,-2,-3,-4], [5,6,7,8]])</p>
<h1>Select two rows, one segment.</h1>
<p>tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 0]))
  ==&gt; [[0 0 0 0]]</p>
<h1>Select two rows, two segment.</h1>
<p>tf.sparse_segment_sum(c, tf.constant([0, 1]), tf.constant([0, 1]))
  ==&gt; [[ 1  2  3  4]
       [-1 -2 -3 -4]]</p>
<h1>Select all rows, two segments.</h1>
<p>tf.sparse_segment_sum(c, tf.constant([0, 1, 2]), tf.constant([0, 0, 1]))
  ==&gt; [[0 0 0 0]
       [5 6 7 8]]</p>
<h1>Which is equivalent to:</h1>
<p>tf.segment_sum(c, tf.constant([0, 0, 1]))
```</p>
<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>uint16</code>, <code>half</code>.
  indices: A <code>Tensor</code> of type <code>int32</code>.
    A 1-D tensor. Has same rank as <code>segment_ids</code>.
  segment_ids: A <code>Tensor</code> of type <code>int32</code>.
    A 1-D tensor. Values should be sorted and can be repeated.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>k</code>, the number of segments.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_segment_sum_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_segment_sum_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_softmax">
    <p>def <span class="ident">sparse_softmax</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_softmax, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_softmax</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_softmax</strong></p>
<div class="codehilite"><pre><span></span>def sparse_softmax(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_softmax</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_softmax</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_softmax(sp_input, name=None)
</pre></div>


<p>Applies softmax to a batched N-D <code>SparseTensor</code>.</p>
<p>The inputs represent an N-D SparseTensor  with logical shape <code>[..., B, C]</code>
(where <code>N &gt;= 2</code>), and with indices sorted in the canonical lexicographic
order.</p>
<p>This op is equivalent to applying the normal <code>tf.nn.softmax()</code> to each
innermost logical submatrix with shape <code>[B, C]</code>, but with the catch that <em>the
implicitly zero elements do not participate</em>.  Specifically, the algorithm is
equivalent to:</p>
<p>(1) Applies <code>tf.nn.softmax()</code> to a densified view of each innermost
      submatrix with shape <code>[B, C]</code>, along the size-C dimension;
  (2) Masks out the original implicitly-zero locations;
  (3) Renormalizes the remaining elements.</p>
<p>Hence, the <code>SparseTensor</code> result has exactly the same non-zero indices and
shape.</p>
<p>Example:</p>
<p>```python</p>
<h1>First batch:</h1>
<h1>[?   e.]</h1>
<h1>[1.  ? ]</h1>
<h1>Second batch:</h1>
<h1>[e   ? ]</h1>
<h1>[e   e ]</h1>
<p>shape = [2, 2, 2]  # 3-D SparseTensor
values = np.asarray([[[0., np.e], [1., 0.]], [[np.e, 0.], [np.e, np.e]]])
indices = np.vstack(np.where(values)).astype(np.int64).T</p>
<p>result = tf.sparse_softmax(tf.SparseTensor(indices, values, shape))</p>
<h1>...returning a 3-D SparseTensor, equivalent to:</h1>
<h1>[?   1.]     [1    ?]</h1>
<h1>[1.  ? ] and [.5  .5]</h1>
<h1>where ? means implicitly zero.</h1>
<p>```</p>
<p>Args:
  sp_input: N-D <code>SparseTensor</code>, where <code>N &gt;= 2</code>.
  name: optional name of the operation.
Returns:
  output: N-D <code>SparseTensor</code> representing the results.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_softmax', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_softmax" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_softmax_cross_entropy_with_logits">
    <p>def <span class="ident">sparse_softmax_cross_entropy_with_logits</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_softmax_cross_entropy_with_logits, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_softmax_cross_entropy_with_logits</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_softmax_cross_entropy_with_logits</strong></p>
<div class="codehilite"><pre><span></span>def sparse_softmax_cross_entropy_with_logits(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.sparse_softmax_cross_entropy_with_logits</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_softmax_cross_entropy_with_logits(logits, labels, name=None)
</pre></div>


<p>Computes sparse softmax cross entropy between <code>logits</code> and <code>labels</code>.</p>
<p>Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both.</p>
<p><strong>NOTE:</strong>  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the <code>labels</code> vector
must provide a single specific index for the true class for each row of
<code>logits</code> (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
<code>softmax_cross_entropy_with_logits</code>.</p>
<p><strong>WARNING:</strong> This op expects unscaled logits, since it performs a softmax
on <code>logits</code> internally for efficiency.  Do not call this op with the
output of <code>softmax</code>, as it will produce incorrect results.</p>
<p><code>logits</code> must have the shape <code>[batch_size, num_classes]</code>
and dtype <code>float32</code> or <code>float64</code>.</p>
<p><code>labels</code> must have the shape <code>[batch_size]</code> and dtype <code>int32</code> or <code>int64</code>.</p>
<p>Args:
  logits: Unscaled log probabilities.
  labels: Each entry <code>labels[i]</code> must be an index in <code>[0, num_classes)</code>. Other
    values will result in a loss of 0, but incorrect gradient computations.
  name: A name for the operation (optional).</p>
<p>Returns:
  A 1-D <code>Tensor</code> of length <code>batch_size</code> of the same type as <code>logits</code> with the
  softmax cross entropy loss.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_softmax_cross_entropy_with_logits', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_softmax_cross_entropy_with_logits" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_softmax_cross_entropy_with_logits_layer">
    <p>def <span class="ident">sparse_softmax_cross_entropy_with_logits_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_softmax_cross_entropy_with_logits_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_softmax_cross_entropy_with_logits_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_softmax_cross_entropy_with_logits_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_softmax_cross_entropy_with_logits_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.sparse_softmax_cross_entropy_with_logits, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.sparse_softmax_cross_entropy_with_logits</strong></p>
<div class="codehilite"><pre><span></span>def sparse_softmax_cross_entropy_with_logits(logits, labels, name=None):
</pre></div>


<p>Computes sparse softmax cross entropy between <code>logits</code> and <code>labels</code>.</p>
<p>Measures the probability error in discrete classification tasks in which the
classes are mutually exclusive (each entry is in exactly one class).  For
example, each CIFAR-10 image is labeled with one and only one label: an image
can be a dog or a truck, but not both.</p>
<p><strong>NOTE:</strong>  For this operation, the probability of a given label is considered
exclusive.  That is, soft classes are not allowed, and the <code>labels</code> vector
must provide a single specific index for the true class for each row of
<code>logits</code> (each minibatch entry).  For soft softmax classification with
a probability distribution for each entry, see
<code>softmax_cross_entropy_with_logits</code>.</p>
<p><strong>WARNING:</strong> This op expects unscaled logits, since it performs a softmax
on <code>logits</code> internally for efficiency.  Do not call this op with the
output of <code>softmax</code>, as it will produce incorrect results.</p>
<p><code>logits</code> must have the shape <code>[batch_size, num_classes]</code>
and dtype <code>float32</code> or <code>float64</code>.</p>
<p><code>labels</code> must have the shape <code>[batch_size]</code> and dtype <code>int32</code> or <code>int64</code>.</p>
<p>Args:
  logits: Unscaled log probabilities.
  labels: Each entry <code>labels[i]</code> must be an index in <code>[0, num_classes)</code>. Other
    values will result in a loss of 0, but incorrect gradient computations.
  name: A name for the operation (optional).</p>
<p>Returns:
  A 1-D <code>Tensor</code> of length <code>batch_size</code> of the same type as <code>logits</code> with the
  softmax cross entropy loss.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_softmax_cross_entropy_with_logits_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_softmax_cross_entropy_with_logits_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_softmax_layer">
    <p>def <span class="ident">sparse_softmax_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_softmax_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_softmax_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_softmax_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_softmax_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_softmax, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_softmax</strong></p>
<div class="codehilite"><pre><span></span>def sparse_softmax(sp_input, name=None):
</pre></div>


<p>Applies softmax to a batched N-D <code>SparseTensor</code>.</p>
<p>The inputs represent an N-D SparseTensor  with logical shape <code>[..., B, C]</code>
(where <code>N &gt;= 2</code>), and with indices sorted in the canonical lexicographic
order.</p>
<p>This op is equivalent to applying the normal <code>tf.nn.softmax()</code> to each
innermost logical submatrix with shape <code>[B, C]</code>, but with the catch that <em>the
implicitly zero elements do not participate</em>.  Specifically, the algorithm is
equivalent to:</p>
<p>(1) Applies <code>tf.nn.softmax()</code> to a densified view of each innermost
      submatrix with shape <code>[B, C]</code>, along the size-C dimension;
  (2) Masks out the original implicitly-zero locations;
  (3) Renormalizes the remaining elements.</p>
<p>Hence, the <code>SparseTensor</code> result has exactly the same non-zero indices and
shape.</p>
<p>Example:</p>
<p>```python</p>
<h1>First batch:</h1>
<h1>[?   e.]</h1>
<h1>[1.  ? ]</h1>
<h1>Second batch:</h1>
<h1>[e   ? ]</h1>
<h1>[e   e ]</h1>
<p>shape = [2, 2, 2]  # 3-D SparseTensor
values = np.asarray([[[0., np.e], [1., 0.]], [[np.e, 0.], [np.e, np.e]]])
indices = np.vstack(np.where(values)).astype(np.int64).T</p>
<p>result = tf.sparse_softmax(tf.SparseTensor(indices, values, shape))</p>
<h1>...returning a 3-D SparseTensor, equivalent to:</h1>
<h1>[?   1.]     [1    ?]</h1>
<h1>[1.  ? ] and [.5  .5]</h1>
<h1>where ? means implicitly zero.</h1>
<p>```</p>
<p>Args:
  sp_input: N-D <code>SparseTensor</code>, where <code>N &gt;= 2</code>.
  name: optional name of the operation.
Returns:
  output: N-D <code>SparseTensor</code> representing the results.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_softmax_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_softmax_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_split">
    <p>def <span class="ident">sparse_split</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_split, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_split</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_split</strong></p>
<div class="codehilite"><pre><span></span>def sparse_split(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_split</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_split</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_split(split_dim, num_split, sp_input, name=None)
</pre></div>


<p>Split a <code>SparseTensor</code> into <code>num_split</code> tensors along <code>split_dim</code>.</p>
<p>If the <code>sp_input.shape[split_dim]</code> is not an integer multiple of <code>num_split</code>
each slice starting from 0:<code>shape[split_dim] % num_split</code> gets extra one
dimension. For example, if <code>split_dim = 1</code> and <code>num_split = 2</code> and the
input is:</p>
<div class="codehilite"><pre><span></span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="p">[</span>    <span class="n">a</span>   <span class="n">d</span> <span class="n">e</span>  <span class="p">]</span>
<span class="p">[</span><span class="n">b</span> <span class="n">c</span>          <span class="p">]</span>
</pre></div>


<p>Graphically the output tensors are:</p>
<div class="codehilite"><pre><span></span><span class="n">output_tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span>
<span class="p">[</span>    <span class="n">a</span> <span class="p">]</span>
<span class="p">[</span><span class="n">b</span> <span class="n">c</span>   <span class="p">]</span>

<span class="n">output_tensor</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span>
<span class="p">[</span> <span class="n">d</span> <span class="n">e</span>  <span class="p">]</span>
<span class="p">[</span>      <span class="p">]</span>
</pre></div>


<p>Args:
  split_dim: A 0-D <code>int32</code> <code>Tensor</code>. The dimension along which to split.
  num_split: A Python integer. The number of ways to split.
  sp_input: The <code>SparseTensor</code> to split.
  name: A name for the operation (optional).</p>
<p>Returns:
  <code>num_split</code> <code>SparseTensor</code> objects resulting from splitting <code>value</code>.</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_split', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_split" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_split_layer">
    <p>def <span class="ident">sparse_split_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_split_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_split_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_split_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_split_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_split, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_split</strong></p>
<div class="codehilite"><pre><span></span>def sparse_split(split_dim, num_split, sp_input, name=None):
</pre></div>


<p>Split a <code>SparseTensor</code> into <code>num_split</code> tensors along <code>split_dim</code>.</p>
<p>If the <code>sp_input.shape[split_dim]</code> is not an integer multiple of <code>num_split</code>
each slice starting from 0:<code>shape[split_dim] % num_split</code> gets extra one
dimension. For example, if <code>split_dim = 1</code> and <code>num_split = 2</code> and the
input is:</p>
<div class="codehilite"><pre><span></span><span class="n">input_tensor</span> <span class="o">=</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">]</span>
<span class="p">[</span>    <span class="n">a</span>   <span class="n">d</span> <span class="n">e</span>  <span class="p">]</span>
<span class="p">[</span><span class="n">b</span> <span class="n">c</span>          <span class="p">]</span>
</pre></div>


<p>Graphically the output tensors are:</p>
<div class="codehilite"><pre><span></span><span class="n">output_tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span>
<span class="p">[</span>    <span class="n">a</span> <span class="p">]</span>
<span class="p">[</span><span class="n">b</span> <span class="n">c</span>   <span class="p">]</span>

<span class="n">output_tensor</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span>
<span class="p">[</span> <span class="n">d</span> <span class="n">e</span>  <span class="p">]</span>
<span class="p">[</span>      <span class="p">]</span>
</pre></div>


<p>Args:
  split_dim: A 0-D <code>int32</code> <code>Tensor</code>. The dimension along which to split.
  num_split: A Python integer. The number of ways to split.
  sp_input: The <code>SparseTensor</code> to split.
  name: A name for the operation (optional).</p>
<p>Returns:
  <code>num_split</code> <code>SparseTensor</code> objects resulting from splitting <code>value</code>.</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_split_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_split_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_tensor_dense_matmul">
    <p>def <span class="ident">sparse_tensor_dense_matmul</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_tensor_dense_matmul, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_tensor_dense_matmul</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_tensor_dense_matmul</strong></p>
<div class="codehilite"><pre><span></span>def sparse_tensor_dense_matmul(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_tensor_dense_matmul</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_tensor_dense_matmul</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_tensor_dense_matmul(sp_a, b, adjoint_a=False, adjoint_b=False, name=None)
</pre></div>


<p>Multiply SparseTensor (of rank 2) "A" by dense matrix "B".</p>
<p>No validity checking is performed on the indices of A.  However, the following
input format is recommended for optimal behavior:</p>
<p>if adjoint_a == false:
  A should be sorted in lexicographically increasing order.  Use
  sparse_reorder if you're not sure.
if adjoint_a == true:
  A should be sorted in order of increasing dimension 1 (i.e., "column major"
  order instead of "row major" order).</p>
<p>Deciding when to use sparse_tensor_dense_matmul vs. matmul(sp_a=True):</p>
<p>There are a number of questions to ask in the decision process, including:</p>
<ul>
<li>Will the SparseTensor A fit in memory if densified?</li>
<li>Is the column count of the product large (&gt;&gt; 1)?</li>
<li>Is the density of A larger than approximately 15%?</li>
</ul>
<p>If the answer to several of these questions is yes, consider
converting the SparseTensor to a dense one and using tf.matmul with sp_a=True.</p>
<p>This operation tends to perform well when A is more sparse, if the column size
of the product is small (e.g. matrix-vector multiplication), if sp_a.shape
takes on large values.</p>
<p>Below is a rough speed comparison between sparse_tensor_dense_matmul,
labelled 'sparse', and matmul(sp_a=True), labelled 'dense'.  For purposes of
the comparison, the time spent converting from a SparseTensor to a dense
Tensor is not included, so it is overly conservative with respect to
the time ratio.</p>
<p>Benchmark system:
CPU: Intel Ivybridge with HyperThreading (6 cores) dL1:32KB dL2:256KB dL3:12MB
GPU: NVidia Tesla k40c</p>
<p>Compiled with:
-c opt --config=cuda --copt=-mavx</p>
<p>```tensorflow/python/sparse_tensor_dense_matmul_op_test --benchmarks
A sparse [m, k] with % nonzero values between 1% and 80%
B dense [k, n]</p>
<p>% nnz    n       gpu     m       k       dt(dense)       dt(sparse)      dt(sparse)/dt(dense)
0.01     1       True    100     100     0.000221166     0.00010154      0.459112
0.01     1       True    100     1000    0.00033858      0.000109275     0.322745
0.01     1       True    1000    100     0.000310557     9.85661e-05     0.317385
0.01     1       True    1000    1000    0.0008721       0.000100875     0.115669
0.01     1       False   100     100     0.000208085     0.000107603     0.51711
0.01     1       False   100     1000    0.000327112     9.51118e-05     0.290762
0.01     1       False   1000    100     0.000308222     0.00010345      0.335635
0.01     1       False   1000    1000    0.000865721     0.000101397     0.117124
0.01     10      True    100     100     0.000218522     0.000105537     0.482958
0.01     10      True    100     1000    0.000340882     0.000111641     0.327506
0.01     10      True    1000    100     0.000315472     0.000117376     0.372064
0.01     10      True    1000    1000    0.000905493     0.000123263     0.136128
0.01     10      False   100     100     0.000221529     9.82571e-05     0.44354
0.01     10      False   100     1000    0.000330552     0.000112615     0.340687
0.01     10      False   1000    100     0.000341277     0.000114097     0.334324
0.01     10      False   1000    1000    0.000819944     0.000120982     0.147549
0.01     25      True    100     100     0.000207806     0.000105977     0.509981
0.01     25      True    100     1000    0.000322879     0.00012921      0.400181
0.01     25      True    1000    100     0.00038262      0.000141583     0.370035
0.01     25      True    1000    1000    0.000865438     0.000202083     0.233504
0.01     25      False   100     100     0.000209401     0.000104696     0.499979
0.01     25      False   100     1000    0.000321161     0.000130737     0.407076
0.01     25      False   1000    100     0.000377012     0.000136801     0.362856
0.01     25      False   1000    1000    0.000861125     0.00020272      0.235413
0.2      1       True    100     100     0.000206952     9.69219e-05     0.46833
0.2      1       True    100     1000    0.000348674     0.000147475     0.422959
0.2      1       True    1000    100     0.000336908     0.00010122      0.300439
0.2      1       True    1000    1000    0.001022        0.000203274     0.198898
0.2      1       False   100     100     0.000207532     9.5412e-05      0.459746
0.2      1       False   100     1000    0.000356127     0.000146824     0.41228
0.2      1       False   1000    100     0.000322664     0.000100918     0.312764
0.2      1       False   1000    1000    0.000998987     0.000203442     0.203648
0.2      10      True    100     100     0.000211692     0.000109903     0.519165
0.2      10      True    100     1000    0.000372819     0.000164321     0.440753
0.2      10      True    1000    100     0.000338651     0.000144806     0.427596
0.2      10      True    1000    1000    0.00108312      0.000758876     0.70064
0.2      10      False   100     100     0.000215727     0.000110502     0.512231
0.2      10      False   100     1000    0.000375419     0.0001613       0.429653
0.2      10      False   1000    100     0.000336999     0.000145628     0.432132
0.2      10      False   1000    1000    0.00110502      0.000762043     0.689618
0.2      25      True    100     100     0.000218705     0.000129913     0.594009
0.2      25      True    100     1000    0.000394794     0.00029428      0.745402
0.2      25      True    1000    100     0.000404483     0.0002693       0.665788
0.2      25      True    1000    1000    0.0012002       0.00194494      1.62052
0.2      25      False   100     100     0.000221494     0.0001306       0.589632
0.2      25      False   100     1000    0.000396436     0.000297204     0.74969
0.2      25      False   1000    100     0.000409346     0.000270068     0.659754
0.2      25      False   1000    1000    0.00121051      0.00193737      1.60046
0.5      1       True    100     100     0.000214981     9.82111e-05     0.456836
0.5      1       True    100     1000    0.000415328     0.000223073     0.537101
0.5      1       True    1000    100     0.000358324     0.00011269      0.314492
0.5      1       True    1000    1000    0.00137612      0.000437401     0.317851
0.5      1       False   100     100     0.000224196     0.000101423     0.452386
0.5      1       False   100     1000    0.000400987     0.000223286     0.556841
0.5      1       False   1000    100     0.000368825     0.00011224      0.304318
0.5      1       False   1000    1000    0.00136036      0.000429369     0.31563
0.5      10      True    100     100     0.000222125     0.000112308     0.505608
0.5      10      True    100     1000    0.000461088     0.00032357      0.701753
0.5      10      True    1000    100     0.000394624     0.000225497     0.571422
0.5      10      True    1000    1000    0.00158027      0.00190898      1.20801
0.5      10      False   100     100     0.000232083     0.000114978     0.495418
0.5      10      False   100     1000    0.000454574     0.000324632     0.714146
0.5      10      False   1000    100     0.000379097     0.000227768     0.600817
0.5      10      False   1000    1000    0.00160292      0.00190168      1.18638
0.5      25      True    100     100     0.00023429      0.000151703     0.647501
0.5      25      True    100     1000    0.000497462     0.000598873     1.20386
0.5      25      True    1000    100     0.000460778     0.000557038     1.20891
0.5      25      True    1000    1000    0.00170036      0.00467336      2.74845
0.5      25      False   100     100     0.000228981     0.000155334     0.678371
0.5      25      False   100     1000    0.000496139     0.000620789     1.25124
0.5      25      False   1000    100     0.00045473      0.000551528     1.21287
0.5      25      False   1000    1000    0.00171793      0.00467152      2.71927
0.8      1       True    100     100     0.000222037     0.000105301     0.47425
0.8      1       True    100     1000    0.000410804     0.000329327     0.801664
0.8      1       True    1000    100     0.000349735     0.000131225     0.375212
0.8      1       True    1000    1000    0.00139219      0.000677065     0.48633
0.8      1       False   100     100     0.000214079     0.000107486     0.502085
0.8      1       False   100     1000    0.000413746     0.000323244     0.781261
0.8      1       False   1000    100     0.000348983     0.000131983     0.378193
0.8      1       False   1000    1000    0.00136296      0.000685325     0.50282
0.8      10      True    100     100     0.000229159     0.00011825      0.516017
0.8      10      True    100     1000    0.000498845     0.000532618     1.0677
0.8      10      True    1000    100     0.000383126     0.00029935      0.781336
0.8      10      True    1000    1000    0.00162866      0.00307312      1.88689
0.8      10      False   100     100     0.000230783     0.000124958     0.541452
0.8      10      False   100     1000    0.000493393     0.000550654     1.11606
0.8      10      False   1000    100     0.000377167     0.000298581     0.791642
0.8      10      False   1000    1000    0.00165795      0.00305103      1.84024
0.8      25      True    100     100     0.000233496     0.000175241     0.75051
0.8      25      True    100     1000    0.00055654      0.00102658      1.84458
0.8      25      True    1000    100     0.000463814     0.000783267     1.68875
0.8      25      True    1000    1000    0.00186905      0.00755344      4.04132
0.8      25      False   100     100     0.000240243     0.000175047     0.728625
0.8      25      False   100     1000    0.000578102     0.00104499      1.80763
0.8      25      False   1000    100     0.000485113     0.000776849     1.60138
0.8      25      False   1000    1000    0.00211448      0.00752736      3.55992
```</p>
<p>Args:
  sp_a: SparseTensor A, of rank 2.
  b: A dense Matrix with the same dtype as sp_a.
  adjoint_a: Use the adjoint of A in the matrix multiply.  If A is complex,
    this is transpose(conj(A)).  Otherwise it's transpose(A).
  adjoint_b: Use the adjoint of B in the matrix multiply.  If B is complex,
    this is transpose(conj(B)).  Otherwise it's transpose(B).
  name: A name prefix for the returned tensors (optional)</p>
<p>Returns:
  A dense matrix (pseudo-code in dense np.matrix notation):
    A = A.H if adjoint_a else A
    B = B.H if adjoint_b else B
    return A*B</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_tensor_dense_matmul', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_tensor_dense_matmul" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_tensor_dense_matmul_layer">
    <p>def <span class="ident">sparse_tensor_dense_matmul_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_tensor_dense_matmul_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_tensor_dense_matmul_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_tensor_dense_matmul_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_tensor_dense_matmul_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_tensor_dense_matmul, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_tensor_dense_matmul</strong></p>
<div class="codehilite"><pre><span></span>def sparse_tensor_dense_matmul(sp_a, b, adjoint_a=False, adjoint_b=False, name=None):
</pre></div>


<p>Multiply SparseTensor (of rank 2) "A" by dense matrix "B".</p>
<p>No validity checking is performed on the indices of A.  However, the following
input format is recommended for optimal behavior:</p>
<p>if adjoint_a == false:
  A should be sorted in lexicographically increasing order.  Use
  sparse_reorder if you're not sure.
if adjoint_a == true:
  A should be sorted in order of increasing dimension 1 (i.e., "column major"
  order instead of "row major" order).</p>
<p>Deciding when to use sparse_tensor_dense_matmul vs. matmul(sp_a=True):</p>
<p>There are a number of questions to ask in the decision process, including:</p>
<ul>
<li>Will the SparseTensor A fit in memory if densified?</li>
<li>Is the column count of the product large (&gt;&gt; 1)?</li>
<li>Is the density of A larger than approximately 15%?</li>
</ul>
<p>If the answer to several of these questions is yes, consider
converting the SparseTensor to a dense one and using tf.matmul with sp_a=True.</p>
<p>This operation tends to perform well when A is more sparse, if the column size
of the product is small (e.g. matrix-vector multiplication), if sp_a.shape
takes on large values.</p>
<p>Below is a rough speed comparison between sparse_tensor_dense_matmul,
labelled 'sparse', and matmul(sp_a=True), labelled 'dense'.  For purposes of
the comparison, the time spent converting from a SparseTensor to a dense
Tensor is not included, so it is overly conservative with respect to
the time ratio.</p>
<p>Benchmark system:
CPU: Intel Ivybridge with HyperThreading (6 cores) dL1:32KB dL2:256KB dL3:12MB
GPU: NVidia Tesla k40c</p>
<p>Compiled with:
-c opt --config=cuda --copt=-mavx</p>
<p>```tensorflow/python/sparse_tensor_dense_matmul_op_test --benchmarks
A sparse [m, k] with % nonzero values between 1% and 80%
B dense [k, n]</p>
<p>% nnz    n       gpu     m       k       dt(dense)       dt(sparse)      dt(sparse)/dt(dense)
0.01     1       True    100     100     0.000221166     0.00010154      0.459112
0.01     1       True    100     1000    0.00033858      0.000109275     0.322745
0.01     1       True    1000    100     0.000310557     9.85661e-05     0.317385
0.01     1       True    1000    1000    0.0008721       0.000100875     0.115669
0.01     1       False   100     100     0.000208085     0.000107603     0.51711
0.01     1       False   100     1000    0.000327112     9.51118e-05     0.290762
0.01     1       False   1000    100     0.000308222     0.00010345      0.335635
0.01     1       False   1000    1000    0.000865721     0.000101397     0.117124
0.01     10      True    100     100     0.000218522     0.000105537     0.482958
0.01     10      True    100     1000    0.000340882     0.000111641     0.327506
0.01     10      True    1000    100     0.000315472     0.000117376     0.372064
0.01     10      True    1000    1000    0.000905493     0.000123263     0.136128
0.01     10      False   100     100     0.000221529     9.82571e-05     0.44354
0.01     10      False   100     1000    0.000330552     0.000112615     0.340687
0.01     10      False   1000    100     0.000341277     0.000114097     0.334324
0.01     10      False   1000    1000    0.000819944     0.000120982     0.147549
0.01     25      True    100     100     0.000207806     0.000105977     0.509981
0.01     25      True    100     1000    0.000322879     0.00012921      0.400181
0.01     25      True    1000    100     0.00038262      0.000141583     0.370035
0.01     25      True    1000    1000    0.000865438     0.000202083     0.233504
0.01     25      False   100     100     0.000209401     0.000104696     0.499979
0.01     25      False   100     1000    0.000321161     0.000130737     0.407076
0.01     25      False   1000    100     0.000377012     0.000136801     0.362856
0.01     25      False   1000    1000    0.000861125     0.00020272      0.235413
0.2      1       True    100     100     0.000206952     9.69219e-05     0.46833
0.2      1       True    100     1000    0.000348674     0.000147475     0.422959
0.2      1       True    1000    100     0.000336908     0.00010122      0.300439
0.2      1       True    1000    1000    0.001022        0.000203274     0.198898
0.2      1       False   100     100     0.000207532     9.5412e-05      0.459746
0.2      1       False   100     1000    0.000356127     0.000146824     0.41228
0.2      1       False   1000    100     0.000322664     0.000100918     0.312764
0.2      1       False   1000    1000    0.000998987     0.000203442     0.203648
0.2      10      True    100     100     0.000211692     0.000109903     0.519165
0.2      10      True    100     1000    0.000372819     0.000164321     0.440753
0.2      10      True    1000    100     0.000338651     0.000144806     0.427596
0.2      10      True    1000    1000    0.00108312      0.000758876     0.70064
0.2      10      False   100     100     0.000215727     0.000110502     0.512231
0.2      10      False   100     1000    0.000375419     0.0001613       0.429653
0.2      10      False   1000    100     0.000336999     0.000145628     0.432132
0.2      10      False   1000    1000    0.00110502      0.000762043     0.689618
0.2      25      True    100     100     0.000218705     0.000129913     0.594009
0.2      25      True    100     1000    0.000394794     0.00029428      0.745402
0.2      25      True    1000    100     0.000404483     0.0002693       0.665788
0.2      25      True    1000    1000    0.0012002       0.00194494      1.62052
0.2      25      False   100     100     0.000221494     0.0001306       0.589632
0.2      25      False   100     1000    0.000396436     0.000297204     0.74969
0.2      25      False   1000    100     0.000409346     0.000270068     0.659754
0.2      25      False   1000    1000    0.00121051      0.00193737      1.60046
0.5      1       True    100     100     0.000214981     9.82111e-05     0.456836
0.5      1       True    100     1000    0.000415328     0.000223073     0.537101
0.5      1       True    1000    100     0.000358324     0.00011269      0.314492
0.5      1       True    1000    1000    0.00137612      0.000437401     0.317851
0.5      1       False   100     100     0.000224196     0.000101423     0.452386
0.5      1       False   100     1000    0.000400987     0.000223286     0.556841
0.5      1       False   1000    100     0.000368825     0.00011224      0.304318
0.5      1       False   1000    1000    0.00136036      0.000429369     0.31563
0.5      10      True    100     100     0.000222125     0.000112308     0.505608
0.5      10      True    100     1000    0.000461088     0.00032357      0.701753
0.5      10      True    1000    100     0.000394624     0.000225497     0.571422
0.5      10      True    1000    1000    0.00158027      0.00190898      1.20801
0.5      10      False   100     100     0.000232083     0.000114978     0.495418
0.5      10      False   100     1000    0.000454574     0.000324632     0.714146
0.5      10      False   1000    100     0.000379097     0.000227768     0.600817
0.5      10      False   1000    1000    0.00160292      0.00190168      1.18638
0.5      25      True    100     100     0.00023429      0.000151703     0.647501
0.5      25      True    100     1000    0.000497462     0.000598873     1.20386
0.5      25      True    1000    100     0.000460778     0.000557038     1.20891
0.5      25      True    1000    1000    0.00170036      0.00467336      2.74845
0.5      25      False   100     100     0.000228981     0.000155334     0.678371
0.5      25      False   100     1000    0.000496139     0.000620789     1.25124
0.5      25      False   1000    100     0.00045473      0.000551528     1.21287
0.5      25      False   1000    1000    0.00171793      0.00467152      2.71927
0.8      1       True    100     100     0.000222037     0.000105301     0.47425
0.8      1       True    100     1000    0.000410804     0.000329327     0.801664
0.8      1       True    1000    100     0.000349735     0.000131225     0.375212
0.8      1       True    1000    1000    0.00139219      0.000677065     0.48633
0.8      1       False   100     100     0.000214079     0.000107486     0.502085
0.8      1       False   100     1000    0.000413746     0.000323244     0.781261
0.8      1       False   1000    100     0.000348983     0.000131983     0.378193
0.8      1       False   1000    1000    0.00136296      0.000685325     0.50282
0.8      10      True    100     100     0.000229159     0.00011825      0.516017
0.8      10      True    100     1000    0.000498845     0.000532618     1.0677
0.8      10      True    1000    100     0.000383126     0.00029935      0.781336
0.8      10      True    1000    1000    0.00162866      0.00307312      1.88689
0.8      10      False   100     100     0.000230783     0.000124958     0.541452
0.8      10      False   100     1000    0.000493393     0.000550654     1.11606
0.8      10      False   1000    100     0.000377167     0.000298581     0.791642
0.8      10      False   1000    1000    0.00165795      0.00305103      1.84024
0.8      25      True    100     100     0.000233496     0.000175241     0.75051
0.8      25      True    100     1000    0.00055654      0.00102658      1.84458
0.8      25      True    1000    100     0.000463814     0.000783267     1.68875
0.8      25      True    1000    1000    0.00186905      0.00755344      4.04132
0.8      25      False   100     100     0.000240243     0.000175047     0.728625
0.8      25      False   100     1000    0.000578102     0.00104499      1.80763
0.8      25      False   1000    100     0.000485113     0.000776849     1.60138
0.8      25      False   1000    1000    0.00211448      0.00752736      3.55992
```</p>
<p>Args:
  sp_a: SparseTensor A, of rank 2.
  b: A dense Matrix with the same dtype as sp_a.
  adjoint_a: Use the adjoint of A in the matrix multiply.  If A is complex,
    this is transpose(conj(A)).  Otherwise it's transpose(A).
  adjoint_b: Use the adjoint of B in the matrix multiply.  If B is complex,
    this is transpose(conj(B)).  Otherwise it's transpose(B).
  name: A name prefix for the returned tensors (optional)</p>
<p>Returns:
  A dense matrix (pseudo-code in dense np.matrix notation):
    A = A.H if adjoint_a else A
    B = B.H if adjoint_b else B
    return A*B</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_tensor_dense_matmul_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_tensor_dense_matmul_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_tensor_to_dense">
    <p>def <span class="ident">sparse_tensor_to_dense</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_tensor_to_dense, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_tensor_to_dense</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_tensor_to_dense</strong></p>
<div class="codehilite"><pre><span></span>def sparse_tensor_to_dense(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_tensor_to_dense</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_tensor_to_dense</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_tensor_to_dense(sp_input, default_value=0, validate_indices=True, name=None)
</pre></div>


<p>Converts a <code>SparseTensor</code> into a dense tensor.</p>
<p>This op is a convenience wrapper around <code>sparse_to_dense</code> for <code>SparseTensor</code>s.</p>
<p>For example, if <code>sp_input</code> has shape <code>[3, 5]</code> and non-empty string values:</p>
<div class="codehilite"><pre><span></span>[0, 1]: a
[0, 3]: b
[2, 0]: c
</pre></div>


<p>and <code>default_value</code> is <code>x</code>, then the output will be a dense <code>[3, 5]</code>
string tensor with values:</p>
<div class="codehilite"><pre><span></span><span class="k">[[x a x b x]</span>
 <span class="k">[x x x x x]</span>
 <span class="k">[c x x x x]]</span>
</pre></div>


<p>Indices must be without repeats.  This is only
tested if validate_indices is True.</p>
<p>Args:
  sp_input: The input <code>SparseTensor</code>.
  default_value: Scalar value to set for indices not specified in
    <code>sp_input</code>.  Defaults to zero.
  validate_indices: A boolean value.  If <code>True</code>, indices are checked to make
    sure they are sorted in lexicographic order and that there are no repeats.
  name: A name prefix for the returned tensors (optional).</p>
<p>Returns:
  A dense tensor with shape <code>sp_input.shape</code> and values specified by
  the non-empty values in <code>sp_input</code>. Indices not in <code>sp_input</code> are assigned
  <code>default_value</code>.</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_tensor_to_dense', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_tensor_to_dense" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_tensor_to_dense_layer">
    <p>def <span class="ident">sparse_tensor_to_dense_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_tensor_to_dense_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_tensor_to_dense_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_tensor_to_dense_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_tensor_to_dense_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_tensor_to_dense, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_tensor_to_dense</strong></p>
<div class="codehilite"><pre><span></span>def sparse_tensor_to_dense(sp_input, default_value=0, validate_indices=True, name=None):
</pre></div>


<p>Converts a <code>SparseTensor</code> into a dense tensor.</p>
<p>This op is a convenience wrapper around <code>sparse_to_dense</code> for <code>SparseTensor</code>s.</p>
<p>For example, if <code>sp_input</code> has shape <code>[3, 5]</code> and non-empty string values:</p>
<div class="codehilite"><pre><span></span>[0, 1]: a
[0, 3]: b
[2, 0]: c
</pre></div>


<p>and <code>default_value</code> is <code>x</code>, then the output will be a dense <code>[3, 5]</code>
string tensor with values:</p>
<div class="codehilite"><pre><span></span><span class="k">[[x a x b x]</span>
 <span class="k">[x x x x x]</span>
 <span class="k">[c x x x x]]</span>
</pre></div>


<p>Indices must be without repeats.  This is only
tested if validate_indices is True.</p>
<p>Args:
  sp_input: The input <code>SparseTensor</code>.
  default_value: Scalar value to set for indices not specified in
    <code>sp_input</code>.  Defaults to zero.
  validate_indices: A boolean value.  If <code>True</code>, indices are checked to make
    sure they are sorted in lexicographic order and that there are no repeats.
  name: A name prefix for the returned tensors (optional).</p>
<p>Returns:
  A dense tensor with shape <code>sp_input.shape</code> and values specified by
  the non-empty values in <code>sp_input</code>. Indices not in <code>sp_input</code> are assigned
  <code>default_value</code>.</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_tensor_to_dense_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_tensor_to_dense_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_to_dense">
    <p>def <span class="ident">sparse_to_dense</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_to_dense, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_to_dense</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_to_dense</strong></p>
<div class="codehilite"><pre><span></span>def sparse_to_dense(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_to_dense</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_to_dense</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_to_dense(sparse_indices, output_shape, sparse_values, default_value=0, validate_indices=True, name=None)
</pre></div>


<p>Converts a sparse representation into a dense tensor.</p>
<p>Builds an array <code>dense</code> with shape <code>output_shape</code> such that</p>
<p>```python</p>
<h1>If sparse_indices is scalar</h1>
<p>dense[i] = (i == sparse_indices ? sparse_values : default_value)</p>
<h1>If sparse_indices is a vector, then for each i</h1>
<p>dense[sparse_indices[i]] = sparse_values[i]</p>
<h1>If sparse_indices is an n by d matrix, then for each i in [0, n)</h1>
<p>dense[sparse_indices[i][0], ..., sparse_indices[i][d-1]] = sparse_values[i]
```</p>
<p>All other values in <code>dense</code> are set to <code>default_value</code>.  If <code>sparse_values</code>
is a scalar, all sparse indices are set to this single value.</p>
<p>Indices should be sorted in lexicographic order, and indices must not
contain any repeats. If <code>validate_indices</code> is True, these properties
are checked during execution.</p>
<p>Args:
  sparse_indices: A 0-D, 1-D, or 2-D <code>Tensor</code> of type <code>int32</code> or <code>int64</code>.
    <code>sparse_indices[i]</code> contains the complete index where <code>sparse_values[i]</code>
    will be placed.
  output_shape: A 1-D <code>Tensor</code> of the same type as <code>sparse_indices</code>.  Shape
    of the dense output tensor.
  sparse_values: A 0-D or 1-D <code>Tensor</code>.  Values corresponding to each row of
    <code>sparse_indices</code>, or a scalar value to be used for all sparse indices.
  default_value: A 0-D <code>Tensor</code> of the same type as <code>sparse_values</code>.  Value
    to set for indices not specified in <code>sparse_indices</code>.  Defaults to zero.
  validate_indices: A boolean value.  If True, indices are checked to make
    sure they are sorted in lexicographic order and that there are no repeats.
  name: A name for the operation (optional).</p>
<p>Returns:
  Dense <code>Tensor</code> of shape <code>output_shape</code>.  Has the same type as
  <code>sparse_values</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_to_dense', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_to_dense" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_to_dense_layer">
    <p>def <span class="ident">sparse_to_dense_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_to_dense_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_to_dense_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_to_dense_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_to_dense_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_to_dense, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_to_dense</strong></p>
<div class="codehilite"><pre><span></span>def sparse_to_dense(sparse_indices, output_shape, sparse_values, default_value=0, validate_indices=True, name=None):
</pre></div>


<p>Converts a sparse representation into a dense tensor.</p>
<p>Builds an array <code>dense</code> with shape <code>output_shape</code> such that</p>
<p>```python</p>
<h1>If sparse_indices is scalar</h1>
<p>dense[i] = (i == sparse_indices ? sparse_values : default_value)</p>
<h1>If sparse_indices is a vector, then for each i</h1>
<p>dense[sparse_indices[i]] = sparse_values[i]</p>
<h1>If sparse_indices is an n by d matrix, then for each i in [0, n)</h1>
<p>dense[sparse_indices[i][0], ..., sparse_indices[i][d-1]] = sparse_values[i]
```</p>
<p>All other values in <code>dense</code> are set to <code>default_value</code>.  If <code>sparse_values</code>
is a scalar, all sparse indices are set to this single value.</p>
<p>Indices should be sorted in lexicographic order, and indices must not
contain any repeats. If <code>validate_indices</code> is True, these properties
are checked during execution.</p>
<p>Args:
  sparse_indices: A 0-D, 1-D, or 2-D <code>Tensor</code> of type <code>int32</code> or <code>int64</code>.
    <code>sparse_indices[i]</code> contains the complete index where <code>sparse_values[i]</code>
    will be placed.
  output_shape: A 1-D <code>Tensor</code> of the same type as <code>sparse_indices</code>.  Shape
    of the dense output tensor.
  sparse_values: A 0-D or 1-D <code>Tensor</code>.  Values corresponding to each row of
    <code>sparse_indices</code>, or a scalar value to be used for all sparse indices.
  default_value: A 0-D <code>Tensor</code> of the same type as <code>sparse_values</code>.  Value
    to set for indices not specified in <code>sparse_indices</code>.  Defaults to zero.
  validate_indices: A boolean value.  If True, indices are checked to make
    sure they are sorted in lexicographic order and that there are no repeats.
  name: A name for the operation (optional).</p>
<p>Returns:
  Dense <code>Tensor</code> of shape <code>output_shape</code>.  Has the same type as
  <code>sparse_values</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_to_dense_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_to_dense_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_to_indicator">
    <p>def <span class="ident">sparse_to_indicator</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_to_indicator, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_to_indicator</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_to_indicator</strong></p>
<div class="codehilite"><pre><span></span>def sparse_to_indicator(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sparse_to_indicator</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sparse_to_indicator</code></strong></p>
<div class="codehilite"><pre><span></span>def sparse_to_indicator(sp_input, vocab_size, name=None)
</pre></div>


<p>Converts a <code>SparseTensor</code> of ids into a dense bool indicator tensor.</p>
<p>The last dimension of <code>sp_input.indices</code> is discarded and replaced with
the values of <code>sp_input</code>.  If <code>sp_input.shape = [D0, D1, ..., Dn, K]</code>, then
<code>output.shape = [D0, D1, ..., Dn, vocab_size]</code>, where</p>
<div class="codehilite"><pre><span></span>output[d_0, d_1, ..., d_n, sp_input[d_0, d_1, ..., d_n, k]] = True
</pre></div>


<p>and False elsewhere in <code>output</code>.</p>
<p>For example, if <code>sp_input.shape = [2, 3, 4]</code> with non-empty values:</p>
<div class="codehilite"><pre><span></span>[0, 0, 0]: 0
[0, 1, 0]: 10
[1, 0, 3]: 103
[1, 1, 2]: 150
[1, 1, 3]: 149
[1, 1, 4]: 150
[1, 2, 1]: 121
</pre></div>


<p>and <code>vocab_size = 200</code>, then the output will be a <code>[2, 3, 200]</code> dense bool
tensor with False everywhere except at positions</p>
<div class="codehilite"><pre><span></span>(0, 0, 0), (0, 1, 10), (1, 0, 103), (1, 1, 149), (1, 1, 150),
(1, 2, 121).
</pre></div>


<p>Note that repeats are allowed in the input SparseTensor.
This op is useful for converting <code>SparseTensor</code>s into dense formats for
compatibility with ops that expect dense tensors.</p>
<p>The input <code>SparseTensor</code> must be in row-major order.</p>
<p>Args:
  sp_input: A <code>SparseTensor</code> with <code>values</code> property of type <code>int32</code> or
    <code>int64</code>.
  vocab_size: A scalar int64 Tensor (or Python int) containing the new size
    of the last dimension, <code>all(0 &lt;= sp_input.values &lt; vocab_size)</code>.
  name: A name prefix for the returned tensors (optional)</p>
<p>Returns:
  A dense bool indicator tensor representing the indices with specified value.</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_to_indicator', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_to_indicator" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sparse_to_indicator_layer">
    <p>def <span class="ident">sparse_to_indicator_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sparse_to_indicator_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sparse_to_indicator_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sparse_to_indicator_layer</strong></p>
<div class="codehilite"><pre><span></span>def sparse_to_indicator_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sparse_to_indicator, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sparse_to_indicator</strong></p>
<div class="codehilite"><pre><span></span>def sparse_to_indicator(sp_input, vocab_size, name=None):
</pre></div>


<p>Converts a <code>SparseTensor</code> of ids into a dense bool indicator tensor.</p>
<p>The last dimension of <code>sp_input.indices</code> is discarded and replaced with
the values of <code>sp_input</code>.  If <code>sp_input.shape = [D0, D1, ..., Dn, K]</code>, then
<code>output.shape = [D0, D1, ..., Dn, vocab_size]</code>, where</p>
<div class="codehilite"><pre><span></span>output[d_0, d_1, ..., d_n, sp_input[d_0, d_1, ..., d_n, k]] = True
</pre></div>


<p>and False elsewhere in <code>output</code>.</p>
<p>For example, if <code>sp_input.shape = [2, 3, 4]</code> with non-empty values:</p>
<div class="codehilite"><pre><span></span>[0, 0, 0]: 0
[0, 1, 0]: 10
[1, 0, 3]: 103
[1, 1, 2]: 150
[1, 1, 3]: 149
[1, 1, 4]: 150
[1, 2, 1]: 121
</pre></div>


<p>and <code>vocab_size = 200</code>, then the output will be a <code>[2, 3, 200]</code> dense bool
tensor with False everywhere except at positions</p>
<div class="codehilite"><pre><span></span>(0, 0, 0), (0, 1, 10), (1, 0, 103), (1, 1, 149), (1, 1, 150),
(1, 2, 121).
</pre></div>


<p>Note that repeats are allowed in the input SparseTensor.
This op is useful for converting <code>SparseTensor</code>s into dense formats for
compatibility with ops that expect dense tensors.</p>
<p>The input <code>SparseTensor</code> must be in row-major order.</p>
<p>Args:
  sp_input: A <code>SparseTensor</code> with <code>values</code> property of type <code>int32</code> or
    <code>int64</code>.
  vocab_size: A scalar int64 Tensor (or Python int) containing the new size
    of the last dimension, <code>all(0 &lt;= sp_input.values &lt; vocab_size)</code>.
  name: A name prefix for the returned tensors (optional)</p>
<p>Returns:
  A dense bool indicator tensor representing the indices with specified value.</p>
<p>Raises:
  TypeError: If <code>sp_input</code> is not a <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sparse_to_indicator_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sparse_to_indicator_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.split">
    <p>def <span class="ident">split</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.split, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.split</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.split</strong></p>
<div class="codehilite"><pre><span></span>def split(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.split</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.split</code></strong></p>
<div class="codehilite"><pre><span></span>def split(split_dim, num_split, value, name=&quot;split&quot;)
</pre></div>


<p>Splits a tensor into <code>num_split</code> tensors along one dimension.</p>
<p>Splits <code>value</code> along dimension <code>split_dim</code> into <code>num_split</code> smaller tensors.
Requires that <code>num_split</code> evenly divide <code>value.shape[split_dim]</code>.</p>
<p>For example:</p>
<p>```python</p>
<h1>'value' is a tensor with shape [5, 30]</h1>
<h1>Split 'value' into 3 tensors along dimension 1</h1>
<p>split0, split1, split2 = tf.split(1, 3, value)
tf.shape(split0) ==&gt; [5, 10]
```</p>
<p>Args:
  split_dim: A 0-D <code>int32</code> <code>Tensor</code>. The dimension along which to split.
    Must be in the range <code>[0, rank(value))</code>.
  num_split: A Python integer. The number of ways to split.
  value: The <code>Tensor</code> to split.
  name: A name for the operation (optional).</p>
<p>Returns:
  <code>num_split</code> <code>Tensor</code> objects resulting from splitting <code>value</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.split', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.split" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.split_layer">
    <p>def <span class="ident">split_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.split_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.split_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.split_layer</strong></p>
<div class="codehilite"><pre><span></span>def split_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.split, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.split</strong></p>
<div class="codehilite"><pre><span></span>def split(split_dim, num_split, value, name=&quot;split&quot;):
</pre></div>


<p>Splits a tensor into <code>num_split</code> tensors along one dimension.</p>
<p>Splits <code>value</code> along dimension <code>split_dim</code> into <code>num_split</code> smaller tensors.
Requires that <code>num_split</code> evenly divide <code>value.shape[split_dim]</code>.</p>
<p>For example:</p>
<p>```python</p>
<h1>'value' is a tensor with shape [5, 30]</h1>
<h1>Split 'value' into 3 tensors along dimension 1</h1>
<p>split0, split1, split2 = tf.split(1, 3, value)
tf.shape(split0) ==&gt; [5, 10]
```</p>
<p>Args:
  split_dim: A 0-D <code>int32</code> <code>Tensor</code>. The dimension along which to split.
    Must be in the range <code>[0, rank(value))</code>.
  num_split: A Python integer. The number of ways to split.
  value: The <code>Tensor</code> to split.
  name: A name for the operation (optional).</p>
<p>Returns:
  <code>num_split</code> <code>Tensor</code> objects resulting from splitting <code>value</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.split_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.split_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sqrt">
    <p>def <span class="ident">sqrt</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sqrt, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sqrt</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sqrt</strong></p>
<div class="codehilite"><pre><span></span>def sqrt(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sqrt</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sqrt</code></strong></p>
<div class="codehilite"><pre><span></span>def sqrt(x, name=None)
</pre></div>


<p>Computes square root of x element-wise.</p>
<p>I.e., \(y = \sqrt{x} = x^{1/2}\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sqrt', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sqrt" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sqrt_layer">
    <p>def <span class="ident">sqrt_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sqrt_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sqrt_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sqrt_layer</strong></p>
<div class="codehilite"><pre><span></span>def sqrt_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sqrt, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sqrt</strong></p>
<div class="codehilite"><pre><span></span>def sqrt(x, name=None):
</pre></div>


<p>Computes square root of x element-wise.</p>
<p>I.e., \(y = \sqrt{x} = x^{1/2}\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sqrt_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sqrt_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.square">
    <p>def <span class="ident">square</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.square, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.square</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.square</strong></p>
<div class="codehilite"><pre><span></span>def square(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.square</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.square</code></strong></p>
<div class="codehilite"><pre><span></span>def square(x, name=None)
</pre></div>


<p>Computes square of x element-wise.</p>
<p>I.e., \(y = x * x = x^2\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.square', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.square" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.square_layer">
    <p>def <span class="ident">square_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.square_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.square_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.square_layer</strong></p>
<div class="codehilite"><pre><span></span>def square_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.square, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.square</strong></p>
<div class="codehilite"><pre><span></span>def square(x, name=None):
</pre></div>


<p>Computes square of x element-wise.</p>
<p>I.e., \(y = x * x = x^2\).</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.square_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.square_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.squared_difference">
    <p>def <span class="ident">squared_difference</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.squared_difference, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.squared_difference</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.squared_difference</strong></p>
<div class="codehilite"><pre><span></span>def squared_difference(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.squared_difference</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.squared_difference</code></strong></p>
<div class="codehilite"><pre><span></span>def squared_difference(x, y, name=None)
</pre></div>


<p>Returns (x - y)(x - y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.squared_difference', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.squared_difference" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.squared_difference_layer">
    <p>def <span class="ident">squared_difference_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.squared_difference_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.squared_difference_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.squared_difference_layer</strong></p>
<div class="codehilite"><pre><span></span>def squared_difference_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.squared_difference, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.squared_difference</strong></p>
<div class="codehilite"><pre><span></span>def squared_difference(x, y, name=None):
</pre></div>


<p>Returns (x - y)(x - y) element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.squared_difference_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.squared_difference_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.squeeze">
    <p>def <span class="ident">squeeze</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.squeeze, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.squeeze</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.squeeze</strong></p>
<div class="codehilite"><pre><span></span>def squeeze(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.squeeze</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.squeeze</code></strong></p>
<div class="codehilite"><pre><span></span>def squeeze(input, squeeze_dims=None, name=None)
</pre></div>


<p>Removes dimensions of size 1 from the shape of a tensor.</p>
<p>Given a tensor <code>input</code>, this operation returns a tensor of the same type with
all dimensions of size 1 removed. If you don't want to remove all size 1
dimensions, you can remove specific size 1 dimensions by specifying
<code>squeeze_dims</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'t' is a tensor of shape [1, 2, 1, 3, 1, 1]</h1>
<p>shape(squeeze(t)) ==&gt; [2, 3]
```</p>
<p>Or, to remove specific size 1 dimensions:</p>
<p>```prettyprint</p>
<h1>'t' is a tensor of shape [1, 2, 1, 3, 1, 1]</h1>
<p>shape(squeeze(t, [2, 4])) ==&gt; [1, 2, 3, 1]
```</p>
<p>Args:
  input: A <code>Tensor</code>. The <code>input</code> to squeeze.
  squeeze_dims: An optional list of <code>ints</code>. Defaults to <code>[]</code>.
    If specified, only squeezes the dimensions listed. The dimension
    index starts at 0. It is an error to squeeze a dimension that is not 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  Contains the same data as <code>input</code>, but has one or more dimensions of
  size 1 removed.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.squeeze', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.squeeze" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.squeeze_layer">
    <p>def <span class="ident">squeeze_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.squeeze_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.squeeze_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.squeeze_layer</strong></p>
<div class="codehilite"><pre><span></span>def squeeze_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.squeeze, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.squeeze</strong></p>
<div class="codehilite"><pre><span></span>def squeeze(input, squeeze_dims=None, name=None):
</pre></div>


<p>Removes dimensions of size 1 from the shape of a tensor.</p>
<p>Given a tensor <code>input</code>, this operation returns a tensor of the same type with
all dimensions of size 1 removed. If you don't want to remove all size 1
dimensions, you can remove specific size 1 dimensions by specifying
<code>squeeze_dims</code>.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'t' is a tensor of shape [1, 2, 1, 3, 1, 1]</h1>
<p>shape(squeeze(t)) ==&gt; [2, 3]
```</p>
<p>Or, to remove specific size 1 dimensions:</p>
<p>```prettyprint</p>
<h1>'t' is a tensor of shape [1, 2, 1, 3, 1, 1]</h1>
<p>shape(squeeze(t, [2, 4])) ==&gt; [1, 2, 3, 1]
```</p>
<p>Args:
  input: A <code>Tensor</code>. The <code>input</code> to squeeze.
  squeeze_dims: An optional list of <code>ints</code>. Defaults to <code>[]</code>.
    If specified, only squeezes the dimensions listed. The dimension
    index starts at 0. It is an error to squeeze a dimension that is not 1.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.
  Contains the same data as <code>input</code>, but has one or more dimensions of
  size 1 removed.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.squeeze_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.squeeze_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.state_saving_rnn">
    <p>def <span class="ident">state_saving_rnn</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.state_saving_rnn, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.state_saving_rnn</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.state_saving_rnn</strong></p>
<div class="codehilite"><pre><span></span>def state_saving_rnn(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.state_saving_rnn</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.state_saving_rnn</code></strong></p>
<div class="codehilite"><pre><span></span>def state_saving_rnn(cell, inputs, state_saver, state_name, sequence_length=None, scope=None)
</pre></div>


<p>RNN that accepts a state saver for time-truncated RNN calculation.</p>
<p>Args:
  cell: An instance of <code>RNNCell</code>.
  inputs: A length T list of inputs, each a tensor of shape
    <code>[batch_size, input_size]</code>.
  state_saver: A state saver object with methods <code>state</code> and <code>save_state</code>.
  state_name: Python string or tuple of strings.  The name to use with the
    state_saver. If the cell returns tuples of states (i.e.,
    <code>cell.state_size</code> is a tuple) then <code>state_name</code> should be a tuple of
    strings having the same length as <code>cell.state_size</code>.  Otherwise it should
    be a single string.
  sequence_length: (optional) An int32/int64 vector size [batch_size].
    See the documentation for rnn() for more details about sequence_length.
  scope: VariableScope for the created subgraph; defaults to "RNN".</p>
<p>Returns:
  A pair (outputs, state) where:
    outputs is a length T list of outputs (one for each input)
    states is the final state</p>
<p>Raises:
  TypeError: If <code>cell</code> is not an instance of RNNCell.
  ValueError: If <code>inputs</code> is <code>None</code> or an empty list, or if the arity and
   type of <code>state_name</code> does not match that of <code>cell.state_size</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.state_saving_rnn', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.state_saving_rnn" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.state_saving_rnn_layer">
    <p>def <span class="ident">state_saving_rnn_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.state_saving_rnn_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.state_saving_rnn_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.state_saving_rnn_layer</strong></p>
<div class="codehilite"><pre><span></span>def state_saving_rnn_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.state_saving_rnn, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.state_saving_rnn</strong></p>
<div class="codehilite"><pre><span></span>def state_saving_rnn(cell, inputs, state_saver, state_name, sequence_length=None, scope=None):
</pre></div>


<p>RNN that accepts a state saver for time-truncated RNN calculation.</p>
<p>Args:
  cell: An instance of <code>RNNCell</code>.
  inputs: A length T list of inputs, each a tensor of shape
    <code>[batch_size, input_size]</code>.
  state_saver: A state saver object with methods <code>state</code> and <code>save_state</code>.
  state_name: Python string or tuple of strings.  The name to use with the
    state_saver. If the cell returns tuples of states (i.e.,
    <code>cell.state_size</code> is a tuple) then <code>state_name</code> should be a tuple of
    strings having the same length as <code>cell.state_size</code>.  Otherwise it should
    be a single string.
  sequence_length: (optional) An int32/int64 vector size [batch_size].
    See the documentation for rnn() for more details about sequence_length.
  scope: VariableScope for the created subgraph; defaults to "RNN".</p>
<p>Returns:
  A pair (outputs, state) where:
    outputs is a length T list of outputs (one for each input)
    states is the final state</p>
<p>Raises:
  TypeError: If <code>cell</code> is not an instance of RNNCell.
  ValueError: If <code>inputs</code> is <code>None</code> or an empty list, or if the arity and
   type of <code>state_name</code> does not match that of <code>cell.state_size</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.state_saving_rnn_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.state_saving_rnn_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.stop_gradient">
    <p>def <span class="ident">stop_gradient</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.stop_gradient, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.stop_gradient</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.stop_gradient</strong></p>
<div class="codehilite"><pre><span></span>def stop_gradient(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.stop_gradient</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.stop_gradient</code></strong></p>
<div class="codehilite"><pre><span></span>def stop_gradient(input, name=None)
</pre></div>


<p>Stops gradient computation.</p>
<p>When executed in a graph, this op outputs its input tensor as-is.</p>
<p>When building ops to compute gradients, this op prevents the contribution of
its inputs to be taken into account.  Normally, the gradient generator adds ops
to a graph to compute the derivatives of a specified 'loss' by recursively
finding out inputs that contributed to its computation.  If you insert this op
in the graph it inputs are masked from the gradient generator.  They are not
taken into account for computing gradients.</p>
<p>This is useful any time you want to compute a value with TensorFlow but need
to pretend that the value was a constant. Some examples include:</p>
<ul>
<li>The <em>EM</em> algorithm where the <em>M-step</em> should not involve backpropagation
   through the output of the <em>E-step</em>.</li>
<li>Contrastive divergence training of Boltzmann machines where, when
   differentiating the energy function, the training must not backpropagate
   through the graph that generated the samples from the model.</li>
<li>Adversarial training, where no backprop should happen through the adversarial
   example generation process.</li>
</ul>
<p>Args:
  input: A <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.stop_gradient', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.stop_gradient" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.stop_gradient_layer">
    <p>def <span class="ident">stop_gradient_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.stop_gradient_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.stop_gradient_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.stop_gradient_layer</strong></p>
<div class="codehilite"><pre><span></span>def stop_gradient_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.stop_gradient, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.stop_gradient</strong></p>
<div class="codehilite"><pre><span></span>def stop_gradient(input, name=None):
</pre></div>


<p>Stops gradient computation.</p>
<p>When executed in a graph, this op outputs its input tensor as-is.</p>
<p>When building ops to compute gradients, this op prevents the contribution of
its inputs to be taken into account.  Normally, the gradient generator adds ops
to a graph to compute the derivatives of a specified 'loss' by recursively
finding out inputs that contributed to its computation.  If you insert this op
in the graph it inputs are masked from the gradient generator.  They are not
taken into account for computing gradients.</p>
<p>This is useful any time you want to compute a value with TensorFlow but need
to pretend that the value was a constant. Some examples include:</p>
<ul>
<li>The <em>EM</em> algorithm where the <em>M-step</em> should not involve backpropagation
   through the output of the <em>E-step</em>.</li>
<li>Contrastive divergence training of Boltzmann machines where, when
   differentiating the energy function, the training must not backpropagate
   through the graph that generated the samples from the model.</li>
<li>Adversarial training, where no backprop should happen through the adversarial
   example generation process.</li>
</ul>
<p>Args:
  input: A <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.stop_gradient_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.stop_gradient_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.string_to_hash_bucket">
    <p>def <span class="ident">string_to_hash_bucket</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.string_to_hash_bucket, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.string_to_hash_bucket</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.string_to_hash_bucket</strong></p>
<div class="codehilite"><pre><span></span>def string_to_hash_bucket(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.string_to_hash_bucket</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.string_to_hash_bucket</code></strong></p>
<div class="codehilite"><pre><span></span>def string_to_hash_bucket(string_tensor, num_buckets, name=None)
</pre></div>


<p>Converts each string in the input Tensor to its hash mod by a number of buckets.</p>
<p>The hash function is deterministic on the content of the string within the
process.</p>
<p>Note that the hash function may change from time to time.</p>
<p>Args:
  string_tensor: A <code>Tensor</code> of type <code>string</code>.
  num_buckets: An <code>int</code> that is <code>&gt;= 1</code>. The number of buckets.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.
  A Tensor of the same shape as the input <code>string_tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.string_to_hash_bucket', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.string_to_hash_bucket" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_fast">
    <p>def <span class="ident">string_to_hash_bucket_fast</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.string_to_hash_bucket_fast, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.string_to_hash_bucket_fast</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.string_to_hash_bucket_fast</strong></p>
<div class="codehilite"><pre><span></span>def string_to_hash_bucket_fast(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.string_to_hash_bucket_fast</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.string_to_hash_bucket_fast</code></strong></p>
<div class="codehilite"><pre><span></span>def string_to_hash_bucket_fast(input, num_buckets, name=None)
</pre></div>


<p>Converts each string in the input Tensor to its hash mod by a number of buckets.</p>
<p>The hash function is deterministic on the content of the string within the
process and will never change. However, it is not suitable for cryptography.
This function may be used when CPU time is scarce and inputs are trusted or
unimportant. There is a risk of adversaries constructing inputs that all hash
to the same bucket. To prevent this problem, use a strong hash function with
<code>tf.string_to_hash_bucket_strong</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>string</code>. The strings to assign a hash bucket.
  num_buckets: An <code>int</code> that is <code>&gt;= 1</code>. The number of buckets.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.
  A Tensor of the same shape as the input <code>string_tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_fast', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_fast" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_fast_layer">
    <p>def <span class="ident">string_to_hash_bucket_fast_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.string_to_hash_bucket_fast_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.string_to_hash_bucket_fast_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.string_to_hash_bucket_fast_layer</strong></p>
<div class="codehilite"><pre><span></span>def string_to_hash_bucket_fast_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.string_to_hash_bucket_fast, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.string_to_hash_bucket_fast</strong></p>
<div class="codehilite"><pre><span></span>def string_to_hash_bucket_fast(input, num_buckets, name=None):
</pre></div>


<p>Converts each string in the input Tensor to its hash mod by a number of buckets.</p>
<p>The hash function is deterministic on the content of the string within the
process and will never change. However, it is not suitable for cryptography.
This function may be used when CPU time is scarce and inputs are trusted or
unimportant. There is a risk of adversaries constructing inputs that all hash
to the same bucket. To prevent this problem, use a strong hash function with
<code>tf.string_to_hash_bucket_strong</code>.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>string</code>. The strings to assign a hash bucket.
  num_buckets: An <code>int</code> that is <code>&gt;= 1</code>. The number of buckets.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.
  A Tensor of the same shape as the input <code>string_tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_fast_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_fast_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_layer">
    <p>def <span class="ident">string_to_hash_bucket_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.string_to_hash_bucket_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.string_to_hash_bucket_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.string_to_hash_bucket_layer</strong></p>
<div class="codehilite"><pre><span></span>def string_to_hash_bucket_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.string_to_hash_bucket, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.string_to_hash_bucket</strong></p>
<div class="codehilite"><pre><span></span>def string_to_hash_bucket(string_tensor, num_buckets, name=None):
</pre></div>


<p>Converts each string in the input Tensor to its hash mod by a number of buckets.</p>
<p>The hash function is deterministic on the content of the string within the
process.</p>
<p>Note that the hash function may change from time to time.</p>
<p>Args:
  string_tensor: A <code>Tensor</code> of type <code>string</code>.
  num_buckets: An <code>int</code> that is <code>&gt;= 1</code>. The number of buckets.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.
  A Tensor of the same shape as the input <code>string_tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_strong">
    <p>def <span class="ident">string_to_hash_bucket_strong</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.string_to_hash_bucket_strong, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.string_to_hash_bucket_strong</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.string_to_hash_bucket_strong</strong></p>
<div class="codehilite"><pre><span></span>def string_to_hash_bucket_strong(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.string_to_hash_bucket_strong</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.string_to_hash_bucket_strong</code></strong></p>
<div class="codehilite"><pre><span></span>def string_to_hash_bucket_strong(input, num_buckets, key, name=None)
</pre></div>


<p>Converts each string in the input Tensor to its hash mod by a number of buckets.</p>
<p>The hash function is deterministic on the content of the string within the
process. The hash function is a keyed hash function, where attribute <code>key</code>
defines the key of the hash function. <code>key</code> is an array of 2 elements.</p>
<p>A strong hash is important when inputs may be malicious, e.g. URLs with
additional components. Adversaries could try to make their inputs hash to the
same bucket for a denial-of-service attack or to skew the results. A strong
hash prevents this by making it dificult, if not infeasible, to compute inputs
that hash to the same bucket. This comes at a cost of roughly 4x higher compute
time than tf.string_to_hash_bucket_fast.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>string</code>. The strings to assign a hash bucket.
  num_buckets: An <code>int</code> that is <code>&gt;= 1</code>. The number of buckets.
  key: A list of <code>ints</code>.
    The key for the keyed hash function passed as a list of two uint64
    elements.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.
  A Tensor of the same shape as the input <code>string_tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_strong', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_strong" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_strong_layer">
    <p>def <span class="ident">string_to_hash_bucket_strong_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.string_to_hash_bucket_strong_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.string_to_hash_bucket_strong_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.string_to_hash_bucket_strong_layer</strong></p>
<div class="codehilite"><pre><span></span>def string_to_hash_bucket_strong_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.string_to_hash_bucket_strong, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.string_to_hash_bucket_strong</strong></p>
<div class="codehilite"><pre><span></span>def string_to_hash_bucket_strong(input, num_buckets, key, name=None):
</pre></div>


<p>Converts each string in the input Tensor to its hash mod by a number of buckets.</p>
<p>The hash function is deterministic on the content of the string within the
process. The hash function is a keyed hash function, where attribute <code>key</code>
defines the key of the hash function. <code>key</code> is an array of 2 elements.</p>
<p>A strong hash is important when inputs may be malicious, e.g. URLs with
additional components. Adversaries could try to make their inputs hash to the
same bucket for a denial-of-service attack or to skew the results. A strong
hash prevents this by making it dificult, if not infeasible, to compute inputs
that hash to the same bucket. This comes at a cost of roughly 4x higher compute
time than tf.string_to_hash_bucket_fast.</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>string</code>. The strings to assign a hash bucket.
  num_buckets: An <code>int</code> that is <code>&gt;= 1</code>. The number of buckets.
  key: A list of <code>ints</code>.
    The key for the keyed hash function passed as a list of two uint64
    elements.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.
  A Tensor of the same shape as the input <code>string_tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_strong_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.string_to_hash_bucket_strong_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.string_to_number">
    <p>def <span class="ident">string_to_number</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.string_to_number, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.string_to_number</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.string_to_number</strong></p>
<div class="codehilite"><pre><span></span>def string_to_number(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.string_to_number</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.string_to_number</code></strong></p>
<div class="codehilite"><pre><span></span>def string_to_number(string_tensor, out_type=None, name=None)
</pre></div>


<p>Converts each string in the input Tensor to the specified numeric type.</p>
<p>(Note that int32 overflow results in an error while float overflow
results in a rounded value.)</p>
<p>Args:
  string_tensor: A <code>Tensor</code> of type <code>string</code>.
  out_type: An optional <code>tf.DType</code> from: <code>tf.float32, tf.int32</code>. Defaults to <code>tf.float32</code>.
    The numeric type to interpret each string in string_tensor as.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>out_type</code>.
  A Tensor of the same shape as the input <code>string_tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.string_to_number', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.string_to_number" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.string_to_number_layer">
    <p>def <span class="ident">string_to_number_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.string_to_number_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.string_to_number_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.string_to_number_layer</strong></p>
<div class="codehilite"><pre><span></span>def string_to_number_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.string_to_number, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.string_to_number</strong></p>
<div class="codehilite"><pre><span></span>def string_to_number(string_tensor, out_type=None, name=None):
</pre></div>


<p>Converts each string in the input Tensor to the specified numeric type.</p>
<p>(Note that int32 overflow results in an error while float overflow
results in a rounded value.)</p>
<p>Args:
  string_tensor: A <code>Tensor</code> of type <code>string</code>.
  out_type: An optional <code>tf.DType</code> from: <code>tf.float32, tf.int32</code>. Defaults to <code>tf.float32</code>.
    The numeric type to interpret each string in string_tensor as.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>out_type</code>.
  A Tensor of the same shape as the input <code>string_tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.string_to_number_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.string_to_number_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sub">
    <p>def <span class="ident">sub</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sub, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sub</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sub</strong></p>
<div class="codehilite"><pre><span></span>def sub(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.sub</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.sub</code></strong></p>
<div class="codehilite"><pre><span></span>def sub(x, y, name=None)
</pre></div>


<p>Returns x - y element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sub', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sub" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sub_layer">
    <p>def <span class="ident">sub_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sub_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sub_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sub_layer</strong></p>
<div class="codehilite"><pre><span></span>def sub_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.sub, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.sub</strong></p>
<div class="codehilite"><pre><span></span>def sub(x, y, name=None):
</pre></div>


<p>Returns x - y element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  y: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sub_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sub_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sufficient_statistics">
    <p>def <span class="ident">sufficient_statistics</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sufficient_statistics, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sufficient_statistics</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sufficient_statistics</strong></p>
<div class="codehilite"><pre><span></span>def sufficient_statistics(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.sufficient_statistics</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.sufficient_statistics</code></strong></p>
<div class="codehilite"><pre><span></span>def sufficient_statistics(x, axes, shift=None, keep_dims=False, name=None)
</pre></div>


<p>Calculate the sufficient statistics for the mean and variance of <code>x</code>.</p>
<p>These sufficient statistics are computed using the one pass algorithm on
an input that's optionally shifted. See:
https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Computing_shifted_data</p>
<p>Args:
  x: A <code>Tensor</code>.
  axes: Array of ints. Axes along which to compute mean and variance.
  shift: A <code>Tensor</code> containing the value by which to shift the data for
    numerical stability, or <code>None</code> if no shift is to be performed. A shift
    close to the true mean provides the most numerically stable results.
  keep_dims: produce statistics with the same dimensionality as the input.
  name: Name used to scope the operations that compute the sufficient stats.</p>
<p>Returns:
  Four <code>Tensor</code> objects of the same type as <code>x</code>:
  * the count (number of elements to average over).
  * the (possibly shifted) sum of the elements in the array.
  * the (possibly shifted) sum of squares of the elements in the array.
  * the shift by which the mean must be corrected or None if <code>shift</code> is None.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sufficient_statistics', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sufficient_statistics" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.sufficient_statistics_layer">
    <p>def <span class="ident">sufficient_statistics_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.sufficient_statistics_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.sufficient_statistics_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.sufficient_statistics_layer</strong></p>
<div class="codehilite"><pre><span></span>def sufficient_statistics_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.sufficient_statistics, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.sufficient_statistics</strong></p>
<div class="codehilite"><pre><span></span>def sufficient_statistics(x, axes, shift=None, keep_dims=False, name=None):
</pre></div>


<p>Calculate the sufficient statistics for the mean and variance of <code>x</code>.</p>
<p>These sufficient statistics are computed using the one pass algorithm on
an input that's optionally shifted. See:
https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Computing_shifted_data</p>
<p>Args:
  x: A <code>Tensor</code>.
  axes: Array of ints. Axes along which to compute mean and variance.
  shift: A <code>Tensor</code> containing the value by which to shift the data for
    numerical stability, or <code>None</code> if no shift is to be performed. A shift
    close to the true mean provides the most numerically stable results.
  keep_dims: produce statistics with the same dimensionality as the input.
  name: Name used to scope the operations that compute the sufficient stats.</p>
<p>Returns:
  Four <code>Tensor</code> objects of the same type as <code>x</code>:
  * the count (number of elements to average over).
  * the (possibly shifted) sum of the elements in the array.
  * the (possibly shifted) sum of squares of the elements in the array.
  * the shift by which the mean must be corrected or None if <code>shift</code> is None.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.sufficient_statistics_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.sufficient_statistics_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.tan">
    <p>def <span class="ident">tan</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.tan, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.tan</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.tan</strong></p>
<div class="codehilite"><pre><span></span>def tan(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.tan</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.tan</code></strong></p>
<div class="codehilite"><pre><span></span>def tan(x, name=None)
</pre></div>


<p>Computes tan of x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.tan', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.tan" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.tan_layer">
    <p>def <span class="ident">tan_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.tan_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.tan_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.tan_layer</strong></p>
<div class="codehilite"><pre><span></span>def tan_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.tan, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.tan</strong></p>
<div class="codehilite"><pre><span></span>def tan(x, name=None):
</pre></div>


<p>Computes tan of x element-wise.</p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>half</code>, <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>int64</code>, <code>complex64</code>, <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.tan_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.tan_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.tanh">
    <p>def <span class="ident">tanh</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.tanh, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.tanh</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.tanh</strong></p>
<div class="codehilite"><pre><span></span>def tanh(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.tanh</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.tanh</code></strong></p>
<div class="codehilite"><pre><span></span>def tanh(x, name=None)
</pre></div>


<p>Computes hyperbolic tangent of <code>x</code> element-wise.</p>
<p>Args:
  x: A Tensor with type <code>float</code>, <code>double</code>, <code>int32</code>, <code>complex64</code>, <code>int64</code>,
    or <code>qint32</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A Tensor with the same type as <code>x</code> if <code>x.dtype != qint32</code> otherwise
    the return type is <code>quint8</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.tanh', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.tanh" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.tanh_layer">
    <p>def <span class="ident">tanh_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.tanh_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.tanh_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.tanh_layer</strong></p>
<div class="codehilite"><pre><span></span>def tanh_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.tanh, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.tanh</strong></p>
<div class="codehilite"><pre><span></span>def tanh(x, name=None):
</pre></div>


<p>Computes hyperbolic tangent of <code>x</code> element-wise.</p>
<p>Args:
  x: A Tensor with type <code>float</code>, <code>double</code>, <code>int32</code>, <code>complex64</code>, <code>int64</code>,
    or <code>qint32</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A Tensor with the same type as <code>x</code> if <code>x.dtype != qint32</code> otherwise
    the return type is <code>quint8</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.tanh_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.tanh_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.tensor">
    <p>def <span class="ident">tensor</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.tensor, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.tensor</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.tensor</strong></p>
<div class="codehilite"><pre><span></span>def tensor(self):
</pre></div>


<p>Returns the Tensor contianed by the Builder</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.tensor', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.tensor" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.tensors">
    <p>def <span class="ident">tensors</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(BuilderTree.tensors, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>BuilderTree.tensors</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for BuilderTree.tensors</strong></p>
<div class="codehilite"><pre><span></span>def tensors(self):
</pre></div>


<p>Same as <code>tensorbuilder.core.builders.BuilderTree.builders</code> but extracts the tensor from each <code>tensorbuilder.core.builders.Builder</code>.</p>
<p><strong>Return</strong></p>
<ul>
<li><code>list( tf.Tensor )</code></li>
</ul>
<p><strong> Example </strong></p>
<p>This examples creates a network to that solves the XOR problem using sigmoid units</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>


<span class="c1">#Network</span>
<span class="p">[</span><span class="n">activation_tensor</span><span class="p">,</span> <span class="n">trainer_tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="k">lambda</span> <span class="n">logit</span><span class="p">:</span>
    <span class="p">[</span>
        <span class="n">logit</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span> <span class="c1"># activation</span>
    <span class="p">,</span>
        <span class="n">logit</span>
        <span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># loss</span>
        <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">)</span> <span class="c1"># trainer</span>
    <span class="p">])</span>
    <span class="o">.</span><span class="n">tensors</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>


<p>Same example using the DSL</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>


<span class="c1">#Network</span>
<span class="p">[</span><span class="n">activation_tensor</span><span class="p">,</span> <span class="n">trainer_tensor</span><span class="p">]</span> <span class="o">=</span> <span class="n">tb</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span>
    <span class="p">[</span>
        <span class="n">tb</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span> <span class="c1"># activation</span>
    <span class="p">,</span>
        <span class="n">tb</span>
        <span class="o">.</span><span class="n">sigmoid_cross_entropy_with_logits</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="c1"># loss</span>
        <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">)</span> <span class="c1"># trainer</span>
    <span class="p">],</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">tensors</span><span class="p">()</span>
<span class="p">)</span>
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.tensors', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.tensors" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.then">
    <p>def <span class="ident">then</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.then, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.then</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.then</strong></p>
<div class="codehilite"><pre><span></span>def then(builder, fn):
</pre></div>


<p><code>@immutable</code></p>
<p>Expects a function <strong>fn</strong> with type <code>builder -&gt; builder</code>. This method is used primarily to manupilate the Builder with very fine grain control through the fluent immutable API.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>fn</code>: a function of type <code>builder -&gt; builder</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li><code>tensorbuilder.core.builders.Builder</code></li>
</ul>
<p><strong> Example </strong></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.then', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.then" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.then_with">
    <p>def <span class="ident">then_with</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.then_with, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.then_with</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.then_with</strong></p>
<div class="codehilite"><pre><span></span>def then_with(builder, scope_fn):
</pre></div>


<p><code>@immutable</code></p>
<p>Expects a function <strong>fn</strong> with that returns a "Disposable" (implement <code>__enter__</code> and <code>__exit__</code>) plus some *args and **kwargs, and return a function <code>g</code> that expects a function <code>h</code> of type <code>Builder -&gt; Builder</code> such that</p>
<div class="codehilite"><pre><span></span><span class="na">.then_with</span><span class="p">(</span><span class="no">fn</span><span class="p">,</span> <span class="p">*</span><span class="no">args</span><span class="p">,</span> <span class="p">**</span><span class="no">kwargs</span><span class="p">)(</span><span class="no">h</span><span class="p">)</span>
</pre></div>


<p>roughly perform this computations (given the current <code>builder</code>)</p>
<div class="codehilite"><pre><span></span>with fn(*args, **kwargs):
    return h(builder)
</pre></div>


<p>For a more practical understanding look at the example.</p>
<p><strong>Parameters</strong></p>
<ul>
<li><code>fn</code>: a function of type <code>Builder -&gt; Disposable</code>.</li>
</ul>
<p><strong>Return</strong></p>
<ul>
<li>Function of type <code>(Builder -&gt; Builder)</code></li>
</ul>
<p><strong> Examples </strong></p>
<p>Create a network with 3 branches and execute each on the devices "/gpu:0", "/gpu:1", "cpu:3" respectively</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">h</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="o">.</span><span class="n">branch</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">[</span>
        <span class="n">x</span><span class="o">.</span><span class="n">then_with</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="s2">&quot;/gpu:0&quot;</span><span class="p">)(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span>
            <span class="n">x</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
            <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="p">,</span>
        <span class="n">x</span><span class="o">.</span><span class="n">then_with</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="s2">&quot;/gpu:1&quot;</span><span class="p">)(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span>
            <span class="n">x</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
            <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="p">,</span>
        <span class="n">x</span><span class="o">.</span><span class="n">then_with</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="s2">&quot;/cpu:0&quot;</span><span class="p">)(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span>
            <span class="n">x</span><span class="o">.</span><span class="n">tanh_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
            <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
        <span class="p">)</span>
    <span class="p">])</span>
    <span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">)</span>
    <span class="o">.</span><span class="n">softmax</span><span class="p">()</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>


<p>This looks much better with the DSL thanks to its support for scopes</p>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">tb</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="bp">None</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>

<span class="n">h</span> <span class="o">=</span> <span class="n">tb</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span>
    <span class="p">[</span>
        <span class="p">{</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/gpu:0&quot;</span><span class="p">):</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">relu_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
            <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">,</span>
        <span class="p">{</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/gpu:1&quot;</span><span class="p">):</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">sigmoid_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
            <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">,</span>
        <span class="p">{</span> <span class="n">tf</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;/cpu:0&quot;</span><span class="p">):</span>
            <span class="n">tb</span><span class="o">.</span><span class="n">tanh_layer</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span>
            <span class="o">.</span><span class="n">linear_layer</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
        <span class="p">}</span>
    <span class="p">],</span>
    <span class="n">tb</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">)</span>
    <span class="o">.</span><span class="n">softmax</span><span class="p">()</span>
    <span class="o">.</span><span class="n">tensor</span><span class="p">()</span>
<span class="p">)</span>
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.then_with', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.then_with" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.tile">
    <p>def <span class="ident">tile</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.tile, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.tile</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.tile</strong></p>
<div class="codehilite"><pre><span></span>def tile(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.tile</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.tile</code></strong></p>
<div class="codehilite"><pre><span></span>def tile(input, multiples, name=None)
</pre></div>


<p>Constructs a tensor by tiling a given tensor.</p>
<p>This operation creates a new tensor by replicating <code>input</code> <code>multiples</code> times.
The output tensor's i'th dimension has <code>input.dims(i) * multiples[i]</code> elements,
and the values of <code>input</code> are replicated <code>multiples[i]</code> times along the 'i'th
dimension. For example, tiling <code>[a b c d]</code> by <code>[2]</code> produces
<code>[a b c d a b c d]</code>.</p>
<p>Args:
  input: A <code>Tensor</code>. 1-D or higher.
  multiples: A <code>Tensor</code> of type <code>int32</code>.
    1-D. Length must be the same as the number of dimensions in <code>input</code>
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.tile', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.tile" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.tile_layer">
    <p>def <span class="ident">tile_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.tile_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.tile_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.tile_layer</strong></p>
<div class="codehilite"><pre><span></span>def tile_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.tile, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.tile</strong></p>
<div class="codehilite"><pre><span></span>def tile(input, multiples, name=None):
</pre></div>


<p>Constructs a tensor by tiling a given tensor.</p>
<p>This operation creates a new tensor by replicating <code>input</code> <code>multiples</code> times.
The output tensor's i'th dimension has <code>input.dims(i) * multiples[i]</code> elements,
and the values of <code>input</code> are replicated <code>multiples[i]</code> times along the 'i'th
dimension. For example, tiling <code>[a b c d]</code> by <code>[2]</code> produces
<code>[a b c d a b c d]</code>.</p>
<p>Args:
  input: A <code>Tensor</code>. 1-D or higher.
  multiples: A <code>Tensor</code> of type <code>int32</code>.
    1-D. Length must be the same as the number of dimensions in <code>input</code>
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.tile_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.tile_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.to_bfloat16">
    <p>def <span class="ident">to_bfloat16</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.to_bfloat16, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.to_bfloat16</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.to_bfloat16</strong></p>
<div class="codehilite"><pre><span></span>def to_bfloat16(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.to_bfloat16</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.to_bfloat16</code></strong></p>
<div class="codehilite"><pre><span></span>def to_bfloat16(x, name=&quot;ToBFloat16&quot;)
</pre></div>


<p>Casts a tensor to type <code>bfloat16</code>.</p>
<p>Args:
  x: A <code>Tensor</code> or <code>SparseTensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> or <code>SparseTensor</code> with same shape as <code>x</code> with type <code>bfloat16</code>.</p>
<p>Raises:
  TypeError: If <code>x</code> cannot be cast to the <code>bfloat16</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.to_bfloat16', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.to_bfloat16" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.to_bfloat16_layer">
    <p>def <span class="ident">to_bfloat16_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.to_bfloat16_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.to_bfloat16_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.to_bfloat16_layer</strong></p>
<div class="codehilite"><pre><span></span>def to_bfloat16_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.to_bfloat16, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.to_bfloat16</strong></p>
<div class="codehilite"><pre><span></span>def to_bfloat16(x, name=&quot;ToBFloat16&quot;):
</pre></div>


<p>Casts a tensor to type <code>bfloat16</code>.</p>
<p>Args:
  x: A <code>Tensor</code> or <code>SparseTensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> or <code>SparseTensor</code> with same shape as <code>x</code> with type <code>bfloat16</code>.</p>
<p>Raises:
  TypeError: If <code>x</code> cannot be cast to the <code>bfloat16</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.to_bfloat16_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.to_bfloat16_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.to_double">
    <p>def <span class="ident">to_double</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.to_double, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.to_double</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.to_double</strong></p>
<div class="codehilite"><pre><span></span>def to_double(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.to_double</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.to_double</code></strong></p>
<div class="codehilite"><pre><span></span>def to_double(x, name=&quot;ToDouble&quot;)
</pre></div>


<p>Casts a tensor to type <code>float64</code>.</p>
<p>Args:
  x: A <code>Tensor</code> or <code>SparseTensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> or <code>SparseTensor</code> with same shape as <code>x</code> with type <code>float64</code>.</p>
<p>Raises:
  TypeError: If <code>x</code> cannot be cast to the <code>float64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.to_double', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.to_double" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.to_double_layer">
    <p>def <span class="ident">to_double_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.to_double_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.to_double_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.to_double_layer</strong></p>
<div class="codehilite"><pre><span></span>def to_double_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.to_double, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.to_double</strong></p>
<div class="codehilite"><pre><span></span>def to_double(x, name=&quot;ToDouble&quot;):
</pre></div>


<p>Casts a tensor to type <code>float64</code>.</p>
<p>Args:
  x: A <code>Tensor</code> or <code>SparseTensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> or <code>SparseTensor</code> with same shape as <code>x</code> with type <code>float64</code>.</p>
<p>Raises:
  TypeError: If <code>x</code> cannot be cast to the <code>float64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.to_double_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.to_double_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.to_float">
    <p>def <span class="ident">to_float</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.to_float, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.to_float</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.to_float</strong></p>
<div class="codehilite"><pre><span></span>def to_float(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.to_float</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.to_float</code></strong></p>
<div class="codehilite"><pre><span></span>def to_float(x, name=&quot;ToFloat&quot;)
</pre></div>


<p>Casts a tensor to type <code>float32</code>.</p>
<p>Args:
  x: A <code>Tensor</code> or <code>SparseTensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> or <code>SparseTensor</code> with same shape as <code>x</code> with type <code>float32</code>.</p>
<p>Raises:
  TypeError: If <code>x</code> cannot be cast to the <code>float32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.to_float', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.to_float" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.to_float_layer">
    <p>def <span class="ident">to_float_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.to_float_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.to_float_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.to_float_layer</strong></p>
<div class="codehilite"><pre><span></span>def to_float_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.to_float, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.to_float</strong></p>
<div class="codehilite"><pre><span></span>def to_float(x, name=&quot;ToFloat&quot;):
</pre></div>


<p>Casts a tensor to type <code>float32</code>.</p>
<p>Args:
  x: A <code>Tensor</code> or <code>SparseTensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> or <code>SparseTensor</code> with same shape as <code>x</code> with type <code>float32</code>.</p>
<p>Raises:
  TypeError: If <code>x</code> cannot be cast to the <code>float32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.to_float_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.to_float_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.to_int32">
    <p>def <span class="ident">to_int32</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.to_int32, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.to_int32</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.to_int32</strong></p>
<div class="codehilite"><pre><span></span>def to_int32(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.to_int32</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.to_int32</code></strong></p>
<div class="codehilite"><pre><span></span>def to_int32(x, name=&quot;ToInt32&quot;)
</pre></div>


<p>Casts a tensor to type <code>int32</code>.</p>
<p>Args:
  x: A <code>Tensor</code> or <code>SparseTensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> or <code>SparseTensor</code> with same shape as <code>x</code> with type <code>int32</code>.</p>
<p>Raises:
  TypeError: If <code>x</code> cannot be cast to the <code>int32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.to_int32', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.to_int32" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.to_int32_layer">
    <p>def <span class="ident">to_int32_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.to_int32_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.to_int32_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.to_int32_layer</strong></p>
<div class="codehilite"><pre><span></span>def to_int32_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.to_int32, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.to_int32</strong></p>
<div class="codehilite"><pre><span></span>def to_int32(x, name=&quot;ToInt32&quot;):
</pre></div>


<p>Casts a tensor to type <code>int32</code>.</p>
<p>Args:
  x: A <code>Tensor</code> or <code>SparseTensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> or <code>SparseTensor</code> with same shape as <code>x</code> with type <code>int32</code>.</p>
<p>Raises:
  TypeError: If <code>x</code> cannot be cast to the <code>int32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.to_int32_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.to_int32_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.to_int64">
    <p>def <span class="ident">to_int64</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.to_int64, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.to_int64</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.to_int64</strong></p>
<div class="codehilite"><pre><span></span>def to_int64(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.to_int64</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.to_int64</code></strong></p>
<div class="codehilite"><pre><span></span>def to_int64(x, name=&quot;ToInt64&quot;)
</pre></div>


<p>Casts a tensor to type <code>int64</code>.</p>
<p>Args:
  x: A <code>Tensor</code> or <code>SparseTensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> or <code>SparseTensor</code> with same shape as <code>x</code> with type <code>int64</code>.</p>
<p>Raises:
  TypeError: If <code>x</code> cannot be cast to the <code>int64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.to_int64', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.to_int64" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.to_int64_layer">
    <p>def <span class="ident">to_int64_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.to_int64_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.to_int64_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.to_int64_layer</strong></p>
<div class="codehilite"><pre><span></span>def to_int64_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.to_int64, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.to_int64</strong></p>
<div class="codehilite"><pre><span></span>def to_int64(x, name=&quot;ToInt64&quot;):
</pre></div>


<p>Casts a tensor to type <code>int64</code>.</p>
<p>Args:
  x: A <code>Tensor</code> or <code>SparseTensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> or <code>SparseTensor</code> with same shape as <code>x</code> with type <code>int64</code>.</p>
<p>Raises:
  TypeError: If <code>x</code> cannot be cast to the <code>int64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.to_int64_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.to_int64_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.top_k">
    <p>def <span class="ident">top_k</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.top_k, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.top_k</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.top_k</strong></p>
<div class="codehilite"><pre><span></span>def top_k(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.top_k</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.top_k</code></strong></p>
<div class="codehilite"><pre><span></span>def top_k(input, k=1, sorted=True, name=None)
</pre></div>


<p>Finds values and indices of the <code>k</code> largest entries for the last dimension.</p>
<p>If the input is a vector (rank-1), finds the <code>k</code> largest entries in the vector
and outputs their values and indices as vectors.  Thus <code>values[j]</code> is the
<code>j</code>-th largest entry in <code>input</code>, and its index is <code>indices[j]</code>.</p>
<p>For matrices (resp. higher rank input), computes the top <code>k</code> entries in each
row (resp. vector along the last dimension).  Thus,</p>
<div class="codehilite"><pre><span></span><span class="s s-Atom">values</span><span class="p">.</span><span class="s s-Atom">shape</span> <span class="o">=</span> <span class="s s-Atom">indices</span><span class="p">.</span><span class="s s-Atom">shape</span> <span class="o">=</span> <span class="s s-Atom">input</span><span class="p">.</span><span class="s s-Atom">shape</span><span class="p">[:-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s s-Atom">k</span><span class="p">]</span>
</pre></div>


<p>If two elements are equal, the lower-index element appears first.</p>
<p>Args:
  input: 1-D or higher <code>Tensor</code> with last dimension at least <code>k</code>.
  k: 0-D <code>int32</code> <code>Tensor</code>.  Number of top elements to look for along the last
    dimension (along each row for matrices).
  sorted: If true the resulting <code>k</code> elements will be sorted by the values in
    descending order.
  name: Optional name for the operation.</p>
<p>Returns:
  values: The <code>k</code> largest elements along each last dimensional slice.
  indices: The indices of <code>values</code> within the last dimension of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.top_k', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.top_k" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.top_k_layer">
    <p>def <span class="ident">top_k_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.top_k_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.top_k_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.top_k_layer</strong></p>
<div class="codehilite"><pre><span></span>def top_k_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.top_k, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.top_k</strong></p>
<div class="codehilite"><pre><span></span>def top_k(input, k=1, sorted=True, name=None):
</pre></div>


<p>Finds values and indices of the <code>k</code> largest entries for the last dimension.</p>
<p>If the input is a vector (rank-1), finds the <code>k</code> largest entries in the vector
and outputs their values and indices as vectors.  Thus <code>values[j]</code> is the
<code>j</code>-th largest entry in <code>input</code>, and its index is <code>indices[j]</code>.</p>
<p>For matrices (resp. higher rank input), computes the top <code>k</code> entries in each
row (resp. vector along the last dimension).  Thus,</p>
<div class="codehilite"><pre><span></span><span class="s s-Atom">values</span><span class="p">.</span><span class="s s-Atom">shape</span> <span class="o">=</span> <span class="s s-Atom">indices</span><span class="p">.</span><span class="s s-Atom">shape</span> <span class="o">=</span> <span class="s s-Atom">input</span><span class="p">.</span><span class="s s-Atom">shape</span><span class="p">[:-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s s-Atom">k</span><span class="p">]</span>
</pre></div>


<p>If two elements are equal, the lower-index element appears first.</p>
<p>Args:
  input: 1-D or higher <code>Tensor</code> with last dimension at least <code>k</code>.
  k: 0-D <code>int32</code> <code>Tensor</code>.  Number of top elements to look for along the last
    dimension (along each row for matrices).
  sorted: If true the resulting <code>k</code> elements will be sorted by the values in
    descending order.
  name: Optional name for the operation.</p>
<p>Returns:
  values: The <code>k</code> largest elements along each last dimensional slice.
  indices: The indices of <code>values</code> within the last dimension of <code>input</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.top_k_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.top_k_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.trace">
    <p>def <span class="ident">trace</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.trace, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.trace</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.trace</strong></p>
<div class="codehilite"><pre><span></span>def trace(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.trace</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.trace</code></strong></p>
<div class="codehilite"><pre><span></span>def trace(x, name=None)
</pre></div>


<p>Compute the trace of a tensor <code>x</code>.</p>
<p><code>trace(x)</code> returns the sum of along the diagonal.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' is [[1, 1],</h1>
<h1>[1, 1]]</h1>
<p>tf.trace(x) ==&gt; 2</p>
<h1>'x' is [[1,2,3],</h1>
<h1>[4,5,6],</h1>
<h1>[7,8,9]]</h1>
<p>tf.trace(x) ==&gt; 15
```</p>
<p>Args:
  x: 2-D tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  The trace of input tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.trace', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.trace" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.trace_layer">
    <p>def <span class="ident">trace_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.trace_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.trace_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.trace_layer</strong></p>
<div class="codehilite"><pre><span></span>def trace_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.trace, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.trace</strong></p>
<div class="codehilite"><pre><span></span>def trace(x, name=None):
</pre></div>


<p>Compute the trace of a tensor <code>x</code>.</p>
<p><code>trace(x)</code> returns the sum of along the diagonal.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' is [[1, 1],</h1>
<h1>[1, 1]]</h1>
<p>tf.trace(x) ==&gt; 2</p>
<h1>'x' is [[1,2,3],</h1>
<h1>[4,5,6],</h1>
<h1>[7,8,9]]</h1>
<p>tf.trace(x) ==&gt; 15
```</p>
<p>Args:
  x: 2-D tensor.
  name: A name for the operation (optional).</p>
<p>Returns:
  The trace of input tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.trace_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.trace_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.trainable_variables">
    <p>def <span class="ident">trainable_variables</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.trainable_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.trainable_variables</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.trainable_variables</strong></p>
<div class="codehilite"><pre><span></span>def trainable_variables(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.trainable_variables</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.trainable_variables</code></strong></p>
<div class="codehilite"><pre><span></span>def trainable_variables()
</pre></div>


<p>Returns all variables created with <code>trainable=True</code>.</p>
<p>When passed <code>trainable=True</code>, the <code>Variable()</code> constructor automatically
adds new variables to the graph collection
<code>GraphKeys.TRAINABLE_VARIABLES</code>. This convenience function returns the
contents of that collection.</p>
<p>Returns:
  A list of Variable objects.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.trainable_variables', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.trainable_variables" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.trainable_variables_layer">
    <p>def <span class="ident">trainable_variables_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.trainable_variables_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.trainable_variables_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.trainable_variables_layer</strong></p>
<div class="codehilite"><pre><span></span>def trainable_variables_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.trainable_variables, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.trainable_variables</strong></p>
<div class="codehilite"><pre><span></span>def trainable_variables():
</pre></div>


<p>Returns all variables created with <code>trainable=True</code>.</p>
<p>When passed <code>trainable=True</code>, the <code>Variable()</code> constructor automatically
adds new variables to the graph collection
<code>GraphKeys.TRAINABLE_VARIABLES</code>. This convenience function returns the
contents of that collection.</p>
<p>Returns:
  A list of Variable objects.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.trainable_variables_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.trainable_variables_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.transpose">
    <p>def <span class="ident">transpose</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.transpose, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.transpose</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.transpose</strong></p>
<div class="codehilite"><pre><span></span>def transpose(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.transpose</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.transpose</code></strong></p>
<div class="codehilite"><pre><span></span>def transpose(a, perm=None, name=&quot;transpose&quot;)
</pre></div>


<p>Transposes <code>a</code>. Permutes the dimensions according to <code>perm</code>.</p>
<p>The returned tensor's dimension i will correspond to the input dimension
<code>perm[i]</code>. If <code>perm</code> is not given, it is set to (n-1...0), where n is
the rank of the input tensor. Hence by default, this operation performs a
regular matrix transpose on 2-D input Tensors.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' is [[1 2 3]</h1>
<h1>[4 5 6]]</h1>
<p>tf.transpose(x) ==&gt; [[1 4]
                     [2 5]
                     [3 6]]</p>
<h1>Equivalently</h1>
<p>tf.transpose(x, perm=[1, 0]) ==&gt; [[1 4]
                                  [2 5]
                                  [3 6]]</p>
<h1>'perm' is more useful for n-dimensional tensors, for n &gt; 2</h1>
<h1>'x' is   [[[1  2  3]</h1>
<h1>[4  5  6]]</h1>
<h1>[[7  8  9]</h1>
<h1>[10 11 12]]]</h1>
<h1>Take the transpose of the matrices in dimension-0</h1>
<p>tf.transpose(x, perm=[0, 2, 1]) ==&gt; [[[1  4]
                                      [2  5]
                                      [3  6]]</p>
<div class="codehilite"><pre><span></span>                                 [[7 10]
                                  [8 11]
                                  [9 12]]]
</pre></div>


<p>```</p>
<p>Args:
  a: A <code>Tensor</code>.
  perm: A permutation of the dimensions of <code>a</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A transposed <code>Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.transpose', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.transpose" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.transpose_layer">
    <p>def <span class="ident">transpose_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.transpose_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.transpose_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.transpose_layer</strong></p>
<div class="codehilite"><pre><span></span>def transpose_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.transpose, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.transpose</strong></p>
<div class="codehilite"><pre><span></span>def transpose(a, perm=None, name=&quot;transpose&quot;):
</pre></div>


<p>Transposes <code>a</code>. Permutes the dimensions according to <code>perm</code>.</p>
<p>The returned tensor's dimension i will correspond to the input dimension
<code>perm[i]</code>. If <code>perm</code> is not given, it is set to (n-1...0), where n is
the rank of the input tensor. Hence by default, this operation performs a
regular matrix transpose on 2-D input Tensors.</p>
<p>For example:</p>
<p>```python</p>
<h1>'x' is [[1 2 3]</h1>
<h1>[4 5 6]]</h1>
<p>tf.transpose(x) ==&gt; [[1 4]
                     [2 5]
                     [3 6]]</p>
<h1>Equivalently</h1>
<p>tf.transpose(x, perm=[1, 0]) ==&gt; [[1 4]
                                  [2 5]
                                  [3 6]]</p>
<h1>'perm' is more useful for n-dimensional tensors, for n &gt; 2</h1>
<h1>'x' is   [[[1  2  3]</h1>
<h1>[4  5  6]]</h1>
<h1>[[7  8  9]</h1>
<h1>[10 11 12]]]</h1>
<h1>Take the transpose of the matrices in dimension-0</h1>
<p>tf.transpose(x, perm=[0, 2, 1]) ==&gt; [[[1  4]
                                      [2  5]
                                      [3  6]]</p>
<div class="codehilite"><pre><span></span>                                 [[7 10]
                                  [8 11]
                                  [9 12]]]
</pre></div>


<p>```</p>
<p>Args:
  a: A <code>Tensor</code>.
  perm: A permutation of the dimensions of <code>a</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A transposed <code>Tensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.transpose_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.transpose_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.truediv">
    <p>def <span class="ident">truediv</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.truediv, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.truediv</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.truediv</strong></p>
<div class="codehilite"><pre><span></span>def truediv(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.truediv</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.truediv</code></strong></p>
<div class="codehilite"><pre><span></span>def truediv(x, y, name=None)
</pre></div>


<p>Divides x / y elementwise, always producing floating point results.</p>
<p>The same as <code>tf.div</code> for floating point arguments, but casts integer arguments
to floating point before dividing so that the result is always floating point.
This op is generated by normal <code>x / y</code> division in Python 3 and in Python 2.7
with <code>from __future__ import division</code>.  If you want integer division that
rounds down, use <code>x // y</code> or <code>tf.floordiv</code>.</p>
<p><code>x</code> and <code>y</code> must have the same numeric type.  If the inputs are floating
point, the output will have the same type.  If the inputs are integral, the
inputs are cast to <code>float32</code> for <code>int8</code> and <code>int16</code> and <code>float64</code> for <code>int32</code>
and <code>int64</code> (matching the behavior of Numpy).</p>
<p>Args:
  x: <code>Tensor</code> numerator of numeric type.
  y: <code>Tensor</code> denominator of numeric type.
  name: A name for the operation (optional).</p>
<p>Returns:
  <code>x / y</code> evaluated in floating point.</p>
<p>Raises:
  TypeError: If <code>x</code> and <code>y</code> have different dtypes.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.truediv', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.truediv" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.truediv_layer">
    <p>def <span class="ident">truediv_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.truediv_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.truediv_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.truediv_layer</strong></p>
<div class="codehilite"><pre><span></span>def truediv_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.truediv, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.truediv</strong></p>
<div class="codehilite"><pre><span></span>def truediv(x, y, name=None):
</pre></div>


<p>Divides x / y elementwise, always producing floating point results.</p>
<p>The same as <code>tf.div</code> for floating point arguments, but casts integer arguments
to floating point before dividing so that the result is always floating point.
This op is generated by normal <code>x / y</code> division in Python 3 and in Python 2.7
with <code>from __future__ import division</code>.  If you want integer division that
rounds down, use <code>x // y</code> or <code>tf.floordiv</code>.</p>
<p><code>x</code> and <code>y</code> must have the same numeric type.  If the inputs are floating
point, the output will have the same type.  If the inputs are integral, the
inputs are cast to <code>float32</code> for <code>int8</code> and <code>int16</code> and <code>float64</code> for <code>int32</code>
and <code>int64</code> (matching the behavior of Numpy).</p>
<p>Args:
  x: <code>Tensor</code> numerator of numeric type.
  y: <code>Tensor</code> denominator of numeric type.
  name: A name for the operation (optional).</p>
<p>Returns:
  <code>x / y</code> evaluated in floating point.</p>
<p>Raises:
  TypeError: If <code>x</code> and <code>y</code> have different dtypes.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.truediv_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.truediv_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.truncated_normal">
    <p>def <span class="ident">truncated_normal</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.truncated_normal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.truncated_normal</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.truncated_normal</strong></p>
<div class="codehilite"><pre><span></span>def truncated_normal(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.truncated_normal</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.truncated_normal</code></strong></p>
<div class="codehilite"><pre><span></span>def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=&lt;dtype: &#39;float32&#39;&gt;, seed=None, name=None)
</pre></div>


<p>Outputs random values from a truncated normal distribution.</p>
<p>The generated values follow a normal distribution with specified mean and
standard deviation, except that values whose magnitude is more than 2 standard
deviations from the mean are dropped and re-picked.</p>
<p>Args:
  shape: A 1-D integer Tensor or Python array. The shape of the output tensor.
  mean: A 0-D Tensor or Python value of type <code>dtype</code>. The mean of the
    truncated normal distribution.
  stddev: A 0-D Tensor or Python value of type <code>dtype</code>. The standard deviation
    of the truncated normal distribution.
  dtype: The type of the output.
  seed: A Python integer. Used to create a random seed for the distribution.
    See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tensor of the specified shape filled with random truncated normal values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.truncated_normal', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.truncated_normal" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.truncated_normal_initializer">
    <p>def <span class="ident">truncated_normal_initializer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.truncated_normal_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.truncated_normal_initializer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.truncated_normal_initializer</strong></p>
<div class="codehilite"><pre><span></span>def truncated_normal_initializer(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.truncated_normal_initializer</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.truncated_normal_initializer</code></strong></p>
<div class="codehilite"><pre><span></span>def truncated_normal_initializer(mean=0.0, stddev=1.0, seed=None, dtype=&lt;dtype: &#39;float32&#39;&gt;)
</pre></div>


<p>Returns an initializer that generates a truncated normal distribution.</p>
<p>These values are similar to values from a <code>random_normal_initializer</code>
except that values more than two standard deviations from the mean
are discarded and re-drawn. This is the recommended initializer for
neural network weights and filters.</p>
<p>Args:
  mean: a python scalar or a scalar tensor. Mean of the random values
    to generate.
  stddev: a python scalar or a scalar tensor. Standard deviation of the
    random values to generate.
  seed: A Python integer. Used to create random seeds. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  dtype: The data type. Only floating point types are supported.</p>
<p>Returns:
  An initializer that generates tensors with a truncated normal
  distribution.</p>
<p>Raises:
  ValueError: if <code>dtype</code> is not a floating point type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.truncated_normal_initializer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.truncated_normal_initializer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.truncated_normal_initializer_layer">
    <p>def <span class="ident">truncated_normal_initializer_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.truncated_normal_initializer_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.truncated_normal_initializer_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.truncated_normal_initializer_layer</strong></p>
<div class="codehilite"><pre><span></span>def truncated_normal_initializer_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.truncated_normal_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.truncated_normal_initializer</strong></p>
<div class="codehilite"><pre><span></span>def truncated_normal_initializer(mean=0.0, stddev=1.0, seed=None, dtype=&lt;dtype: &#39;float32&#39;&gt;):
</pre></div>


<p>Returns an initializer that generates a truncated normal distribution.</p>
<p>These values are similar to values from a <code>random_normal_initializer</code>
except that values more than two standard deviations from the mean
are discarded and re-drawn. This is the recommended initializer for
neural network weights and filters.</p>
<p>Args:
  mean: a python scalar or a scalar tensor. Mean of the random values
    to generate.
  stddev: a python scalar or a scalar tensor. Standard deviation of the
    random values to generate.
  seed: A Python integer. Used to create random seeds. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  dtype: The data type. Only floating point types are supported.</p>
<p>Returns:
  An initializer that generates tensors with a truncated normal
  distribution.</p>
<p>Raises:
  ValueError: if <code>dtype</code> is not a floating point type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.truncated_normal_initializer_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.truncated_normal_initializer_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.truncated_normal_layer">
    <p>def <span class="ident">truncated_normal_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.truncated_normal_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.truncated_normal_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.truncated_normal_layer</strong></p>
<div class="codehilite"><pre><span></span>def truncated_normal_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.truncated_normal, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.truncated_normal</strong></p>
<div class="codehilite"><pre><span></span>def truncated_normal(shape, mean=0.0, stddev=1.0, dtype=&lt;dtype: &#39;float32&#39;&gt;, seed=None, name=None):
</pre></div>


<p>Outputs random values from a truncated normal distribution.</p>
<p>The generated values follow a normal distribution with specified mean and
standard deviation, except that values whose magnitude is more than 2 standard
deviations from the mean are dropped and re-picked.</p>
<p>Args:
  shape: A 1-D integer Tensor or Python array. The shape of the output tensor.
  mean: A 0-D Tensor or Python value of type <code>dtype</code>. The mean of the
    truncated normal distribution.
  stddev: A 0-D Tensor or Python value of type <code>dtype</code>. The standard deviation
    of the truncated normal distribution.
  dtype: The type of the output.
  seed: A Python integer. Used to create a random seed for the distribution.
    See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tensor of the specified shape filled with random truncated normal values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.truncated_normal_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.truncated_normal_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.tuple">
    <p>def <span class="ident">tuple</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.tuple, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.tuple</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.tuple</strong></p>
<div class="codehilite"><pre><span></span>def tuple(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.tuple</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.tuple</code></strong></p>
<div class="codehilite"><pre><span></span>def tuple(tensors, name=None, control_inputs=None)
</pre></div>


<p>Group tensors together.</p>
<p>This creates a tuple of tensors with the same values as the <code>tensors</code>
argument, except that the value of each tensor is only returned after the
values of all tensors have been computed.</p>
<p><code>control_inputs</code> contains additional ops that have to finish before this op
finishes, but whose outputs are not returned.</p>
<p>This can be used as a "join" mechanism for parallel computations: all the
argument tensors can be computed in parallel, but the values of any tensor
returned by <code>tuple</code> are only available after all the parallel computations
are done.</p>
<p>See also <code>group</code> and <code>with_dependencies</code>.</p>
<p>Args:
  tensors: A list of <code>Tensor</code>s or <code>IndexedSlices</code>, some entries can be <code>None</code>.
  name: (optional) A name to use as a <code>name_scope</code> for the operation.
  control_inputs: List of additional ops to finish before returning.</p>
<p>Returns:
  Same as <code>tensors</code>.</p>
<p>Raises:
  ValueError: If <code>tensors</code> does not contain any <code>Tensor</code> or <code>IndexedSlices</code>.
  TypeError: If <code>control_inputs</code> is not a list of <code>Operation</code> or <code>Tensor</code>
    objects.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.tuple', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.tuple" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.tuple_layer">
    <p>def <span class="ident">tuple_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.tuple_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.tuple_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.tuple_layer</strong></p>
<div class="codehilite"><pre><span></span>def tuple_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.tuple, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.tuple</strong></p>
<div class="codehilite"><pre><span></span>def tuple(tensors, name=None, control_inputs=None):
</pre></div>


<p>Group tensors together.</p>
<p>This creates a tuple of tensors with the same values as the <code>tensors</code>
argument, except that the value of each tensor is only returned after the
values of all tensors have been computed.</p>
<p><code>control_inputs</code> contains additional ops that have to finish before this op
finishes, but whose outputs are not returned.</p>
<p>This can be used as a "join" mechanism for parallel computations: all the
argument tensors can be computed in parallel, but the values of any tensor
returned by <code>tuple</code> are only available after all the parallel computations
are done.</p>
<p>See also <code>group</code> and <code>with_dependencies</code>.</p>
<p>Args:
  tensors: A list of <code>Tensor</code>s or <code>IndexedSlices</code>, some entries can be <code>None</code>.
  name: (optional) A name to use as a <code>name_scope</code> for the operation.
  control_inputs: List of additional ops to finish before returning.</p>
<p>Returns:
  Same as <code>tensors</code>.</p>
<p>Raises:
  ValueError: If <code>tensors</code> does not contain any <code>Tensor</code> or <code>IndexedSlices</code>.
  TypeError: If <code>control_inputs</code> is not a list of <code>Operation</code> or <code>Tensor</code>
    objects.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.tuple_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.tuple_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.uniform_candidate_sampler">
    <p>def <span class="ident">uniform_candidate_sampler</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.uniform_candidate_sampler, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.uniform_candidate_sampler</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.uniform_candidate_sampler</strong></p>
<div class="codehilite"><pre><span></span>def uniform_candidate_sampler(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.uniform_candidate_sampler</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.uniform_candidate_sampler</code></strong></p>
<div class="codehilite"><pre><span></span>def uniform_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, seed=None, name=None)
</pre></div>


<p>Samples a set of classes using a uniform base distribution.</p>
<p>This operation randomly samples a tensor of sampled classes
(<code>sampled_candidates</code>) from the range of integers <code>[0, range_max)</code>.</p>
<p>The elements of <code>sampled_candidates</code> are drawn without replacement
(if <code>unique=True</code>) or with replacement (if <code>unique=False</code>) from
the base distribution.</p>
<p>The base distribution for this operation is the uniform distribution
over the range of integers <code>[0, range_max)</code>.</p>
<p>In addition, this operation returns tensors <code>true_expected_count</code>
and <code>sampled_expected_count</code> representing the number of times each
of the target classes (<code>true_classes</code>) and the sampled
classes (<code>sampled_candidates</code>) is expected to occur in an average
tensor of sampled classes.  These values correspond to <code>Q(y|x)</code>
defined in <a href="http://www.tensorflow.org/extras/candidate_sampling.pdf">this
document</a>.
If <code>unique=True</code>, then these are post-rejection probabilities and we
compute them approximately.</p>
<p>Args:
  true_classes: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
    num_true]</code>. The target classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  num_sampled: An <code>int</code>.  The number of classes to randomly sample per batch.
  unique: A <code>bool</code>. Determines whether all sampled classes in a batch are
    unique.
  range_max: An <code>int</code>. The number of possible classes.
  seed: An <code>int</code>. An operation-specific seed. Default is 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  sampled_candidates: A tensor of type <code>int64</code> and shape <code>[num_sampled]</code>.
    The sampled classes.
  true_expected_count: A tensor of type <code>float</code>.  Same shape as
    <code>true_classes</code>. The expected counts under the sampling distribution
    of each of <code>true_classes</code>.
  sampled_expected_count: A tensor of type <code>float</code>. Same shape as
    <code>sampled_candidates</code>. The expected counts under the sampling distribution
    of each of <code>sampled_candidates</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.uniform_candidate_sampler', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.uniform_candidate_sampler" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.uniform_candidate_sampler_layer">
    <p>def <span class="ident">uniform_candidate_sampler_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.uniform_candidate_sampler_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.uniform_candidate_sampler_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.uniform_candidate_sampler_layer</strong></p>
<div class="codehilite"><pre><span></span>def uniform_candidate_sampler_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.uniform_candidate_sampler, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.uniform_candidate_sampler</strong></p>
<div class="codehilite"><pre><span></span>def uniform_candidate_sampler(true_classes, num_true, num_sampled, unique, range_max, seed=None, name=None):
</pre></div>


<p>Samples a set of classes using a uniform base distribution.</p>
<p>This operation randomly samples a tensor of sampled classes
(<code>sampled_candidates</code>) from the range of integers <code>[0, range_max)</code>.</p>
<p>The elements of <code>sampled_candidates</code> are drawn without replacement
(if <code>unique=True</code>) or with replacement (if <code>unique=False</code>) from
the base distribution.</p>
<p>The base distribution for this operation is the uniform distribution
over the range of integers <code>[0, range_max)</code>.</p>
<p>In addition, this operation returns tensors <code>true_expected_count</code>
and <code>sampled_expected_count</code> representing the number of times each
of the target classes (<code>true_classes</code>) and the sampled
classes (<code>sampled_candidates</code>) is expected to occur in an average
tensor of sampled classes.  These values correspond to <code>Q(y|x)</code>
defined in <a href="http://www.tensorflow.org/extras/candidate_sampling.pdf">this
document</a>.
If <code>unique=True</code>, then these are post-rejection probabilities and we
compute them approximately.</p>
<p>Args:
  true_classes: A <code>Tensor</code> of type <code>int64</code> and shape <code>[batch_size,
    num_true]</code>. The target classes.
  num_true: An <code>int</code>.  The number of target classes per training example.
  num_sampled: An <code>int</code>.  The number of classes to randomly sample per batch.
  unique: A <code>bool</code>. Determines whether all sampled classes in a batch are
    unique.
  range_max: An <code>int</code>. The number of possible classes.
  seed: An <code>int</code>. An operation-specific seed. Default is 0.
  name: A name for the operation (optional).</p>
<p>Returns:
  sampled_candidates: A tensor of type <code>int64</code> and shape <code>[num_sampled]</code>.
    The sampled classes.
  true_expected_count: A tensor of type <code>float</code>.  Same shape as
    <code>true_classes</code>. The expected counts under the sampling distribution
    of each of <code>true_classes</code>.
  sampled_expected_count: A tensor of type <code>float</code>. Same shape as
    <code>sampled_candidates</code>. The expected counts under the sampling distribution
    of each of <code>sampled_candidates</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.uniform_candidate_sampler_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.uniform_candidate_sampler_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.uniform_unit_scaling_initializer">
    <p>def <span class="ident">uniform_unit_scaling_initializer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.uniform_unit_scaling_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.uniform_unit_scaling_initializer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.uniform_unit_scaling_initializer</strong></p>
<div class="codehilite"><pre><span></span>def uniform_unit_scaling_initializer(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.uniform_unit_scaling_initializer</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.uniform_unit_scaling_initializer</code></strong></p>
<div class="codehilite"><pre><span></span>def uniform_unit_scaling_initializer(factor=1.0, seed=None, dtype=&lt;dtype: &#39;float32&#39;&gt;, full_shape=None)
</pre></div>


<p>Returns an initializer that generates tensors without scaling variance.</p>
<p>When initializing a deep network, it is in principle advantageous to keep
the scale of the input variance constant, so it does not explode or diminish
by reaching the final layer. If the input is <code>x</code> and the operation <code>x * W</code>,
and we want to initialize <code>W</code> uniformly at random, we need to pick <code>W</code> from</p>
<div class="codehilite"><pre><span></span>[-sqrt(3) / sqrt(dim), sqrt(3) / sqrt(dim)]
</pre></div>


<p>to keep the scale intact, where <code>dim = W.shape[0]</code> (the size of the input).
A similar calculation for convolutional networks gives an analogous result
with <code>dim</code> equal to the product of the first 3 dimensions.  When
nonlinearities are present, we need to multiply this by a constant <code>factor</code>.
See <a href="https://arxiv.org/abs/1412.6558">Sussillo et al., 2014</a>
(<a href="http://arxiv.org/pdf/1412.6558.pdf">pdf</a>) for deeper motivation, experiments
and the calculation of constants. In section 2.3 there, the constants were
numerically computed: for a linear layer it's 1.0, relu: ~1.43, tanh: ~1.15.</p>
<p>If the shape tuple <code>full_shape</code> is provided, the scale will be calculated from
this predefined shape.  This is useful when a <code>Variable</code> is being partitioned
across several shards, and each shard has a smaller shape than the whole.
Since the shards are usually concatenated when used, the scale should be
based on the shape of the whole.</p>
<p>Args:
  factor: Float.  A multiplicative factor by which the values will be scaled.
  seed: A Python integer. Used to create random seeds. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  dtype: The data type. Only floating point types are supported.
  full_shape: Tuple or list of integers.  The shape used for calculating
    scale normalization (instead of the shape passed at creation time).
    Useful when creating sharded variables via partitioning.</p>
<p>Returns:
  An initializer that generates tensors with unit variance.</p>
<p>Raises:
  ValueError: if <code>dtype</code> is not a floating point type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.uniform_unit_scaling_initializer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.uniform_unit_scaling_initializer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.uniform_unit_scaling_initializer_layer">
    <p>def <span class="ident">uniform_unit_scaling_initializer_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.uniform_unit_scaling_initializer_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.uniform_unit_scaling_initializer_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.uniform_unit_scaling_initializer_layer</strong></p>
<div class="codehilite"><pre><span></span>def uniform_unit_scaling_initializer_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.uniform_unit_scaling_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.uniform_unit_scaling_initializer</strong></p>
<div class="codehilite"><pre><span></span>def uniform_unit_scaling_initializer(factor=1.0, seed=None, dtype=&lt;dtype: &#39;float32&#39;&gt;, full_shape=None):
</pre></div>


<p>Returns an initializer that generates tensors without scaling variance.</p>
<p>When initializing a deep network, it is in principle advantageous to keep
the scale of the input variance constant, so it does not explode or diminish
by reaching the final layer. If the input is <code>x</code> and the operation <code>x * W</code>,
and we want to initialize <code>W</code> uniformly at random, we need to pick <code>W</code> from</p>
<div class="codehilite"><pre><span></span>[-sqrt(3) / sqrt(dim), sqrt(3) / sqrt(dim)]
</pre></div>


<p>to keep the scale intact, where <code>dim = W.shape[0]</code> (the size of the input).
A similar calculation for convolutional networks gives an analogous result
with <code>dim</code> equal to the product of the first 3 dimensions.  When
nonlinearities are present, we need to multiply this by a constant <code>factor</code>.
See <a href="https://arxiv.org/abs/1412.6558">Sussillo et al., 2014</a>
(<a href="http://arxiv.org/pdf/1412.6558.pdf">pdf</a>) for deeper motivation, experiments
and the calculation of constants. In section 2.3 there, the constants were
numerically computed: for a linear layer it's 1.0, relu: ~1.43, tanh: ~1.15.</p>
<p>If the shape tuple <code>full_shape</code> is provided, the scale will be calculated from
this predefined shape.  This is useful when a <code>Variable</code> is being partitioned
across several shards, and each shard has a smaller shape than the whole.
Since the shards are usually concatenated when used, the scale should be
based on the shape of the whole.</p>
<p>Args:
  factor: Float.  A multiplicative factor by which the values will be scaled.
  seed: A Python integer. Used to create random seeds. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  dtype: The data type. Only floating point types are supported.
  full_shape: Tuple or list of integers.  The shape used for calculating
    scale normalization (instead of the shape passed at creation time).
    Useful when creating sharded variables via partitioning.</p>
<p>Returns:
  An initializer that generates tensors with unit variance.</p>
<p>Raises:
  ValueError: if <code>dtype</code> is not a floating point type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.uniform_unit_scaling_initializer_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.uniform_unit_scaling_initializer_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.unique">
    <p>def <span class="ident">unique</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.unique, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.unique</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.unique</strong></p>
<div class="codehilite"><pre><span></span>def unique(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.unique</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.unique</code></strong></p>
<div class="codehilite"><pre><span></span>def unique(x, name=None)
</pre></div>


<p>Finds unique elements in a 1-D tensor.</p>
<p>This operation returns a tensor <code>y</code> containing all of the unique elements of <code>x</code>
sorted in the same order that they occur in <code>x</code>. This operation also returns a
tensor <code>idx</code> the same size as <code>x</code> that contains the index of each value of <code>x</code>
in the unique output <code>y</code>. In other words:</p>
<p><code>y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]</code></p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]</h1>
<p>y, idx = unique(x)
y ==&gt; [1, 2, 4, 7, 8]
idx ==&gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]
```</p>
<p>Args:
  x: A <code>Tensor</code>. 1-D.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tuple of <code>Tensor</code> objects (y, idx).
  y: A <code>Tensor</code>. Has the same type as <code>x</code>. 1-D.
  idx: A <code>Tensor</code> of type <code>int32</code>. 1-D.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.unique', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.unique" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.unique_layer">
    <p>def <span class="ident">unique_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.unique_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.unique_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.unique_layer</strong></p>
<div class="codehilite"><pre><span></span>def unique_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.unique, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.unique</strong></p>
<div class="codehilite"><pre><span></span>def unique(x, name=None):
</pre></div>


<p>Finds unique elements in a 1-D tensor.</p>
<p>This operation returns a tensor <code>y</code> containing all of the unique elements of <code>x</code>
sorted in the same order that they occur in <code>x</code>. This operation also returns a
tensor <code>idx</code> the same size as <code>x</code> that contains the index of each value of <code>x</code>
in the unique output <code>y</code>. In other words:</p>
<p><code>y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]</code></p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]</h1>
<p>y, idx = unique(x)
y ==&gt; [1, 2, 4, 7, 8]
idx ==&gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]
```</p>
<p>Args:
  x: A <code>Tensor</code>. 1-D.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tuple of <code>Tensor</code> objects (y, idx).
  y: A <code>Tensor</code>. Has the same type as <code>x</code>. 1-D.
  idx: A <code>Tensor</code> of type <code>int32</code>. 1-D.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.unique_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.unique_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.unique_with_counts">
    <p>def <span class="ident">unique_with_counts</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.unique_with_counts, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.unique_with_counts</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.unique_with_counts</strong></p>
<div class="codehilite"><pre><span></span>def unique_with_counts(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.unique_with_counts</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.unique_with_counts</code></strong></p>
<div class="codehilite"><pre><span></span>def unique_with_counts(x, name=None)
</pre></div>


<p>Finds unique elements in a 1-D tensor.</p>
<p>This operation returns a tensor <code>y</code> containing all of the unique elements of <code>x</code>
sorted in the same order that they occur in <code>x</code>. This operation also returns a
tensor <code>idx</code> the same size as <code>x</code> that contains the index of each value of <code>x</code>
in the unique output <code>y</code>. Finally, it returns a third tensor <code>count</code> that
contains the count of each element of <code>y</code> in <code>x</code>. In other words:</p>
<p><code>y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]</code></p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]</h1>
<p>y, idx, count = unique_with_counts(x)
y ==&gt; [1, 2, 4, 7, 8]
idx ==&gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]
count ==&gt; [2, 1, 3, 1, 2]
```</p>
<p>Args:
  x: A <code>Tensor</code>. 1-D.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tuple of <code>Tensor</code> objects (y, idx, count).
  y: A <code>Tensor</code>. Has the same type as <code>x</code>. 1-D.
  idx: A <code>Tensor</code> of type <code>int32</code>. 1-D.
  count: A <code>Tensor</code> of type <code>int32</code>. 1-D.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.unique_with_counts', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.unique_with_counts" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.unique_with_counts_layer">
    <p>def <span class="ident">unique_with_counts_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.unique_with_counts_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.unique_with_counts_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.unique_with_counts_layer</strong></p>
<div class="codehilite"><pre><span></span>def unique_with_counts_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.unique_with_counts, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.unique_with_counts</strong></p>
<div class="codehilite"><pre><span></span>def unique_with_counts(x, name=None):
</pre></div>


<p>Finds unique elements in a 1-D tensor.</p>
<p>This operation returns a tensor <code>y</code> containing all of the unique elements of <code>x</code>
sorted in the same order that they occur in <code>x</code>. This operation also returns a
tensor <code>idx</code> the same size as <code>x</code> that contains the index of each value of <code>x</code>
in the unique output <code>y</code>. Finally, it returns a third tensor <code>count</code> that
contains the count of each element of <code>y</code> in <code>x</code>. In other words:</p>
<p><code>y[idx[i]] = x[i] for i in [0, 1,...,rank(x) - 1]</code></p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>tensor 'x' is [1, 1, 2, 4, 4, 4, 7, 8, 8]</h1>
<p>y, idx, count = unique_with_counts(x)
y ==&gt; [1, 2, 4, 7, 8]
idx ==&gt; [0, 0, 1, 2, 2, 2, 3, 4, 4]
count ==&gt; [2, 1, 3, 1, 2]
```</p>
<p>Args:
  x: A <code>Tensor</code>. 1-D.
  name: A name for the operation (optional).</p>
<p>Returns:
  A tuple of <code>Tensor</code> objects (y, idx, count).
  y: A <code>Tensor</code>. Has the same type as <code>x</code>. 1-D.
  idx: A <code>Tensor</code> of type <code>int32</code>. 1-D.
  count: A <code>Tensor</code> of type <code>int32</code>. 1-D.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.unique_with_counts_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.unique_with_counts_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.unpack">
    <p>def <span class="ident">unpack</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.unpack, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.unpack</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.unpack</strong></p>
<div class="codehilite"><pre><span></span>def unpack(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.unpack</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.unpack</code></strong></p>
<div class="codehilite"><pre><span></span>def unpack(value, num=None, name=&quot;unpack&quot;)
</pre></div>


<p>Unpacks the outer dimension of a rank-<code>R</code> tensor into rank-<code>(R-1)</code> tensors.</p>
<p>Unpacks <code>num</code> tensors from <code>value</code> along the first dimension.
If <code>num</code> is not specified (the default), it is inferred from <code>value</code>'s shape.
If <code>value.shape[0]</code> is not known, <code>ValueError</code> is raised.</p>
<p>The ith tensor in <code>output</code> is the slice <code>value[i, ...]</code>. Each tensor in
<code>output</code> has shape <code>value.shape[1:]</code>.</p>
<p>This is the opposite of pack.  The numpy equivalent is</p>
<div class="codehilite"><pre><span></span>tf.unpack(x, n) = list(x)
</pre></div>


<p>Args:
  value: A rank <code>R &gt; 0</code> <code>Tensor</code> to be unpacked.
  num: An <code>int</code>. The first dimension of value. Automatically inferred if
    <code>None</code> (the default).
  name: A name for the operation (optional).</p>
<p>Returns:
  The list of <code>Tensor</code> objects unpacked from <code>value</code>.</p>
<p>Raises:
  ValueError: If <code>num</code> is unspecified and cannot be inferred.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.unpack', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.unpack" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.unpack_layer">
    <p>def <span class="ident">unpack_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.unpack_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.unpack_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.unpack_layer</strong></p>
<div class="codehilite"><pre><span></span>def unpack_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.unpack, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.unpack</strong></p>
<div class="codehilite"><pre><span></span>def unpack(value, num=None, name=&quot;unpack&quot;):
</pre></div>


<p>Unpacks the outer dimension of a rank-<code>R</code> tensor into rank-<code>(R-1)</code> tensors.</p>
<p>Unpacks <code>num</code> tensors from <code>value</code> along the first dimension.
If <code>num</code> is not specified (the default), it is inferred from <code>value</code>'s shape.
If <code>value.shape[0]</code> is not known, <code>ValueError</code> is raised.</p>
<p>The ith tensor in <code>output</code> is the slice <code>value[i, ...]</code>. Each tensor in
<code>output</code> has shape <code>value.shape[1:]</code>.</p>
<p>This is the opposite of pack.  The numpy equivalent is</p>
<div class="codehilite"><pre><span></span>tf.unpack(x, n) = list(x)
</pre></div>


<p>Args:
  value: A rank <code>R &gt; 0</code> <code>Tensor</code> to be unpacked.
  num: An <code>int</code>. The first dimension of value. Automatically inferred if
    <code>None</code> (the default).
  name: A name for the operation (optional).</p>
<p>Returns:
  The list of <code>Tensor</code> objects unpacked from <code>value</code>.</p>
<p>Raises:
  ValueError: If <code>num</code> is unspecified and cannot be inferred.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.unpack_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.unpack_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.unsorted_segment_sum">
    <p>def <span class="ident">unsorted_segment_sum</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.unsorted_segment_sum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.unsorted_segment_sum</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.unsorted_segment_sum</strong></p>
<div class="codehilite"><pre><span></span>def unsorted_segment_sum(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.unsorted_segment_sum</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.unsorted_segment_sum</code></strong></p>
<div class="codehilite"><pre><span></span>def unsorted_segment_sum(data, segment_ids, num_segments, name=None)
</pre></div>


<p>Computes the sum along segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Computes a tensor such that
\(output_i = \sum_j data_j\) where sum is over <code>j</code> such
that <code>segment_ids[j] == i</code>. Unlike <code>SegmentSum</code>, <code>segment_ids</code>
need not be sorted and need not cover all values in the full
  range of valid values.</p>
<p>If the sum is empty for a given segment ID <code>i</code>, <code>output[i] = 0</code>.</p>
<p><code>num_segments</code> should equal the number of distinct segment IDs.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/UnsortedSegmentSum.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  segment_ids: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A 1-D tensor whose rank is equal to the rank of <code>data</code>'s
    first dimension.
  num_segments: A <code>Tensor</code> of type <code>int32</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>num_segments</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.unsorted_segment_sum', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.unsorted_segment_sum" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.unsorted_segment_sum_layer">
    <p>def <span class="ident">unsorted_segment_sum_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.unsorted_segment_sum_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.unsorted_segment_sum_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.unsorted_segment_sum_layer</strong></p>
<div class="codehilite"><pre><span></span>def unsorted_segment_sum_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.unsorted_segment_sum, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.unsorted_segment_sum</strong></p>
<div class="codehilite"><pre><span></span>def unsorted_segment_sum(data, segment_ids, num_segments, name=None):
</pre></div>


<p>Computes the sum along segments of a tensor.</p>
<p>Read <a href="../../api_docs/python/math_ops.md#segmentation">the section on
Segmentation</a> for an explanation
of segments.</p>
<p>Computes a tensor such that
\(output_i = \sum_j data_j\) where sum is over <code>j</code> such
that <code>segment_ids[j] == i</code>. Unlike <code>SegmentSum</code>, <code>segment_ids</code>
need not be sorted and need not cover all values in the full
  range of valid values.</p>
<p>If the sum is empty for a given segment ID <code>i</code>, <code>output[i] = 0</code>.</p>
<p><code>num_segments</code> should equal the number of distinct segment IDs.</p>
<div style="width:70%; margin:auto; margin-bottom:10px; margin-top:20px;">
<img style="width:100%" src="../../images/UnsortedSegmentSum.png" alt>
</div>

<p>Args:
  data: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int64</code>, <code>int32</code>, <code>uint8</code>, <code>uint16</code>, <code>int16</code>, <code>int8</code>, <code>complex64</code>, <code>complex128</code>, <code>qint8</code>, <code>quint8</code>, <code>qint32</code>, <code>half</code>.
  segment_ids: A <code>Tensor</code>. Must be one of the following types: <code>int32</code>, <code>int64</code>.
    A 1-D tensor whose rank is equal to the rank of <code>data</code>'s
    first dimension.
  num_segments: A <code>Tensor</code> of type <code>int32</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>data</code>.
  Has same shape as data, except for dimension 0 which
  has size <code>num_segments</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.unsorted_segment_sum_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.unsorted_segment_sum_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.variable_axis_size_partitioner">
    <p>def <span class="ident">variable_axis_size_partitioner</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.variable_axis_size_partitioner, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.variable_axis_size_partitioner</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.variable_axis_size_partitioner</strong></p>
<div class="codehilite"><pre><span></span>def variable_axis_size_partitioner(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.variable_axis_size_partitioner</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.variable_axis_size_partitioner</code></strong></p>
<div class="codehilite"><pre><span></span>def variable_axis_size_partitioner(max_shard_bytes, axis=0, bytes_per_string_element=16, max_shards=None)
</pre></div>


<p>Get a partitioner for VariableScope to keep shards below <code>max_shard_bytes</code>.</p>
<p>This partitioner will shard a Variable along one axis, attempting to keep
the maximum shard size below <code>max_shard_bytes</code>.  In practice, this is not
always possible when sharding along only one axis.  When this happens,
this axis is sharded as much as possible (i.e., every dimension becomes
a separate shard).</p>
<p>If the partitioner hits the <code>max_shards</code> limit, then each shard may end up
larger than <code>max_shard_bytes</code>. By default <code>max_shards</code> equals <code>None</code> and no
limit on the number of shards is enforced.</p>
<p>One reasonable value for <code>max_shard_bytes</code> is <code>(64 &lt;&lt; 20) - 1</code>, or almost
<code>64MB</code>, to keep below the protobuf byte limit.</p>
<p>Args:
  max_shard_bytes: The maximum size any given shard is allowed to be.
  axis: The axis to partition along.  Default: outermost axis.
  bytes_per_string_element: If the <code>Variable</code> is of type string, this provides
    an estimate of how large each scalar in the <code>Variable</code> is.
  max_shards: The maximum number of shards in int created taking precedence
    over <code>max_shard_bytes</code>.</p>
<p>Returns:
  A partition function usable as the <code>partitioner</code> argument to
  <code>variable_scope</code>, <code>get_variable</code>, and <code>get_partitioned_variable_list</code>.</p>
<p>Raises:
  ValueError: If any of the byte counts are non-positive.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.variable_axis_size_partitioner', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.variable_axis_size_partitioner" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.variable_axis_size_partitioner_layer">
    <p>def <span class="ident">variable_axis_size_partitioner_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.variable_axis_size_partitioner_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.variable_axis_size_partitioner_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.variable_axis_size_partitioner_layer</strong></p>
<div class="codehilite"><pre><span></span>def variable_axis_size_partitioner_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.variable_axis_size_partitioner, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.variable_axis_size_partitioner</strong></p>
<div class="codehilite"><pre><span></span>def variable_axis_size_partitioner(max_shard_bytes, axis=0, bytes_per_string_element=16, max_shards=None):
</pre></div>


<p>Get a partitioner for VariableScope to keep shards below <code>max_shard_bytes</code>.</p>
<p>This partitioner will shard a Variable along one axis, attempting to keep
the maximum shard size below <code>max_shard_bytes</code>.  In practice, this is not
always possible when sharding along only one axis.  When this happens,
this axis is sharded as much as possible (i.e., every dimension becomes
a separate shard).</p>
<p>If the partitioner hits the <code>max_shards</code> limit, then each shard may end up
larger than <code>max_shard_bytes</code>. By default <code>max_shards</code> equals <code>None</code> and no
limit on the number of shards is enforced.</p>
<p>One reasonable value for <code>max_shard_bytes</code> is <code>(64 &lt;&lt; 20) - 1</code>, or almost
<code>64MB</code>, to keep below the protobuf byte limit.</p>
<p>Args:
  max_shard_bytes: The maximum size any given shard is allowed to be.
  axis: The axis to partition along.  Default: outermost axis.
  bytes_per_string_element: If the <code>Variable</code> is of type string, this provides
    an estimate of how large each scalar in the <code>Variable</code> is.
  max_shards: The maximum number of shards in int created taking precedence
    over <code>max_shard_bytes</code>.</p>
<p>Returns:
  A partition function usable as the <code>partitioner</code> argument to
  <code>variable_scope</code>, <code>get_variable</code>, and <code>get_partitioned_variable_list</code>.</p>
<p>Raises:
  ValueError: If any of the byte counts are non-positive.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.variable_axis_size_partitioner_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.variable_axis_size_partitioner_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.variable_op_scope">
    <p>def <span class="ident">variable_op_scope</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.variable_op_scope, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.variable_op_scope</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.variable_op_scope</strong></p>
<div class="codehilite"><pre><span></span>def variable_op_scope(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.variable_op_scope</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.variable_op_scope</code></strong></p>
<div class="codehilite"><pre><span></span>def variable_op_scope()
</pre></div>


<p>Returns a context manager for defining an op that creates variables.</p>
<p>This context manager validates that the given <code>values</code> are from the
same graph, ensures that graph is the default graph, and pushes a
name scope and a variable scope.</p>
<p>If <code>name_or_scope</code> is not None, it is used as is in the variable scope. If
<code>scope</code> is None, then <code>default_name</code> is used.  In that case, if the same name
has been previously used in the same scope, it will made unique be appending
<code>_N</code> to it.</p>
<p>This is intended to be used when defining generic ops and so reuse is always
inherited.</p>
<p>For example, to define a new Python op called <code>my_op_with_vars</code>:</p>
<p><code>python
def my_op_with_vars(a, b, scope=None):
  with tf.variable_op_scope([a, b], scope, "MyOp") as scope:
    a = tf.convert_to_tensor(a, name="a")
    b = tf.convert_to_tensor(b, name="b")
    c = tf.get_variable('c')
    # Define some computation that uses `a`, `b`, and `c`.
    return foo_op(..., name=scope)</code></p>
<p>Args:
  values: The list of <code>Tensor</code> arguments that are passed to the op function.
  name_or_scope: The name argument that is passed to the op function,
    this name_or_scope is not uniquified in the variable scope.
  default_name: The default name to use if the <code>name_or_scope</code> argument is
    <code>None</code>, this name will be uniquified. If name_or_scope is provided it
    won't be used and therefore it is not required and can be None.
  initializer: The default initializer to pass to variable scope.
  regularizer: The default regularizer for variables within this scope.
  caching_device: The default caching device for variables within this scope.
  partitioner: The default partitioner for variables within this scope.
  reuse: <code>True</code> or <code>None</code>; if <code>True</code>, we go into reuse mode for this scope as
    well as all sub-scopes; if <code>None</code>, we just inherit the parent scope reuse.</p>
<p>Returns:
  A context manager for use in defining a Python op.</p>
<p>Raises:
  ValueError: when trying to reuse within a create scope, or create within
    a reuse scope, or if reuse is not <code>None</code> or <code>True</code>.
  TypeError: when the types of some arguments are not appropriate.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.variable_op_scope', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.variable_op_scope" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.variable_op_scope_layer">
    <p>def <span class="ident">variable_op_scope_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.variable_op_scope_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.variable_op_scope_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.variable_op_scope_layer</strong></p>
<div class="codehilite"><pre><span></span>def variable_op_scope_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.variable_op_scope, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.variable_op_scope</strong></p>
<div class="codehilite"><pre><span></span>def variable_op_scope():
</pre></div>


<p>Returns a context manager for defining an op that creates variables.</p>
<p>This context manager validates that the given <code>values</code> are from the
same graph, ensures that graph is the default graph, and pushes a
name scope and a variable scope.</p>
<p>If <code>name_or_scope</code> is not None, it is used as is in the variable scope. If
<code>scope</code> is None, then <code>default_name</code> is used.  In that case, if the same name
has been previously used in the same scope, it will made unique be appending
<code>_N</code> to it.</p>
<p>This is intended to be used when defining generic ops and so reuse is always
inherited.</p>
<p>For example, to define a new Python op called <code>my_op_with_vars</code>:</p>
<p><code>python
def my_op_with_vars(a, b, scope=None):
  with tf.variable_op_scope([a, b], scope, "MyOp") as scope:
    a = tf.convert_to_tensor(a, name="a")
    b = tf.convert_to_tensor(b, name="b")
    c = tf.get_variable('c')
    # Define some computation that uses `a`, `b`, and `c`.
    return foo_op(..., name=scope)</code></p>
<p>Args:
  values: The list of <code>Tensor</code> arguments that are passed to the op function.
  name_or_scope: The name argument that is passed to the op function,
    this name_or_scope is not uniquified in the variable scope.
  default_name: The default name to use if the <code>name_or_scope</code> argument is
    <code>None</code>, this name will be uniquified. If name_or_scope is provided it
    won't be used and therefore it is not required and can be None.
  initializer: The default initializer to pass to variable scope.
  regularizer: The default regularizer for variables within this scope.
  caching_device: The default caching device for variables within this scope.
  partitioner: The default partitioner for variables within this scope.
  reuse: <code>True</code> or <code>None</code>; if <code>True</code>, we go into reuse mode for this scope as
    well as all sub-scopes; if <code>None</code>, we just inherit the parent scope reuse.</p>
<p>Returns:
  A context manager for use in defining a Python op.</p>
<p>Raises:
  ValueError: when trying to reuse within a create scope, or create within
    a reuse scope, or if reuse is not <code>None</code> or <code>True</code>.
  TypeError: when the types of some arguments are not appropriate.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.variable_op_scope_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.variable_op_scope_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.verify_tensor_all_finite">
    <p>def <span class="ident">verify_tensor_all_finite</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.verify_tensor_all_finite, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.verify_tensor_all_finite</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.verify_tensor_all_finite</strong></p>
<div class="codehilite"><pre><span></span>def verify_tensor_all_finite(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.verify_tensor_all_finite</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.verify_tensor_all_finite</code></strong></p>
<div class="codehilite"><pre><span></span>def verify_tensor_all_finite(t, msg, name=None)
</pre></div>


<p>Assert that the tensor does not contain any NaN's or Inf's.</p>
<p>Args:
  t: Tensor to check.
  msg: Message to log on failure.
  name: A name for this operation (optional).</p>
<p>Returns:
  Same tensor as <code>t</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.verify_tensor_all_finite', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.verify_tensor_all_finite" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.verify_tensor_all_finite_layer">
    <p>def <span class="ident">verify_tensor_all_finite_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.verify_tensor_all_finite_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.verify_tensor_all_finite_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.verify_tensor_all_finite_layer</strong></p>
<div class="codehilite"><pre><span></span>def verify_tensor_all_finite_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.verify_tensor_all_finite, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.verify_tensor_all_finite</strong></p>
<div class="codehilite"><pre><span></span>def verify_tensor_all_finite(t, msg, name=None):
</pre></div>


<p>Assert that the tensor does not contain any NaN's or Inf's.</p>
<p>Args:
  t: Tensor to check.
  msg: Message to log on failure.
  name: A name for this operation (optional).</p>
<p>Returns:
  Same tensor as <code>t</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.verify_tensor_all_finite_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.verify_tensor_all_finite_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.weighted_cross_entropy_with_logits">
    <p>def <span class="ident">weighted_cross_entropy_with_logits</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.weighted_cross_entropy_with_logits, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.weighted_cross_entropy_with_logits</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.weighted_cross_entropy_with_logits</strong></p>
<div class="codehilite"><pre><span></span>def weighted_cross_entropy_with_logits(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.weighted_cross_entropy_with_logits</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.weighted_cross_entropy_with_logits</code></strong></p>
<div class="codehilite"><pre><span></span>def weighted_cross_entropy_with_logits(logits, targets, pos_weight, name=None)
</pre></div>


<p>Computes a weighted cross entropy.</p>
<p>This is like <code>sigmoid_cross_entropy_with_logits()</code> except that <code>pos_weight</code>,
allows one to trade off recall and precision by up- or down-weighting the
cost of a positive error relative to a negative error.</p>
<p>The usual cross-entropy cost is defined as:</p>
<p>targets * -log(sigmoid(logits)) + (1 - targets) * -log(1 - sigmoid(logits))</p>
<p>The argument <code>pos_weight</code> is used as a multiplier for the positive targets:</p>
<p>targets * -log(sigmoid(logits)) * pos_weight +
      (1 - targets) * -log(1 - sigmoid(logits))</p>
<p>For brevity, let <code>x = logits</code>, <code>z = targets</code>, <code>q = pos_weight</code>.
The loss is:</p>
<div class="codehilite"><pre><span></span>  qz * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
= qz * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))
= qz * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))
= qz * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))
= (1 - z) * x + (qz +  1 - z) * log(1 + exp(-x))
= (1 - z) * x + (1 + (q - 1) * z) * log(1 + exp(-x))
</pre></div>


<p>Setting <code>l = (1 + (q - 1) * z)</code>, to ensure stability and avoid overflow,
the implementation uses</p>
<div class="codehilite"><pre><span></span>(1 - z) * x + l * (log(1 + exp(-abs(x))) + max(-x, 0))
</pre></div>


<p><code>logits</code> and <code>targets</code> must have the same type and shape.</p>
<p>Args:
  logits: A <code>Tensor</code> of type <code>float32</code> or <code>float64</code>.
  targets: A <code>Tensor</code> of the same type and shape as <code>logits</code>.
  pos_weight: A coefficient to use on the positive examples.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of the same shape as <code>logits</code> with the componentwise
  weightedlogistic losses.</p>
<p>Raises:
  ValueError: If <code>logits</code> and <code>targets</code> do not have the same shape.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.weighted_cross_entropy_with_logits', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.weighted_cross_entropy_with_logits" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.weighted_cross_entropy_with_logits_layer">
    <p>def <span class="ident">weighted_cross_entropy_with_logits_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.weighted_cross_entropy_with_logits_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.weighted_cross_entropy_with_logits_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.weighted_cross_entropy_with_logits_layer</strong></p>
<div class="codehilite"><pre><span></span>def weighted_cross_entropy_with_logits_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.weighted_cross_entropy_with_logits, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.weighted_cross_entropy_with_logits</strong></p>
<div class="codehilite"><pre><span></span>def weighted_cross_entropy_with_logits(logits, targets, pos_weight, name=None):
</pre></div>


<p>Computes a weighted cross entropy.</p>
<p>This is like <code>sigmoid_cross_entropy_with_logits()</code> except that <code>pos_weight</code>,
allows one to trade off recall and precision by up- or down-weighting the
cost of a positive error relative to a negative error.</p>
<p>The usual cross-entropy cost is defined as:</p>
<p>targets * -log(sigmoid(logits)) + (1 - targets) * -log(1 - sigmoid(logits))</p>
<p>The argument <code>pos_weight</code> is used as a multiplier for the positive targets:</p>
<p>targets * -log(sigmoid(logits)) * pos_weight +
      (1 - targets) * -log(1 - sigmoid(logits))</p>
<p>For brevity, let <code>x = logits</code>, <code>z = targets</code>, <code>q = pos_weight</code>.
The loss is:</p>
<div class="codehilite"><pre><span></span>  qz * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
= qz * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))
= qz * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))
= qz * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))
= (1 - z) * x + (qz +  1 - z) * log(1 + exp(-x))
= (1 - z) * x + (1 + (q - 1) * z) * log(1 + exp(-x))
</pre></div>


<p>Setting <code>l = (1 + (q - 1) * z)</code>, to ensure stability and avoid overflow,
the implementation uses</p>
<div class="codehilite"><pre><span></span>(1 - z) * x + l * (log(1 + exp(-abs(x))) + max(-x, 0))
</pre></div>


<p><code>logits</code> and <code>targets</code> must have the same type and shape.</p>
<p>Args:
  logits: A <code>Tensor</code> of type <code>float32</code> or <code>float64</code>.
  targets: A <code>Tensor</code> of the same type and shape as <code>logits</code>.
  pos_weight: A coefficient to use on the positive examples.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of the same shape as <code>logits</code> with the componentwise
  weightedlogistic losses.</p>
<p>Raises:
  ValueError: If <code>logits</code> and <code>targets</code> do not have the same shape.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.weighted_cross_entropy_with_logits_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.weighted_cross_entropy_with_logits_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.where">
    <p>def <span class="ident">where</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.where, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.where</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.where</strong></p>
<div class="codehilite"><pre><span></span>def where(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.where</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.where</code></strong></p>
<div class="codehilite"><pre><span></span>def where(input, name=None)
</pre></div>


<p>Returns locations of true values in a boolean tensor.</p>
<p>This operation returns the coordinates of true elements in <code>input</code>. The
coordinates are returned in a 2-D tensor where the first dimension (rows)
represents the number of true elements, and the second dimension (columns)
represents the coordinates of the true elements. Keep in mind, the shape of
the output tensor can vary depending on how many true values there are in
<code>input</code>. Indices are output in row-major order.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'input' tensor is [[True, False]</h1>
<h1>[True, False]]</h1>
<h1>'input' has two true values, so output has two coordinates.</h1>
<h1>'input' has rank of 2, so coordinates have two indices.</h1>
<p>where(input) ==&gt; [[0, 0],
                  [1, 0]]</p>
<h1><code>input</code> tensor is [[[True, False]</h1>
<h1>[True, False]]</h1>
<h1>[[False, True]</h1>
<h1>[False, True]]</h1>
<h1>[[False, False]</h1>
<h1>[False, True]]]</h1>
<h1>'input' has 5 true values, so output has 5 coordinates.</h1>
<h1>'input' has rank of 3, so coordinates have three indices.</h1>
<p>where(input) ==&gt; [[0, 0, 0],
                  [0, 1, 0],
                  [1, 0, 1],
                  [1, 1, 1],
                  [2, 1, 1]]
```</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>bool</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.where', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.where" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.where_layer">
    <p>def <span class="ident">where_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.where_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.where_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.where_layer</strong></p>
<div class="codehilite"><pre><span></span>def where_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.where, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.where</strong></p>
<div class="codehilite"><pre><span></span>def where(input, name=None):
</pre></div>


<p>Returns locations of true values in a boolean tensor.</p>
<p>This operation returns the coordinates of true elements in <code>input</code>. The
coordinates are returned in a 2-D tensor where the first dimension (rows)
represents the number of true elements, and the second dimension (columns)
represents the coordinates of the true elements. Keep in mind, the shape of
the output tensor can vary depending on how many true values there are in
<code>input</code>. Indices are output in row-major order.</p>
<p>For example:</p>
<p>```prettyprint</p>
<h1>'input' tensor is [[True, False]</h1>
<h1>[True, False]]</h1>
<h1>'input' has two true values, so output has two coordinates.</h1>
<h1>'input' has rank of 2, so coordinates have two indices.</h1>
<p>where(input) ==&gt; [[0, 0],
                  [1, 0]]</p>
<h1><code>input</code> tensor is [[[True, False]</h1>
<h1>[True, False]]</h1>
<h1>[[False, True]</h1>
<h1>[False, True]]</h1>
<h1>[[False, False]</h1>
<h1>[False, True]]]</h1>
<h1>'input' has 5 true values, so output has 5 coordinates.</h1>
<h1>'input' has rank of 3, so coordinates have three indices.</h1>
<p>where(input) ==&gt; [[0, 0, 0],
                  [0, 1, 0],
                  [1, 0, 1],
                  [1, 1, 1],
                  [2, 1, 1]]
```</p>
<p>Args:
  input: A <code>Tensor</code> of type <code>bool</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> of type <code>int64</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.where_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.where_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.while_loop">
    <p>def <span class="ident">while_loop</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.while_loop, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.while_loop</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.while_loop</strong></p>
<div class="codehilite"><pre><span></span>def while_loop(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.while_loop</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.while_loop</code></strong></p>
<div class="codehilite"><pre><span></span>def while_loop(cond, body, loop_vars, parallel_iterations=10, back_prop=True, swap_memory=False, name=None)
</pre></div>


<p>Repeat <code>body</code> while the condition <code>cond</code> is true.</p>
<p><code>cond</code> is a callable returning a boolean scalar tensor. <code>body</code> is a callable
returning a list of tensors of the same length and with the same types as
<code>loop_vars</code>. <code>loop_vars</code> is a list of tensors that is passed to both <code>cond</code>
and <code>body</code>. <code>cond</code> and <code>body</code> both take as many arguments as there are
<code>loop_vars</code>.</p>
<p>In addition to regular Tensors or IndexedSlices, the body may accept and
return TensorArray objects.  The flows of the TensorArray objects will
be appropriately forwarded between loops and during gradient calculations.</p>
<p>While <code>cond</code> evaluates to true, <code>body</code> is executed.</p>
<p><code>while_loop</code> implements non-strict semantics, enabling multiple iterations
to run in parallel. The maximum number of parallel iterations can be
controlled by <code>parallel_iterations</code>, which gives users some control over
memory consumption and execution order. For correct programs, <code>while_loop</code>
should return the same result for any parallel_iterations &gt; 0.</p>
<p>For training, TensorFlow remembers the tensors that are produced in the
forward inference but needed in back propagation. These tensors can be a
main source of memory consumption and often cause OOM problems when training
on GPUs.  When the flag swap_memory is true, we swap out these tensors from
GPU to CPU.  This for example allows us to train RNN models with very long
sequences and large batches.</p>
<p>Args:
  cond: A callable that represents the termination condition of the loop.
  body: A callable that represents the loop body.
  loop_vars: The list of variable input tensors.
  parallel_iterations: The number of iterations allowed to run in parallel.
  back_prop: Whether backprop is enabled for this while loop.
  swap_memory: Whether GPU-CPU memory swap is enabled for this loop.
  name: Optional name prefix for the returned tensors.</p>
<p>Returns:
  The output tensors for the loop variables after the loop.</p>
<p>Raises:
  TypeError: if <code>cond</code> or <code>body</code> is not callable.
  ValueError: if <code>loop_var</code> is empty.</p>
<p>Example:</p>
<p><code>python
  i = tf.constant(0)
  c = lambda i: tf.less(i, 10)
  b = lambda i: tf.add(i, 1)
  r = tf.while_loop(c, b, [i])</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.while_loop', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.while_loop" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.while_loop_layer">
    <p>def <span class="ident">while_loop_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.while_loop_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.while_loop_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.while_loop_layer</strong></p>
<div class="codehilite"><pre><span></span>def while_loop_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.while_loop, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.while_loop</strong></p>
<div class="codehilite"><pre><span></span>def while_loop(cond, body, loop_vars, parallel_iterations=10, back_prop=True, swap_memory=False, name=None):
</pre></div>


<p>Repeat <code>body</code> while the condition <code>cond</code> is true.</p>
<p><code>cond</code> is a callable returning a boolean scalar tensor. <code>body</code> is a callable
returning a list of tensors of the same length and with the same types as
<code>loop_vars</code>. <code>loop_vars</code> is a list of tensors that is passed to both <code>cond</code>
and <code>body</code>. <code>cond</code> and <code>body</code> both take as many arguments as there are
<code>loop_vars</code>.</p>
<p>In addition to regular Tensors or IndexedSlices, the body may accept and
return TensorArray objects.  The flows of the TensorArray objects will
be appropriately forwarded between loops and during gradient calculations.</p>
<p>While <code>cond</code> evaluates to true, <code>body</code> is executed.</p>
<p><code>while_loop</code> implements non-strict semantics, enabling multiple iterations
to run in parallel. The maximum number of parallel iterations can be
controlled by <code>parallel_iterations</code>, which gives users some control over
memory consumption and execution order. For correct programs, <code>while_loop</code>
should return the same result for any parallel_iterations &gt; 0.</p>
<p>For training, TensorFlow remembers the tensors that are produced in the
forward inference but needed in back propagation. These tensors can be a
main source of memory consumption and often cause OOM problems when training
on GPUs.  When the flag swap_memory is true, we swap out these tensors from
GPU to CPU.  This for example allows us to train RNN models with very long
sequences and large batches.</p>
<p>Args:
  cond: A callable that represents the termination condition of the loop.
  body: A callable that represents the loop body.
  loop_vars: The list of variable input tensors.
  parallel_iterations: The number of iterations allowed to run in parallel.
  back_prop: Whether backprop is enabled for this while loop.
  swap_memory: Whether GPU-CPU memory swap is enabled for this loop.
  name: Optional name prefix for the returned tensors.</p>
<p>Returns:
  The output tensors for the loop variables after the loop.</p>
<p>Raises:
  TypeError: if <code>cond</code> or <code>body</code> is not callable.
  ValueError: if <code>loop_var</code> is empty.</p>
<p>Example:</p>
<p><code>python
  i = tf.constant(0)
  c = lambda i: tf.less(i, 10)
  b = lambda i: tf.add(i, 1)
  r = tf.while_loop(c, b, [i])</code></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.while_loop_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.while_loop_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.xw_plus_b">
    <p>def <span class="ident">xw_plus_b</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.xw_plus_b, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.xw_plus_b</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.xw_plus_b</strong></p>
<div class="codehilite"><pre><span></span>def xw_plus_b(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.xw_plus_b</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.xw_plus_b</code></strong></p>
<div class="codehilite"><pre><span></span>def xw_plus_b(x, weights, biases, name=None)
</pre></div>


<p>Computes matmul(x, weights) + biases.</p>
<p>Args:
  x: a 2D tensor.  Dimensions typically: batch, in_units
  weights: a 2D tensor.  Dimensions typically: in_units, out_units
  biases: a 1D tensor.  Dimensions: out_units
  name: A name for the operation (optional).  If not specified
    "xw_plus_b" is used.</p>
<p>Returns:
  A 2-D Tensor computing matmul(x, weights) + biases.
  Dimensions typically: batch, out_units.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.xw_plus_b', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.xw_plus_b" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.xw_plus_b_layer">
    <p>def <span class="ident">xw_plus_b_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.xw_plus_b_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.xw_plus_b_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.xw_plus_b_layer</strong></p>
<div class="codehilite"><pre><span></span>def xw_plus_b_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.xw_plus_b, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.xw_plus_b</strong></p>
<div class="codehilite"><pre><span></span>def xw_plus_b(x, weights, biases, name=None):
</pre></div>


<p>Computes matmul(x, weights) + biases.</p>
<p>Args:
  x: a 2D tensor.  Dimensions typically: batch, in_units
  weights: a 2D tensor.  Dimensions typically: in_units, out_units
  biases: a 1D tensor.  Dimensions: out_units
  name: A name for the operation (optional).  If not specified
    "xw_plus_b" is used.</p>
<p>Returns:
  A 2-D Tensor computing matmul(x, weights) + biases.
  Dimensions typically: batch, out_units.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.xw_plus_b_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.xw_plus_b_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.xw_plus_b_v1">
    <p>def <span class="ident">xw_plus_b_v1</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.xw_plus_b_v1, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.xw_plus_b_v1</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.xw_plus_b_v1</strong></p>
<div class="codehilite"><pre><span></span>def xw_plus_b_v1(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.xw_plus_b_v1</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.xw_plus_b_v1</code></strong></p>
<div class="codehilite"><pre><span></span>def xw_plus_b_v1(x, weights, biases, name=None)
</pre></div>


<p>Computes matmul(x, weights) + biases.</p>
<p>This is a deprecated version of that will soon be removed.</p>
<p>Args:
  x: a 2D tensor.  Dimensions typically: batch, in_units
  weights: a 2D tensor.  Dimensions typically: in_units, out_units
  biases: a 1D tensor.  Dimensions: out_units
  name: A name for the operation (optional).  If not specified
    "xw_plus_b_v1" is used.</p>
<p>Returns:
  A 2-D Tensor computing matmul(x, weights) + biases.
  Dimensions typically: batch, out_units.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.xw_plus_b_v1', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.xw_plus_b_v1" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.xw_plus_b_v1_layer">
    <p>def <span class="ident">xw_plus_b_v1_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.xw_plus_b_v1_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.xw_plus_b_v1_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.xw_plus_b_v1_layer</strong></p>
<div class="codehilite"><pre><span></span>def xw_plus_b_v1_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.xw_plus_b_v1, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.xw_plus_b_v1</strong></p>
<div class="codehilite"><pre><span></span>def xw_plus_b_v1(x, weights, biases, name=None):
</pre></div>


<p>Computes matmul(x, weights) + biases.</p>
<p>This is a deprecated version of that will soon be removed.</p>
<p>Args:
  x: a 2D tensor.  Dimensions typically: batch, in_units
  weights: a 2D tensor.  Dimensions typically: in_units, out_units
  biases: a 1D tensor.  Dimensions: out_units
  name: A name for the operation (optional).  If not specified
    "xw_plus_b_v1" is used.</p>
<p>Returns:
  A 2-D Tensor computing matmul(x, weights) + biases.
  Dimensions typically: batch, out_units.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.xw_plus_b_v1_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.xw_plus_b_v1_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.zero_fraction">
    <p>def <span class="ident">zero_fraction</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.zero_fraction, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.zero_fraction</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.zero_fraction</strong></p>
<div class="codehilite"><pre><span></span>def zero_fraction(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.nn.zero_fraction</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.nn.zero_fraction</code></strong></p>
<div class="codehilite"><pre><span></span>def zero_fraction(value, name=None)
</pre></div>


<p>Returns the fraction of zeros in <code>value</code>.</p>
<p>If <code>value</code> is empty, the result is <code>nan</code>.</p>
<p>This is useful in summaries to measure and report sparsity.  For example,</p>
<div class="codehilite"><pre><span></span>z = tf.Relu(...)
summ = tf.scalar_summary(&#39;sparsity&#39;, tf.nn.zero_fraction(z))
</pre></div>


<p>Args:
  value: A tensor of numeric type.
  name: A name for the operation (optional).</p>
<p>Returns:
  The fraction of zeros in <code>value</code>, with type <code>float32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.zero_fraction', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.zero_fraction" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.zero_fraction_layer">
    <p>def <span class="ident">zero_fraction_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.zero_fraction_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.zero_fraction_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.zero_fraction_layer</strong></p>
<div class="codehilite"><pre><span></span>def zero_fraction_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.nn.zero_fraction, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.nn.zero_fraction</strong></p>
<div class="codehilite"><pre><span></span>def zero_fraction(value, name=None):
</pre></div>


<p>Returns the fraction of zeros in <code>value</code>.</p>
<p>If <code>value</code> is empty, the result is <code>nan</code>.</p>
<p>This is useful in summaries to measure and report sparsity.  For example,</p>
<div class="codehilite"><pre><span></span>z = tf.Relu(...)
summ = tf.scalar_summary(&#39;sparsity&#39;, tf.nn.zero_fraction(z))
</pre></div>


<p>Args:
  value: A tensor of numeric type.
  name: A name for the operation (optional).</p>
<p>Returns:
  The fraction of zeros in <code>value</code>, with type <code>float32</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.zero_fraction_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.zero_fraction_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.zeros">
    <p>def <span class="ident">zeros</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.zeros, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.zeros</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.zeros</strong></p>
<div class="codehilite"><pre><span></span>def zeros(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.zeros</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.zeros</code></strong></p>
<div class="codehilite"><pre><span></span>def zeros(shape, dtype=&lt;dtype: &#39;float32&#39;&gt;, name=None)
</pre></div>


<p>Creates a tensor with all elements set to zero.</p>
<p>This operation returns a tensor of type <code>dtype</code> with shape <code>shape</code> and
all elements set to zero.</p>
<p>For example:</p>
<p><code>python
tf.zeros([3, 4], int32) ==&gt; [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]</code></p>
<p>Args:
  shape: Either a list of integers, or a 1-D <code>Tensor</code> of type <code>int32</code>.
  dtype: The type of an element in the resulting <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with all elements set to zero.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.zeros', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.zeros" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.zeros_initializer">
    <p>def <span class="ident">zeros_initializer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.zeros_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.zeros_initializer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.zeros_initializer</strong></p>
<div class="codehilite"><pre><span></span>def zeros_initializer(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.zeros_initializer</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.zeros_initializer</code></strong></p>
<div class="codehilite"><pre><span></span>def zeros_initializer(shape, dtype=&lt;dtype: &#39;float32&#39;&gt;)
</pre></div>


<p>An adaptor for zeros() to match the Initializer spec.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.zeros_initializer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.zeros_initializer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.zeros_initializer_layer">
    <p>def <span class="ident">zeros_initializer_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.zeros_initializer_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.zeros_initializer_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.zeros_initializer_layer</strong></p>
<div class="codehilite"><pre><span></span>def zeros_initializer_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.zeros_initializer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.zeros_initializer</strong></p>
<div class="codehilite"><pre><span></span>def zeros_initializer(shape, dtype=&lt;dtype: &#39;float32&#39;&gt;):
</pre></div>


<p>An adaptor for zeros() to match the Initializer spec.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.zeros_initializer_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.zeros_initializer_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.zeros_layer">
    <p>def <span class="ident">zeros_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.zeros_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.zeros_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.zeros_layer</strong></p>
<div class="codehilite"><pre><span></span>def zeros_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.zeros, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.zeros</strong></p>
<div class="codehilite"><pre><span></span>def zeros(shape, dtype=&lt;dtype: &#39;float32&#39;&gt;, name=None):
</pre></div>


<p>Creates a tensor with all elements set to zero.</p>
<p>This operation returns a tensor of type <code>dtype</code> with shape <code>shape</code> and
all elements set to zero.</p>
<p>For example:</p>
<p><code>python
tf.zeros([3, 4], int32) ==&gt; [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]</code></p>
<p>Args:
  shape: Either a list of integers, or a 1-D <code>Tensor</code> of type <code>int32</code>.
  dtype: The type of an element in the resulting <code>Tensor</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with all elements set to zero.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.zeros_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.zeros_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.zeros_like">
    <p>def <span class="ident">zeros_like</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.zeros_like, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.zeros_like</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.zeros_like</strong></p>
<div class="codehilite"><pre><span></span>def zeros_like(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.zeros_like</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.zeros_like</code></strong></p>
<div class="codehilite"><pre><span></span>def zeros_like(tensor, dtype=None, name=None)
</pre></div>


<p>Creates a tensor with all elements set to zero.</p>
<p>Given a single tensor (<code>tensor</code>), this operation returns a tensor of the
same type and shape as <code>tensor</code> with all elements set to zero. Optionally,
you can use <code>dtype</code> to specify a new type for the returned tensor.</p>
<p>For example:</p>
<p>```python</p>
<h1>'tensor' is [[1, 2, 3], [4, 5, 6]]</h1>
<p>tf.zeros_like(tensor) ==&gt; [[0, 0, 0], [0, 0, 0]]
```</p>
<p>Args:
  tensor: A <code>Tensor</code>.
  dtype: A type for the returned <code>Tensor</code>. Must be <code>float32</code>, <code>float64</code>,
  <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>complex64</code>, or <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with all elements set to zero.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.zeros_like', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.zeros_like" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.zeros_like_layer">
    <p>def <span class="ident">zeros_like_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.zeros_like_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.zeros_like_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.zeros_like_layer</strong></p>
<div class="codehilite"><pre><span></span>def zeros_like_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.zeros_like, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.zeros_like</strong></p>
<div class="codehilite"><pre><span></span>def zeros_like(tensor, dtype=None, name=None):
</pre></div>


<p>Creates a tensor with all elements set to zero.</p>
<p>Given a single tensor (<code>tensor</code>), this operation returns a tensor of the
same type and shape as <code>tensor</code> with all elements set to zero. Optionally,
you can use <code>dtype</code> to specify a new type for the returned tensor.</p>
<p>For example:</p>
<p>```python</p>
<h1>'tensor' is [[1, 2, 3], [4, 5, 6]]</h1>
<p>tf.zeros_like(tensor) ==&gt; [[0, 0, 0], [0, 0, 0]]
```</p>
<p>Args:
  tensor: A <code>Tensor</code>.
  dtype: A type for the returned <code>Tensor</code>. Must be <code>float32</code>, <code>float64</code>,
  <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>, <code>complex64</code>, or <code>complex128</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code> with all elements set to zero.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.zeros_like_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.zeros_like_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.zeta">
    <p>def <span class="ident">zeta</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.zeta, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.zeta</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.zeta</strong></p>
<div class="codehilite"><pre><span></span>def zeta(builder):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p><strong>@immutable</strong></p>
<p>This method is a lifted version the function <code>tf.zeta</code> to work with <code>tensorbuilder.core.builders.Builder</code>s. Instead of taking a Tensor as its first argument it takes a builder, the rest of the arguments are exactly the same.</p>
<p><strong> Original Documentation for <code>tf.zeta</code></strong></p>
<div class="codehilite"><pre><span></span>def zeta(x, q, name=None)
</pre></div>


<p>Compute the Hurwitz zeta function \(\zeta(x, q)\).</p>
<p>The Hurwitz zeta function is defined as:</p>
<p><code>\zeta(x, q) = \sum_{n=0}^{\infty} (q + n)^{-x}</code></p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  q: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.zeta', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.zeta" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.api.applicative.Applicative.zeta_layer">
    <p>def <span class="ident">zeta_layer</span>(</p><p>app, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.compose(Builder.zeta_layer, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li>All other *args and **kwargs are forwarded to <code>Builder.zeta_layer</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Applicative</p>
<p><strong>Origial documentation for Builder.zeta_layer</strong></p>
<div class="codehilite"><pre><span></span>def zeta_layer(builder, size):
</pre></div>


<p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<p>Alias for <code>.fully_connected(size, activation_fn = tf.zeta, ...)</code></p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>size</code>: the size of the resulting layer</li>
<li>All other *args and **kwargs are forwarded to <code>tf.contrib.layers.fully_connected</code></li>
</ul>
<p><strong>Return</strong></p>
<p>Builder</p>
<p><strong>Origial documentation for tf.zeta</strong></p>
<div class="codehilite"><pre><span></span>def zeta(x, q, name=None):
</pre></div>


<p>Compute the Hurwitz zeta function \(\zeta(x, q)\).</p>
<p>The Hurwitz zeta function is defined as:</p>
<p><code>\zeta(x, q) = \sum_{n=0}^{\infty} (q + n)^{-x}</code></p>
<p>Args:
  x: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>.
  q: A <code>Tensor</code>. Must have the same type as <code>x</code>.
  name: A name for the operation (optional).</p>
<p>Returns:
  A <code>Tensor</code>. Has the same type as <code>x</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.api.applicative.Applicative.zeta_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.api.applicative.Applicative.zeta_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">_method</span><span class="p">(</span><span class="n">app</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">builder</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">builder</span><span class="p">,</span> <span class="n">f</span><span class="o">.</span><span class="n">__name__</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">g</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">app</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="n">_lambda</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      </div>
      </div>

  </section>

    </article>
  <div class="clear"> </div>
  <footer id="footer">
    <p>
      Documentation generated by
      <a href="https://github.com/BurntSushi/pdoc">pdoc 0.3.2</a>
    </p>

    <p>pdoc is in the public domain with the
      <a href="http://unlicense.org">UNLICENSE</a></p>

    <p>Design by <a href="http://nadh.in">Kailash Nadh</a></p>
  </footer>
</div>
</body>
</html>
