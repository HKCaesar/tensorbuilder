<!doctype html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />

    <title>tensorbuilder.patches.layers_patch API documentation</title>
    <meta name="description" content="" />

  <link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300' rel='stylesheet' type='text/css'>
  
  <style type="text/css">
  
* {
  box-sizing: border-box;
}
/*! normalize.css v1.1.1 | MIT License | git.io/normalize */

/* ==========================================================================
   HTML5 display definitions
   ========================================================================== */

/**
 * Correct `block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
nav,
section,
summary {
    display: block;
}

/**
 * Correct `inline-block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

audio,
canvas,
video {
    display: inline-block;
    *display: inline;
    *zoom: 1;
}

/**
 * Prevent modern browsers from displaying `audio` without controls.
 * Remove excess height in iOS 5 devices.
 */

audio:not([controls]) {
    display: none;
    height: 0;
}

/**
 * Address styling not present in IE 7/8/9, Firefox 3, and Safari 4.
 * Known issue: no IE 6 support.
 */

[hidden] {
    display: none;
}

/* ==========================================================================
   Base
   ========================================================================== */

/**
 * 1. Prevent system color scheme's background color being used in Firefox, IE,
 *    and Opera.
 * 2. Prevent system color scheme's text color being used in Firefox, IE, and
 *    Opera.
 * 3. Correct text resizing oddly in IE 6/7 when body `font-size` is set using
 *    `em` units.
 * 4. Prevent iOS text size adjust after orientation change, without disabling
 *    user zoom.
 */

html {
    background: #fff; /* 1 */
    color: #000; /* 2 */
    font-size: 100%; /* 3 */
    -webkit-text-size-adjust: 100%; /* 4 */
    -ms-text-size-adjust: 100%; /* 4 */
}

/**
 * Address `font-family` inconsistency between `textarea` and other form
 * elements.
 */

html,
button,
input,
select,
textarea {
    font-family: sans-serif;
}

/**
 * Address margins handled incorrectly in IE 6/7.
 */

body {
    margin: 0;
}

/* ==========================================================================
   Links
   ========================================================================== */

/**
 * Address `outline` inconsistency between Chrome and other browsers.
 */

a:focus {
    outline: thin dotted;
}

/**
 * Improve readability when focused and also mouse hovered in all browsers.
 */

a:active,
a:hover {
    outline: 0;
}

/* ==========================================================================
   Typography
   ========================================================================== */

/**
 * Address font sizes and margins set differently in IE 6/7.
 * Address font sizes within `section` and `article` in Firefox 4+, Safari 5,
 * and Chrome.
 */

h1 {
    font-size: 2em;
    margin: 0.67em 0;
}

h2 {
    font-size: 1.5em;
    margin: 0.83em 0;
}

h3 {
    font-size: 1.17em;
    margin: 1em 0;
}

h4 {
    font-size: 1em;
    margin: 1.33em 0;
}

h5 {
    font-size: 0.83em;
    margin: 1.67em 0;
}

h6 {
    font-size: 0.67em;
    margin: 2.33em 0;
}

/**
 * Address styling not present in IE 7/8/9, Safari 5, and Chrome.
 */

abbr[title] {
    border-bottom: 1px dotted;
}

/**
 * Address style set to `bolder` in Firefox 3+, Safari 4/5, and Chrome.
 */

b,
strong {
    font-weight: bold;
}

blockquote {
    margin: 1em 40px;
}

/**
 * Address styling not present in Safari 5 and Chrome.
 */

dfn {
    font-style: italic;
}

/**
 * Address differences between Firefox and other browsers.
 * Known issue: no IE 6/7 normalization.
 */

hr {
    -moz-box-sizing: content-box;
    box-sizing: content-box;
    height: 0;
}

/**
 * Address styling not present in IE 6/7/8/9.
 */

mark {
    background: #ff0;
    color: #000;
}

/**
 * Address margins set differently in IE 6/7.
 */

p,
pre {
    margin: 1em 0;
}

/**
 * Correct font family set oddly in IE 6, Safari 4/5, and Chrome.
 */

code,
kbd,
pre,
samp {
    font-family: monospace, serif;
    _font-family: 'courier new', monospace;
    font-size: 1em;
}

/**
 * Improve readability of pre-formatted text in all browsers.
 */

pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
}

/**
 * Address CSS quotes not supported in IE 6/7.
 */

q {
    quotes: none;
}

/**
 * Address `quotes` property not supported in Safari 4.
 */

q:before,
q:after {
    content: '';
    content: none;
}

/**
 * Address inconsistent and variable font size in all browsers.
 */

small {
    font-size: 80%;
}

/**
 * Prevent `sub` and `sup` affecting `line-height` in all browsers.
 */

sub,
sup {
    font-size: 75%;
    line-height: 0;
    position: relative;
    vertical-align: baseline;
}

sup {
    top: -0.5em;
}

sub {
    bottom: -0.25em;
}

/* ==========================================================================
   Lists
   ========================================================================== */

/**
 * Address margins set differently in IE 6/7.
 */

dl,
menu,
ol,
ul {
    margin: 1em 0;
}

dd {
    margin: 0 0 0 40px;
}

/**
 * Address paddings set differently in IE 6/7.
 */

menu,
ol,
ul {
    padding: 0 0 0 40px;
}

/**
 * Correct list images handled incorrectly in IE 7.
 */

nav ul,
nav ol {
    list-style: none;
    list-style-image: none;
}

/* ==========================================================================
   Embedded content
   ========================================================================== */

/**
 * 1. Remove border when inside `a` element in IE 6/7/8/9 and Firefox 3.
 * 2. Improve image quality when scaled in IE 7.
 */

img {
    border: 0; /* 1 */
    -ms-interpolation-mode: bicubic; /* 2 */
}

/**
 * Correct overflow displayed oddly in IE 9.
 */

svg:not(:root) {
    overflow: hidden;
}

/* ==========================================================================
   Figures
   ========================================================================== */

/**
 * Address margin not present in IE 6/7/8/9, Safari 5, and Opera 11.
 */

figure {
    margin: 0;
}

/* ==========================================================================
   Forms
   ========================================================================== */

/**
 * Correct margin displayed oddly in IE 6/7.
 */

form {
    margin: 0;
}

/**
 * Define consistent border, margin, and padding.
 */

fieldset {
    border: 1px solid #c0c0c0;
    margin: 0 2px;
    padding: 0.35em 0.625em 0.75em;
}

/**
 * 1. Correct color not being inherited in IE 6/7/8/9.
 * 2. Correct text not wrapping in Firefox 3.
 * 3. Correct alignment displayed oddly in IE 6/7.
 */

legend {
    border: 0; /* 1 */
    padding: 0;
    white-space: normal; /* 2 */
    *margin-left: -7px; /* 3 */
}

/**
 * 1. Correct font size not being inherited in all browsers.
 * 2. Address margins set differently in IE 6/7, Firefox 3+, Safari 5,
 *    and Chrome.
 * 3. Improve appearance and consistency in all browsers.
 */

button,
input,
select,
textarea {
    font-size: 100%; /* 1 */
    margin: 0; /* 2 */
    vertical-align: baseline; /* 3 */
    *vertical-align: middle; /* 3 */
}

/**
 * Address Firefox 3+ setting `line-height` on `input` using `!important` in
 * the UA stylesheet.
 */

button,
input {
    line-height: normal;
}

/**
 * Address inconsistent `text-transform` inheritance for `button` and `select`.
 * All other form control elements do not inherit `text-transform` values.
 * Correct `button` style inheritance in Chrome, Safari 5+, and IE 6+.
 * Correct `select` style inheritance in Firefox 4+ and Opera.
 */

button,
select {
    text-transform: none;
}

/**
 * 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
 *    and `video` controls.
 * 2. Correct inability to style clickable `input` types in iOS.
 * 3. Improve usability and consistency of cursor style between image-type
 *    `input` and others.
 * 4. Remove inner spacing in IE 7 without affecting normal text inputs.
 *    Known issue: inner spacing remains in IE 6.
 */

button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
    -webkit-appearance: button; /* 2 */
    cursor: pointer; /* 3 */
    *overflow: visible;  /* 4 */
}

/**
 * Re-set default cursor for disabled elements.
 */

button[disabled],
html input[disabled] {
    cursor: default;
}

/**
 * 1. Address box sizing set to content-box in IE 8/9.
 * 2. Remove excess padding in IE 8/9.
 * 3. Remove excess padding in IE 7.
 *    Known issue: excess padding remains in IE 6.
 */

input[type="checkbox"],
input[type="radio"] {
    box-sizing: border-box; /* 1 */
    padding: 0; /* 2 */
    *height: 13px; /* 3 */
    *width: 13px; /* 3 */
}

/**
 * 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome.
 * 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome
 *    (include `-moz` to future-proof).
 */

input[type="search"] {
    -webkit-appearance: textfield; /* 1 */
    -moz-box-sizing: content-box;
    -webkit-box-sizing: content-box; /* 2 */
    box-sizing: content-box;
}

/**
 * Remove inner padding and search cancel button in Safari 5 and Chrome
 * on OS X.
 */

input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
    -webkit-appearance: none;
}

/**
 * Remove inner padding and border in Firefox 3+.
 */

button::-moz-focus-inner,
input::-moz-focus-inner {
    border: 0;
    padding: 0;
}

/**
 * 1. Remove default vertical scrollbar in IE 6/7/8/9.
 * 2. Improve readability and alignment in all browsers.
 */

textarea {
    overflow: auto; /* 1 */
    vertical-align: top; /* 2 */
}

/* ==========================================================================
   Tables
   ========================================================================== */

/**
 * Remove most spacing between table cells.
 */

table {
    border-collapse: collapse;
    border-spacing: 0;
}

  </style>

  <style type="text/css">
  
  html, body {
    margin: 0;
    padding: 0;
    min-height: 100%;
  }
  body {
    background: #fff;
    font-family: "Source Sans Pro", "Helvetica Neueue", Helvetica, sans;
    font-weight: 300;
    font-size: 16px;
    line-height: 1.6em;
  }
  #content {
    width: 70%;
    max-width: 850px;
    float: left;
    padding: 30px 60px;
    border-left: 1px solid #ddd;
  }
  #sidebar {
    width: 25%;
    float: left;
    padding: 30px;
    overflow: hidden;
  }
  #nav {
    font-size: 130%;
    margin: 0 0 15px 0;
  }

  #top {
    display: block;
    position: fixed;
    bottom: 5px;
    left: 5px;
    font-size: .85em;
    text-transform: uppercase;
  }

  #footer {
    font-size: .75em;
    padding: 5px 30px;
    border-top: 1px solid #ddd;
    text-align: right;
  }
    #footer p {
      margin: 0 0 0 30px;
      display: inline-block;
    }

  h1, h2, h3, h4, h5 {
    font-weight: 300;
  }
  h1 {
    font-size: 2.5em;
    line-height: 1.1em;
    margin: 0 0 .50em 0;
  }

  h2 {
    font-size: 1.75em;
    margin: 1em 0 .50em 0;
  }

  h3 {
    margin: 25px 0 10px 0;
  }

  h4 {
    margin: 0;
    font-size: 105%;
  }

  a {
    color: #058;
    text-decoration: none;
    transition: color .3s ease-in-out;
  }

  a:hover {
    color: #e08524;
    transition: color .3s ease-in-out;
  }

  pre, code, .mono, .name {
    font-family: "Ubuntu Mono", "Cousine", "DejaVu Sans Mono", monospace;
  }

  .title .name {
    font-weight: bold;
  }
  .section-title {
    margin-top: 2em;
  }
  .ident {
    color: #900;
  }

  code {
    background: #f9f9f9;
  } 

  pre {
    background: #fefefe;
    border: 1px solid #ddd;
    box-shadow: 2px 2px 0 #f3f3f3;
    margin: 0 30px;
    padding: 15px 30px;
  }

  .codehilite {
    margin: 0 30px 10px 30px;
  }

    .codehilite pre {
      margin: 0;
    }
    .codehilite .err { background: #ff3300; color: #fff !important; } 

  table#module-list {
    font-size: 110%;
  }

    table#module-list tr td:first-child {
      padding-right: 10px;
      white-space: nowrap;
    }

    table#module-list td {
      vertical-align: top;
      padding-bottom: 8px;
    }

      table#module-list td p {
        margin: 0 0 7px 0;
      }

  .def {
    display: table;
  }

    .def p {
      display: table-cell;
      vertical-align: top;
      text-align: left;
    }

    .def p:first-child {
      white-space: nowrap;
    }

    .def p:last-child {
      width: 100%;
    }


  #index {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }
    ul#index .class_name {
      /* font-size: 110%; */
      font-weight: bold;
    }
    #index ul {
      margin: 0;
    }

  .item {
    margin: 0 0 15px 0;
  }

    .item .class {
      margin: 0 0 25px 30px;
    }

      .item .class ul.class_list {
        margin: 0 0 20px 0;
      }

    .item .name {
      background: #fafafa;
      margin: 0;
      font-weight: bold;
      padding: 5px 10px;
      border-radius: 3px;
      display: inline-block;
      min-width: 40%;
    }
      .item .name:hover {
        background: #f6f6f6;
      }

    .item .empty_desc {
      margin: 0 0 5px 0;
      padding: 0;
    }

    .item .inheritance {
      margin: 3px 0 0 30px;
    }

    .item .inherited {
      color: #666;
    }

    .item .desc {
      padding: 0 8px;
      margin: 0;
    }

      .item .desc p {
        margin: 0 0 10px 0;
      }

    .source_cont {
      margin: 0;
      padding: 0;
    }

    .source_link a {
      background: #ffc300;
      font-weight: 400;
      font-size: .75em;
      text-transform: uppercase;
      color: #fff;
      text-shadow: 1px 1px 0 #f4b700;
      
      padding: 3px 8px;
      border-radius: 2px;
      transition: background .3s ease-in-out;
    }
      .source_link a:hover {
        background: #FF7200;
        text-shadow: none;
        transition: background .3s ease-in-out;
      }

    .source {
      display: none;
      max-height: 600px;
      overflow-y: scroll;
      margin-bottom: 15px;
    }

      .source .codehilite {
        margin: 0;
      }

  .desc h1, .desc h2, .desc h3 {
    font-size: 100% !important;
  }
  .clear {
    clear: both;
  }

  @media all and (max-width: 950px) {
    #sidebar {
      width: 35%;
    }
    #content {
      width: 65%;
    }
  }
  @media all and (max-width: 650px) {
    #top {
      display: none;
    }
    #sidebar {
      float: none;
      width: auto;
    }
    #content {
      float: none;
      width: auto;
      padding: 30px;
    }

    #index ul {
      padding: 0;
      margin-bottom: 15px;
    }
    #index ul li {
      display: inline-block;
      margin-right: 30px;
    }
    #footer {
      text-align: left;
    }
    #footer p {
      display: block;
      margin: inherit;
    }
  }

  /*****************************/

  </style>

  <style type="text/css">
  .codehilite .hll { background-color: #ffffcc }
.codehilite  { background: #f8f8f8; }
.codehilite .c { color: #408080; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #FF0000 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666666 } /* Operator */
.codehilite .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.codehilite .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #BC7A00 } /* Comment.Preproc */
.codehilite .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.codehilite .c1 { color: #408080; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #408080; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .gr { color: #FF0000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #00A000 } /* Generic.Inserted */
.codehilite .go { color: #888888 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #0044DD } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #7D9029 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.codehilite .no { color: #880000 } /* Name.Constant */
.codehilite .nd { color: #AA22FF } /* Name.Decorator */
.codehilite .ni { color: #999999; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #0000FF } /* Name.Function */
.codehilite .nl { color: #A0A000 } /* Name.Label */
.codehilite .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #bbbbbb } /* Text.Whitespace */
.codehilite .mb { color: #666666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666666 } /* Literal.Number.Float */
.codehilite .mh { color: #666666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666666 } /* Literal.Number.Oct */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #BB6688 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .il { color: #666666 } /* Literal.Number.Integer.Long */
  </style>

  <style type="text/css">
  
/* ==========================================================================
   EXAMPLE Media Queries for Responsive Design.
   These examples override the primary ('mobile first') styles.
   Modify as content requires.
   ========================================================================== */

@media only screen and (min-width: 35em) {
    /* Style adjustments for viewports that meet the condition */
}

@media print,
       (-o-min-device-pixel-ratio: 5/4),
       (-webkit-min-device-pixel-ratio: 1.25),
       (min-resolution: 120dpi) {
    /* Style adjustments for high resolution devices */
}

/* ==========================================================================
   Print styles.
   Inlined to avoid required HTTP connection: h5bp.com/r
   ========================================================================== */

@media print {
    * {
        background: transparent !important;
        color: #000 !important; /* Black prints faster: h5bp.com/s */
        box-shadow: none !important;
        text-shadow: none !important;
    }

    a,
    a:visited {
        text-decoration: underline;
    }

    a[href]:after {
        content: " (" attr(href) ")";
    }

    abbr[title]:after {
        content: " (" attr(title) ")";
    }

    /*
     * Don't show links for images, or javascript/internal links
     */

    .ir a:after,
    a[href^="javascript:"]:after,
    a[href^="#"]:after {
        content: "";
    }

    pre,
    blockquote {
        border: 1px solid #999;
        page-break-inside: avoid;
    }

    thead {
        display: table-header-group; /* h5bp.com/t */
    }

    tr,
    img {
        page-break-inside: avoid;
    }

    img {
        max-width: 100% !important;
    }

    @page {
        margin: 0.5cm;
    }

    p,
    h2,
    h3 {
        orphans: 3;
        widows: 3;
    }

    h2,
    h3 {
        page-break-after: avoid;
    }
}

  </style>

  <script type="text/javascript">
  function toggle(id, $link) {
    $node = document.getElementById(id);
    if (!$node)
    return;
    if (!$node.style.display || $node.style.display == 'none') {
    $node.style.display = 'block';
    $link.innerHTML = 'Hide source &nequiv;';
    } else {
    $node.style.display = 'none';
    $link.innerHTML = 'Show source &equiv;';
    }
  }
  </script>
</head>
<body>
<a href="#" id="top">Top</a>

<div id="container">
    
  
  <div id="sidebar">
    <h1>Index</h1>
    <ul id="index">
    <li class="set"><h3><a href="#header-variables">Module variables</a></h3>
      
  <ul>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.blacklist">blacklist</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.explanation">explanation</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.funs">funs</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.name">name</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.whitelist">whitelist</a></li>
  </ul>

    </li>

    <li class="set"><h3><a href="#header-functions">Functions</a></h3>
      
  <ul>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.linear_conv2d_layer">linear_conv2d_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.linear_layer">linear_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.polynomial_layer">polynomial_layer</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.register_conv_layer_functions">register_conv_layer_functions</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.register_layer_functions">register_layer_functions</a></li>
  </ul>

    </li>

    <li class="set"><h3><a href="#header-classes">Classes</a></h3>
      <ul>
        <li class="mono">
        <span class="class_name"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder">LayerBuilder</a></span>
        
          
  <ul>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.__init__">__init__</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Context">Context</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.DoRegisterMethod">DoRegisterMethod</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Make">Make</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.NMake">NMake</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.NPipe">NPipe</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.NRun">NRun</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Pipe">Pipe</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Register0">Register0</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Register1">Register1</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Register2">Register2</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Register3">Register3</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Register4">Register4</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Register5">Register5</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction0">RegisterFunction0</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction1">RegisterFunction1</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction2">RegisterFunction2</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction3">RegisterFunction3</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction4">RegisterFunction4</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction5">RegisterFunction5</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.RegisterMethod">RegisterMethod</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Run">Run</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Then">Then</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Then0">Then0</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Then1">Then1</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Then2">Then2</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Then3">Then3</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Then4">Then4</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Then5">Then5</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.ThenAt">ThenAt</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.Val">Val</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.With">With</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.apply_regularization">apply_regularization</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.assert_summary_tag_unique">assert_summary_tag_unique</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.avg_pool2d">avg_pool2d</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.batch_norm">batch_norm</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.bias_add">bias_add</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.binary_svm_target">binary_svm_target</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.bucketize">bucketize</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.bucketized_column">bucketized_column</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.check_feature_columns">check_feature_columns</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.convolution2d">convolution2d</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.convolution2d_in_plane">convolution2d_in_plane</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.convolution2d_transpose">convolution2d_transpose</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.create_feature_spec_for_parsing">create_feature_spec_for_parsing</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.crossed_column">crossed_column</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.dropout">dropout</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.embedding_column">embedding_column</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.flatten">flatten</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.fully_connected">fully_connected</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.get_default_binary_metrics_for_eval">get_default_binary_metrics_for_eval</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.hashed_embedding_column">hashed_embedding_column</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.hashed_embedding_lookup">hashed_embedding_lookup</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.hashed_embedding_lookup_sparse">hashed_embedding_lookup_sparse</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.infer_real_valued_columns">infer_real_valued_columns</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.input_from_feature_columns">input_from_feature_columns</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.is_summary_tag_unique">is_summary_tag_unique</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.joint_weighted_sum_from_feature_columns">joint_weighted_sum_from_feature_columns</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.l1_l2_regularizer">l1_l2_regularizer</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.l1_regularizer">l1_regularizer</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.l2_regularizer">l2_regularizer</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.layer_norm">layer_norm</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.legacy_fully_connected">legacy_fully_connected</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.make_all">make_all</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.make_place_holder_tensors_for_base_features">make_place_holder_tensors_for_base_features</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.max_pool2d">max_pool2d</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.multi_class_target">multi_class_target</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.one_hot_column">one_hot_column</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.one_hot_encoding">one_hot_encoding</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.optimize_loss">optimize_loss</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.parse_feature_columns_from_examples">parse_feature_columns_from_examples</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.real_valued_column">real_valued_column</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.regression_target">regression_target</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.repeat">repeat</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.safe_embedding_lookup_sparse">safe_embedding_lookup_sparse</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.separable_convolution2d">separable_convolution2d</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.shared_embedding_columns">shared_embedding_columns</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.softmax">softmax</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.sparse_column_with_hash_bucket">sparse_column_with_hash_bucket</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.sparse_column_with_integerized_feature">sparse_column_with_integerized_feature</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.sparse_column_with_keys">sparse_column_with_keys</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.sparse_feature_cross">sparse_feature_cross</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.stack">stack</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.sum_regularizer">sum_regularizer</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.summarize_activation">summarize_activation</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.summarize_activations">summarize_activations</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.summarize_collection">summarize_collection</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.summarize_tensor">summarize_tensor</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.summarize_tensors">summarize_tensors</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.unit_norm">unit_norm</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.variance_scaling_initializer">variance_scaling_initializer</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.weighted_sparse_column">weighted_sparse_column</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.weighted_sum_from_feature_columns">weighted_sum_from_feature_columns</a></li>
    <li class="mono"><a href="#tensorbuilder.patches.layers_patch.LayerBuilder.xavier_initializer">xavier_initializer</a></li>
  </ul>

        </li>
      </ul>
    </li>

    </ul>
  </div>

    <article id="content">
      
  

  


  <header id="section-intro">
  <h1 class="title"><span class="name">tensorbuilder.patches.layers_patch</span> module</h1>
  
  
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch" class="source">
    <div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">functools</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib</span> <span class="kn">import</span> <span class="n">layers</span>
<span class="kn">from</span> <span class="nn">tensorflow.contrib.layers</span> <span class="kn">import</span> <span class="n">fully_connected</span><span class="p">,</span> <span class="n">convolution2d</span>
<span class="kn">from</span> <span class="nn">tensorbuilder</span> <span class="kn">import</span> <span class="n">TensorBuilder</span>
<span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">utils</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">patch</span>
<span class="kn">from</span> <span class="nn">phi.builder</span> <span class="kn">import</span> <span class="n">Builder</span>


<span class="k">class</span> <span class="nc">LayerBuilder</span><span class="p">(</span><span class="n">Builder</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;docstring for LayerBuilder.&quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">TensorBuilder</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">TensorBuilder</span><span class="p">()</span><span class="o">.</span><span class="n">_unit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_refs</span><span class="p">)</span>

<span class="c1">#Add property to TensorBuilder</span>
<span class="n">TensorBuilder</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="nb">property</span><span class="p">(</span><span class="k">lambda</span> <span class="bp">self</span><span class="p">:</span> <span class="n">LayerBuilder</span><span class="p">()</span><span class="o">.</span><span class="n">_unit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_refs</span><span class="p">))</span>

<span class="c1"># patch all layer functions</span>
<span class="n">patch</span><span class="o">.</span><span class="n">builder_with_members_from_1</span><span class="p">(</span><span class="n">LayerBuilder</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">module_alias</span><span class="o">=</span><span class="s2">&quot;tf.contrib.layers&quot;</span><span class="p">)</span> <span class="c1">#, _return_type=TensorBuilder)</span>

<span class="c1"># fully conneted layers</span>
<span class="n">blacklist</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">[</span><span class="s2">&quot;relu_layer&quot;</span><span class="p">]</span> <span class="o">+</span>
    <span class="n">TensorBuilder</span><span class="o">.</span><span class="n">__core__</span>
<span class="p">)</span>

<span class="n">funs</span> <span class="o">=</span> <span class="p">(</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span> <span class="ow">in</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getmembers</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="p">,</span> <span class="n">inspect</span><span class="o">.</span><span class="n">isfunction</span><span class="p">)</span> <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">blacklist</span> <span class="p">)</span>

<span class="k">def</span> <span class="nf">register_layer_functions</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
    <span class="n">explanation</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;and the keyword argument `activation_fn` is set to `tf.nn.{0}`.&quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

    <span class="nd">@TensorBuilder.Register1</span><span class="p">(</span><span class="s2">&quot;tf.contrib.layers&quot;</span><span class="p">,</span> <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_layer&quot;</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">fully_connected</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">)</span> <span class="c1">#, _return_type=TensorBuilder)</span>
    <span class="k">def</span> <span class="nf">layer_function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;activation_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span>
        <span class="k">return</span> <span class="n">fully_connected</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">register_conv_layer_functions</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
    <span class="n">explanation</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;and the keyword argument `activation_fn` is set to `tf.nn.{0}`.&quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

    <span class="nd">@TensorBuilder.Register1</span><span class="p">(</span><span class="s2">&quot;tf.contrib.layers&quot;</span><span class="p">,</span> <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_conv2d_layer&quot;</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">convolution2d</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">)</span> <span class="c1">#, _return_type=TensorBuilder)</span>
    <span class="k">def</span> <span class="nf">layer_function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;activation_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span>
        <span class="k">return</span> <span class="n">convolution2d</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">funs</span><span class="p">:</span>
    <span class="n">register_layer_functions</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
    <span class="n">register_conv_layer_functions</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>



<span class="c1">#linear_layer</span>
<span class="n">explanation</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;and the keyword argument `activation_fn` is set to `None`.&quot;&quot;&quot;</span>

<span class="nd">@TensorBuilder.Register1</span><span class="p">(</span><span class="s2">&quot;tf.contrib.layers&quot;</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="s2">&quot;linear_layer&quot;</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">fully_connected</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">)</span> <span class="c1">#, _return_type=TensorBuilder)</span>
<span class="k">def</span> <span class="nf">linear_layer</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;activation_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="nd">@TensorBuilder.Register1</span><span class="p">(</span><span class="s2">&quot;tf.contrib.layers&quot;</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="s2">&quot;linear_conv2d_layer&quot;</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">convolution2d</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">)</span> <span class="c1">#, _return_type=TensorBuilder)</span>
<span class="k">def</span> <span class="nf">linear_conv2d_layer</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;activation_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_polynomial</span><span class="p">(</span><span class="n">tensor</span><span class="p">):</span>
    <span class="n">size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">tensor</span><span class="o">.</span><span class="n">get_shape</span><span class="p">()[</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">pows</span> <span class="o">=</span> <span class="p">[</span> <span class="n">tf</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">tensor</span><span class="p">[:,</span> <span class="n">n</span><span class="p">],</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">)</span> <span class="p">]</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">pack</span><span class="p">(</span><span class="n">pows</span><span class="p">))</span>

<span class="n">explanation</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">However, it uses an activation function of the form</span>
<span class="s2">```</span>
<span class="s2">y(i) = z(i)^(i+1)</span>
<span class="s2">```</span>
<span class="s2">where `z = w*x + b`</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="nd">@TensorBuilder.Register1</span><span class="p">(</span><span class="s2">&quot;tb&quot;</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="s2">&quot;polynomial_layer&quot;</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">fully_connected</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">)</span> <span class="c1">#, _return_type=TensorBuilder)</span>
<span class="k">def</span> <span class="nf">polynomial_layer</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;activation_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_polynomial</span>
    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<span class="n">whitelist</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;convolution2d&quot;</span><span class="p">,</span> <span class="s2">&quot;max_pool2d&quot;</span><span class="p">,</span> <span class="s2">&quot;avg_pool2d&quot;</span><span class="p">,</span> <span class="s2">&quot;flatten&quot;</span><span class="p">]</span>
<span class="n">patch</span><span class="o">.</span><span class="n">builder_with_members_from_1</span><span class="p">(</span><span class="n">TensorBuilder</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">module_alias</span><span class="o">=</span><span class="s2">&quot;tf.contrib.layers&quot;</span><span class="p">,</span> <span class="n">whitelist</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">whitelist</span><span class="p">)</span> <span class="c1">#, _return_type=TensorBuilder)</span>
</pre></div>

  </div>

  </header>

  <section id="section-items">
    <h2 class="section-title" id="header-variables">Module variables</h2>
      <div class="item">
      <p id="tensorbuilder.patches.layers_patch.blacklist" class="name">var <span class="ident">blacklist</span></p>
      
  
  <div class="source_cont">
</div>

      </div>
      <div class="item">
      <p id="tensorbuilder.patches.layers_patch.explanation" class="name">var <span class="ident">explanation</span></p>
      
  
  <div class="source_cont">
</div>

      </div>
      <div class="item">
      <p id="tensorbuilder.patches.layers_patch.funs" class="name">var <span class="ident">funs</span></p>
      
  
  <div class="source_cont">
</div>

      </div>
      <div class="item">
      <p id="tensorbuilder.patches.layers_patch.name" class="name">var <span class="ident">name</span></p>
      
  
  <div class="source_cont">
</div>

      </div>
      <div class="item">
      <p id="tensorbuilder.patches.layers_patch.whitelist" class="name">var <span class="ident">whitelist</span></p>
      
  
  <div class="source_cont">
</div>

      </div>

    <h2 class="section-title" id="header-functions">Functions</h2>
      
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.linear_conv2d_layer">
    <p>def <span class="ident">linear_conv2d_layer</span>(</p><p>*args, **kwargs)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.linear_conv2d_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.linear_conv2d_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@TensorBuilder.Register1</span><span class="p">(</span><span class="s2">&quot;tf.contrib.layers&quot;</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="s2">&quot;linear_conv2d_layer&quot;</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">convolution2d</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">)</span> <span class="c1">#, _return_type=TensorBuilder)</span>
<span class="k">def</span> <span class="nf">linear_conv2d_layer</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;activation_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.linear_layer">
    <p>def <span class="ident">linear_layer</span>(</p><p>*args, **kwargs)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.linear_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.linear_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@TensorBuilder.Register1</span><span class="p">(</span><span class="s2">&quot;tf.contrib.layers&quot;</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="s2">&quot;linear_layer&quot;</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">fully_connected</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">)</span> <span class="c1">#, _return_type=TensorBuilder)</span>
<span class="k">def</span> <span class="nf">linear_layer</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;activation_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.polynomial_layer">
    <p>def <span class="ident">polynomial_layer</span>(</p><p>*args, **kwargs)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.polynomial_layer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.polynomial_layer" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@TensorBuilder.Register1</span><span class="p">(</span><span class="s2">&quot;tb&quot;</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="s2">&quot;polynomial_layer&quot;</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">fully_connected</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">)</span> <span class="c1">#, _return_type=TensorBuilder)</span>
<span class="k">def</span> <span class="nf">polynomial_layer</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;activation_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_polynomial</span>
    <span class="k">return</span> <span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.register_conv_layer_functions">
    <p>def <span class="ident">register_conv_layer_functions</span>(</p><p>name, f)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.register_conv_layer_functions', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.register_conv_layer_functions" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_conv_layer_functions</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
    <span class="n">explanation</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;and the keyword argument `activation_fn` is set to `tf.nn.{0}`.&quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

    <span class="nd">@TensorBuilder.Register1</span><span class="p">(</span><span class="s2">&quot;tf.contrib.layers&quot;</span><span class="p">,</span> <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_conv2d_layer&quot;</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">convolution2d</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">)</span> <span class="c1">#, _return_type=TensorBuilder)</span>
    <span class="k">def</span> <span class="nf">layer_function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;activation_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span>
        <span class="k">return</span> <span class="n">convolution2d</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.register_layer_functions">
    <p>def <span class="ident">register_layer_functions</span>(</p><p>name, f)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.register_layer_functions', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.register_layer_functions" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">register_layer_functions</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
    <span class="n">explanation</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;and the keyword argument `activation_fn` is set to `tf.nn.{0}`.&quot;&quot;&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

    <span class="nd">@TensorBuilder.Register1</span><span class="p">(</span><span class="s2">&quot;tf.contrib.layers&quot;</span><span class="p">,</span> <span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;_layer&quot;</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">fully_connected</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">)</span> <span class="c1">#, _return_type=TensorBuilder)</span>
    <span class="k">def</span> <span class="nf">layer_function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;activation_fn&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">f</span>
        <span class="k">return</span> <span class="n">fully_connected</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  

    <h2 class="section-title" id="header-classes">Classes</h2>
      
      <div class="item">
      <p id="tensorbuilder.patches.layers_patch.LayerBuilder" class="name">class <span class="ident">LayerBuilder</span></p>
      
  
    <div class="desc"><p>docstring for LayerBuilder.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder" class="source">
    <div class="codehilite"><pre><span></span><span class="k">class</span> <span class="nc">LayerBuilder</span><span class="p">(</span><span class="n">Builder</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;docstring for LayerBuilder.&quot;&quot;&quot;</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">TensorBuilder</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">TensorBuilder</span><span class="p">()</span><span class="o">.</span><span class="n">_unit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_refs</span><span class="p">)</span>
</pre></div>

  </div>
</div>


      <div class="class">
          <h3>Ancestors (in MRO)</h3>
          <ul class="class_list">
          <li><a href="#tensorbuilder.patches.layers_patch.LayerBuilder">LayerBuilder</a></li>
          <li>phi.builder.Builder</li>
          <li>phi.lambdas.Lambda</li>
          <li>phi.dsl.Function</li>
          <li>phi.dsl.Node</li>
          <li>__builtin__.object</li>
          </ul>
          <h3>Class variables</h3>
            <div class="item">
            <p id="tensorbuilder.patches.layers_patch.LayerBuilder.If" class="name">var <span class="ident">If</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="tensorbuilder.patches.layers_patch.LayerBuilder.Ref" class="name">var <span class="ident">Ref</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
          <h3>Instance variables</h3>
            <div class="item">
            <p id="tensorbuilder.patches.layers_patch.LayerBuilder.Obj" class="name">var <span class="ident">Obj</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="tensorbuilder.patches.layers_patch.LayerBuilder.Read" class="name">var <span class="ident">Read</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="tensorbuilder.patches.layers_patch.LayerBuilder.Rec" class="name">var <span class="ident">Rec</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="tensorbuilder.patches.layers_patch.LayerBuilder.TensorBuilder" class="name">var <span class="ident">TensorBuilder</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
            <div class="item">
            <p id="tensorbuilder.patches.layers_patch.LayerBuilder.Write" class="name">var <span class="ident">Write</span></p>
            

            
  
  <div class="source_cont">
</div>

            </div>
          <h3>Methods</h3>
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.__init__">
    <p>def <span class="ident">__init__</span>(</p><p>self, f)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.__init__', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.__init__" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Lambda</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_f</span> <span class="o">=</span> <span class="n">f</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Context">
    <p>def <span class="ident">Context</span>(</p><p>cls, *args)</p>
    </div>
    

    
  
    <div class="desc"><p><strong>Builder Core</strong>. Also available as a global function as <code>phi.Context</code>.</p>
<p>Returns the context object of the current <code>dsl.With</code> statemente.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><strong>*args</strong>: By design <code>Context</code> accepts any number of arguments and completely ignores them.</li>
</ul>
<p>This is a classmethod and it doesnt return a <code>Builder</code>/<code>Lambda</code> by design so it can be called directly:</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span><span class="p">,</span> <span class="n">Context</span><span class="p">,</span> <span class="n">Obj</span>

<span class="k">def</span> <span class="nf">read_file</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">Context</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

<span class="n">lines</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span>
    <span class="s2">&quot;text.txt&quot;</span><span class="p">,</span>
    <span class="n">P</span><span class="o">.</span><span class="n">With</span><span class="p">(</span> <span class="nb">open</span><span class="p">,</span>
        <span class="n">read_file</span><span class="p">,</span>
        <span class="n">Obj</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>


<p>Here we called <code>Context</code> with no arguments to get the context back, however, since you can also give this function an argument (which it will ignore) it can be passed to the DSL so we can rewrite the previous as:</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span><span class="p">,</span> <span class="n">Context</span><span class="p">,</span> <span class="n">Obj</span>

<span class="n">lines</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span>
    <span class="s2">&quot;text.txt&quot;</span><span class="p">,</span>
    <span class="n">P</span><span class="o">.</span><span class="n">With</span><span class="p">(</span> <span class="nb">open</span><span class="p">,</span>
        <span class="n">Context</span><span class="p">,</span> <span class="c1"># f</span>
        <span class="n">Obj</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">Obj</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>


<p><code>Context</code> yields an exception when used outside of a <code>With</code> block.</p>
<p><strong>Also see</strong></p>
<ul>
<li><code>phi.builder.Builder.Obj</code></li>
<li><a href="https://cgarciae.github.io/phi/dsl.m.html">dsl</a></li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Context', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Context" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">Context</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">ilder Core**. Also available as a global function as `phi.Context`.</span>
<span class="sd">rns the context object of the current `dsl.With` statemente.</span>
<span class="sd">guments**</span>
<span class="sd">*args**: By design `Context` accepts any number of arguments and completely ignores them.</span>
<span class="sd"> is a classmethod and it doesnt return a `Builder`/`Lambda` by design so it can be called directly:</span>
<span class="sd">from phi import P, Context, Obj</span>
<span class="sd">def read_file(z):</span>
<span class="sd">    f = Context()</span>
<span class="sd">    return f.read()</span>
<span class="sd">lines = P.Pipe(</span>
<span class="sd">    &quot;text.txt&quot;,</span>
<span class="sd">    P.With( open,</span>
<span class="sd">        read_file,</span>
<span class="sd">        Obj.split(&quot;\\n&quot;)</span>
<span class="sd">    )</span>
<span class="sd">)</span>
<span class="sd"> we called `Context` with no arguments to get the context back, however, since you can also give this function an argument (which it will ignore) it can be passed to the DSL so we can rewrite the previous as:</span>
<span class="sd">from phi import P, Context, Obj</span>
<span class="sd">lines = P.Pipe(</span>
<span class="sd">    &quot;text.txt&quot;,</span>
<span class="sd">    P.With( open,</span>
<span class="sd">        Context, # f</span>
<span class="sd">        Obj.read()</span>
<span class="sd">        Obj.split(&quot;\\n&quot;)</span>
<span class="sd">    )</span>
<span class="sd">)</span>
<span class="sd">text` yields an exception when used outside of a `With` block.</span>
<span class="sd">so see**</span>
<span class="sd">hi.builder.Builder.Obj`</span>
<span class="sd">sl](https://cgarciae.github.io/phi/dsl.m.html)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">dsl</span><span class="o">.</span><span class="n">With</span><span class="o">.</span><span class="n">GLOBAL_CONTEXT</span> <span class="ow">is</span> <span class="n">dsl</span><span class="o">.</span><span class="n">_NO_VALUE</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Cannot use &#39;Context&#39; outside of a &#39;With&#39; block&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dsl</span><span class="o">.</span><span class="n">With</span><span class="o">.</span><span class="n">GLOBAL_CONTEXT</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.DoRegisterMethod">
    <p>def <span class="ident">DoRegisterMethod</span>(</p><p>cls, fn, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True)</p>
    </div>
    

    
  
    <div class="desc"><p>This method enables you to register any function <code>fn</code> that takes an Applicative as its first argument as a method of the Builder class.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>fn</code>: a function that atleast takes an Applicative as its first argument.</li>
<li><code>library_path</code>: the route of the librar from which this function was taken, used for documentation purposes.</li>
<li><code>alias</code>: allows you to specify the name of the method, it will take the name of the function if its <code>None</code>.</li>
<li><code>doc</code>: the documentation for the method, if <code>None</code> a predefied documentation will be generated based on the documentation of <code>fn</code>.</li>
</ul>
<p><strong>Return</strong></p>
<p><code>None</code></p>
<p><strong>Examples</strong></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.DoRegisterMethod', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.DoRegisterMethod" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">DoRegisterMethod</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method enables you to register any function `fn` that takes an Applicative as its first argument as a method of the Builder class.</span>
<span class="sd">    **Arguments**</span>
<span class="sd">    * `fn`: a function that atleast takes an Applicative as its first argument.</span>
<span class="sd">    * `library_path`: the route of the librar from which this function was taken, used for documentation purposes.</span>
<span class="sd">    * `alias`: allows you to specify the name of the method, it will take the name of the function if its `None`.</span>
<span class="sd">    * `doc`: the documentation for the method, if `None` a predefied documentation will be generated based on the documentation of `fn`.</span>
<span class="sd">    **Return**</span>
<span class="sd">    `None`</span>
<span class="sd">    **Examples**</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">wrapped</span><span class="p">:</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="n">functools</span><span class="o">.</span><span class="n">wraps</span><span class="p">(</span><span class="n">wrapped</span><span class="p">)(</span><span class="n">fn</span><span class="p">)</span>
    <span class="n">fn_signature</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">get_method_sig</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
 	<span class="n">fn_docs</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">getdoc</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="n">name</span> <span class="o">=</span> <span class="n">alias</span> <span class="k">if</span> <span class="n">alias</span> <span class="k">else</span> <span class="n">fn</span><span class="o">.</span><span class="n">__name__</span>
    <span class="n">original_name</span> <span class="o">=</span> <span class="n">fn</span><span class="o">.</span><span class="n">__name__</span> <span class="k">if</span> <span class="n">wrapped</span> <span class="k">else</span> <span class="n">original_name</span> <span class="k">if</span> <span class="n">original_name</span> <span class="k">else</span> <span class="n">name</span>
    <span class="n">fn</span><span class="o">.</span><span class="n">__name__</span> <span class="o">=</span> <span class="n">name</span>
    <span class="n">fn</span><span class="o">.</span><span class="n">__doc__</span> <span class="o">=</span> <span class="n">doc</span> <span class="k">if</span> <span class="n">doc</span> <span class="k">else</span> <span class="p">(</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2"> METHOD IS AUTOMATICALLY GENERATED</span>
<span class="s2">builder.{1}(*args, **kwargs)</span>
<span class="s2">ccepts the same arguments as `{3}.{0}`. &quot;&quot;&quot;</span> <span class="o">+</span> <span class="n">explanation</span> <span class="o">+</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">}.{0}**</span>
<span class="s2">{2}</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">original_name</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">fn_docs</span><span class="p">,</span> <span class="n">library_path</span><span class="p">)</span> <span class="k">if</span> <span class="n">explain</span> <span class="k">else</span> <span class="n">fn_docs</span>
    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">cls</span><span class="o">.</span><span class="n">__core__</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Can&#39;t add method &#39;{0}&#39; because its on __core__&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">))</span>
    <span class="n">fn</span> <span class="o">=</span> <span class="n">method_type</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="nb">setattr</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">fn</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Make">
    <p>def <span class="ident">Make</span>(</p><p>self, *code, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>The <code>Make</code> method takes an expression from the DSL and compiles it to a function.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><strong>*code</strong>: any expression from the DSL.<code>code</code> is implicitly a <code>tuple</code> since that is what Python gives you when you declare a <a href="https://docs.python.org/3/tutorial/controlflow.html#arbitrary-argument-lists">Variadic Function</a>, therefore, according to the rules of the DSL, all expressions inside of <code>code</code> will be composed together. See <a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Composition">Composition</a>.</li>
<li><em>flatten = False</em>: if <code>flatten</code> is True and the argument being returned by the compiled function is a <code>list</code> it will instead return a flattened list.</li>
<li><em>_return_type = None</em>: By default <code>Make</code> returns an object of the same class e.g. <code>Builder</code>, however you can pass in a custom class that inherits from <code>Builder</code> as the returned contianer. This is useful if the custom builder has specialized methods.</li>
<li><em>create_ref_context = True</em>: determines if a reference manager should be created on compilation. See <a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile">Compile</a>.</li>
<li><em>refs = True</em>: external/default values for references passed during compilation. See <a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile">Compile</a>.</li>
</ul>
<p><strong>Examples</strong></p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span>

<span class="k">def</span> <span class="nf">add1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
<span class="k">def</span> <span class="nf">mul3</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">3</span>

<span class="n">f</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Make</span><span class="p">(</span>
    <span class="n">add1</span><span class="p">,</span>
    <span class="n">mul3</span>
<span class="p">)</span>

<span class="k">assert</span> <span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">6</span>
</pre></div>


<p>Here <code>f</code> is equivalent to</p>
<p>def f(x):
    x = add1(x)
    x = mul3(x)
    return x</p>
<p>The previous example using <a href="https://cgarciae.github.io/phi/lambdas.m.html">lambdas</a> to create the functions</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span>

<span class="n">f</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Make</span><span class="p">(</span>
    <span class="n">P</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">P</span> <span class="o">*</span> <span class="mi">3</span>
<span class="p">)</span>

<span class="k">assert</span> <span class="n">f</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mi">6</span>
</pre></div>


<p><strong>Also see</strong></p>
<ul>
<li><a href="https://cgarciae.github.io/phi/dsl.m.html">dsl</a></li>
<li><a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile">Compile</a></li>
<li><a href="https://cgarciae.github.io/phi/lambdas.m.html">lambdas</a>
**</li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Make', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Make" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">Make</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">code</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">`Make` method takes an expression from the DSL and compiles it to a function.</span>
<span class="sd">guments**</span>
<span class="sd">*code**: any expression from the DSL.`code` is implicitly a `tuple` since that is what Python gives you when you declare a [Variadic Function](https://docs.python.org/3/tutorial/controlflow.html#arbitrary-argument-lists), therefore, according to the rules of the DSL, all expressions inside of `code` will be composed together. See [Composition](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Composition).</span>
<span class="sd">latten = False*: if `flatten` is True and the argument being returned by the compiled function is a `list` it will instead return a flattened list.</span>
<span class="sd">return_type = None*: By default `Make` returns an object of the same class e.g. `Builder`, however you can pass in a custom class that inherits from `Builder` as the returned contianer. This is useful if the custom builder has specialized methods.</span>
<span class="sd">reate_ref_context = True*: determines if a reference manager should be created on compilation. See [Compile](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile).</span>
<span class="sd">efs = True*: external/default values for references passed during compilation. See [Compile](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile).</span>
<span class="sd">amples**</span>
<span class="sd">from phi import P</span>
<span class="sd">def add1(x): return x + 1</span>
<span class="sd">def mul3(x): return x * 3</span>
<span class="sd">f = P.Make(</span>
<span class="sd">    add1,</span>
<span class="sd">    mul3</span>
<span class="sd">)</span>
<span class="sd">assert f(1) == 6</span>
<span class="sd"> `f` is equivalent to</span>
<span class="sd">f(x):</span>
<span class="sd">x = add1(x)</span>
<span class="sd">x = mul3(x)</span>
<span class="sd">return x</span>
<span class="sd">previous example using [lambdas](https://cgarciae.github.io/phi/lambdas.m.html) to create the functions</span>
<span class="sd">from phi import P</span>
<span class="sd">f = P.Make(</span>
<span class="sd">    P + 1,</span>
<span class="sd">    P * 3</span>
<span class="sd">)</span>
<span class="sd">assert f(1) == 6</span>
<span class="sd">so see**</span>
<span class="sd">sl](https://cgarciae.github.io/phi/dsl.m.html)</span>
<span class="sd">ompile](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile)</span>
<span class="sd">ambdas](https://cgarciae.github.io/phi/lambdas.m.html)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_return_type</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;_return_type&#39;</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>
    <span class="n">flatten</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;flatten&#39;</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>
    <span class="n">refs</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;refs&#39;</span><span class="p">,</span> <span class="p">{})</span>
    <span class="n">create_ref_context</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;create_ref_context&#39;</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
    <span class="c1"># code = (self, code)</span>
    <span class="k">if</span> <span class="n">flatten</span><span class="p">:</span>
        <span class="n">code</span> <span class="o">=</span> <span class="p">(</span><span class="n">code</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">utils</span><span class="o">.</span><span class="n">flatten_list</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="ow">is</span> <span class="nb">list</span> <span class="k">else</span> <span class="n">x</span><span class="p">)</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">dsl</span><span class="o">.</span><span class="n">Compile</span><span class="p">(</span><span class="n">code</span><span class="p">,</span> <span class="n">refs</span><span class="p">,</span> <span class="n">create_ref_context</span><span class="o">=</span><span class="n">create_ref_context</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__then__</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="n">_return_type</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.NMake">
    <p>def <span class="ident">NMake</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p><code>NMake</code> is shortcut for <code>Make(..., create_ref_context=False)</code>, its full name should be <em>NoCreateRefContextMake</em> but its impractically long. Normally methods that <a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile">compile</a> DSL expressions like <code>phi.builder.Builder.Make</code> or <code>phi.builder.Builder.Pipe</code> create a reference context unless especified, these contexts encapsulate references (see <a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Read">read</a> or <a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Write">write</a>) and prevent them from leaking, which is good. There are times however when you consciously want a sub-Make or sub-Pipe expression to read or write references from the main Make or Pipe expression, for this you need to set <code>create_ref_context</code> to <code>False</code>.</p>
<p><strong>Arguments</strong></p>
<ul>
<li>Same arguments as <code>phi.builder.Builder.Make</code> but...</li>
<li><strong>create_ref_context</strong> is hardcoded to <code>False</code></li>
</ul>
<p><strong>Examples</strong></p>
<p>If you compile a sub expression as a function for another expression e.g.</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span>

<span class="k">assert</span> <span class="mi">1</span> <span class="o">==</span> <span class="n">P</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span>
    <span class="mi">1</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;s&#39;</span><span class="p">},</span> <span class="c1"># write s == 1, outer context</span>
    <span class="n">P</span><span class="o">.</span><span class="n">Make</span><span class="p">(</span>
        <span class="n">P</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;s&#39;</span><span class="p">}</span> <span class="c1"># write s == 2, inner context</span>
    <span class="p">),</span>
    <span class="s1">&#39;s&#39;</span>  <span class="c1"># read s == 1, outer context</span>
<span class="p">)</span>
</pre></div>


<p>you find that references are not shared. However if you avoid the creation of a new reference context via a keyword arguments</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span>

<span class="k">assert</span> <span class="mi">2</span> <span class="o">==</span> <span class="n">P</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span>
    <span class="mi">1</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;s&#39;</span><span class="p">},</span>   <span class="c1">#write s == 1, same context</span>
    <span class="n">P</span><span class="o">.</span><span class="n">Make</span><span class="p">(</span>
        <span class="n">P</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;s&#39;</span><span class="p">},</span>   <span class="c1">#write s == 2, same context</span>
        <span class="n">create_ref_context</span><span class="o">=</span><span class="bp">False</span>
    <span class="p">),</span>
    <span class="s1">&#39;s&#39;</span>   <span class="c1"># read s == 2, same context</span>
<span class="p">)</span>
</pre></div>


<p>you can achieve what you want. Yet writting <code>create_ref_context=False</code> is a little cumbersome, so to make things nicer we just use a shortcut by appending an <code>N</code> at the beggining of the <code>NMake</code> method</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span>

<span class="k">assert</span> <span class="mi">2</span> <span class="o">==</span> <span class="n">P</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span>
    <span class="mi">1</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;s&#39;</span><span class="p">},</span>   <span class="c1">#write s == 1, same context</span>
    <span class="n">P</span><span class="o">.</span><span class="n">NMake</span><span class="p">(</span>
        <span class="n">P</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;s&#39;</span><span class="p">}</span>   <span class="c1">#write s == 2, same context</span>
    <span class="p">),</span>
    <span class="s1">&#39;s&#39;</span>   <span class="c1"># read s == 2, same context</span>
<span class="p">)</span>
</pre></div>


<p><strong>Also see</strong></p>
<ul>
<li><code>phi.builder.Builder.Make</code></li>
<li><code>phi.builder.Builder.NPipe</code></li>
<li><code>phi.builder.Builder.NRun</code></li>
<li><a href="https://cgarciae.github.io/phi/dsl.m.html">dsl</a></li>
<li><a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile">Compile</a></li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.NMake', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.NMake" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">NMake</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">ke` is shortcut for `Make(..., create_ref_context=False)`, its full name should be *NoCreateRefContextMake* but its impractically long. Normally methods that [compile](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile) DSL expressions like `phi.builder.Builder.Make` or `phi.builder.Builder.Pipe` create a reference context unless especified, these contexts encapsulate references (see [read](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Read) or [write](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Write)) and prevent them from leaking, which is good. There are times however when you consciously want a sub-Make or sub-Pipe expression to read or write references from the main Make or Pipe expression, for this you need to set `create_ref_context` to `False`.</span>
<span class="sd">guments**</span>
<span class="sd">me arguments as `phi.builder.Builder.Make` but...</span>
<span class="sd">create_ref_context** is hardcoded to `False`</span>
<span class="sd">amples**</span>
<span class="sd">ou compile a sub expression as a function for another expression e.g.</span>
<span class="sd">from phi import P</span>
<span class="sd">assert 1 == P.Pipe(</span>
<span class="sd">    1, {&#39;s&#39;}, # write s == 1, outer context</span>
<span class="sd">    P.Make(</span>
<span class="sd">        P + 1, {&#39;s&#39;} # write s == 2, inner context</span>
<span class="sd">    ),</span>
<span class="sd">    &#39;s&#39;  # read s == 1, outer context</span>
<span class="sd">)</span>
<span class="sd">find that references are not shared. However if you avoid the creation of a new reference context via a keyword arguments</span>
<span class="sd">from phi import P</span>
<span class="sd">assert 2 == P.Pipe(</span>
<span class="sd">    1, {&#39;s&#39;},   #write s == 1, same context</span>
<span class="sd">    P.Make(</span>
<span class="sd">        P + 1, {&#39;s&#39;},   #write s == 2, same context</span>
<span class="sd">        create_ref_context=False</span>
<span class="sd">    ),</span>
<span class="sd">    &#39;s&#39;   # read s == 2, same context</span>
<span class="sd">)</span>
<span class="sd">can achieve what you want. Yet writting `create_ref_context=False` is a little cumbersome, so to make things nicer we just use a shortcut by appending an `N` at the beggining of the `NMake` method</span>
<span class="sd">from phi import P</span>
<span class="sd">assert 2 == P.Pipe(</span>
<span class="sd">    1, {&#39;s&#39;},   #write s == 1, same context</span>
<span class="sd">    P.NMake(</span>
<span class="sd">        P + 1, {&#39;s&#39;}   #write s == 2, same context</span>
<span class="sd">    ),</span>
<span class="sd">    &#39;s&#39;   # read s == 2, same context</span>
<span class="sd">)</span>
<span class="sd">so see**</span>
<span class="sd">hi.builder.Builder.Make`</span>
<span class="sd">hi.builder.Builder.NPipe`</span>
<span class="sd">hi.builder.Builder.NRun`</span>
<span class="sd">sl](https://cgarciae.github.io/phi/dsl.m.html)</span>
<span class="sd">ompile](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;create_ref_context&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Make</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.NPipe">
    <p>def <span class="ident">NPipe</span>(</p><p>self, x, *code, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p><code>NPipe</code> is shortcut for <code>Pipe(..., create_ref_context=False)</code>, its full name should be <em>NoCreateRefContextPipe</em> but its impractically long. Normally methods that <a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile">compile</a> DSL expressions like <code>phi.builder.Builder.Make</code> or <code>phi.builder.Builder.Pipe</code> create a reference context unless especified, these contexts encapsulate references (see <a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Read">read</a> or <a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Write">write</a>) and prevent them from leaking, which is good. There are times however when you consciously want a sub-Make or sub-Pipe expression to read or write references from the main Make or Pipe expression, for this you need to set <code>create_ref_context</code> to <code>False</code>.</p>
<p><strong>Arguments</strong></p>
<ul>
<li>Same arguments as <code>phi.builder.Builder.Pipe</code> but...</li>
<li><strong>create_ref_context</strong> is hardcoded to <code>False</code></li>
</ul>
<p><strong>Examples</strong></p>
<p>If you compile a sub expression as a function for another expression e.g.</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span>

<span class="k">assert</span> <span class="mi">1</span> <span class="o">==</span> <span class="n">P</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span>
    <span class="mi">1</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;s&#39;</span><span class="p">},</span> <span class="c1"># write s == 1, outer context</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">P</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">P</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;s&#39;</span><span class="p">}</span> <span class="c1"># write s == 2, inner context</span>
    <span class="p">),</span>
    <span class="s1">&#39;s&#39;</span>  <span class="c1"># read s == 1, outer context</span>
<span class="p">)</span>
</pre></div>


<p>you find that references are not shared. However if you avoid the creation of a new reference context via a keyword arguments</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span>

<span class="k">assert</span> <span class="mi">2</span> <span class="o">==</span> <span class="n">P</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span>
    <span class="mi">1</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;s&#39;</span><span class="p">},</span>   <span class="c1">#write s == 1, same context</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">P</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">P</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;s&#39;</span><span class="p">},</span>   <span class="c1">#write s == 2, same context</span>
        <span class="n">create_ref_context</span><span class="o">=</span><span class="bp">False</span>
    <span class="p">),</span>
    <span class="s1">&#39;s&#39;</span>   <span class="c1"># read s == 2, same context</span>
<span class="p">)</span>
</pre></div>


<p>you can achieve what you want. Yet writting <code>create_ref_context=False</code> is a little cumbersome, so to make things nicer we just use a shortcut by appending an <code>N</code> at the beggining of the <code>NPipe</code> method</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span>

<span class="k">assert</span> <span class="mi">2</span> <span class="o">==</span> <span class="n">P</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span>
    <span class="mi">1</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;s&#39;</span><span class="p">},</span>   <span class="c1">#write s == 1, same context</span>
    <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">P</span><span class="o">.</span><span class="n">NPipe</span><span class="p">(</span>
        <span class="n">x</span><span class="p">,</span>
        <span class="n">P</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">{</span><span class="s1">&#39;s&#39;</span><span class="p">}</span>   <span class="c1">#write s == 2, same context</span>
    <span class="p">),</span>
    <span class="s1">&#39;s&#39;</span>   <span class="c1"># read s == 2, same context</span>
<span class="p">)</span>
</pre></div>


<p><strong>Also see</strong></p>
<ul>
<li><code>phi.builder.Builder.Pipe</code></li>
<li><code>phi.builder.Builder.NMake</code></li>
<li><code>phi.builder.Builder.NRun</code></li>
<li><a href="https://cgarciae.github.io/phi/dsl.m.html">dsl</a></li>
<li><a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile">Compile</a></li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.NPipe', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.NPipe" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">NPipe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">code</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">pe` is shortcut for `Pipe(..., create_ref_context=False)`, its full name should be *NoCreateRefContextPipe* but its impractically long. Normally methods that [compile](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile) DSL expressions like `phi.builder.Builder.Make` or `phi.builder.Builder.Pipe` create a reference context unless especified, these contexts encapsulate references (see [read](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Read) or [write](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Write)) and prevent them from leaking, which is good. There are times however when you consciously want a sub-Make or sub-Pipe expression to read or write references from the main Make or Pipe expression, for this you need to set `create_ref_context` to `False`.</span>
<span class="sd">guments**</span>
<span class="sd">me arguments as `phi.builder.Builder.Pipe` but...</span>
<span class="sd">create_ref_context** is hardcoded to `False`</span>
<span class="sd">amples**</span>
<span class="sd">ou compile a sub expression as a function for another expression e.g.</span>
<span class="sd">from phi import P</span>
<span class="sd">assert 1 == P.Pipe(</span>
<span class="sd">    1, {&#39;s&#39;}, # write s == 1, outer context</span>
<span class="sd">    lambda x: P.Pipe(</span>
<span class="sd">        x,</span>
<span class="sd">        P + 1, {&#39;s&#39;} # write s == 2, inner context</span>
<span class="sd">    ),</span>
<span class="sd">    &#39;s&#39;  # read s == 1, outer context</span>
<span class="sd">)</span>
<span class="sd">find that references are not shared. However if you avoid the creation of a new reference context via a keyword arguments</span>
<span class="sd">from phi import P</span>
<span class="sd">assert 2 == P.Pipe(</span>
<span class="sd">    1, {&#39;s&#39;},   #write s == 1, same context</span>
<span class="sd">    lambda x: P.Pipe(</span>
<span class="sd">        x,</span>
<span class="sd">        P + 1, {&#39;s&#39;},   #write s == 2, same context</span>
<span class="sd">        create_ref_context=False</span>
<span class="sd">    ),</span>
<span class="sd">    &#39;s&#39;   # read s == 2, same context</span>
<span class="sd">)</span>
<span class="sd">can achieve what you want. Yet writting `create_ref_context=False` is a little cumbersome, so to make things nicer we just use a shortcut by appending an `N` at the beggining of the `NPipe` method</span>
<span class="sd">from phi import P</span>
<span class="sd">assert 2 == P.Pipe(</span>
<span class="sd">    1, {&#39;s&#39;},   #write s == 1, same context</span>
<span class="sd">    lambda x: P.NPipe(</span>
<span class="sd">        x,</span>
<span class="sd">        P + 1, {&#39;s&#39;}   #write s == 2, same context</span>
<span class="sd">    ),</span>
<span class="sd">    &#39;s&#39;   # read s == 2, same context</span>
<span class="sd">)</span>
<span class="sd">so see**</span>
<span class="sd">hi.builder.Builder.Pipe`</span>
<span class="sd">hi.builder.Builder.NMake`</span>
<span class="sd">hi.builder.Builder.NRun`</span>
<span class="sd">sl](https://cgarciae.github.io/phi/dsl.m.html)</span>
<span class="sd">ompile](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">NMake</span><span class="p">(</span><span class="o">*</span><span class="n">code</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.NRun">
    <p>def <span class="ident">NRun</span>(</p><p>self, *code, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p><code>NRun</code> is shortcut for <code>Run(..., create_ref_context=False)</code>, its full name should be <em>NoCreateRefContextRun</em> but its impractically long.</p>
<p><strong>Also see</strong></p>
<ul>
<li><code>phi.builder.Builder.Run</code></li>
<li><code>phi.builder.Builder.NMake</code></li>
<li><code>phi.builder.Builder.NPipe</code></li>
<li><a href="https://cgarciae.github.io/phi/dsl.m.html">dsl</a></li>
<li><a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile">Compile</a></li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.NRun', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.NRun" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">NRun</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">code</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">n` is shortcut for `Run(..., create_ref_context=False)`, its full name should be *NoCreateRefContextRun* but its impractically long.</span>
<span class="sd">so see**</span>
<span class="sd">hi.builder.Builder.Run`</span>
<span class="sd">hi.builder.Builder.NMake`</span>
<span class="sd">hi.builder.Builder.NPipe`</span>
<span class="sd">sl](https://cgarciae.github.io/phi/dsl.m.html)</span>
<span class="sd">ompile](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">NPipe</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="o">*</span><span class="n">code</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Pipe">
    <p>def <span class="ident">Pipe</span>(</p><p>self, x, *code, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p><code>Pipe</code> is method that takes an input argument plus an expression from the DSL, it compiles the expression and applies the resulting function to the input. Its highly inspired by Elixir's <a href="https://hexdocs.pm/elixir/Kernel.html#%7C%3E/2">|&gt; (pipe)</a> operator.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><strong>x</strong>: any input object</li>
<li><strong>*code</strong>: any expression from the DSL.<code>code</code> is implicitly a <code>tuple</code> since that is what Python gives you when you declare a <a href="https://docs.python.org/3/tutorial/controlflow.html#arbitrary-argument-lists">Variadic Function</a>, therefore, according to the rules of the DSL, all expressions inside of <code>code</code> will be composed together. See <a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Composition">Composition</a>.</li>
<li><strong>**kwargs</strong>: <code>Pipe</code> forwards all <code>kwargs</code> to <code>phi.builder.Builder.Make</code>, visit its documentation for more info.</li>
</ul>
<p><strong>Examples</strong></p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span>

<span class="k">def</span> <span class="nf">add1</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">1</span>
<span class="k">def</span> <span class="nf">mul3</span><span class="p">(</span><span class="n">x</span><span class="p">):</span> <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">3</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span>
    <span class="mi">1</span><span class="p">,</span>     <span class="c1">#input</span>
    <span class="n">add1</span><span class="p">,</span>  <span class="c1">#1 + 1 == 2</span>
    <span class="n">mul3</span>   <span class="c1">#2 * 3 == 6</span>
<span class="p">)</span>

<span class="k">assert</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">6</span>
</pre></div>


<p>The previous using <a href="https://cgarciae.github.io/phi/lambdas.m.html">lambdas</a> to create the functions</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span>
    <span class="mi">1</span><span class="p">,</span>      <span class="c1">#input</span>
    <span class="n">P</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>  <span class="c1">#1 + 1 == 2</span>
    <span class="n">P</span> <span class="o">*</span> <span class="mi">3</span>   <span class="c1">#2 * 3 == 6</span>
<span class="p">)</span>

<span class="k">assert</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">6</span>
</pre></div>


<p><strong>Also see</strong></p>
<ul>
<li><code>phi.builder.Builder.Make</code></li>
<li><code>phi.builder.Builder.Run</code></li>
<li><a href="https://cgarciae.github.io/phi/dsl.m.html">dsl</a></li>
<li><a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile">Compile</a></li>
<li><a href="https://cgarciae.github.io/phi/lambdas.m.html">lambdas</a></li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Pipe', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Pipe" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">Pipe</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="n">code</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">e` is method that takes an input argument plus an expression from the DSL, it compiles the expression and applies the resulting function to the input. Its highly inspired by Elixir&#39;s [|&gt; (pipe)](https://hexdocs.pm/elixir/Kernel.html#%7C%3E/2) operator.</span>
<span class="sd">guments**</span>
<span class="sd">x**: any input object</span>
<span class="sd">*code**: any expression from the DSL.`code` is implicitly a `tuple` since that is what Python gives you when you declare a [Variadic Function](https://docs.python.org/3/tutorial/controlflow.html#arbitrary-argument-lists), therefore, according to the rules of the DSL, all expressions inside of `code` will be composed together. See [Composition](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Composition).</span>
<span class="sd">**kwargs**: `Pipe` forwards all `kwargs` to `phi.builder.Builder.Make`, visit its documentation for more info.</span>
<span class="sd">amples**</span>
<span class="sd">from phi import P</span>
<span class="sd">def add1(x): return x + 1</span>
<span class="sd">def mul3(x): return x * 3</span>
<span class="sd">x = P.Pipe(</span>
<span class="sd">    1,     #input</span>
<span class="sd">    add1,  #1 + 1 == 2</span>
<span class="sd">    mul3   #2 * 3 == 6</span>
<span class="sd">)</span>
<span class="sd">assert x == 6</span>
<span class="sd">previous using [lambdas](https://cgarciae.github.io/phi/lambdas.m.html) to create the functions</span>
<span class="sd">from phi import P</span>
<span class="sd">x = P.Pipe(</span>
<span class="sd">    1,      #input</span>
<span class="sd">    P + 1,  #1 + 1 == 2</span>
<span class="sd">    P * 3   #2 * 3 == 6</span>
<span class="sd">)</span>
<span class="sd">assert x == 6</span>
<span class="sd">so see**</span>
<span class="sd">hi.builder.Builder.Make`</span>
<span class="sd">hi.builder.Builder.Run`</span>
<span class="sd">sl](https://cgarciae.github.io/phi/dsl.m.html)</span>
<span class="sd">ompile](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile)</span>
<span class="sd">ambdas](https://cgarciae.github.io/phi/lambdas.m.html)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Make</span><span class="p">(</span><span class="o">*</span><span class="n">code</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)(</span><span class="n">x</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Register0">
    <p>def <span class="ident">Register0</span>(</p><p>cls, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True, _return_type=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Register0', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Register0" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">Register0</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">register_decorator</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="n">cls</span><span class="o">.</span><span class="n">RegisterFunction0</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="n">alias</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="n">original_name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">doc</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">method_type</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="n">explain</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="n">_return_type</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fn</span>
    <span class="k">return</span> <span class="n">register_decorator</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Register1">
    <p>def <span class="ident">Register1</span>(</p><p>cls, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True, _return_type=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Register1', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Register1" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">Register1</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">register_decorator</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="n">_wrapped</span> <span class="o">=</span> <span class="n">wrapped</span> <span class="k">if</span> <span class="n">wrapped</span> <span class="k">else</span> <span class="n">fn</span>
        <span class="n">cls</span><span class="o">.</span><span class="n">RegisterFunction1</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="n">alias</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="n">original_name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">doc</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">_wrapped</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">method_type</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="n">explain</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="n">_return_type</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fn</span>
    <span class="k">return</span> <span class="n">register_decorator</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Register2">
    <p>def <span class="ident">Register2</span>(</p><p>cls, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True, _return_type=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Register2', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Register2" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">Register2</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">register_decorator</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="n">cls</span><span class="o">.</span><span class="n">RegisterFunction2</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="n">alias</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="n">original_name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">doc</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">method_type</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="n">explain</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="n">_return_type</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fn</span>
    <span class="k">return</span> <span class="n">register_decorator</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Register3">
    <p>def <span class="ident">Register3</span>(</p><p>cls, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True, _return_type=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Register3', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Register3" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">Register3</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">register_decorator</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="n">cls</span><span class="o">.</span><span class="n">RegisterFunction3</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="n">alias</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="n">original_name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">doc</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">method_type</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="n">explain</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="n">_return_type</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fn</span>
    <span class="k">return</span> <span class="n">register_decorator</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Register4">
    <p>def <span class="ident">Register4</span>(</p><p>cls, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True, _return_type=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Register4', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Register4" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">Register4</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">register_decorator</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="n">cls</span><span class="o">.</span><span class="n">RegisterFunction4</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="n">alias</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="n">original_name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">doc</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">method_type</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="n">explain</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="n">_return_type</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fn</span>
    <span class="k">return</span> <span class="n">register_decorator</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Register5">
    <p>def <span class="ident">Register5</span>(</p><p>cls, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True, _return_type=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Register5', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Register5" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">Register5</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">register_decorator</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="n">cls</span><span class="o">.</span><span class="n">RegisterFunction5</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="n">alias</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="n">original_name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">doc</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">method_type</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="n">explain</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="n">_return_type</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fn</span>
    <span class="k">return</span> <span class="n">register_decorator</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction0">
    <p>def <span class="ident">RegisterFunction0</span>(</p><p>cls, fn, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True, _return_type=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction0', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction0" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">RegisterFunction0</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then0</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">explanation</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">ver, a partial with the arguments is returned which expects any argument `x` and complete ignores it, such that</span>
<span class="s2">{3}.{0}(*args, **kwargs)</span>
<span class="s2">quivalent to</span>
<span class="s2">builder.{1}(*args, **kwargs)(x)</span>
<span class="s2">    &quot;&quot;&quot;</span> <span class="o">+</span> <span class="n">explanation</span> <span class="k">if</span> <span class="n">explain</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
    <span class="n">cls</span><span class="o">.</span><span class="n">DoRegisterMethod</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="n">alias</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="n">original_name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">doc</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">method_type</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="n">explain</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction1">
    <p>def <span class="ident">RegisterFunction1</span>(</p><p>cls, fn, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True, _return_type=None)</p>
    </div>
    

    
  
    <div class="desc"><p>This method enables you to register any function <code>fn</code> that takes an object as its first argument as a method of the Builder and Applicative class.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><code>fn</code>: a function that atleast takes an Object as its first argument.</li>
<li><code>library_path</code>: the route of the librar from which this function was taken, used for documentation purposes.</li>
<li><code>alias</code>: allows you to specify the name of the method, it will take the name of the function if its <code>None</code>.</li>
<li><code>doc</code>: the documentation for the method, if <code>None</code> a predefied documentation will be generated based on the documentation of <code>fn</code>.</li>
</ul>
<p><strong>Return</strong></p>
<p><code>None</code></p>
<p><strong>Examples</strong></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction1', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction1" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">RegisterFunction1</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method enables you to register any function `fn` that takes an object as its first argument as a method of the Builder and Applicative class.</span>
<span class="sd">    **Arguments**</span>
<span class="sd">    * `fn`: a function that atleast takes an Object as its first argument.</span>
<span class="sd">    * `library_path`: the route of the librar from which this function was taken, used for documentation purposes.</span>
<span class="sd">    * `alias`: allows you to specify the name of the method, it will take the name of the function if its `None`.</span>
<span class="sd">    * `doc`: the documentation for the method, if `None` a predefied documentation will be generated based on the documentation of `fn`.</span>
<span class="sd">    **Return**</span>
<span class="sd">    `None`</span>
<span class="sd">    **Examples**</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">explanation</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">ver, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</span>
<span class="s2">{3}.{0}(x1, *args, **kwargs)</span>
<span class="s2">quivalent to</span>
<span class="s2">builder.{1}(*args, **kwargs)(x1)</span>
<span class="s2">    &quot;&quot;&quot;</span> <span class="o">+</span> <span class="n">explanation</span>  <span class="k">if</span> <span class="n">explain</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
    <span class="n">cls</span><span class="o">.</span><span class="n">DoRegisterMethod</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="n">alias</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="n">original_name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">doc</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">method_type</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="n">explain</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction2">
    <p>def <span class="ident">RegisterFunction2</span>(</p><p>cls, fn, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True, _return_type=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction2', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction2" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">RegisterFunction2</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then2</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">explanation</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">ver, the 2nd argument is omitted, a partial with the rest of the arguments is returned which expects the 2nd argument such that</span>
<span class="s2">{3}.{0}(x1, x2, *args, **kwargs)</span>
<span class="s2">quivalent to</span>
<span class="s2">builder.{1}(x1, *args, **kwargs)(x2)</span>
<span class="s2">    &quot;&quot;&quot;</span> <span class="o">+</span> <span class="n">explanation</span> <span class="k">if</span> <span class="n">explain</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
    <span class="n">cls</span><span class="o">.</span><span class="n">DoRegisterMethod</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="n">alias</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="n">original_name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">doc</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">method_type</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="n">explain</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction3">
    <p>def <span class="ident">RegisterFunction3</span>(</p><p>cls, fn, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True, _return_type=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction3', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction3" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">RegisterFunction3</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then3</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">explanation</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">ver, the 3rd argument is omitted, a partial with the rest of the arguments is returned which expects the 3rd argument such that</span>
<span class="s2">{3}.{0}(x1, x2, x3, *args, **kwargs)</span>
<span class="s2">quivalent to</span>
<span class="s2">builder.{1}(x1, x2, *args, **kwargs)(x3)</span>
<span class="s2">    &quot;&quot;&quot;</span> <span class="o">+</span> <span class="n">explanation</span> <span class="k">if</span> <span class="n">explain</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
    <span class="n">cls</span><span class="o">.</span><span class="n">DoRegisterMethod</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="n">alias</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="n">original_name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">doc</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">method_type</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="n">explain</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction4">
    <p>def <span class="ident">RegisterFunction4</span>(</p><p>cls, fn, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True, _return_type=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction4', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction4" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">RegisterFunction4</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then4</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">explanation</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">ver, the 4th argument is omitted, a partial with the rest of the arguments is returned which expects the 4th argument such that</span>
<span class="s2">{3}.{0}(x1, x2, x3, x4, *args, **kwargs)</span>
<span class="s2">quivalent to</span>
<span class="s2">builder.{1}(x1, x2, x3, *args, **kwargs)(x4)</span>
<span class="s2">    &quot;&quot;&quot;</span> <span class="o">+</span> <span class="n">explanation</span> <span class="k">if</span> <span class="n">explain</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
    <span class="n">cls</span><span class="o">.</span><span class="n">DoRegisterMethod</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="n">alias</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="n">original_name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">doc</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">method_type</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="n">explain</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction5">
    <p>def <span class="ident">RegisterFunction5</span>(</p><p>cls, fn, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True, _return_type=None)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction5', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterFunction5" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">RegisterFunction5</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then5</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="n">explanation</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">ver, the 5th argument is omitted, a partial with the rest of the arguments is returned which expects the 5th argument such that</span>
<span class="s2">{3}.{0}(x1, x2, x3, x4, x5, *args, **kwargs)</span>
<span class="s2">quivalent to</span>
<span class="s2">builder.{1}(x1, x2, x3, x4, *args, **kwargs)(x5)</span>
<span class="s2">    &quot;&quot;&quot;</span> <span class="o">+</span> <span class="n">explanation</span> <span class="k">if</span> <span class="n">explain</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
    <span class="n">cls</span><span class="o">.</span><span class="n">DoRegisterMethod</span><span class="p">(</span><span class="n">method</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="n">alias</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="n">original_name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">doc</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">method_type</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="n">explain</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="n">_return_type</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.RegisterMethod">
    <p>def <span class="ident">RegisterMethod</span>(</p><p>cls, library_path, alias=None, original_name=None, doc=None, wrapped=None, explanation=&#39;&#39;, method_type=&lt;function identity at 0x7fe86c6f1848&gt;, explain=True)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterMethod', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.RegisterMethod" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">RegisterMethod</span><span class="p">(</span><span class="n">cls</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">utils</span><span class="o">.</span><span class="n">identity</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">register_decorator</span><span class="p">(</span><span class="n">fn</span><span class="p">):</span>
        <span class="n">cls</span><span class="o">.</span><span class="n">DoRegisterMethod</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="n">library_path</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="n">alias</span><span class="p">,</span> <span class="n">original_name</span><span class="o">=</span><span class="n">original_name</span><span class="p">,</span> <span class="n">doc</span><span class="o">=</span><span class="n">doc</span><span class="p">,</span> <span class="n">wrapped</span><span class="o">=</span><span class="n">wrapped</span><span class="p">,</span> <span class="n">explanation</span><span class="o">=</span><span class="n">explanation</span><span class="p">,</span> <span class="n">method_type</span><span class="o">=</span><span class="n">method_type</span><span class="p">,</span> <span class="n">explain</span><span class="o">=</span><span class="n">explain</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fn</span>
    <span class="k">return</span> <span class="n">register_decorator</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Run">
    <p>def <span class="ident">Run</span>(</p><p>self, *code, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p><code>Run(*code, **kwargs)</code> is equivalent to <code>Pipe(None, *code, **kwargs)</code>, that is, it compiles the code and applies in a <code>None</code> value.</p>
<p><strong>Arguments</strong></p>
<ul>
<li>Same as <code>phi.builder.Builder.Make</code>.</li>
</ul>
<p><strong>Examples</strong></p>
<p>You might create code that totally ignores its input argument e.g.</p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span>
    <span class="bp">None</span><span class="p">,</span>
    <span class="nb">dict</span><span class="p">(</span>
        <span class="n">x</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">Val</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
            <span class="n">P</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="p">),</span>
        <span class="n">y</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">Val</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span>
            <span class="n">P</span> <span class="o">*</span> <span class="mi">5</span>
        <span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="k">assert</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span> <span class="o">==</span> <span class="mi">9</span>
<span class="k">assert</span> <span class="n">result</span><span class="o">.</span><span class="n">y</span> <span class="o">==</span> <span class="mi">25</span>
</pre></div>


<p>Here the <code>Val</code> statemente drops the <code>None</code> and introduces its own constants. Given this its more suitable to use <code>Run</code></p>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span>

<span class="n">result</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">Run</span><span class="p">(</span>
    <span class="nb">dict</span><span class="p">(</span>
        <span class="n">x</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">Val</span><span class="p">(</span><span class="mi">10</span><span class="p">),</span>
            <span class="n">P</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="p">),</span>
        <span class="n">y</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">Val</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span>
            <span class="n">P</span> <span class="o">*</span> <span class="mi">5</span>
        <span class="p">)</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="k">assert</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span> <span class="o">==</span> <span class="mi">9</span>
<span class="k">assert</span> <span class="n">result</span><span class="o">.</span><span class="n">y</span> <span class="o">==</span> <span class="mi">25</span>
</pre></div>


<p><strong>Also see</strong></p>
<ul>
<li><code>phi.builder.Builder.Make</code></li>
<li><code>phi.builder.Builder.Pipe</code></li>
<li><a href="https://cgarciae.github.io/phi/dsl.m.html">dsl</a></li>
<li><a href="https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile">Compile</a></li>
</ul></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Run', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Run" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">Run</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">code</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">(*code, **kwargs)` is equivalent to `Pipe(None, *code, **kwargs)`, that is, it compiles the code and applies in a `None` value.</span>
<span class="sd">guments**</span>
<span class="sd">me as `phi.builder.Builder.Make`.</span>
<span class="sd">amples**</span>
<span class="sd">might create code that totally ignores its input argument e.g.</span>
<span class="sd">from phi import P</span>
<span class="sd">result = P.Pipe(</span>
<span class="sd">    None,</span>
<span class="sd">    dict(</span>
<span class="sd">        x = (</span>
<span class="sd">            Val(10),</span>
<span class="sd">            P + 1</span>
<span class="sd">        ),</span>
<span class="sd">        y = (</span>
<span class="sd">            Val(5),</span>
<span class="sd">            P * 5</span>
<span class="sd">        )</span>
<span class="sd">    )</span>
<span class="sd">)</span>
<span class="sd">assert result.x == 9</span>
<span class="sd">assert result.y == 25</span>
<span class="sd"> the `Val` statemente drops the `None` and introduces its own constants. Given this its more suitable to use `Run`</span>
<span class="sd">from phi import P</span>
<span class="sd">result = P.Run(</span>
<span class="sd">    dict(</span>
<span class="sd">        x = (</span>
<span class="sd">            Val(10),</span>
<span class="sd">            P + 1</span>
<span class="sd">        ),</span>
<span class="sd">        y = (</span>
<span class="sd">            Val(5),</span>
<span class="sd">            P * 5</span>
<span class="sd">        )</span>
<span class="sd">    )</span>
<span class="sd">)</span>
<span class="sd">assert result.x == 9</span>
<span class="sd">assert result.y == 25</span>
<span class="sd">so see**</span>
<span class="sd">hi.builder.Builder.Make`</span>
<span class="sd">hi.builder.Builder.Pipe`</span>
<span class="sd">sl](https://cgarciae.github.io/phi/dsl.m.html)</span>
<span class="sd">ompile](https://cgarciae.github.io/phi/dsl.m.html#phi.dsl.Compile)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Pipe</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="o">*</span><span class="n">code</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Then">
    <p>def <span class="ident">Then</span>(</p><p>self, expr, *args, **kwargs)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Then', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Then" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">Then</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ThenAt</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Then0">
    <p>def <span class="ident">Then0</span>(</p><p>self, expr, *args, **kwargs)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Then0', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Then0" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">Then0</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ThenAt</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Then1">
    <p>def <span class="ident">Then1</span>(</p><p>self, expr, *args, **kwargs)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Then1', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Then1" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">Then</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ThenAt</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Then2">
    <p>def <span class="ident">Then2</span>(</p><p>self, expr, arg1, *args, **kwargs)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Then2', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Then2" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">Then2</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">arg1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">args</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ThenAt</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Then3">
    <p>def <span class="ident">Then3</span>(</p><p>self, expr, arg1, arg2, *args, **kwargs)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Then3', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Then3" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">Then3</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">)</span> <span class="o">+</span> <span class="n">args</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ThenAt</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Then4">
    <p>def <span class="ident">Then4</span>(</p><p>self, expr, arg1, arg2, arg3, *args, **kwargs)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Then4', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Then4" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">Then4</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">)</span> <span class="o">+</span> <span class="n">args</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ThenAt</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Then5">
    <p>def <span class="ident">Then5</span>(</p><p>self, expr, arg1, arg2, arg3, arg4, *args, **kwargs)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Then5', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Then5" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">Then5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">,</span> <span class="n">arg4</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">args</span> <span class="o">=</span> <span class="p">(</span><span class="n">arg1</span><span class="p">,</span> <span class="n">arg2</span><span class="p">,</span> <span class="n">arg3</span><span class="p">,</span> <span class="n">arg4</span><span class="p">)</span> <span class="o">+</span> <span class="n">args</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ThenAt</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.ThenAt">
    <p>def <span class="ident">ThenAt</span>(</p><p>self, n, expr, *args, **kwargs)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.ThenAt', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.ThenAt" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">ThenAt</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">expr</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">_return_type</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="k">if</span> <span class="s1">&#39;_return_type&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
        <span class="n">_return_type</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span>
        <span class="k">del</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span>
    <span class="k">def</span> <span class="nf">_lambda</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">new_args</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">n</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">,)</span> <span class="o">+</span> <span class="n">args</span><span class="p">[</span><span class="n">n</span><span class="p">:]</span> <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">args</span>
        <span class="k">return</span> <span class="n">expr</span><span class="p">(</span><span class="o">*</span><span class="n">new_args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__unit__</span><span class="p">(</span><span class="n">_lambda</span><span class="p">,</span> <span class="n">_return_type</span><span class="o">=</span><span class="n">_return_type</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.Val">
    <p>def <span class="ident">Val</span>(</p><p>self, x)</p>
    </div>
    

    
  
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.Val', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.Val" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">Val</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__then__</span><span class="p">(</span><span class="k">lambda</span> <span class="n">z</span><span class="p">:</span> <span class="n">x</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.With">
    <p>def <span class="ident">With</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p><strong>With</strong></p>
<div class="codehilite"><pre><span></span>def With(context_manager, *body):
</pre></div>


<p><strong>Arguments</strong></p>
<ul>
<li><strong>context_manager</strong>: a <a href="https://docs.python.org/2/reference/datamodel.html#context-managers">context manager</a> object or valid expression from the DSL that returns a context manager.</li>
<li><strong>*body</strong>: any valid expression of the DSL to be evaluated inside the context. <code>*body</code> is interpreted as a tuple so all expression contained are composed.</li>
</ul>
<p>As with normal python programs you sometimes might want to create a context for a block of code. You normally give a <a href="https://docs.python.org/2/reference/datamodel.html#context-managers">context manager</a> to the <a href="https://docs.python.org/2/reference/compound_stmts.html#the-with-statement">with</a> statemente, in Phi you use <code>P.With</code> or <code>phi.With</code></p>
<p><strong>Context</strong></p>
<p>Python's <code>with</code> statemente returns a context object through <code>as</code> keyword, in the DSL this object can be obtained using the <code>P.Context</code> method or the <code>phi.Context</code> function.</p>
<h3>Examples</h3>
<div class="codehilite"><pre><span></span><span class="kn">from</span> <span class="nn">phi</span> <span class="kn">import</span> <span class="n">P</span><span class="p">,</span> <span class="n">Obj</span><span class="p">,</span> <span class="n">Context</span><span class="p">,</span> <span class="n">With</span><span class="p">,</span> <span class="n">Pipe</span>

<span class="n">text</span> <span class="o">=</span> <span class="n">Pipe</span><span class="p">(</span>
    <span class="s2">&quot;text.txt&quot;</span><span class="p">,</span>
    <span class="n">With</span><span class="p">(</span> <span class="nb">open</span><span class="p">,</span> <span class="n">Context</span><span class="p">,</span>
        <span class="n">Obj</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>


<p>The previous is equivalent to</p>
<div class="codehilite"><pre><span></span>with open(&quot;text.txt&quot;) as f:
    text = f.read()
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.With', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.With" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span> <span class="nf">With</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">NMake</span><span class="p">(</span><span class="n">dsl</span><span class="o">.</span><span class="n">With</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.apply_regularization">
    <p>def <span class="ident">apply_regularization</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.apply_regularization(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.apply_regularization</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.apply_regularization(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.apply_regularization(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.apply_regularization</strong></p>
<div class="codehilite"><pre><span></span>Returns the summed penalty by applying `regularizer` to the `weights_list`.
</pre></div>


<p>Adding a regularization penalty over the layer weights and embedding weights
can help prevent overfitting the training data. Regularization over layer
biases is less common/useful, but assuming proper data preprocessing/mean
subtraction, it usually shouldn't hurt much either.</p>
<p>Args:
  regularizer: A function that takes a single <code>Tensor</code> argument and returns
    a scalar <code>Tensor</code> output.
  weights_list: List of weights <code>Tensors</code> or <code>Variables</code> to apply
    <code>regularizer</code> over. Defaults to the <code>GraphKeys.WEIGHTS</code> collection if
    <code>None</code>.</p>
<p>Returns:
  A scalar representing the overall regularization penalty.</p>
<p>Raises:
  ValueError: If <code>regularizer</code> does not return a scalar output, or if we find
      no weights.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.apply_regularization', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.apply_regularization" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.assert_summary_tag_unique">
    <p>def <span class="ident">assert_summary_tag_unique</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.assert_summary_tag_unique(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.assert_summary_tag_unique</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.assert_summary_tag_unique(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.assert_summary_tag_unique(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.assert_summary_tag_unique</strong></p>
<div class="codehilite"><pre><span></span>None
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.assert_summary_tag_unique', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.assert_summary_tag_unique" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.avg_pool2d">
    <p>def <span class="ident">avg_pool2d</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.avg_pool2d(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.avg_pool2d</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.avg_pool2d(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.avg_pool2d(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.avg_pool2d</strong></p>
<div class="codehilite"><pre><span></span>Adds a 2D average pooling op.
</pre></div>


<p>It is assumed that the pooling is done per image but not in batch or channels.</p>
<p>Args:
  inputs: A <code>Tensor</code> of size [batch_size, height, width, channels].
  kernel_size: A list of length 2: [kernel_height, kernel_width] of the
    pooling kernel over which the op is computed. Can be an int if both
    values are the same.
  stride: A list of length 2: [stride_height, stride_width].
    Can be an int if both strides are the same. Note that presently
    both strides must have the same value.
  padding: The padding method, either 'VALID' or 'SAME'.
  outputs_collections: The collections to which the outputs are added.
  scope: Optional scope for name_scope.</p>
<p>Returns:
  A <code>Tensor</code> representing the results of the pooling operation.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.avg_pool2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.avg_pool2d" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.batch_norm">
    <p>def <span class="ident">batch_norm</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.batch_norm(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.batch_norm</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.batch_norm(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.batch_norm(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.batch_norm</strong></p>
<div class="codehilite"><pre><span></span>Adds a Batch Normalization layer from http://arxiv.org/abs/1502.03167.
</pre></div>


<p>"Batch Normalization: Accelerating Deep Network Training by Reducing
  Internal Covariate Shift"</p>
<p>Sergey Ioffe, Christian Szegedy</p>
<p>Can be used as a normalizer function for conv2d and fully_connected.</p>
<p>Note: When is_training is True the moving_mean and moving_variance need to be
updated, by default the update_ops are placed in tf.GraphKeys.UPDATE_OPS so
they need to be added as a dependency to the train_op, example:</p>
<p>update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)
  if update_ops:
    updates = tf.group(*update_ops)
    total_loss = control_flow_ops.with_dependencies([updates], total_loss)</p>
<p>One can set update_collections=None to force the updates in place, but that
can have speed penalty, specially in distributed settings.</p>
<p>Args:
  inputs: a tensor with 2 or more dimensions, where the first dimension has
    <code>batch_size</code>. The normalization is over all but the last dimension.
  decay: decay for the moving average.
  center: If True, subtract <code>beta</code>. If False, <code>beta</code> is ignored.
  scale: If True, multiply by <code>gamma</code>. If False, <code>gamma</code> is
    not used. When the next layer is linear (also e.g. <code>nn.relu</code>), this can be
    disabled since the scaling can be done by the next layer.
  epsilon: small float added to variance to avoid dividing by zero.
  activation_fn: activation function, default set to None to skip it and
    maintain a linear activation.
  updates_collections: collections to collect the update ops for computation.
    The updates_ops need to be excuted with the train_op.
    If None, a control dependency would be added to make sure the updates are
    computed in place.
  is_training: whether or not the layer is in training mode. In training mode
    it would accumulate the statistics of the moments into <code>moving_mean</code> and
    <code>moving_variance</code> using an exponential moving average with the given
    <code>decay</code>. When it is not in training mode then it would use the values of
    the <code>moving_mean</code> and the <code>moving_variance</code>.
  reuse: whether or not the layer and its variables should be reused. To be
    able to reuse the layer scope must be given.
  variables_collections: optional collections for the variables.
  outputs_collections: collections to add the outputs.
  trainable: If <code>True</code> also add variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  scope: Optional scope for <code>variable_scope</code>.</p>
<p>Returns:
  A <code>Tensor</code> representing the output of the operation.</p>
<p>Raises:
  ValueError: if rank or last dimension of <code>inputs</code> is undefined.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.batch_norm', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.batch_norm" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.bias_add">
    <p>def <span class="ident">bias_add</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.bias_add(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.bias_add</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.bias_add(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.bias_add(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.bias_add</strong></p>
<div class="codehilite"><pre><span></span>Adds a bias to the inputs.
</pre></div>


<p>Can be used as a normalizer function for conv2d and fully_connected.</p>
<p>Args:
  inputs: a tensor of with at least rank 2 and value for the last dimension,
    e.g. <code>[batch_size, depth]</code>, <code>[None, None, None, depth]</code>.
  activation_fn: activation function, default set to None to skip it and
    maintain a linear activation.
  initializer: An initializer for the bias, defaults to 0.
  regularizer: A regularizer like the result of
    <code>l1_regularizer</code> or <code>l2_regularizer</code>.
  reuse: whether or not the layer and its variables should be reused. To be
    able to reuse the layer scope must be given.
  variables_collections: optional collections for the variables.
  outputs_collections: collections to add the outputs.
  trainable: If <code>True</code> also add variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  scope: Optional scope for variable_scope.</p>
<p>Returns:
  a tensor representing the result of adding biases to the inputs.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.bias_add', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.bias_add" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.binary_svm_target">
    <p>def <span class="ident">binary_svm_target</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.binary_svm_target(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.binary_svm_target</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.binary_svm_target(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.binary_svm_target(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.binary_svm_target</strong></p>
<div class="codehilite"><pre><span></span>Creates a _TargetColumn for binary classification with SVMs.
</pre></div>


<p>The target column uses binary hinge loss.</p>
<p>Args:
  label_name: String, name of the key in label dict. Can be null if label
    is a tensor (single headed models).
  weight_column_name: A string defining feature column name representing
    weights. It is used to down weight or boost examples during training. It
    will be multiplied by the loss of the example.</p>
<p>Returns:
  An instance of _TargetColumn.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.binary_svm_target', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.binary_svm_target" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.bucketize">
    <p>def <span class="ident">bucketize</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.bucketize(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.bucketize</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.bucketize(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.bucketize(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.bucketize</strong></p>
<div class="codehilite"><pre><span></span>Bucketizes input_tensor by given boundaries.
</pre></div>


<p>See bucketize_op.cc for more details.</p>
<p>Args:
  input_tensor: A <code>Tensor</code> which will be bucketize.
  boundaries: A list of floats gives the boundaries. It has to be sorted.
  name: A name prefix for the returned tensors (optional).</p>
<p>Returns:
  A <code>Tensor</code> with type int32 which indicates the corresponding bucket for
    each value in <code>input_tensor</code>.</p>
<p>Raises:
  TypeError: If boundaries is not a list.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.bucketize', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.bucketize" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.bucketized_column">
    <p>def <span class="ident">bucketized_column</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.bucketized_column(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.bucketized_column</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.bucketized_column(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.bucketized_column(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.bucketized_column</strong></p>
<div class="codehilite"><pre><span></span>Creates a _BucketizedColumn.
</pre></div>


<p>Args:
  source_column: A _RealValuedColumn defining dense column.
  boundaries: A list of floats specifying the boundaries. It has to be sorted.</p>
<p>Returns:
  A _BucketizedColumn.</p>
<p>Raises:
  ValueError: if 'boundaries' is empty or not sorted.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.bucketized_column', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.bucketized_column" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.check_feature_columns">
    <p>def <span class="ident">check_feature_columns</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.check_feature_columns(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.check_feature_columns</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.check_feature_columns(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.check_feature_columns(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.check_feature_columns</strong></p>
<div class="codehilite"><pre><span></span>Checks the validity of the set of FeatureColumns.
</pre></div>


<p>Args:
  feature_columns: A set of instances or subclasses of FeatureColumn.</p>
<p>Raises:
  ValueError: If there are duplicate feature column keys.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.check_feature_columns', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.check_feature_columns" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.convolution2d">
    <p>def <span class="ident">convolution2d</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.convolution2d(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.convolution2d</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.convolution2d(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.convolution2d(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.convolution2d</strong></p>
<div class="codehilite"><pre><span></span>Adds a 2D convolution followed by an optional batch_norm layer.
</pre></div>


<p><code>convolution2d</code> creates a variable called <code>weights</code>, representing the
convolutional kernel, that is convolved with the <code>inputs</code> to produce a
<code>Tensor</code> of activations. If a <code>normalizer_fn</code> is provided (such as
<code>batch_norm</code>), it is then applied. Otherwise, if <code>normalizer_fn</code> is
None and a <code>biases_initializer</code> is provided then a <code>biases</code> variable would be
created and added the activations. Finally, if <code>activation_fn</code> is not <code>None</code>,
it is applied to the activations as well.</p>
<p>Performs a'trous convolution with input stride equal to rate if rate is
greater than one.</p>
<p>Args:
  inputs: a 4-D tensor  <code>[batch_size, height, width, channels]</code>.
  num_outputs: integer, the number of output filters.
  kernel_size: a list of length 2 <code>[kernel_height, kernel_width]</code> of
    of the filters. Can be an int if both values are the same.
  stride: a list of length 2 <code>[stride_height, stride_width]</code>.
    Can be an int if both strides are the same. Note that presently
    both strides must have the same value.
  padding: one of <code>VALID</code> or <code>SAME</code>.
  rate: integer. If less than or equal to 1, a standard convolution is used.
    If greater than 1, than the a'trous convolution is applied and <code>stride</code>
    must be set to 1.
  activation_fn: activation function, set to None to skip it and maintain
    a linear activation.
  normalizer_fn: normalization function to use instead of <code>biases</code>. If
    <code>normalizer_fn</code> is provided then <code>biases_initializer</code> and
    <code>biases_regularizer</code> are ignored and <code>biases</code> are not created nor added.
    default set to None for no normalizer function
  normalizer_params: normalization function parameters.
  weights_initializer: An initializer for the weights.
  weights_regularizer: Optional regularizer for the weights.
  biases_initializer: An initializer for the biases. If None skip biases.
  biases_regularizer: Optional regularizer for the biases.
  reuse: whether or not the layer and its variables should be reused. To be
    able to reuse the layer scope must be given.
  variables_collections: optional list of collections for all the variables or
    a dictionay containing a different list of collection per variable.
  outputs_collections: collection to add the outputs.
  trainable: If <code>True</code> also add variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  scope: Optional scope for <code>variable_scope</code>.</p>
<p>Returns:
  a tensor representing the output of the operation.</p>
<p>Raises:
  ValueError: if both 'rate' and <code>stride</code> are larger than one.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.convolution2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.convolution2d" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.convolution2d_in_plane">
    <p>def <span class="ident">convolution2d_in_plane</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.convolution2d_in_plane(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.convolution2d_in_plane</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.convolution2d_in_plane(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.convolution2d_in_plane(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.convolution2d_in_plane</strong></p>
<div class="codehilite"><pre><span></span>Performs the same in-plane convolution to each channel independently.
</pre></div>


<p>This is useful for performing various simple channel-independent convolution
operations such as image gradients:</p>
<p>image = tf.constant(..., shape=(16, 240, 320, 3))
  vert_gradients = layers.conv2d_in_plane(image,
                                          kernel=[1, -1],
                                          kernel_size=[2, 1])
  horz_gradients = layers.conv2d_in_plane(image,
                                          kernel=[1, -1],
                                          kernel_size=[1, 2])</p>
<p>Args:
  inputs: a 4-D tensor with dimensions [batch_size, height, width, channels].
  kernel_size: a list of length 2 holding the [kernel_height, kernel_width] of
    of the pooling. Can be an int if both values are the same.
  stride: a list of length 2 <code>[stride_height, stride_width]</code>.
    Can be an int if both strides are the same. Note that presently
    both strides must have the same value.
  padding: the padding type to use, either 'SAME' or 'VALID'.
  activation_fn: activation function, set to None to skip it and maintain
    a linear activation.
  normalizer_fn: normalization function to use instead of <code>biases</code>. If
    <code>normalizer_fn</code> is provided then <code>biases_initializer</code> and
    <code>biases_regularizer</code> are ignored and <code>biases</code> are not created nor added.
    default set to None for no normalizer function
  normalizer_params: normalization function parameters.
  weights_initializer: An initializer for the weights.
  weights_regularizer: Optional regularizer for the weights.
  biases_initializer: An initializer for the biases. If None skip biases.
  biases_regularizer: Optional regularizer for the biases.
  reuse: whether or not the layer and its variables should be reused. To be
    able to reuse the layer scope must be given.
  variables_collections: optional list of collections for all the variables or
    a dictionay containing a different list of collection per variable.
  outputs_collections: collection to add the outputs.
  trainable: If <code>True</code> also add variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  scope: Optional scope for <code>variable_scope</code>.</p>
<p>Returns:
  A <code>Tensor</code> representing the output of the operation.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.convolution2d_in_plane', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.convolution2d_in_plane" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.convolution2d_transpose">
    <p>def <span class="ident">convolution2d_transpose</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.convolution2d_transpose(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.convolution2d_transpose</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.convolution2d_transpose(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.convolution2d_transpose(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.convolution2d_transpose</strong></p>
<div class="codehilite"><pre><span></span>Adds a convolution2d_transpose with an optional batch normalization layer.
</pre></div>


<p>The function creates a variable called <code>weights</code>, representing the
kernel, that is convolved with the input. If <code>batch_norm_params</code> is <code>None</code>, a
second variable called 'biases' is added to the result of the operation.</p>
<p>Args:
  inputs: a tensor of size [batch_size, height, width, channels].
  num_outputs: integer, the number of output filters.
  kernel_size: a list of length 2 holding the [kernel_height, kernel_width] of
    of the filters. Can be an int if both values are the same.
  stride: a list of length 2: [stride_height, stride_width].
    Can be an int if both strides are the same.  Note that presently
    both strides must have the same value.
  padding: one of 'VALID' or 'SAME'.
  activation_fn: activation function, set to None to skip it and maintain
    a linear activation.
  normalizer_fn: normalization function to use instead of <code>biases</code>. If
    <code>normalizer_fn</code> is provided then <code>biases_initializer</code> and
    <code>biases_regularizer</code> are ignored and <code>biases</code> are not created nor added.
    default set to None for no normalizer function
  normalizer_params: normalization function parameters.
  weights_initializer: An initializer for the weights.
  weights_regularizer: Optional regularizer for the weights.
  biases_initializer: An initializer for the biases. If None skip biases.
  biases_regularizer: Optional regularizer for the biases.
  reuse: whether or not the layer and its variables should be reused. To be
    able to reuse the layer scope must be given.
  variables_collections: optional list of collections for all the variables or
    a dictionay containing a different list of collection per variable.
  outputs_collections: collection to add the outputs.
  trainable: whether or not the variables should be trainable or not.
  scope: Optional scope for variable_scope.</p>
<p>Returns:
  a tensor representing the output of the operation.</p>
<p>Raises:
  ValueError: if 'kernel_size' is not a list of length 2.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.convolution2d_transpose', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.convolution2d_transpose" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.create_feature_spec_for_parsing">
    <p>def <span class="ident">create_feature_spec_for_parsing</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.create_feature_spec_for_parsing(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.create_feature_spec_for_parsing</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.create_feature_spec_for_parsing(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.create_feature_spec_for_parsing(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.create_feature_spec_for_parsing</strong></p>
<div class="codehilite"><pre><span></span>Helper that prepares features config from input feature_columns.
</pre></div>


<p>The returned feature config can be used as arg 'features' in tf.parse_example.</p>
<p>Typical usage example:</p>
<p>```python</p>
<h1>Define features and transformations</h1>
<p>country = sparse_column_with_vocabulary_file("country", VOCAB_FILE)
age = real_valued_column("age")
click_bucket = bucketized_column(real_valued_column("historical_click_ratio"),
                                 boundaries=[i/10. for i in range(10)])
country_x_click = crossed_column([country, click_bucket], 10)</p>
<p>feature_columns = set([age, click_bucket, country_x_click])
batch_examples = tf.parse_example(
    serialized_examples,
    create_feature_spec_for_parsing(feature_columns))
```</p>
<p>For the above example, create_feature_spec_for_parsing would return the dict:
{"age": parsing_ops.FixedLenFeature([1], dtype=tf.float32),
 "historical_click_ratio": parsing_ops.FixedLenFeature([1], dtype=tf.float32),
 "country": parsing_ops.VarLenFeature(tf.string)}</p>
<p>Args:
  feature_columns: An iterable containing all the feature columns. All items
    should be instances of classes derived from _FeatureColumn.
Returns:
  A dict mapping feature keys to FixedLenFeature or VarLenFeature values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.create_feature_spec_for_parsing', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.create_feature_spec_for_parsing" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.crossed_column">
    <p>def <span class="ident">crossed_column</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.crossed_column(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.crossed_column</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.crossed_column(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.crossed_column(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.crossed_column</strong></p>
<div class="codehilite"><pre><span></span>Creates a _CrossedColumn.
</pre></div>


<p>Args:
  columns: An iterable of _FeatureColumn. Items can be an instance of
    _SparseColumn, _CrossedColumn, or _BucketizedColumn.
  hash_bucket_size: An int that is &gt; 1. The number of buckets.
  combiner: A combiner string, supports sum, mean, sqrtn.
  ckpt_to_load_from: (Optional). String representing checkpoint name/pattern
    to restore the column weights. Required if <code>tensor_name_in_ckpt</code> is not
    None.
  tensor_name_in_ckpt: (Optional). Name of the <code>Tensor</code> in the provided
    checkpoint from which to restore the column weights. Required if
    <code>ckpt_to_load_from</code> is not None.</p>
<p>Returns:
  A _CrossedColumn.</p>
<p>Raises:
  TypeError: if any item in columns is not an instance of _SparseColumn,
    _CrossedColumn, or _BucketizedColumn, or
    hash_bucket_size is not an int.
  ValueError: if hash_bucket_size is not &gt; 1 or
    len(columns) is not &gt; 1.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.crossed_column', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.crossed_column" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.dropout">
    <p>def <span class="ident">dropout</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.dropout(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.dropout</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.dropout(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.dropout(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.dropout</strong></p>
<div class="codehilite"><pre><span></span>Returns a dropout op applied to the input.
</pre></div>


<p>With probability <code>keep_prob</code>, outputs the input element scaled up by
<code>1 / keep_prob</code>, otherwise outputs <code>0</code>.  The scaling is so that the expected
sum is unchanged.</p>
<p>Args:
  inputs: the tensor to pass to the nn.dropout op.
  keep_prob: A scalar <code>Tensor</code> with the same type as x. The probability
    that each element is kept.
  noise_shape: A 1-D <code>Tensor</code> of type <code>int32</code>, representing the
    shape for randomly generated keep/drop flags.
  is_training: A bool <code>Tensor</code> indicating whether or not the model
    is in training mode. If so, dropout is applied and values scaled.
    Otherwise, inputs is returned.
  outputs_collections: collection to add the outputs.
  scope: Optional scope for name_scope.</p>
<p>Returns:
  a tensor representing the output of the operation.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.dropout', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.dropout" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.embedding_column">
    <p>def <span class="ident">embedding_column</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.embedding_column(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.embedding_column</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.embedding_column(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.embedding_column(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.embedding_column</strong></p>
<div class="codehilite"><pre><span></span>Creates an `_EmbeddingColumn`.
</pre></div>


<p>Args:
  sparse_id_column: A <code>_SparseColumn</code> which is created by for example
    <code>sparse_column_with_*</code> or crossed_column functions. Note that <code>combiner</code>
    defined in <code>sparse_id_column</code> is ignored.
  dimension: An integer specifying dimension of the embedding.
  combiner: A string specifying how to reduce if there are multiple entries
    in a single row. Currently "mean", "sqrtn" and "sum" are supported. Each
    of this can be considered an example level normalization on the column:
      * "sum": do not normalize
      * "mean": do l1 normalization
      * "sqrtn": do l2 normalization
    For more information: <code>tf.embedding_lookup_sparse</code>.
  initializer: A variable initializer function to be used in embedding
    variable initialization. If not specified, defaults to
    <code>tf.truncated_normal_initializer</code> with mean 0.0 and standard deviation
    1/sqrt(sparse_id_column.length).
  ckpt_to_load_from: (Optional). String representing checkpoint name/pattern
    to restore the column weights. Required if <code>tensor_name_in_ckpt</code> is not
    None.
  tensor_name_in_ckpt: (Optional). Name of the <code>Tensor</code> in the provided
    checkpoint from which to restore the column weights. Required if
    <code>ckpt_to_load_from</code> is not None.</p>
<p>Returns:
  An <code>_EmbeddingColumn</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.embedding_column', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.embedding_column" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.flatten">
    <p>def <span class="ident">flatten</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.flatten(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.flatten</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.flatten(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.flatten(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.flatten</strong></p>
<div class="codehilite"><pre><span></span>Flattens the input while maintaining the batch_size.
</pre></div>


<p>Assumes that the first dimension represents the batch.</p>
<p>Args:
  inputs: a tensor of size [batch_size, ...].
  outputs_collections: collection to add the outputs.
  scope: Optional scope for name_scope.</p>
<p>Returns:
  a flattened tensor with shape [batch_size, k].
Raises:
  ValueError: if inputs.shape is wrong.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.flatten', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.flatten" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.fully_connected">
    <p>def <span class="ident">fully_connected</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.fully_connected(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.fully_connected</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.fully_connected(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.fully_connected(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.fully_connected</strong></p>
<div class="codehilite"><pre><span></span>Adds a fully connected layer.
</pre></div>


<p><code>fully_connected</code> creates a variable called <code>weights</code>, representing a fully
connected weight matrix, which is multiplied by the <code>inputs</code> to produce a
<code>Tensor</code> of hidden units. If a <code>normalizer_fn</code> is provided (such as
<code>batch_norm</code>), it is then applied. Otherwise, if <code>normalizer_fn</code> is
None and a <code>biases_initializer</code> is provided then a <code>biases</code> variable would be
created and added the hidden units. Finally, if <code>activation_fn</code> is not <code>None</code>,
it is applied to the hidden units as well.</p>
<p>Note: that if <code>inputs</code> have a rank greater than 2, then <code>inputs</code> is flattened
prior to the initial matrix multiply by <code>weights</code>.</p>
<p>Args:
  inputs: A tensor of with at least rank 2 and value for the last dimension,
    i.e. <code>[batch_size, depth]</code>, <code>[None, None, None, channels]</code>.
  num_outputs: Integer or long, the number of output units in the layer.
  activation_fn: activation function, set to None to skip it and maintain
    a linear activation.
  normalizer_fn: normalization function to use instead of <code>biases</code>. If
    <code>normalizer_fn</code> is provided then <code>biases_initializer</code> and
    <code>biases_regularizer</code> are ignored and <code>biases</code> are not created nor added.
    default set to None for no normalizer function
  normalizer_params: normalization function parameters.
  weights_initializer: An initializer for the weights.
  weights_regularizer: Optional regularizer for the weights.
  biases_initializer: An initializer for the biases. If None skip biases.
  biases_regularizer: Optional regularizer for the biases.
  reuse: whether or not the layer and its variables should be reused. To be
    able to reuse the layer scope must be given.
  variables_collections: Optional list of collections for all the variables or
    a dictionary containing a different list of collections per variable.
  outputs_collections: collection to add the outputs.
  trainable: If <code>True</code> also add variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  scope: Optional scope for variable_scope.</p>
<p>Returns:
   the tensor variable representing the result of the series of operations.</p>
<p>Raises:
  ValueError: if x has rank less than 2 or if its last dimension is not set.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.fully_connected', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.fully_connected" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.get_default_binary_metrics_for_eval">
    <p>def <span class="ident">get_default_binary_metrics_for_eval</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.get_default_binary_metrics_for_eval(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.get_default_binary_metrics_for_eval</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.get_default_binary_metrics_for_eval(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.get_default_binary_metrics_for_eval(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.get_default_binary_metrics_for_eval</strong></p>
<div class="codehilite"><pre><span></span>Returns a dictionary of basic metrics for logistic regression.
</pre></div>


<p>Args:
  thresholds: List of floating point thresholds to use for accuracy,
    precision, and recall metrics. If None, defaults to [0.5].</p>
<p>Returns:
  Dictionary mapping metrics string names to metrics functions.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.get_default_binary_metrics_for_eval', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.get_default_binary_metrics_for_eval" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.hashed_embedding_column">
    <p>def <span class="ident">hashed_embedding_column</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.hashed_embedding_column(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.hashed_embedding_column</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.hashed_embedding_column(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.hashed_embedding_column(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.hashed_embedding_column</strong></p>
<div class="codehilite"><pre><span></span>Creates an embedding column of a sparse feature using parameter hashing.
</pre></div>


<p>The i-th embedding component of a value v is found by retrieving an
embedding weight whose index is a fingerprint of the pair (v,i).</p>
<p>Args:
  column_name: A string defining sparse column name.
  size: An integer specifying the number of parameters in the embedding layer.
  dimension: An integer specifying dimension of the embedding.
  combiner: A string specifying how to reduce if there are multiple entries
    in a single row. Currently "mean", "sqrtn" and "sum" are supported. Each
    of this can be thought as example level normalizations on the column:
      * "sum": do not normalize features in the column
      * "mean": do l1 normalization on features in the column
      * "sqrtn": do l2 normalization on features in the column
    For more information: <code>tf.embedding_lookup_sparse</code>.
  initializer: A variable initializer function to be used in embedding
    variable initialization. If not specified, defaults to
    <code>tf.truncated_normal_initializer</code> with mean 0 and standard deviation 0.1.</p>
<p>Returns:
  A _HashedEmbeddingColumn.</p>
<p>Raises:
  ValueError: if dimension or size is not a positive integer; or if combiner
    is not supported.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.hashed_embedding_column', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.hashed_embedding_column" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.hashed_embedding_lookup">
    <p>def <span class="ident">hashed_embedding_lookup</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.hashed_embedding_lookup(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.hashed_embedding_lookup</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.hashed_embedding_lookup(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.hashed_embedding_lookup(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.hashed_embedding_lookup</strong></p>
<div class="codehilite"><pre><span></span>Looks up embeddings using parameter hashing for each value in `values`.
</pre></div>


<p>The i-th embedding component of a value v in <code>values</code> is found by retrieving
the weight whose index is a fingerprint of the pair (v,i).
The concept is explored as "feature hashing" for model compression in this
paper: http://arxiv.org/pdf/1504.04788.pdf</p>
<p>Feature hashing has the pleasant effect of allowing us to compute an embedding
without needing a pre-determined vocabulary, relieving some amount of process
complexity. It also allows for us to maintain embeddings for possibly
trillions of features with a fixed amount of memory.</p>
<p>Note that this is superior to out-of-vocabulary shared "hash buckets" in that
the embedding is extremely likely to be unique for each token as opposed to
being shared across probably-colliding tokens. The price is that we must
compute a hash once for each scalar in the token's embedding as opposed to
once per token.</p>
<p>If <code>params</code> is a list, it represents a partition of the embedding parameters.
Each tensor in the list should have the same length, except for the first ones
which may have an additional element. For instance 10 parameters can be
partitioned in 4 tensors with length <code>[3, 3, 2, 2]</code>.</p>
<p>Args:
  params: A <code>Tensor</code> or <code>list</code> of <code>Tensors</code>.
    Each tensor must be of rank 1 with fully-defined shape.
  values: <code>Tensor</code> of values to be embedded.
  dimension: Embedding dimension
  name: An optional name for this op.</p>
<p>Returns:
  A tensor with shape [d0, ..., dn, dimension]
    with shape(values) = [d0, ..., dn]</p>
<p>Raises:
  ValueError: if dimension is not positive or the partition size is invalid.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.hashed_embedding_lookup', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.hashed_embedding_lookup" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.hashed_embedding_lookup_sparse">
    <p>def <span class="ident">hashed_embedding_lookup_sparse</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.hashed_embedding_lookup_sparse(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.hashed_embedding_lookup_sparse</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.hashed_embedding_lookup_sparse(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.hashed_embedding_lookup_sparse(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.hashed_embedding_lookup_sparse</strong></p>
<div class="codehilite"><pre><span></span>Looks up embeddings of a sparse feature using parameter hashing.
</pre></div>


<p>See <code>tf.contrib.layers.hashed_embedding_lookup</code> for embedding with hashing.</p>
<p>Args:
  params: A <code>Tensor</code> or <code>list</code> of <code>Tensors</code>.
    Each tensor must be of rank 1 with fully-defined shape.
  sparse_values: A 2-D <code>SparseTensor</code> containing the values to be embedded.
    Some rows may be empty.
  dimension: Embedding dimension
  combiner: A string specifying how to combine embedding results for each
      entry. Currently "mean", "sqrtn" and "sum" are supported, with "mean"
      the default.
  default_value: The value to use for an entry with no features.
  name: An optional name for this op.</p>
<p>Returns:
   Dense tensor with shape [N, dimension] with N the number of rows in
     sparse_values.</p>
<p>Raises:
  TypeError: If sparse_values is not a SparseTensor.
  ValueError: If combiner is not one of {"mean", "sqrtn", "sum"}.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.hashed_embedding_lookup_sparse', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.hashed_embedding_lookup_sparse" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.infer_real_valued_columns">
    <p>def <span class="ident">infer_real_valued_columns</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.infer_real_valued_columns(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.infer_real_valued_columns</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.infer_real_valued_columns(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.infer_real_valued_columns(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.infer_real_valued_columns</strong></p>
<div class="codehilite"><pre><span></span>None
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.infer_real_valued_columns', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.infer_real_valued_columns" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.input_from_feature_columns">
    <p>def <span class="ident">input_from_feature_columns</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.input_from_feature_columns(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.input_from_feature_columns</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.input_from_feature_columns(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.input_from_feature_columns(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.input_from_feature_columns</strong></p>
<div class="codehilite"><pre><span></span>A tf.contrib.layer style input layer builder based on FeatureColumns.
</pre></div>


<p>Generally a single example in training data is described with feature columns.
At the first layer of the model, this column oriented data should be converted
to a single tensor. Each feature column needs a different kind of operation
during this conversion. For example sparse features need a totally different
handling than continuous features.</p>
<p>An example usage of input_from_feature_columns is as follows:</p>
<p># Building model for training
  columns_to_tensor = tf.parse_example(...)
  first_layer = input_from_feature_columns(
      columns_to_tensors=columns_to_tensor,
      feature_columns=feature_columns)
  second_layer = fully_connected(first_layer, ...)
  ...</p>
<p>where feature_columns can be defined as follows:</p>
<p>occupation = sparse_column_with_hash_bucket(column_name="occupation",
                                            hash_bucket_size=1000)
  occupation_emb = embedding_column(sparse_id_column=occupation, dimension=16,
                                   combiner="sum")
  age = real_valued_column("age")
  age_buckets = bucketized_column(
      source_column=age,
      boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])
  occupation_x_age = crossed_column(columns=[occupation, age_buckets],
                                    hash_bucket_size=10000)</p>
<p>feature_columns=[occupation_emb, occupation_x_age]</p>
<p>Args:
  columns_to_tensors: A mapping from feature column to tensors. 'string' key
    means a base feature (not-transformed). It can have FeatureColumn as a
    key too. That means that FeatureColumn is already transformed by input
    pipeline. For example, <code>inflow</code> may have handled transformations.
  feature_columns: A set containing all the feature columns. All items in the
    set should be instances of classes derived by FeatureColumn.
  weight_collections: List of graph collections to which weights are added.
  trainable: If <code>True</code> also add variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  scope: Optional scope for variable_scope.</p>
<p>Returns:
  A Tensor which can be consumed by hidden layers in the neural network.</p>
<p>Raises:
  ValueError: if FeatureColumn cannot be consumed by a neural network.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.input_from_feature_columns', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.input_from_feature_columns" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.is_summary_tag_unique">
    <p>def <span class="ident">is_summary_tag_unique</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.is_summary_tag_unique(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.is_summary_tag_unique</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.is_summary_tag_unique(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.is_summary_tag_unique(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.is_summary_tag_unique</strong></p>
<div class="codehilite"><pre><span></span>Checks if a summary tag is unique.
</pre></div>


<p>Args:
  tag: The tag to use</p>
<p>Returns:
  True if the summary tag is unique.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.is_summary_tag_unique', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.is_summary_tag_unique" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.joint_weighted_sum_from_feature_columns">
    <p>def <span class="ident">joint_weighted_sum_from_feature_columns</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.joint_weighted_sum_from_feature_columns(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.joint_weighted_sum_from_feature_columns</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.joint_weighted_sum_from_feature_columns(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.joint_weighted_sum_from_feature_columns(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.joint_weighted_sum_from_feature_columns</strong></p>
<div class="codehilite"><pre><span></span>A restricted linear prediction builder based on FeatureColumns.
</pre></div>


<p>As long as all feature columns are unweighted sparse columns this computes the
prediction of a linear model which stores all weights in a single variable.</p>
<p>Args:
  columns_to_tensors: A mapping from feature column to tensors. 'string' key
    means a base feature (not-transformed). It can have FeatureColumn as a
    key too. That means that FeatureColumn is already transformed by input
    pipeline. For example, <code>inflow</code> may have handled transformations.
  feature_columns: A set containing all the feature columns. All items in the
    set should be instances of classes derived from FeatureColumn.
  num_outputs: An integer specifying number of outputs. Default value is 1.
  weight_collections: List of graph collections to which weights are added.
  trainable: If <code>True</code> also add variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  scope: Optional scope for variable_scope.</p>
<p>Returns:
  A tuple of followings:
    * A Tensor which represents predictions of a linear model.
    * A list of Variables storing the weights.
    * A Variable which is used for bias.</p>
<p>Raises:
  ValueError: if FeatureColumn cannot be used for linear predictions.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.joint_weighted_sum_from_feature_columns', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.joint_weighted_sum_from_feature_columns" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.l1_l2_regularizer">
    <p>def <span class="ident">l1_l2_regularizer</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.l1_l2_regularizer(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.l1_l2_regularizer</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.l1_l2_regularizer(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.l1_l2_regularizer(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.l1_l2_regularizer</strong></p>
<div class="codehilite"><pre><span></span>Returns a function that can be used to apply L1 L2 regularizations.
</pre></div>


<p>Args:
  scale_l1: A scalar multiplier <code>Tensor</code> for L1 regularization.
  scale_l2: A scalar multiplier <code>Tensor</code> for L2 regularization.
  scope: An optional scope name.</p>
<p>Returns:
  A function with signature <code>l1_l2(weights)</code> that applies a weighted sum of
  L1 L2  regularization.</p>
<p>Raises:
  ValueError: If scale is negative or if scale is not a float.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.l1_l2_regularizer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.l1_l2_regularizer" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.l1_regularizer">
    <p>def <span class="ident">l1_regularizer</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.l1_regularizer(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.l1_regularizer</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.l1_regularizer(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.l1_regularizer(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.l1_regularizer</strong></p>
<div class="codehilite"><pre><span></span>Returns a function that can be used to apply L1 regularization to weights.
</pre></div>


<p>L1 regularization encourages sparsity.</p>
<p>Args:
  scale: A scalar multiplier <code>Tensor</code>. 0.0 disables the regularizer.
  scope: An optional scope name.</p>
<p>Returns:
  A function with signature <code>l1(weights)</code> that apply L1 regularization.</p>
<p>Raises:
  ValueError: If scale is negative or if scale is not a float.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.l1_regularizer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.l1_regularizer" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.l2_regularizer">
    <p>def <span class="ident">l2_regularizer</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.l2_regularizer(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.l2_regularizer</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.l2_regularizer(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.l2_regularizer(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.l2_regularizer</strong></p>
<div class="codehilite"><pre><span></span>Returns a function that can be used to apply L2 regularization to weights.
</pre></div>


<p>Small values of L2 can help prevent overfitting the training data.</p>
<p>Args:
  scale: A scalar multiplier <code>Tensor</code>. 0.0 disables the regularizer.
  scope: An optional scope name.</p>
<p>Returns:
  A function with signature <code>l2(weights)</code> that applies L2 regularization.</p>
<p>Raises:
  ValueError: If scale is negative or if scale is not a float.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.l2_regularizer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.l2_regularizer" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.layer_norm">
    <p>def <span class="ident">layer_norm</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.layer_norm(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.layer_norm</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.layer_norm(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.layer_norm(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.layer_norm</strong></p>
<div class="codehilite"><pre><span></span>Adds a Layer Normalization layer from https://arxiv.org/abs/1607.06450.
</pre></div>


<p>"Layer Normalization"</p>
<p>Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton</p>
<p>Can be used as a normalizer function for conv2d and fully_connected.</p>
<p>Args:
  inputs: a tensor with 2 or more dimensions. The normalization
          occurs over all but the first dimension.
  center: If True, subtract <code>beta</code>. If False, <code>beta</code> is ignored.
  scale: If True, multiply by <code>gamma</code>. If False, <code>gamma</code> is
    not used. When the next layer is linear (also e.g. <code>nn.relu</code>), this can be
    disabled since the scaling can be done by the next layer.
  activation_fn: activation function, default set to None to skip it and
    maintain a linear activation.
  reuse: whether or not the layer and its variables should be reused. To be
    able to reuse the layer scope must be given.
  variables_collections: optional collections for the variables.
  outputs_collections: collections to add the outputs.
  trainable: If <code>True</code> also add variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  scope: Optional scope for <code>variable_op_scope</code>.</p>
<p>Returns:
  A <code>Tensor</code> representing the output of the operation.</p>
<p>Raises:
  ValueError: if rank or last dimension of <code>inputs</code> is undefined.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.layer_norm', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.layer_norm" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.legacy_fully_connected">
    <p>def <span class="ident">legacy_fully_connected</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.legacy_fully_connected(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.legacy_fully_connected</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.legacy_fully_connected(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.legacy_fully_connected(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.legacy_fully_connected</strong></p>
<div class="codehilite"><pre><span></span>Adds the parameters for a fully connected layer and returns the output.
</pre></div>


<p>A fully connected layer is generally defined as a matrix multiply:
<code>y = f(w * x + b)</code> where <code>f</code> is given by <code>activation_fn</code>. If
<code>activation_fn</code> is <code>None</code>, the result of <code>y = w * x + b</code> is
returned.</p>
<p>If <code>x</code> has shape [\(\text{dim}<em>0, \text{dim}_1, ..., \text{dim}_n\)]
with more than 2 dimensions (\(n &gt; 1\)), then we repeat the matrix
multiply along the first dimensions. The result r is a tensor of shape
[\(\text{dim}_0, ..., \text{dim}</em>{n-1},\) <code>num_output_units</code>],
where \( r_{i_0, ..., i_{n-1}, k} =
\sum_{0 \leq j &lt; \text{dim}<em>n} x</em>{i_0, ... i_{n-1}, j} \cdot w_{j, k}\).
This is accomplished by reshaping <code>x</code> to 2-D
[\(\text{dim}<em>0 \cdot ... \cdot \text{dim}</em>{n-1}, \text{dim}<em>n\)]
before the matrix multiply and afterwards reshaping it to
[\(\text{dim}_0, ..., \text{dim}</em>{n-1},\) <code>num_output_units</code>].</p>
<p>This op creates <code>w</code> and optionally <code>b</code>. Bias (<code>b</code>) can be disabled by setting
<code>bias_init</code> to <code>None</code>.</p>
<p>The variable creation is compatible with <code>tf.variable_scope</code> and so can be
reused with <code>tf.variable_scope</code> or <code>tf.make_template</code>.</p>
<p>Most of the details of variable creation can be controlled by specifying the
initializers (<code>weight_init</code> and <code>bias_init</code>) and in which collections to place
the created variables (<code>weight_collections</code> and <code>bias_collections</code>; note that
the variables are always added to the <code>VARIABLES</code> collection). The output of
the layer can be placed in custom collections using <code>output_collections</code>.
The collections arguments default to <code>WEIGHTS</code>, <code>BIASES</code> and <code>ACTIVATIONS</code>,
respectively.</p>
<p>A per layer regularization can be specified by setting <code>weight_regularizer</code>
and <code>bias_regularizer</code>, which are applied to the weights and biases
respectively, and whose output is added to the <code>REGULARIZATION_LOSSES</code>
collection.</p>
<p>Args:
  x: The input <code>Tensor</code>.
  num_output_units: The size of the output.
  activation_fn: activation function, default set to None to skip it and
    maintain a linear activation.
  weight_init: An optional weight initialization, defaults to
    <code>xavier_initializer</code>.
  bias_init: An initializer for the bias, defaults to 0. Set to <code>None</code> in
    order to disable bias.
  name: The name for this operation is used to name operations and to find
    variables. If specified it must be unique for this scope, otherwise a
    unique name starting with "fully_connected" will be created.  See
    <code>tf.variable_scope</code> for details.
  weight_collections: List of graph collections to which weights are added.
  bias_collections: List of graph collections to which biases are added.
  output_collections: List of graph collections to which outputs are added.
  trainable: If <code>True</code> also add variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  weight_regularizer: A regularizer like the result of
    <code>l1_regularizer</code> or <code>l2_regularizer</code>. Used for weights.
  bias_regularizer: A regularizer like the result of
    <code>l1_regularizer</code> or <code>l2_regularizer</code>. Used for biases.</p>
<p>Returns:
  The output of the fully connected layer.</p>
<p>Raises:
  ValueError: if x has rank less than 2 or if its last dimension is not set.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.legacy_fully_connected', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.legacy_fully_connected" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.make_all">
    <p>def <span class="ident">make_all</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.make_all(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.make_all</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.make_all(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.make_all(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.make_all</strong></p>
<div class="codehilite"><pre><span></span>Generates `__all__` from the docstring of one or more modules.
</pre></div>


<p>Usage: <code>make_all(__name__)</code> or
<code>make_all(__name__, [sys.modules(__name__), other_module])</code>. The doc string
modules must each a docstring, and <code>__all__</code> will contain all symbols with
<code>@@</code> references, where that symbol currently exists in the module named
<code>module_name</code>.</p>
<p>Args:
  module_name: The name of the module (usually <code>__name__</code>).
  doc_string_modules: a list of modules from which to take docstring.
  If None, then a list containing only the module named <code>module_name</code> is used.</p>
<p>Returns:
  A list suitable for use as <code>__all__</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.make_all', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.make_all" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.make_place_holder_tensors_for_base_features">
    <p>def <span class="ident">make_place_holder_tensors_for_base_features</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.make_place_holder_tensors_for_base_features(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.make_place_holder_tensors_for_base_features</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.make_place_holder_tensors_for_base_features(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.make_place_holder_tensors_for_base_features(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.make_place_holder_tensors_for_base_features</strong></p>
<div class="codehilite"><pre><span></span>Returns placeholder tensors for inference.
</pre></div>


<p>Args:
  feature_columns: An iterable containing all the feature columns. All items
    should be instances of classes derived from _FeatureColumn.
Returns:
  A dict mapping feature keys to SparseTensors (sparse columns) or
  placeholder Tensors (dense columns).</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.make_place_holder_tensors_for_base_features', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.make_place_holder_tensors_for_base_features" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.max_pool2d">
    <p>def <span class="ident">max_pool2d</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.max_pool2d(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.max_pool2d</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.max_pool2d(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.max_pool2d(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.max_pool2d</strong></p>
<div class="codehilite"><pre><span></span>Adds a 2D Max Pooling op.
</pre></div>


<p>It is assumed that the pooling is done per image but not in batch or channels.</p>
<p>Args:
  inputs: A <code>Tensor</code> of size [batch_size, height, width, channels].
  kernel_size: A list of length 2: [kernel_height, kernel_width] of the
    pooling kernel over which the op is computed. Can be an int if both
    values are the same.
  stride: A list of length 2: [stride_height, stride_width].
    Can be an int if both strides are the same. Note that presently
    both strides must have the same value.
  padding: The padding method, either 'VALID' or 'SAME'.
  outputs_collections: The collections to which the outputs are added.
  scope: Optional scope for name_scope.</p>
<p>Returns:
  A <code>Tensor</code> representing the results of the pooling operation.</p>
<p>Raises:
  ValueError: If 'kernel_size' is not a 2-D list</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.max_pool2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.max_pool2d" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.multi_class_target">
    <p>def <span class="ident">multi_class_target</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.multi_class_target(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.multi_class_target</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.multi_class_target(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.multi_class_target(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.multi_class_target</strong></p>
<div class="codehilite"><pre><span></span>Creates a _TargetColumn for multi class single label classification.
</pre></div>


<p>The target column uses softmax cross entropy loss.</p>
<p>Args:
  n_classes: Integer, number of classes, must be &gt;= 2
  label_name: String, name of the key in label dict. Can be null if label
      is a tensor (single headed models).
  weight_column_name: A string defining feature column name representing
    weights. It is used to down weight or boost examples during training. It
    will be multiplied by the loss of the example.</p>
<p>Returns:
  An instance of _MultiClassTargetColumn.</p>
<p>Raises:
  ValueError: if n_classes is &lt; 2</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.multi_class_target', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.multi_class_target" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.one_hot_column">
    <p>def <span class="ident">one_hot_column</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.one_hot_column(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.one_hot_column</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.one_hot_column(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.one_hot_column(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.one_hot_column</strong></p>
<div class="codehilite"><pre><span></span>Creates a _OneHotColumn.
</pre></div>


<p>Args:
    sparse_id_column: A _SparseColumn which is created by
      <code>sparse_column_with_*</code>
      or crossed_column functions. Note that <code>combiner</code> defined in
      <code>sparse_id_column</code> is ignored.</p>
<p>Returns:
  An _OneHotColumn.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.one_hot_column', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.one_hot_column" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.one_hot_encoding">
    <p>def <span class="ident">one_hot_encoding</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.one_hot_encoding(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.one_hot_encoding</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.one_hot_encoding(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.one_hot_encoding(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.one_hot_encoding</strong></p>
<div class="codehilite"><pre><span></span>Transform numeric labels into onehot_labels using tf.one_hot.
</pre></div>


<p>Args:
  labels: [batch_size] target labels.
  num_classes: total number of classes.
  on_value: A scalar defining the on-value.
  off_value: A scalar defining the off-value.
  outputs_collections: collection to add the outputs.
  scope: Optional scope for name_scope.</p>
<p>Returns:
  one hot encoding of the labels.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.one_hot_encoding', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.one_hot_encoding" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.optimize_loss">
    <p>def <span class="ident">optimize_loss</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.optimize_loss(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.optimize_loss</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.optimize_loss(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.optimize_loss(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.optimize_loss</strong></p>
<div class="codehilite"><pre><span></span>Given loss and parameters for optimizer, returns a training op.
</pre></div>


<p>Various ways of passing optimizers, include:
  - string, name of the optimizer like 'SGD', 'Adam', see OPTIMIZER_CLS_NAMES
      for full list. E.g. <code>optimize_loss(..., optimizer='Adam')</code>.
  - function, takes learning rate <code>Tensor</code> as argument and must return
      <code>Optimizer</code> instance. E.g. <code>optimize_loss(...,
      optimizer=lambda lr: tf.train.MomentumOptimizer(lr, momentum=0.5))</code>.
    Alternatively, if <code>learning_rate</code> is <code>None</code>, the function takes no
    arguments. E.g. <code>optimize_loss(..., learning_rate=None,
      optimizer=lambda: tf.train.MomentumOptimizer(0.5, momentum=0.5))</code>.
  - class, subclass of <code>Optimizer</code> that takes only one required argument -
      learning rate, such as AdamOptimizer, AdagradOptimizer.
      E.g. <code>optimize_loss(..., optimizer=tf.train.AdagradOptimizer)</code>.
  - object, instance of subclass of <code>Optimizer</code>.
      E.g., <code>optimizer_loss(..., optimizer=tf.train.AdagradOptimizer(0.5))</code>.</p>
<p>Args:
  loss: Tensor, 0 dimensional.
  global_step: Tensor, step counter for each update.
  learning_rate: float or Tensor, magnitude of update per each training step.
  optimizer: string, class or optimizer instance, used as trainer.
             string should be name of optimizer, like 'SGD',
               'Adam', 'Adagrad'. Full list in OPTIMIZER_CLS_NAMES constant.
             class should be sub-class of tf.Optimizer that implements
               <code>compute_gradients</code> and <code>apply_gradients</code> functions.
             optimizer instance should be instantion of <code>tf.Optimizer</code>
               sub-class and have <code>compute_gradients</code> and <code>apply_gradients</code>
               functions.
  gradient_noise_scale: float or None, adds 0-mean normal noise scaled by this
                        value.
  gradient_multipliers: dict of variables or variable names to floats.
                        If present, gradients for specified
                        variables will be multiplied by given constant.
  clip_gradients: float or <code>None</code>, clips gradients by this value.
  learning_rate_decay_fn: function, takes <code>learning_rate</code> and <code>global_step</code>
                          <code>Tensor</code>s, returns <code>Tensor</code>.
                          Can be used to implement any learning rate decay
                          functions.
                          For example: tf.train.exponential_decay.
  update_ops: list of update <code>Operation</code>s to execute at each step. If <code>None</code>,
              uses elements of UPDATE_OPS collection. The order of execution
              between <code>update_ops</code> and <code>loss</code> is non-deterministic.
  variables: list of variables to optimize or
             <code>None</code> to use all trainable variables.
  name: The name for this operation is used to scope operations and summaries.
  summaries: List of internal quantities to visualize on tensorboard. If not
             set only the loss and the learning rate will be reported. The
             complete list is in OPTIMIZER_SUMMARIES.</p>
<p>Returns:
  Training op.</p>
<p>Raises:
  ValueError: if optimizer is wrong type.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.optimize_loss', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.optimize_loss" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.parse_feature_columns_from_examples">
    <p>def <span class="ident">parse_feature_columns_from_examples</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.parse_feature_columns_from_examples(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.parse_feature_columns_from_examples</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.parse_feature_columns_from_examples(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.parse_feature_columns_from_examples(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.parse_feature_columns_from_examples</strong></p>
<div class="codehilite"><pre><span></span>Parses tf.Examples to extract tensors for given feature_columns.
</pre></div>


<p>This is a wrapper of 'tf.parse_example'. A typical usage is as follows:</p>
<p>```python
columns_to_tensor = parse_feature_columns_from_examples(
    serialized=my_data,
    feature_columns=my_features)</p>
<h1>Where my_features are:</h1>
<h1>Define features and transformations</h1>
<p>country = sparse_column_with_keys(column_name="native_country",
                                  keys=["US", "BRA", ...])
country_emb = embedding_column(sparse_id_column=country, dimension=3,
                               combiner="sum")
occupation = sparse_column_with_hash_bucket(column_name="occupation",
                                            hash_bucket_size=1000)
occupation_emb = embedding_column(sparse_id_column=occupation, dimension=16,
                                 combiner="sum")
occupation_x_country = crossed_column(columns=[occupation, country],
                                      hash_bucket_size=10000)
age = real_valued_column("age")
age_buckets = bucketized_column(
    source_column=age,
    boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])</p>
<p>my_features = [occupation_emb, age_buckets, country_emb]
```</p>
<p>Args:
  serialized: A vector (1-D Tensor) of strings, a batch of binary
    serialized <code>Example</code> protos.
  feature_columns: An iterable containing all the feature columns. All items
    should be instances of classes derived from _FeatureColumn.
  name: A name for this operation (optional).
  example_names: A vector (1-D Tensor) of strings (optional), the names of
    the serialized protos in the batch.</p>
<p>Returns:
  A <code>dict</code> mapping FeatureColumn to <code>Tensor</code> and <code>SparseTensor</code> values.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.parse_feature_columns_from_examples', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.parse_feature_columns_from_examples" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.real_valued_column">
    <p>def <span class="ident">real_valued_column</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.real_valued_column(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.real_valued_column</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.real_valued_column(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.real_valued_column(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.real_valued_column</strong></p>
<div class="codehilite"><pre><span></span>Creates a _RealValuedColumn.
</pre></div>


<p>Args:
  column_name: A string defining real valued column name.
  dimension: An integer specifying dimension of the real valued column.
    The default is 1. The Tensor representing the _RealValuedColumn
    will have the shape of [batch_size, dimension].
  default_value: A single value compatible with dtype or a list of values
    compatible with dtype which the column takes on during tf.Example parsing
    if data is missing. If None, then tf.parse_example will fail if an example
    does not contain this column. If a single value is provided, the same
    value will be applied as the default value for every dimension. If a
    list of values is provided, the length of the list should be equal to the
    value of <code>dimension</code>.
  dtype: defines the type of values. Default value is tf.float32.
  normalizer: If not None, a function that can be used to normalize the value
    of the real valued column after default_value is applied for parsing.
    Normalizer function takes the input tensor as its argument, and returns
    the output tensor. (e.g. lambda x: (x - 3.0) / 4.2).
Returns:
  A _RealValuedColumn.
Raises:
  TypeError: if dimension is not an int
  ValueError: if dimension is not a positive integer
  TypeError: if default_value is a list but its length is not equal to the
    value of <code>dimension</code>.
  TypeError: if default_value is not compatible with dtype.
  ValueError: if dtype is not convertable to tf.float32.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.real_valued_column', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.real_valued_column" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.regression_target">
    <p>def <span class="ident">regression_target</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.regression_target(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.regression_target</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.regression_target(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.regression_target(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.regression_target</strong></p>
<div class="codehilite"><pre><span></span>Creates a _TargetColumn for linear regression.
</pre></div>


<p>Args:
  label_name: String, name of the key in label dict. Can be null if label
      is a tensor (single headed models).
  weight_column_name: A string defining feature column name representing
    weights. It is used to down weight or boost examples during training. It
    will be multiplied by the loss of the example.
  target_dimension: dimension of the target for multilabels.</p>
<p>Returns:
  An instance of _TargetColumn</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.regression_target', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.regression_target" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.repeat">
    <p>def <span class="ident">repeat</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.repeat(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.repeat</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.repeat(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.repeat(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.repeat</strong></p>
<div class="codehilite"><pre><span></span>Applies the same layer with the same arguments repeatedly.
</pre></div>


<p>```python
  y = repeat(x, 3, conv2d, 64, [3, 3], scope='conv1')
  # It is equivalent to:</p>
<p>x = conv2d(x, 64, [3, 3], scope='conv1/conv1_1')
  x = conv2d(x, 64, [3, 3], scope='conv1/conv1_2')
  y = conv2d(x, 64, [3, 3], scope='conv1/conv1_3')
```</p>
<p>If the <code>scope</code> argument is not given in <code>kwargs</code>, it is set to
<code>layer.__name__</code>, or <code>layer.func.__name__</code> (for <code>functools.partial</code>
objects). If neither <code>__name__</code> nor <code>func.__name__</code> is available, the
layers are called with <code>scope='stack'</code>.</p>
<p>Args:
  inputs: A <code>Tensor</code> suitable for layer.
  repetitions: Int, number of repetitions.
  layer: A layer with arguments <code>(inputs, *args, **kwargs)</code>
  <em>args: Extra args for the layer.
  </em>*kwargs: Extra kwargs for the layer.</p>
<p>Returns:
  a tensor result of applying the layer, repetitions times.
Raises:
  ValueError: if the op is unknown or wrong.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.repeat', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.repeat" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.safe_embedding_lookup_sparse">
    <p>def <span class="ident">safe_embedding_lookup_sparse</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.safe_embedding_lookup_sparse(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.safe_embedding_lookup_sparse</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.safe_embedding_lookup_sparse(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.safe_embedding_lookup_sparse(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.safe_embedding_lookup_sparse</strong></p>
<div class="codehilite"><pre><span></span>Lookup embedding results, accounting for invalid IDs and empty features.
</pre></div>


<p>The partitioned embedding in <code>embedding_weights</code> must all be the same shape
except for the first dimension. The first dimension is allowed to vary as the
vocabulary size is not necessarily a multiple of <code>P</code>.</p>
<p>Invalid IDs (&lt; 0) are pruned from input IDs and weights, as well as any IDs
with non-positive weight. For an entry with no features, the embedding vector
for <code>default_id</code> is returned, or the 0-vector if <code>default_id</code> is not supplied.</p>
<p>The ids and weights may be multi-dimensional. Embeddings are always aggregated
along the last dimension.</p>
<p>Args:
  embedding_weights:  A list of <code>P</code> float tensors or values representing
      partitioned embedding tensors.  The total unpartitioned shape should be
      <code>[e_0, e_1, ..., e_m]</code>, where <code>e_0</code> represents the vocab size and
      <code>e_1, ..., e_m</code> are the embedding dimensions.
  sparse_ids: <code>SparseTensor</code> of shape <code>[d_0, d_1, ..., d_n]</code> containing the
      ids. <code>d_0</code> is typically batch size.
  sparse_weights: <code>SparseTensor</code> of same shape as <code>sparse_ids</code>, containing
      float weights corresponding to <code>sparse_ids</code>, or <code>None</code> if all weights
      are be assumed to be 1.0.
  combiner: A string specifying how to combine embedding results for each
      entry. Currently "mean", "sqrtn" and "sum" are supported, with "mean"
      the default.
  default_id: The id to use for an entry with no features.
  name: A name for this operation (optional).
  partition_strategy: A string specifying the partitioning strategy.
      Currently <code>"div"</code> and <code>"mod"</code> are supported. Default is <code>"div"</code>.</p>
<p>Returns:
  Dense tensor of shape <code>[d_0, d_1, ..., d_{n-1}, e_1, ..., e_m]</code>.</p>
<p>Raises:
  ValueError: if <code>embedding_weights</code> is empty.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.safe_embedding_lookup_sparse', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.safe_embedding_lookup_sparse" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.separable_convolution2d">
    <p>def <span class="ident">separable_convolution2d</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.separable_convolution2d(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.separable_convolution2d</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.separable_convolution2d(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.separable_convolution2d(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.separable_convolution2d</strong></p>
<div class="codehilite"><pre><span></span>Adds a depth-separable 2D convolution with optional batch_norm layer.
</pre></div>


<p>This op first performs a depthwise convolution that acts separately on
channels, creating a variable called <code>depthwise_weights</code>. If <code>num_outputs</code>
is not None, it adds a pointwise convolution that mixes channels, creating a
variable called <code>pointwise_weights</code>. Then, if <code>batch_norm_params</code> is None,
it adds bias to the result, creating a variable called 'biases', otherwise
it adds a batch normalization layer. It finally applies an activation function
to produce the end result.</p>
<p>Args:
  inputs: a tensor of size [batch_size, height, width, channels].
  num_outputs: the number of pointwise convolution output filters. If is
    None, then we skip the pointwise convolution stage.
  kernel_size: a list of length 2: [kernel_height, kernel_width] of
    of the filters. Can be an int if both values are the same.
  depth_multiplier: the number of depthwise convolution output channels for
    each input channel. The total number of depthwise convolution output
    channels will be equal to <code>num_filters_in * depth_multiplier</code>.
  stride: a list of length 2: [stride_height, stride_width], specifying the
    depthwise convolution stride. Can be an int if both strides are the same.
  padding: one of 'VALID' or 'SAME'.
  activation_fn: activation function, set to None to skip it and maintain
    a linear activation.
  normalizer_fn: normalization function to use instead of <code>biases</code>. If
    <code>normalizer_fn</code> is provided then <code>biases_initializer</code> and
    <code>biases_regularizer</code> are ignored and <code>biases</code> are not created nor added.
    default set to None for no normalizer function
  normalizer_params: normalization function parameters.
  weights_initializer: An initializer for the weights.
  weights_regularizer: Optional regularizer for the weights.
  biases_initializer: An initializer for the biases. If None skip biases.
  biases_regularizer: Optional regularizer for the biases.
  reuse: whether or not the layer and its variables should be reused. To be
    able to reuse the layer scope must be given.
  variables_collections: optional list of collections for all the variables or
    a dictionay containing a different list of collection per variable.
  outputs_collections: collection to add the outputs.
  trainable: whether or not the variables should be trainable or not.
  scope: Optional scope for variable_scope.</p>
<p>Returns:
  A <code>Tensor</code> representing the output of the operation.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.separable_convolution2d', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.separable_convolution2d" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.shared_embedding_columns">
    <p>def <span class="ident">shared_embedding_columns</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.shared_embedding_columns(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.shared_embedding_columns</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.shared_embedding_columns(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.shared_embedding_columns(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.shared_embedding_columns</strong></p>
<div class="codehilite"><pre><span></span>Creates a list of `_EmbeddingColumn` sharing the same embedding.
</pre></div>


<p>Args:
  sparse_id_columns: An iterable of <code>_SparseColumn</code>, such as those created by
    <code>sparse_column_with_*</code> or crossed_column functions. Note that <code>combiner</code>
    defined in each sparse_id_column is ignored.
  dimension: An integer specifying dimension of the embedding.
  combiner: A string specifying how to reduce if there are multiple entries
    in a single row. Currently "mean", "sqrtn" and "sum" are supported. Each
    of this can be considered an example level normalization on the column:
      * "sum": do not normalize
      * "mean": do l1 normalization
      * "sqrtn": do l2 normalization
    For more information: <code>tf.embedding_lookup_sparse</code>.
  shared_embedding_name: (Optional). A string specifying the name of shared
    embedding weights. This will be needed if you want to reference the shared
    embedding separately from the generated <code>_EmbeddingColumn</code>.
  initializer: A variable initializer function to be used in embedding
    variable initialization. If not specified, defaults to
    <code>tf.truncated_normal_initializer</code> with mean 0.0 and standard deviation
    1/sqrt(sparse_id_columns[0].length).
  ckpt_to_load_from: (Optional). String representing checkpoint name/pattern
    to restore the column weights. Required if <code>tensor_name_in_ckpt</code> is not
    None.
  tensor_name_in_ckpt: (Optional). Name of the <code>Tensor</code> in the provided
    checkpoint from which to restore the column weights. Required if
    <code>ckpt_to_load_from</code> is not None.</p>
<p>Returns:
  A tuple of <code>_EmbeddingColumn</code> with shared embedding space.</p>
<p>Raises:
  ValueError: if sparse_id_columns is empty, or its elements are not
    compatible with each other.
  TypeError: if at least one element of sparse_id_columns is not a
    <code>SparseTensor</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.shared_embedding_columns', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.shared_embedding_columns" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.softmax">
    <p>def <span class="ident">softmax</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.softmax(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.softmax</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.softmax(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.softmax(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.softmax</strong></p>
<div class="codehilite"><pre><span></span>Performs softmax on Nth dimension of N-dimensional logit tensor.
</pre></div>


<p>For two-dimensional logits this reduces to tf.nn.softmax. The N-th dimension
needs to have a specified number of elements (number of classes).</p>
<p>Args:
  logits: N-dimensional <code>Tensor</code> with logits, where N &gt; 1.
  scope: Optional scope for variable_scope.</p>
<p>Returns:
  a <code>Tensor</code> with same shape and type as logits.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.softmax', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.softmax" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.sparse_column_with_hash_bucket">
    <p>def <span class="ident">sparse_column_with_hash_bucket</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.sparse_column_with_hash_bucket(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.sparse_column_with_hash_bucket</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.sparse_column_with_hash_bucket(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.sparse_column_with_hash_bucket(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.sparse_column_with_hash_bucket</strong></p>
<div class="codehilite"><pre><span></span>Creates a _SparseColumn with hashed bucket configuration.
</pre></div>


<p>Use this when your sparse features are in string or integer format, but you
don't have a vocab file that maps each value to an integer ID.
output_id = Hash(input_feature_string) % bucket_size</p>
<p>Args:
  column_name: A string defining sparse column name.
  hash_bucket_size: An int that is &gt; 1. The number of buckets.
  combiner: A string specifying how to reduce if the sparse column is
    multivalent. Currently "mean", "sqrtn" and "sum" are supported, with
    "sum" the default:
      * "sum": do not normalize features in the column
      * "mean": do l1 normalization on features in the column
      * "sqrtn": do l2 normalization on features in the column
    For more information: <code>tf.embedding_lookup_sparse</code>.
  dtype: The type of features. Only string and integer types are supported.</p>
<p>Returns:
  A _SparseColumn with hashed bucket configuration</p>
<p>Raises:
  ValueError: hash_bucket_size is not greater than 2.
  ValueError: dtype is neither string nor integer.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.sparse_column_with_hash_bucket', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.sparse_column_with_hash_bucket" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.sparse_column_with_integerized_feature">
    <p>def <span class="ident">sparse_column_with_integerized_feature</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.sparse_column_with_integerized_feature(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.sparse_column_with_integerized_feature</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.sparse_column_with_integerized_feature(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.sparse_column_with_integerized_feature(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.sparse_column_with_integerized_feature</strong></p>
<div class="codehilite"><pre><span></span>Creates an integerized _SparseColumn.
</pre></div>


<p>Use this when your features are already pre-integerized into int64 IDs.
output_id = input_feature</p>
<p>Args:
  column_name: A string defining sparse column name.
  bucket_size: An int that is &gt; 1. The number of buckets. It should be bigger
    than maximum feature. In other words features in this column should be an
    int64 in range [0, bucket_size)
  combiner: A string specifying how to reduce if the sparse column is
    multivalent. Currently "mean", "sqrtn" and "sum" are supported, with
    "sum" the default:
      * "sum": do not normalize features in the column
      * "mean": do l1 normalization on features in the column
      * "sqrtn": do l2 normalization on features in the column
    For more information: <code>tf.embedding_lookup_sparse</code>.
  dtype: Type of features. It should be an integer type. Default value is
    dtypes.int64.</p>
<p>Returns:
  An integerized _SparseColumn definition.</p>
<p>Raises:
  ValueError: bucket_size is not greater than 1.
  ValueError: dtype is not integer.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.sparse_column_with_integerized_feature', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.sparse_column_with_integerized_feature" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.sparse_column_with_keys">
    <p>def <span class="ident">sparse_column_with_keys</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.sparse_column_with_keys(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.sparse_column_with_keys</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.sparse_column_with_keys(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.sparse_column_with_keys(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.sparse_column_with_keys</strong></p>
<div class="codehilite"><pre><span></span>Creates a _SparseColumn with keys.
</pre></div>


<p>Look up logic is as follows:
lookup_id = index_of_feature_in_keys if feature in keys else default_value</p>
<p>Args:
  column_name: A string defining sparse column name.
  keys: a string list defining vocabulary.
  default_value: The value to use for out-of-vocabulary feature values.
    Default is -1.
  combiner: A string specifying how to reduce if the sparse column is
    multivalent. Currently "mean", "sqrtn" and "sum" are supported, with
    "sum" the default:
      * "sum": do not normalize features in the column
      * "mean": do l1 normalization on features in the column
      * "sqrtn": do l2 normalization on features in the column
    For more information: <code>tf.embedding_lookup_sparse</code>.</p>
<p>Returns:
  A _SparseColumnKeys with keys configuration.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.sparse_column_with_keys', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.sparse_column_with_keys" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.sparse_feature_cross">
    <p>def <span class="ident">sparse_feature_cross</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.sparse_feature_cross(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.sparse_feature_cross</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.sparse_feature_cross(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.sparse_feature_cross(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.sparse_feature_cross</strong></p>
<div class="codehilite"><pre><span></span>Crosses a list of Tensor or SparseTensor objects.
</pre></div>


<p>See sparse_feature_cross_kernel.cc for more details.</p>
<p>Args:
  inputs: List of <code>SparseTensor</code> or <code>Tensor</code> to be crossed.
  hashed_output: If true, returns the hash of the cross instead of the string.
    This will allow us avoiding string manipulations.
  num_buckets: It is used if hashed_output is true.
    output = hashed_value%num_buckets if num_buckets &gt; 0 else hashed_value.
  name: A name prefix for the returned tensors (optional).</p>
<p>Returns:
  A <code>SparseTensor</code> with the crossed features.
  Return type is string if hashed_output=False, int64 otherwise.</p>
<p>Raises:
  TypeError: If the inputs aren't either SparseTensor or Tensor.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.sparse_feature_cross', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.sparse_feature_cross" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.stack">
    <p>def <span class="ident">stack</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.stack(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.stack</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.stack(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.stack(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.stack</strong></p>
<div class="codehilite"><pre><span></span>Builds a stack of layers by applying layer repeatedly using stack_args.
</pre></div>


<p><code>stack</code> allows you to repeatedly apply the same operation with different
arguments <code>stack_args[i]</code>. For each application of the layer, <code>stack</code> creates
a new scope appended with an increasing number. For example:</p>
<p>```python
  y = stack(x, fully_connected, [32, 64, 128], scope='fc')
  # It is equivalent to:</p>
<p>x = fully_connected(x, 32, scope='fc/fc_1')
  x = fully_connected(x, 64, scope='fc/fc_2')
  y = fully_connected(x, 128, scope='fc/fc_3')
```</p>
<p>If the <code>scope</code> argument is not given in <code>kwargs</code>, it is set to
<code>layer.__name__</code>, or <code>layer.func.__name__</code> (for <code>functools.partial</code>
objects). If neither <code>__name__</code> nor <code>func.__name__</code> is available, the
layers are called with <code>scope='stack'</code>.</p>
<p>Args:
  inputs: A <code>Tensor</code> suitable for layer.
  layer: A layer with arguments <code>(inputs, *args, **kwargs)</code>
  stack_args: A list/tuple of parameters for each call of layer.
  **kwargs: Extra kwargs for the layer.</p>
<p>Returns:
  a <code>Tensor</code> result of applying the stacked layers.</p>
<p>Raises:
  ValueError: if the op is unknown or wrong.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.stack', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.stack" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.sum_regularizer">
    <p>def <span class="ident">sum_regularizer</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.sum_regularizer(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.sum_regularizer</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.sum_regularizer(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.sum_regularizer(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.sum_regularizer</strong></p>
<div class="codehilite"><pre><span></span>Returns a function that applies the sum of multiple regularizers.
</pre></div>


<p>Args:
  regularizer_list: A list of regularizers to apply.
  scope: An optional scope name</p>
<p>Returns:
  A function with signature <code>sum_reg(weights)</code> that applies the
  sum of all the input regularizers.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.sum_regularizer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.sum_regularizer" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.summarize_activation">
    <p>def <span class="ident">summarize_activation</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.summarize_activation(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.summarize_activation</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.summarize_activation(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.summarize_activation(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.summarize_activation</strong></p>
<div class="codehilite"><pre><span></span>Summarize an activation.
</pre></div>


<p>This applies the given activation and adds useful summaries specific to the
activation.</p>
<p>Args:
  op: The tensor to summarize (assumed to be a layer activation).
Returns:
  The summary op created to summarize <code>op</code>.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.summarize_activation', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.summarize_activation" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.summarize_activations">
    <p>def <span class="ident">summarize_activations</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.summarize_activations(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.summarize_activations</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.summarize_activations(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.summarize_activations(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.summarize_activations</strong></p>
<div class="codehilite"><pre><span></span>Summarize activations, using `summarize_activation` to summarize.
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.summarize_activations', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.summarize_activations" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.summarize_collection">
    <p>def <span class="ident">summarize_collection</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.summarize_collection(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.summarize_collection</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.summarize_collection(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.summarize_collection(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.summarize_collection</strong></p>
<div class="codehilite"><pre><span></span>Summarize a graph collection of tensors, possibly filtered by name.
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.summarize_collection', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.summarize_collection" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.summarize_tensor">
    <p>def <span class="ident">summarize_tensor</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.summarize_tensor(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.summarize_tensor</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.summarize_tensor(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.summarize_tensor(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.summarize_tensor</strong></p>
<div class="codehilite"><pre><span></span>Summarize a tensor using a suitable summary type.
</pre></div>


<p>This function adds a summary op for <code>tensor</code>. The type of summary depends on
the shape of <code>tensor</code>. For scalars, a <code>scalar_summary</code> is created, for all
other tensors, <code>histogram_summary</code> is used.</p>
<p>Args:
  tensor: The tensor to summarize
  tag: The tag to use, if None then use tensor's op's name.</p>
<p>Returns:
  The summary op created or None for string tensors.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.summarize_tensor', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.summarize_tensor" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.summarize_tensors">
    <p>def <span class="ident">summarize_tensors</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.summarize_tensors(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.summarize_tensors</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.summarize_tensors(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.summarize_tensors(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.summarize_tensors</strong></p>
<div class="codehilite"><pre><span></span>Summarize a set of tensors.
</pre></div></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.summarize_tensors', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.summarize_tensors" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.unit_norm">
    <p>def <span class="ident">unit_norm</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.unit_norm(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.unit_norm</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.unit_norm(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.unit_norm(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.unit_norm</strong></p>
<div class="codehilite"><pre><span></span>Normalizes the given input across the specified dimension to unit length.
</pre></div>


<p>Note that the rank of <code>input</code> must be known.</p>
<p>Args:
  inputs: A <code>Tensor</code> of arbitrary size.
  dim: The dimension along which the input is normalized.
  epsilon: A small value to add to the inputs to avoid dividing by zero.
  scope: Optional scope for variable_scope.</p>
<p>Returns:
  The normalized <code>Tensor</code>.</p>
<p>Raises:
  ValueError: If dim is smaller than the number of dimensions in 'inputs'.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.unit_norm', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.unit_norm" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.variance_scaling_initializer">
    <p>def <span class="ident">variance_scaling_initializer</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.variance_scaling_initializer(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.variance_scaling_initializer</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.variance_scaling_initializer(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.variance_scaling_initializer(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.variance_scaling_initializer</strong></p>
<div class="codehilite"><pre><span></span>Returns an initializer that generates tensors without scaling variance.
</pre></div>


<p>When initializing a deep network, it is in principle advantageous to keep
the scale of the input variance constant, so it does not explode or diminish
by reaching the final layer. This initializer use the following formula:
  if mode='FAN_IN': # Count only number of input connections.
    n = fan_in
  elif mode='FAN_OUT': # Count only number of output connections.
    n = fan_out
  elif mode='FAN_AVG': # Average number of inputs and output connections.
    n = (fan_in + fan_out)/2.0</p>
<div class="codehilite"><pre><span></span>truncated_normal(shape, 0.0, stddev=sqrt(factor / n))
</pre></div>


<p>To get http://arxiv.org/pdf/1502.01852v1.pdf use (Default):
  - factor=2.0 mode='FAN_IN' uniform=False
To get http://arxiv.org/abs/1408.5093 use:
  - factor=1.0 mode='FAN_IN' uniform=True
To get http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf use:
  - factor=1.0 mode='FAN_AVG' uniform=True.
To get xavier_initializer use either:
  - factor=1.0 mode='FAN_AVG' uniform=True.
  - factor=1.0 mode='FAN_AVG' uniform=False.</p>
<p>Args:
  factor: Float.  A multiplicative factor.
  mode: String.  'FAN_IN', 'FAN_OUT', 'FAN_AVG'.
  uniform: Whether to use uniform or normal distributed random initialization.
  seed: A Python integer. Used to create random seeds. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  dtype: The data type. Only floating point types are supported.</p>
<p>Returns:
  An initializer that generates tensors with unit variance.</p>
<p>Raises:
  ValueError: if <code>dtype</code> is not a floating point type.
  TypeError: if <code>mode</code> is not in ['FAN_IN', 'FAN_OUT', 'FAN_AVG'].</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.variance_scaling_initializer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.variance_scaling_initializer" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.weighted_sparse_column">
    <p>def <span class="ident">weighted_sparse_column</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.weighted_sparse_column(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.weighted_sparse_column</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.weighted_sparse_column(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.weighted_sparse_column(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.weighted_sparse_column</strong></p>
<div class="codehilite"><pre><span></span>Creates a _SparseColumn by combining sparse_id_column with a weight column.
</pre></div>


<p>Args:
  sparse_id_column: A <code>_SparseColumn</code> which is created by
    <code>sparse_column_with_*</code> functions.
  weight_column_name: A string defining a sparse column name which represents
    weight or value of the corresponding sparse id feature.
  dtype: Type of weights, such as <code>tf.float32</code>
Returns:
  A _WeightedSparseColumn composed of two sparse features: one represents id,
  the other represents weight (value) of the id feature in that example.
Raises:
  ValueError: if dtype is not convertible to float.</p>
<p>An example usage:
  <code>python
  words = sparse_column_with_hash_bucket("words", 1000)
  tfidf_weighted_words = weighted_sparse_column(words, "tfidf_score")</code></p>
<p>This configuration assumes that input dictionary of model contains the
  following two items:
    * (key="words", value=word_tensor) where word_tensor is a SparseTensor.
    * (key="tfidf_score", value=tfidf_score_tensor) where tfidf_score_tensor
      is a SparseTensor.
   Following are assumed to be true:
     * word_tensor.indices = tfidf_score_tensor.indices
     * word_tensor.shape = tfidf_score_tensor.shape</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.weighted_sparse_column', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.weighted_sparse_column" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.weighted_sum_from_feature_columns">
    <p>def <span class="ident">weighted_sum_from_feature_columns</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.weighted_sum_from_feature_columns(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.weighted_sum_from_feature_columns</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.weighted_sum_from_feature_columns(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.weighted_sum_from_feature_columns(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.weighted_sum_from_feature_columns</strong></p>
<div class="codehilite"><pre><span></span>A tf.contrib.layer style linear prediction builder based on FeatureColumns.
</pre></div>


<p>Generally a single example in training data is described with feature columns.
This function generates weighted sum for each num_outputs. Weighted sum refers
to logits in classification problems. It refers to prediction itself for
linear regression problems.</p>
<p>An example usage of weighted_sum_from_feature_columns is as follows:</p>
<p># Building model for training
  columns_to_tensor = tf.parse_example(...)
  logits = weighted_sum_from_feature_columns(
      columns_to_tensors=columns_to_tensor,
      feature_columns=feature_columns,
      num_outputs=1)
  loss = tf.nn.sigmoid_cross_entropy_with_logits(logits, labels)</p>
<p>where feature_columns can be defined as follows:</p>
<p>occupation = sparse_column_with_hash_bucket(column_name="occupation",
                                            hash_bucket_size=1000)
  occupation_emb = embedding_column(sparse_id_column=occupation, dimension=16,
                                   combiner="sum")
  age = real_valued_column("age")
  age_buckets = bucketized_column(
      source_column=age,
      boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])
  occupation_x_age = crossed_column(columns=[occupation, age_buckets],
                                    hash_bucket_size=10000)</p>
<p>feature_columns=[occupation_emb, occupation_x_age]</p>
<p>Args:
  columns_to_tensors: A mapping from feature column to tensors. 'string' key
    means a base feature (not-transformed). It can have FeatureColumn as a
    key too. That means that FeatureColumn is already transformed by input
    pipeline. For example, <code>inflow</code> may have handled transformations.
  feature_columns: A set containing all the feature columns. All items in the
    set should be instances of classes derived from FeatureColumn.
  num_outputs: An integer specifying number of outputs. Default value is 1.
  weight_collections: List of graph collections to which weights are added.
  trainable: If <code>True</code> also add variables to the graph collection
    <code>GraphKeys.TRAINABLE_VARIABLES</code> (see tf.Variable).
  scope: Optional scope for variable_scope.</p>
<p>Returns:
  A tuple of followings:
    * A Tensor which represents predictions of a linear model.
    * A dictionary which maps feature_column to corresponding Variable.
    * A Variable which is used for bias.</p>
<p>Raises:
  ValueError: if FeatureColumn cannot be used for linear predictions.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.weighted_sum_from_feature_columns', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.weighted_sum_from_feature_columns" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
            
  <div class="item">
    <div class="name def" id="tensorbuilder.patches.layers_patch.LayerBuilder.xavier_initializer">
    <p>def <span class="ident">xavier_initializer</span>(</p><p>self, *args, **kwargs)</p>
    </div>
    

    
  
    <div class="desc"><p>THIS METHOD IS AUTOMATICALLY GENERATED</p>
<div class="codehilite"><pre><span></span>builder.xavier_initializer(*args, **kwargs)
</pre></div>


<p>It accepts the same arguments as <code>tf.contrib.layers.xavier_initializer</code>. 
However, the 1st argument is omitted, a partial with the rest of the arguments is returned which expects the 1st argument such that</p>
<div class="codehilite"><pre><span></span>tf.contrib.layers.xavier_initializer(x1, *args, **kwargs)
</pre></div>


<p>is equivalent to</p>
<div class="codehilite"><pre><span></span>builder.xavier_initializer(*args, **kwargs)(x1)
</pre></div>


<p><strong>tf.contrib.layers.xavier_initializer</strong></p>
<div class="codehilite"><pre><span></span>Returns an initializer performing &quot;Xavier&quot; initialization for weights.
</pre></div>


<p>This function implements the weight initialization from:</p>
<p>Xavier Glorot and Yoshua Bengio (2010):
         Understanding the difficulty of training deep feedforward neural
         networks. International conference on artificial intelligence and
         statistics.</p>
<p>This initializer is designed to keep the scale of the gradients roughly the
same in all layers. In uniform distribution this ends up being the range:
<code>x = sqrt(6. / (in + out)); [-x, x]</code> and for normal distribution a standard
deviation of <code>sqrt(3. / (in + out))</code> is used.</p>
<p>Args:
  uniform: Whether to use uniform or normal distributed random initialization.
  seed: A Python integer. Used to create random seeds. See
    <a href="../../api_docs/python/constant_op.md#set_random_seed"><code>set_random_seed</code></a>
    for behavior.
  dtype: The data type. Only floating point types are supported.</p>
<p>Returns:
  An initializer for a weight matrix.</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-tensorbuilder.patches.layers_patch.LayerBuilder.xavier_initializer', this);">Show source &equiv;</a></p>
  <div id="source-tensorbuilder.patches.layers_patch.LayerBuilder.xavier_initializer" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@functools.wraps</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;_return_type&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">_return_type</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Then</span><span class="p">(</span><span class="n">fn</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>
  
      </div>
      </div>

  </section>

    </article>
  <div class="clear"> </div>
  <footer id="footer">
    <p>
      Documentation generated by
      <a href="https://github.com/BurntSushi/pdoc">pdoc 0.3.2</a>
    </p>

    <p>pdoc is in the public domain with the
      <a href="http://unlicense.org">UNLICENSE</a></p>

    <p>Design by <a href="http://nadh.in">Kailash Nadh</a></p>
  </footer>
</div>
</body>
</html>
